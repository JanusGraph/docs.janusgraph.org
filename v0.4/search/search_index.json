{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The Benefits of JanusGraph JanusGraph is designed to support the processing of graphs so large that they require storage and computational capacities beyond what a single machine can provide. Scaling graph data processing for real time traversals and analytical queries is JanusGraph\u2019s foundational benefit. This section will discuss the various specific benefits of JanusGraph and its underlying, supported persistence solutions. General JanusGraph Benefits Support for very large graphs. JanusGraph graphs scale with the number of machines in the cluster. Support for very many concurrent transactions and operational graph processing. JanusGraph\u2019s transactional capacity scales with the number of machines in the cluster and answers complex traversal queries on huge graphs in milliseconds. Support for global graph analytics and batch graph processing through the Hadoop framework. Support for geo, numeric range, and full text search for vertices and edges on very large graphs. Native support for the popular property graph data model exposed by Apache TinkerPop . Native support for the graph traversal language Gremlin . Numerous graph-level configurations provide knobs for tuning performance. Vertex-centric indices provide vertex-level querying to alleviate issues with the infamous super node problem . Provides an optimized disk representation to allow for efficient use of storage and speed of access. Open source under the liberal Apache 2 license . Benefits of JanusGraph with Apache Cassandra Continuously available with no single point of failure. No read/write bottlenecks to the graph as there is no master/slave architecture. Elastic scalability allows for the introduction and removal of machines. Caching layer ensures that continuously accessed data is available in memory. Increase the size of the cache by adding more machines to the cluster. Integration with Apache Hadoop . Open source under the liberal Apache 2 license. Benefits of JanusGraph with HBase Tight integration with the Apache Hadoop ecosystem. Native support for strong consistency . Linear scalability with the addition of more machines. Strictly consistent reads and writes. Convenient base classes for backing Hadoop MapReduce jobs with HBase tables. Support for exporting metrics via JMX . Open source under the liberal Apache 2 license. JanusGraph and the CAP Theorem Despite your best efforts, your system will experience enough faults that it will have to make a choice between reducing yield (i.e., stop answering requests) and reducing harvest (i.e., giving answers based on incomplete data). This decision should be based on business requirements. \u2014 Coda Hale When using a database, the CAP theorem should be thoroughly considered (C=Consistency, A=Availability, P=Partitionability). JanusGraph is distributed with 3 supporting backends: Apache Cassandra , Apache HBase , and Oracle Berkeley DB Java Edition . Note that BerkeleyDB JE is a non-distributed database and is typically only used with JanusGraph for testing and exploration purposes. HBase gives preference to consistency at the expense of yield, i.e. the probability of completing a request. Cassandra gives preference to availability at the expense of harvest, i.e. the completeness of the answer to the query (data available/complete data).","title":"Introduction"},{"location":"#the-benefits-of-janusgraph","text":"JanusGraph is designed to support the processing of graphs so large that they require storage and computational capacities beyond what a single machine can provide. Scaling graph data processing for real time traversals and analytical queries is JanusGraph\u2019s foundational benefit. This section will discuss the various specific benefits of JanusGraph and its underlying, supported persistence solutions.","title":"The Benefits of JanusGraph"},{"location":"#general-janusgraph-benefits","text":"Support for very large graphs. JanusGraph graphs scale with the number of machines in the cluster. Support for very many concurrent transactions and operational graph processing. JanusGraph\u2019s transactional capacity scales with the number of machines in the cluster and answers complex traversal queries on huge graphs in milliseconds. Support for global graph analytics and batch graph processing through the Hadoop framework. Support for geo, numeric range, and full text search for vertices and edges on very large graphs. Native support for the popular property graph data model exposed by Apache TinkerPop . Native support for the graph traversal language Gremlin . Numerous graph-level configurations provide knobs for tuning performance. Vertex-centric indices provide vertex-level querying to alleviate issues with the infamous super node problem . Provides an optimized disk representation to allow for efficient use of storage and speed of access. Open source under the liberal Apache 2 license .","title":"General JanusGraph Benefits"},{"location":"#benefits-of-janusgraph-with-apache-cassandra","text":"Continuously available with no single point of failure. No read/write bottlenecks to the graph as there is no master/slave architecture. Elastic scalability allows for the introduction and removal of machines. Caching layer ensures that continuously accessed data is available in memory. Increase the size of the cache by adding more machines to the cluster. Integration with Apache Hadoop . Open source under the liberal Apache 2 license.","title":"Benefits of JanusGraph with Apache Cassandra"},{"location":"#benefits-of-janusgraph-with-hbase","text":"Tight integration with the Apache Hadoop ecosystem. Native support for strong consistency . Linear scalability with the addition of more machines. Strictly consistent reads and writes. Convenient base classes for backing Hadoop MapReduce jobs with HBase tables. Support for exporting metrics via JMX . Open source under the liberal Apache 2 license.","title":"Benefits of JanusGraph with HBase"},{"location":"#janusgraph-and-the-cap-theorem","text":"Despite your best efforts, your system will experience enough faults that it will have to make a choice between reducing yield (i.e., stop answering requests) and reducing harvest (i.e., giving answers based on incomplete data). This decision should be based on business requirements. \u2014 Coda Hale When using a database, the CAP theorem should be thoroughly considered (C=Consistency, A=Availability, P=Partitionability). JanusGraph is distributed with 3 supporting backends: Apache Cassandra , Apache HBase , and Oracle Berkeley DB Java Edition . Note that BerkeleyDB JE is a non-distributed database and is typically only used with JanusGraph for testing and exploration purposes. HBase gives preference to consistency at the expense of yield, i.e. the probability of completing a request. Cassandra gives preference to availability at the expense of harvest, i.e. the completeness of the answer to the query (data available/complete data).","title":"JanusGraph and the CAP Theorem"},{"location":"appendices/","text":"Appendices API Documentation (JavaDoc) Refer to the JanusGraph API documentation for a complete documentation of all core APIs exposed by JanusGraph. We strongly encourage all users of JanusGraph to use the Gremlin query language for any queries executed on JanusGraph and to not use JanusGraph\u2019s APIs outside of the management system.","title":"Appendices"},{"location":"appendices/#appendices","text":"","title":"Appendices"},{"location":"appendices/#api-documentation-javadoc","text":"Refer to the JanusGraph API documentation for a complete documentation of all core APIs exposed by JanusGraph. We strongly encourage all users of JanusGraph to use the Gremlin query language for any queries executed on JanusGraph and to not use JanusGraph\u2019s APIs outside of the management system.","title":"API Documentation (JavaDoc)"},{"location":"changelog/","text":"Changelog Version Compatibility The JanusGraph project is growing along with the rest of the graph and big data ecosystem and utilized storage and indexing backends. Below are version compatibilities between the various versions of components. For dependent backend systems, different minor versions are typically supported as well. It is strongly encouraged to verify version compatibility prior to deploying JanusGraph. Although JanusGraph may be compatible with older and no longer supported versions of its dependencies, users are warned that there are possible risks and security exposures with running software that is no longer supported or updated. Please check with the software providers to understand their supported versions. Users are strongly encouraged to use the latest versions of the software. Version Compatibility Matrix JanusGraph Storage Version Cassandra HBase Bigtable Elasticsearch Solr TinkerPop Spark Scala 0.1.z 1 1.2.z, 2.0.z, 2.1.z 0.98.z, 1.0.z, 1.1.z, 1.2.z 0.9.z, 1.0.0-preZ, 1.0.0 1.5.z 5.2.z 3.2.z 1.6.z 2.10.z 0.2.z 1 1.2.z, 2.0.z, 2.1.z, 2.2.z, 3.0.z, 3.11.z 0.98.z, 1.0.z, 1.1.z, 1.2.z, 1.3.z 0.9.z, 1.0.0-preZ, 1.0.0 1.5-1.7.z, 2.3-2.4.z, 5.y, 6.y 5.2-5.5.z, 6.2-6.6.z, 7.y 3.2.z 1.6.z 2.10.z 0.3.z 2 1.2.z, 2.0.z, 2.1.z, 2.2.z, 3.0.z, 3.11.z 1.0.z, 1.1.z, 1.2.z, 1.3.z, 1.4.z 1.0.0, 1.1.0, 1.1.2, 1.2.0, 1.3.0, 1.4.0 1.5-1.7.z, 2.3-2.4.z, 5.y, 6.y 5.2-5.5.z, 6.2-6.6.z, 7.y 3.3.z 2.2.z 2.11.z 0.4.z 2 2.1.z, 2.2.z, 3.0.z, 3.11.z 1.2.z, 1.3.z, 1.4.z, 2.1.z 1.3.0, 1.4.0, 1.5.z, 1.6.z, 1.7.z, 1.8.z, 1.9.z, 1.10.z, 1.11.z 5.y, 6.y 7.y 3.4.z 2.2.z 2.11.z Release Notes Version 0.4.1 (Release Date: January 14, 2020) Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.4.1 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.4.1\" Tested Compatibility: Apache Cassandra 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.10, 2.1.5 Google Bigtable 1.3.0, 1.4.0, 1.5.0, 1.6.0, 1.7.0, 1.8.0, 1.9.0, 1.10.0, 1.11.0 Oracle BerkeleyJE 7.5.11 Elasticsearch 5.6.14, 6.0.1, 6.6.0 Apache Lucene 7.0.0 Apache Solr 7.0.0 Apache TinkerPop 3.4.4 Java 1.8 For more information on features and bug fixes in 0.4.1, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/15?closed=1 Upgrade Instructions TinkerPop: Upgrade from 3.4.1 to 3.4.4 Adding multiple values in the same query to a new vertex property without explicitly defined type (i.e. using Automatic Schema Maker to create a property type) requires explicit usage of VertexProperty.Cardinality for each call (only for the first query which defines a property) if the VertexProperty.Cardinality is different than VertexProperty.Cardinality.single . Version 0.4.0 (Release Date: July 1, 2019) Legacy documentation: https://old-docs.janusgraph.org/0.4.0/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.4.0 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.4.0\" Tested Compatibility: Apache Cassandra 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.10, 2.1.5 Google Bigtable 1.3.0, 1.4.0, 1.5.0, 1.6.0, 1.7.0, 1.8.0, 1.9.0, 1.10.0, 1.11.0 Oracle BerkeleyJE 7.5.11 Elasticsearch 5.6.14, 6.0.1, 6.6.0 Apache Lucene 7.0.0 Apache Solr 7.0.0 Apache TinkerPop 3.4.1 Java 1.8 For more information on features and bug fixes in 0.4.0, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/8?closed=1 Upgrade Instructions HBase: Upgrade from 1.2 to 2.1 The version of HBase that is included in the distribution of JanusGraph was upgraded from 1.2.6 to 2.1.5. HBase 2.x client is not fully backward compatible with HBase 1.x server. Users who operate their own HBase version 1.x cluster may need to upgrade their cluster to version 2.x. Optionally users may build their own distribution of JanusGraph which includes HBase 1.x from source with the maven flags -Dhbase.profile -Phbase1. Cassandra: Upgrade from 2.1 to 2.2 The version of Cassandra that is included in the distribution of JanusGraph was upgraded from 2.1.20 to 2.2.13. Refer to the upgrade documentation of Cassandra for detailed instructions to perform this upgrade. Users who operate their own Cassandra cluster instead of using Cassandra distributed together with JanusGraph are not affected by this upgrade. This also does not change the different versions of Cassandra that are supported by JanusGraph (see < > for a detailed list of the supported versions). BerkeleyDB : Upgrade from 7.4 to 7.5 The BerkeleyDB version has been updated, and it contains changes to the file format stored on disk (see the BerkeleyDB changelog for reference ). This file format change is forward compatible with previous versions of BerkeleyDB, so existing graph data stored with JanusGraph can be read in. However, once the data has been read in with the newer version of BerkeleyDB, those files can no longer be read by the older version. Users are encouraged to backup the BerkeleyDB storage directory before attempting to use it with the JanusGraph release. Solr: Compatible Lucene version changed from 5.0.0 to 7.0.0 in distributed config The JanusGraph distribution contains a solrconfig.xml file that can be used to configure Solr. The value luceneMatchVersion in this config that tells Solr to behave according to that Lucene version was changed from 5.0.0 to 7.0.0 as that is the default version currently used by JanusGraph. Users should generally set this value to the version of their Solr installation. If the config distributed by JanusGraph is used for an existing Solr installation that used a lower version before (like 5.0.0 from a previous versions of this file), it is highly recommended that a re-indexing is performed. Version 0.3.3 (Release Date: January 11, 2020) Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.3.3 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.3.3\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.4 Google Bigtable 1.0.0, 1.1.2, 1.2.0, 1.3.0, 1.4.0 Oracle BerkeleyJE 7.4.5 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.3.3 Java 1.8 For more information on features and bug fixes in 0.3.3, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/14?closed=1 Version 0.3.2 (Release Date: June 16, 2019) Legacy documentation: https://old-docs.janusgraph.org/0.3.2/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.3.2 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.3.2\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.4 Google Bigtable 1.0.0, 1.1.2, 1.2.0, 1.3.0, 1.4.0 Oracle BerkeleyJE 7.4.5 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.3.3 Java 1.8 For more information on features and bug fixes in 0.3.2, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/10?closed=1 Version 0.3.1 (Release Date: October 2, 2018) Legacy documentation: https://old-docs.janusgraph.org/0.3.1/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.3.1 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.3.1\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.4 Google Bigtable 1.0.0, 1.1.2, 1.2.0, 1.3.0, 1.4.0 Oracle BerkeleyJE 7.4.5 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.3.3 Java 1.8 For more information on features and bug fixes in 0.3.1, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/7?closed=1 Version 0.3.0 (Release Date: July 31, 2018) Legacy documentation: https://old-docs.janusgraph.org/0.3.0/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.3.0 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.3.0\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.4 Google Bigtable 1.0.0, 1.1.2, 1.2.0, 1.3.0, 1.4.0 Oracle BerkeleyJE 7.4.5 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.3.3 Java 1.8 For more information on features and bug fixes in 0.3.0, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/4?closed=1 Upgrade Instructions Important You should back-up your data prior to attempting an upgrade! Also please note that once an upgrade has been completed you will no longer be able to connect to your graph with client versions prior to 0.3.0. JanusGraph 0.3.0 implements Schema Constraints which made it necessary to also introduce the concept of a schema version. There is a check to prevent client connections that either expect a different schema version or have no concept of a schema version. To perform an upgrade, the configuration option graph.allow-upgrade=true must be set on each graph you wish to upgrade. The graph must be opened with a 0.3.0 or greater version of JanusGraph since older versions have no concept of graph.storage-version and will not allow for it to be set. Example excerpt from janusgraph.properties file # JanusGraph configuration sample: Cassandra over a socket # # This file connects to a Cassandra daemon running on localhost via # Thrift. Cassandra must already be started before starting JanusGraph # with this file. # This option should be removed as soon as the upgrade is complete. Otherwise if this file # is used in the future to connect to a different graph it could cause an unintended upgrade. graph.allow-upgrade=true gremlin.graph=org.janusgraph.core.JanusGraphFactory # The primary persistence provider used by JanusGraph. This is required. # It should be set one of JanusGraph's built-in shorthand names for its # standard storage backends (shorthands: berkeleyje, cassandrathrift, # cassandra, astyanax, embeddedcassandra, cql, hbase, inmemory) or to the # full package and classname of a custom/third-party StoreManager # implementation. # # Default: (no default value) # Data Type: String # Mutability: LOCAL storage.backend=cassandrathrift # The hostname or comma-separated list of hostnames of storage backend # servers. This is only applicable to some storage backends, such as # cassandra and hbase. # # Default: 127.0.0.1 # Data Type: class java.lang.String[] # Mutability: LOCAL storage.hostname=127.0.0.1 If graph.allow-upgrade is set to true on a graph graph.storage-version and graph.janusgraph-version will automatically be upgraded to match the version level of the server, or local client, that is opening the graph. You can verify the upgrade was successful by opening the management API and validating the values of graph.storage-version and graph.janusgraph-version . Once the storage version has been set you should remove graph.allow-upgrade=true from your properties file and reopen your graph to ensure that the upgrade was successful. Version 0.2.3 (Release Date: May 21, 2019) Legacy documentation: https://old-docs.janusgraph.org/0.2.3/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.2.3 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.2.3\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 0.98.24-hadoop2, 1.2.6, 1.3.1 Google Bigtable 1.0.0 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.2.9 Java 1.8 For more information on features and bug fixes in 0.2.3, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/9?closed=1 Version 0.2.2 (Release Date: October 9, 2018) Legacy documentation: https://old-docs.janusgraph.org/0.2.2/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.2.2 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.2.2\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 0.98.24-hadoop2, 1.2.6, 1.3.1 Google Bigtable 1.0.0 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.2.9 Java 1.8 For more information on features and bug fixes in 0.2.2, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/6?closed=1 Version 0.2.1 (Release Date: July 9, 2018) Legacy documentation: https://old-docs.janusgraph.org/0.2.1/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.2.1 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.2.1\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 0.98.24-hadoop2, 1.2.6, 1.3.1 Google Bigtable 1.0.0 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.2.9 Java 1.8 For more information on features and bug fixes in 0.2.1, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/5?closed=1 Upgrade Instructions HBase TTL In JanusGraph 0.2.0, time-to-live (TTL) support was added for HBase storage backend. In order to utilize the TTL capability on HBase, the graph timestamps need to be MILLI. If the graph.timestamps property is not explicitly set to MILLI, the default is MICRO in JanusGraph 0.2.0, which does not work for HBase TTL. Since the graph.timestamps property is FIXED, a new graph needs to be created to make any change of the graph.timestamps property effective. Version 0.2.0 (Release Date: October 11, 2017) Legacy documentation: https://old-docs.janusgraph.org/0.2.0/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.2.0 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.2.0\" Tested Compatibility: Apache Cassandra 2.1.18, 2.2.10, 3.0.14, 3.11.0 Apache HBase 0.98.24-hadoop2, 1.2.6, 1.3.1 Google Bigtable 1.0.0-pre3 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.7.6, 2.4.6, 5.6.2, 6.0.0-rc1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.2.6 Java 1.8 For more information on features and bug fixes in 0.2.0, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/2?closed=1 Upgrade Instructions Elasticsearch JanusGraph 0.1.z is compatible with Elasticsearch 1.5.z. There were several configuration options available, including transport client, node client, and legacy configuration track. JanusGraph 0.2.0 is compatible with Elasticsearch versions from 1.y through 6.y, however it offers only a single configuration option using the REST client. Transport client The TRANSPORT_CLIENT interface has been replaced with REST_CLIENT . When migrating an existing graph to JanusGraph 0.2.0, the interface property must be set when connecting to the graph: index.search.backend=elasticsearch index.search.elasticsearch.interface=REST_CLIENT index.search.hostname=127.0.0.1 After connecting to the graph, the property update can be made permanent by making the change with JanusGraphManagement : mgmt = graph . openManagement () mgmt . set ( \"index.search.elasticsearch.interface\" , \"REST_CLIENT\" ) mgmt . commit () Node client A node client with JanusGraph can be configured in a few ways. If the node client was configured as a client-only or non-data node, follow the steps from the transport client section to connect to the existing cluster using the REST_CLIENT instead. If the node client was a data node (local-mode), then convert it into a standalone Elasticsearch node, running in a separate JVM from your application process. This can be done by using the node\u2019s configuration from the JanusGraph configuration to start a standalone Elasticsearch 1.5.z node. For example, we start with these JanusGraph 0.1.z properties: 1 2 3 4 index.search.backend=elasticsearch index.search.elasticsearch.interface=NODE index.search.conf-file=es-client.yml index.search.elasticsearch.ext.node.name=alice where the configuration file es-client.yml has properties: 1 2 3 4 node.data: true path.data: /var/lib/elasticsearch/data path.work: /var/lib/elasticsearch/work path.logs: /var/log/elasticsearch The properties found in the configuration file es-client.yml and the index.search.elasticsearch.ext.* properties can be inserted into $ES_HOME/config/elasticsearch.yml so that a standalone Elasticsearch 1.5.z node can be started with the same properties. Keep in mind that if any path locations have relative paths, those values may need to be updated appropriately. Once the standalone Elasticsearch node is started, follow the directions in the transport client section to complete the migration to the REST_CLIENT interface. Note that the index.search.conf-file and index.search.elasticsearch.ext.* properties are not used by the REST_CLIENT interface, so they can be removed from the configuration properties. Legacy configuration The legacy configuration track was not recommended in JanusGraph 0.1.z and is no longer supported in JanusGraph 0.2.0. Users should refer to the previous sections and migrate to the REST_CLIENT . Version 0.1.1 (Release Date: May 11, 2017) Documentation: https://old-docs.janusgraph.org/0.1.1/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.1.1 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.1.1\" Tested Compatibility: Apache Cassandra 2.1.9 Apache HBase 0.98.8-hadoop2, 1.0.3, 1.1.8, 1.2.4 Google Bigtable 0.9.5.1 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.5.1 Apache Lucene 4.10.4 Apache Solr 5.2.1 Apache TinkerPop 3.2.3 Java 1.8 For more information on features and bug fixes in 0.1.1, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/3?closed=1 Version 0.1.0 (Release Date: April 11, 2017) Documentation: https://old-docs.janusgraph.org/0.1.0/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.1.0 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.1.0\" Tested Compatibility: Apache Cassandra 2.1.9 Apache HBase 0.98.8-hadoop2, 1.0.3, 1.1.8, 1.2.4 Google Bigtable 0.9.5.1 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.5.1 Apache Lucene 4.10.4 Apache Solr 5.2.1 Apache TinkerPop 3.2.3 Java 1.8 Features added since version Titan 1.0.0: TinkerPop 3.2.3 compatibility Includes update to Spark 1.6.1 Query optimizations: JanusGraphStep folds in HasId and HasContainers can be folded in even mid-traversal Support Google Cloud Bigtable as a backend over the HBase interface Compatibility with newer versions of backend and index stores HBase 1.2 BerkeleyJE 7.3.7 Includes a number of bug fixes and optimizations For more information on features and bug fixes in 0.1.0, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/1?closed=1 Upgrade Instructions JanusGraph is based on the latest commit to the titan11 branch of Titan repo . JanusGraph has made the following changes to Titan, so you will need to adjust your code and configuration accordingly: module names: titan-* are now janusgraph-* package names: com.thinkaurelius.titan are now org.janusgraph class names: Titan* are now JanusGraph* except in cases where this would duplicate a word, e.g., TitanGraph is simply JanusGraph rather than JanusGraphGraph For more information on how to configure JanusGraph to read data which had previously been written by Titan refer to Migration from titan .","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#version-compatibility","text":"The JanusGraph project is growing along with the rest of the graph and big data ecosystem and utilized storage and indexing backends. Below are version compatibilities between the various versions of components. For dependent backend systems, different minor versions are typically supported as well. It is strongly encouraged to verify version compatibility prior to deploying JanusGraph. Although JanusGraph may be compatible with older and no longer supported versions of its dependencies, users are warned that there are possible risks and security exposures with running software that is no longer supported or updated. Please check with the software providers to understand their supported versions. Users are strongly encouraged to use the latest versions of the software.","title":"Version Compatibility"},{"location":"changelog/#version-compatibility-matrix","text":"JanusGraph Storage Version Cassandra HBase Bigtable Elasticsearch Solr TinkerPop Spark Scala 0.1.z 1 1.2.z, 2.0.z, 2.1.z 0.98.z, 1.0.z, 1.1.z, 1.2.z 0.9.z, 1.0.0-preZ, 1.0.0 1.5.z 5.2.z 3.2.z 1.6.z 2.10.z 0.2.z 1 1.2.z, 2.0.z, 2.1.z, 2.2.z, 3.0.z, 3.11.z 0.98.z, 1.0.z, 1.1.z, 1.2.z, 1.3.z 0.9.z, 1.0.0-preZ, 1.0.0 1.5-1.7.z, 2.3-2.4.z, 5.y, 6.y 5.2-5.5.z, 6.2-6.6.z, 7.y 3.2.z 1.6.z 2.10.z 0.3.z 2 1.2.z, 2.0.z, 2.1.z, 2.2.z, 3.0.z, 3.11.z 1.0.z, 1.1.z, 1.2.z, 1.3.z, 1.4.z 1.0.0, 1.1.0, 1.1.2, 1.2.0, 1.3.0, 1.4.0 1.5-1.7.z, 2.3-2.4.z, 5.y, 6.y 5.2-5.5.z, 6.2-6.6.z, 7.y 3.3.z 2.2.z 2.11.z 0.4.z 2 2.1.z, 2.2.z, 3.0.z, 3.11.z 1.2.z, 1.3.z, 1.4.z, 2.1.z 1.3.0, 1.4.0, 1.5.z, 1.6.z, 1.7.z, 1.8.z, 1.9.z, 1.10.z, 1.11.z 5.y, 6.y 7.y 3.4.z 2.2.z 2.11.z","title":"Version Compatibility Matrix"},{"location":"changelog/#release-notes","text":"","title":"Release Notes"},{"location":"changelog/#version-041-release-date-january-14-2020","text":"Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.4.1 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.4.1\" Tested Compatibility: Apache Cassandra 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.10, 2.1.5 Google Bigtable 1.3.0, 1.4.0, 1.5.0, 1.6.0, 1.7.0, 1.8.0, 1.9.0, 1.10.0, 1.11.0 Oracle BerkeleyJE 7.5.11 Elasticsearch 5.6.14, 6.0.1, 6.6.0 Apache Lucene 7.0.0 Apache Solr 7.0.0 Apache TinkerPop 3.4.4 Java 1.8 For more information on features and bug fixes in 0.4.1, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/15?closed=1","title":"Version 0.4.1 (Release Date: January 14, 2020)"},{"location":"changelog/#upgrade-instructions","text":"","title":"Upgrade Instructions"},{"location":"changelog/#tinkerpop-upgrade-from-341-to-344","text":"Adding multiple values in the same query to a new vertex property without explicitly defined type (i.e. using Automatic Schema Maker to create a property type) requires explicit usage of VertexProperty.Cardinality for each call (only for the first query which defines a property) if the VertexProperty.Cardinality is different than VertexProperty.Cardinality.single .","title":"TinkerPop: Upgrade from 3.4.1 to 3.4.4"},{"location":"changelog/#version-040-release-date-july-1-2019","text":"Legacy documentation: https://old-docs.janusgraph.org/0.4.0/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.4.0 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.4.0\" Tested Compatibility: Apache Cassandra 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.10, 2.1.5 Google Bigtable 1.3.0, 1.4.0, 1.5.0, 1.6.0, 1.7.0, 1.8.0, 1.9.0, 1.10.0, 1.11.0 Oracle BerkeleyJE 7.5.11 Elasticsearch 5.6.14, 6.0.1, 6.6.0 Apache Lucene 7.0.0 Apache Solr 7.0.0 Apache TinkerPop 3.4.1 Java 1.8 For more information on features and bug fixes in 0.4.0, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/8?closed=1","title":"Version 0.4.0 (Release Date: July 1, 2019)"},{"location":"changelog/#upgrade-instructions_1","text":"","title":"Upgrade Instructions"},{"location":"changelog/#hbase-upgrade-from-12-to-21","text":"The version of HBase that is included in the distribution of JanusGraph was upgraded from 1.2.6 to 2.1.5. HBase 2.x client is not fully backward compatible with HBase 1.x server. Users who operate their own HBase version 1.x cluster may need to upgrade their cluster to version 2.x. Optionally users may build their own distribution of JanusGraph which includes HBase 1.x from source with the maven flags -Dhbase.profile -Phbase1.","title":"HBase: Upgrade from 1.2 to 2.1"},{"location":"changelog/#cassandra-upgrade-from-21-to-22","text":"The version of Cassandra that is included in the distribution of JanusGraph was upgraded from 2.1.20 to 2.2.13. Refer to the upgrade documentation of Cassandra for detailed instructions to perform this upgrade. Users who operate their own Cassandra cluster instead of using Cassandra distributed together with JanusGraph are not affected by this upgrade. This also does not change the different versions of Cassandra that are supported by JanusGraph (see < > for a detailed list of the supported versions).","title":"Cassandra: Upgrade from 2.1 to 2.2"},{"location":"changelog/#berkeleydb-upgrade-from-74-to-75","text":"The BerkeleyDB version has been updated, and it contains changes to the file format stored on disk (see the BerkeleyDB changelog for reference ). This file format change is forward compatible with previous versions of BerkeleyDB, so existing graph data stored with JanusGraph can be read in. However, once the data has been read in with the newer version of BerkeleyDB, those files can no longer be read by the older version. Users are encouraged to backup the BerkeleyDB storage directory before attempting to use it with the JanusGraph release.","title":"BerkeleyDB : Upgrade from 7.4 to 7.5"},{"location":"changelog/#solr-compatible-lucene-version-changed-from-500-to-700-in-distributed-config","text":"The JanusGraph distribution contains a solrconfig.xml file that can be used to configure Solr. The value luceneMatchVersion in this config that tells Solr to behave according to that Lucene version was changed from 5.0.0 to 7.0.0 as that is the default version currently used by JanusGraph. Users should generally set this value to the version of their Solr installation. If the config distributed by JanusGraph is used for an existing Solr installation that used a lower version before (like 5.0.0 from a previous versions of this file), it is highly recommended that a re-indexing is performed.","title":"Solr: Compatible Lucene version changed from 5.0.0 to 7.0.0 in distributed config"},{"location":"changelog/#version-033-release-date-january-11-2020","text":"Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.3.3 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.3.3\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.4 Google Bigtable 1.0.0, 1.1.2, 1.2.0, 1.3.0, 1.4.0 Oracle BerkeleyJE 7.4.5 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.3.3 Java 1.8 For more information on features and bug fixes in 0.3.3, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/14?closed=1","title":"Version 0.3.3 (Release Date: January 11, 2020)"},{"location":"changelog/#version-032-release-date-june-16-2019","text":"Legacy documentation: https://old-docs.janusgraph.org/0.3.2/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.3.2 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.3.2\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.4 Google Bigtable 1.0.0, 1.1.2, 1.2.0, 1.3.0, 1.4.0 Oracle BerkeleyJE 7.4.5 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.3.3 Java 1.8 For more information on features and bug fixes in 0.3.2, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/10?closed=1","title":"Version 0.3.2 (Release Date: June 16, 2019)"},{"location":"changelog/#version-031-release-date-october-2-2018","text":"Legacy documentation: https://old-docs.janusgraph.org/0.3.1/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.3.1 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.3.1\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.4 Google Bigtable 1.0.0, 1.1.2, 1.2.0, 1.3.0, 1.4.0 Oracle BerkeleyJE 7.4.5 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.3.3 Java 1.8 For more information on features and bug fixes in 0.3.1, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/7?closed=1","title":"Version 0.3.1 (Release Date: October 2, 2018)"},{"location":"changelog/#version-030-release-date-july-31-2018","text":"Legacy documentation: https://old-docs.janusgraph.org/0.3.0/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.3.0 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.3.0\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 1.2.6, 1.3.1, 1.4.4 Google Bigtable 1.0.0, 1.1.2, 1.2.0, 1.3.0, 1.4.0 Oracle BerkeleyJE 7.4.5 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.3.3 Java 1.8 For more information on features and bug fixes in 0.3.0, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/4?closed=1","title":"Version 0.3.0 (Release Date: July 31, 2018)"},{"location":"changelog/#upgrade-instructions_2","text":"Important You should back-up your data prior to attempting an upgrade! Also please note that once an upgrade has been completed you will no longer be able to connect to your graph with client versions prior to 0.3.0. JanusGraph 0.3.0 implements Schema Constraints which made it necessary to also introduce the concept of a schema version. There is a check to prevent client connections that either expect a different schema version or have no concept of a schema version. To perform an upgrade, the configuration option graph.allow-upgrade=true must be set on each graph you wish to upgrade. The graph must be opened with a 0.3.0 or greater version of JanusGraph since older versions have no concept of graph.storage-version and will not allow for it to be set. Example excerpt from janusgraph.properties file # JanusGraph configuration sample: Cassandra over a socket # # This file connects to a Cassandra daemon running on localhost via # Thrift. Cassandra must already be started before starting JanusGraph # with this file. # This option should be removed as soon as the upgrade is complete. Otherwise if this file # is used in the future to connect to a different graph it could cause an unintended upgrade. graph.allow-upgrade=true gremlin.graph=org.janusgraph.core.JanusGraphFactory # The primary persistence provider used by JanusGraph. This is required. # It should be set one of JanusGraph's built-in shorthand names for its # standard storage backends (shorthands: berkeleyje, cassandrathrift, # cassandra, astyanax, embeddedcassandra, cql, hbase, inmemory) or to the # full package and classname of a custom/third-party StoreManager # implementation. # # Default: (no default value) # Data Type: String # Mutability: LOCAL storage.backend=cassandrathrift # The hostname or comma-separated list of hostnames of storage backend # servers. This is only applicable to some storage backends, such as # cassandra and hbase. # # Default: 127.0.0.1 # Data Type: class java.lang.String[] # Mutability: LOCAL storage.hostname=127.0.0.1 If graph.allow-upgrade is set to true on a graph graph.storage-version and graph.janusgraph-version will automatically be upgraded to match the version level of the server, or local client, that is opening the graph. You can verify the upgrade was successful by opening the management API and validating the values of graph.storage-version and graph.janusgraph-version . Once the storage version has been set you should remove graph.allow-upgrade=true from your properties file and reopen your graph to ensure that the upgrade was successful.","title":"Upgrade Instructions"},{"location":"changelog/#version-023-release-date-may-21-2019","text":"Legacy documentation: https://old-docs.janusgraph.org/0.2.3/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.2.3 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.2.3\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 0.98.24-hadoop2, 1.2.6, 1.3.1 Google Bigtable 1.0.0 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.2.9 Java 1.8 For more information on features and bug fixes in 0.2.3, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/9?closed=1","title":"Version 0.2.3 (Release Date: May 21, 2019)"},{"location":"changelog/#version-022-release-date-october-9-2018","text":"Legacy documentation: https://old-docs.janusgraph.org/0.2.2/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.2.2 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.2.2\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 0.98.24-hadoop2, 1.2.6, 1.3.1 Google Bigtable 1.0.0 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.2.9 Java 1.8 For more information on features and bug fixes in 0.2.2, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/6?closed=1","title":"Version 0.2.2 (Release Date: October 9, 2018)"},{"location":"changelog/#version-021-release-date-july-9-2018","text":"Legacy documentation: https://old-docs.janusgraph.org/0.2.1/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.2.1 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.2.1\" Tested Compatibility: Apache Cassandra 2.1.20, 2.2.10, 3.0.14, 3.11.0 Apache HBase 0.98.24-hadoop2, 1.2.6, 1.3.1 Google Bigtable 1.0.0 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.7.6, 2.4.6, 5.6.5, 6.0.1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.2.9 Java 1.8 For more information on features and bug fixes in 0.2.1, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/5?closed=1","title":"Version 0.2.1 (Release Date: July 9, 2018)"},{"location":"changelog/#upgrade-instructions_3","text":"","title":"Upgrade Instructions"},{"location":"changelog/#hbase-ttl","text":"In JanusGraph 0.2.0, time-to-live (TTL) support was added for HBase storage backend. In order to utilize the TTL capability on HBase, the graph timestamps need to be MILLI. If the graph.timestamps property is not explicitly set to MILLI, the default is MICRO in JanusGraph 0.2.0, which does not work for HBase TTL. Since the graph.timestamps property is FIXED, a new graph needs to be created to make any change of the graph.timestamps property effective.","title":"HBase TTL"},{"location":"changelog/#version-020-release-date-october-11-2017","text":"Legacy documentation: https://old-docs.janusgraph.org/0.2.0/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.2.0 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.2.0\" Tested Compatibility: Apache Cassandra 2.1.18, 2.2.10, 3.0.14, 3.11.0 Apache HBase 0.98.24-hadoop2, 1.2.6, 1.3.1 Google Bigtable 1.0.0-pre3 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.7.6, 2.4.6, 5.6.2, 6.0.0-rc1 Apache Lucene 7.0.0 Apache Solr 5.5.4, 6.6.1, 7.0.0 Apache TinkerPop 3.2.6 Java 1.8 For more information on features and bug fixes in 0.2.0, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/2?closed=1","title":"Version 0.2.0 (Release Date: October 11, 2017)"},{"location":"changelog/#upgrade-instructions_4","text":"","title":"Upgrade Instructions"},{"location":"changelog/#elasticsearch","text":"JanusGraph 0.1.z is compatible with Elasticsearch 1.5.z. There were several configuration options available, including transport client, node client, and legacy configuration track. JanusGraph 0.2.0 is compatible with Elasticsearch versions from 1.y through 6.y, however it offers only a single configuration option using the REST client.","title":"Elasticsearch"},{"location":"changelog/#transport-client","text":"The TRANSPORT_CLIENT interface has been replaced with REST_CLIENT . When migrating an existing graph to JanusGraph 0.2.0, the interface property must be set when connecting to the graph: index.search.backend=elasticsearch index.search.elasticsearch.interface=REST_CLIENT index.search.hostname=127.0.0.1 After connecting to the graph, the property update can be made permanent by making the change with JanusGraphManagement : mgmt = graph . openManagement () mgmt . set ( \"index.search.elasticsearch.interface\" , \"REST_CLIENT\" ) mgmt . commit ()","title":"Transport client"},{"location":"changelog/#node-client","text":"A node client with JanusGraph can be configured in a few ways. If the node client was configured as a client-only or non-data node, follow the steps from the transport client section to connect to the existing cluster using the REST_CLIENT instead. If the node client was a data node (local-mode), then convert it into a standalone Elasticsearch node, running in a separate JVM from your application process. This can be done by using the node\u2019s configuration from the JanusGraph configuration to start a standalone Elasticsearch 1.5.z node. For example, we start with these JanusGraph 0.1.z properties: 1 2 3 4 index.search.backend=elasticsearch index.search.elasticsearch.interface=NODE index.search.conf-file=es-client.yml index.search.elasticsearch.ext.node.name=alice where the configuration file es-client.yml has properties: 1 2 3 4 node.data: true path.data: /var/lib/elasticsearch/data path.work: /var/lib/elasticsearch/work path.logs: /var/log/elasticsearch The properties found in the configuration file es-client.yml and the index.search.elasticsearch.ext.* properties can be inserted into $ES_HOME/config/elasticsearch.yml so that a standalone Elasticsearch 1.5.z node can be started with the same properties. Keep in mind that if any path locations have relative paths, those values may need to be updated appropriately. Once the standalone Elasticsearch node is started, follow the directions in the transport client section to complete the migration to the REST_CLIENT interface. Note that the index.search.conf-file and index.search.elasticsearch.ext.* properties are not used by the REST_CLIENT interface, so they can be removed from the configuration properties.","title":"Node client"},{"location":"changelog/#legacy-configuration","text":"The legacy configuration track was not recommended in JanusGraph 0.1.z and is no longer supported in JanusGraph 0.2.0. Users should refer to the previous sections and migrate to the REST_CLIENT .","title":"Legacy configuration"},{"location":"changelog/#version-011-release-date-may-11-2017","text":"Documentation: https://old-docs.janusgraph.org/0.1.1/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.1.1 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.1.1\" Tested Compatibility: Apache Cassandra 2.1.9 Apache HBase 0.98.8-hadoop2, 1.0.3, 1.1.8, 1.2.4 Google Bigtable 0.9.5.1 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.5.1 Apache Lucene 4.10.4 Apache Solr 5.2.1 Apache TinkerPop 3.2.3 Java 1.8 For more information on features and bug fixes in 0.1.1, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/3?closed=1","title":"Version 0.1.1 (Release Date: May 11, 2017)"},{"location":"changelog/#version-010-release-date-april-11-2017","text":"Documentation: https://old-docs.janusgraph.org/0.1.0/index.html Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.1.0 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.1.0\" Tested Compatibility: Apache Cassandra 2.1.9 Apache HBase 0.98.8-hadoop2, 1.0.3, 1.1.8, 1.2.4 Google Bigtable 0.9.5.1 Oracle BerkeleyJE 7.3.7 Elasticsearch 1.5.1 Apache Lucene 4.10.4 Apache Solr 5.2.1 Apache TinkerPop 3.2.3 Java 1.8 Features added since version Titan 1.0.0: TinkerPop 3.2.3 compatibility Includes update to Spark 1.6.1 Query optimizations: JanusGraphStep folds in HasId and HasContainers can be folded in even mid-traversal Support Google Cloud Bigtable as a backend over the HBase interface Compatibility with newer versions of backend and index stores HBase 1.2 BerkeleyJE 7.3.7 Includes a number of bug fixes and optimizations For more information on features and bug fixes in 0.1.0, see the GitHub milestone: https://github.com/JanusGraph/janusgraph/milestone/1?closed=1","title":"Version 0.1.0 (Release Date: April 11, 2017)"},{"location":"changelog/#upgrade-instructions_5","text":"JanusGraph is based on the latest commit to the titan11 branch of Titan repo . JanusGraph has made the following changes to Titan, so you will need to adjust your code and configuration accordingly: module names: titan-* are now janusgraph-* package names: com.thinkaurelius.titan are now org.janusgraph class names: Titan* are now JanusGraph* except in cases where this would duplicate a word, e.g., TitanGraph is simply JanusGraph rather than JanusGraphGraph For more information on how to configure JanusGraph to read data which had previously been written by Titan refer to Migration from titan .","title":"Upgrade Instructions"},{"location":"development/","text":"The following sections describe the JanusGraph development process. Development Decisions Many development decisions will be made during the day-to-day work of JanusGraph contributors without any extra process overhead. However, for larger bodies of work and significant updates and additions, the following process shall be followed. Significant work may include, but is not limited to: A major new feature or subproject, e.g., a new storage adapter Incrementing the version of a core dependency such as a Apache TinkerPop Addition or deprecation of a public API Internal shared data structure or API change Addition of a new major dependency For these sorts of changes, contributors will: Create one or more issues in the GitHub issue tracker Start a DISCUSS thread on the janusgraph-dev list where the proposed change may be discussed by committers and other community members When the proposer feels it appropriate, a VOTE shall be called Two +1 votes are required for the change to be accepted Branching For features that involve only one developer, developers will work in their own JanusGraph forks, managing their own branches, and submitting pull requests when ready. If multiple developers wish to collaborate on a feature, they may request that a feature branch be created in JanusGraph repository. If the developers are not committers, a JanusGraph committer will be assigned as the shepherd for that branch. The shepherd will be responsible for merging pull requests to that branch. Branch Naming Conventions All branch names hosted in the JanusGraph repository shall be prepended with Issue_#_ . Pull Requests Users wishing to contribute to JanusGraph should fork the JanusGraph repository and then submit pull requests using the GitHub pull request process . Every pull request must be associated with an existing issue. Be sure to include the relevant issue number in the title of your pull request, complete the pull request template checklist, and provide a description of what test suites were run to validate the pull request. Pull requests commit messages should clearly describe what work was accomplished. Intermediate work-in-progress commits should be squashed prior to pull request submittal. Review-Then-Commit (RTC) Pull requests must be reviewed before being merged following a review-then-commit (RTC) process. The JanusGraph project uses the GitHub review process to review pull requests. Non-committers are welcomed and encouraged to review pull requests. Their review will be non-binding, but can be taken into consideration and are still very valuable community input. The following rules apply to the voting process. Approval flows 2 committer approvals are required to merge a pull request If a committer submits the pull request, it has their implicit approval so it requires 1 additional committer approval 1 committer approval followed a one week review period for objections at which point a lazy consensus is assumed One or more -1 votes within a change request will veto the pull request until the noted issue(s) are addressed and the -1 vote is withdrawn Change requests will not be considered valid without an explanation Commit-Then-Review (CTR) In instances where the committer deems the full RTC process unnecessary, a commit-then-review (CTR) process may be employed. The purpose of invoking CTR is to reduce the burden on the committers and minimize the turnaround time for merging trivial changes. Changes of this sort may include: Documentation typo or small documentation addition Addition of a new test case Merging approved fixes into an upstream branch Any commit that is made following CTR shall include the fact that it is a CTR in the commit comments. Community members who wish to review CTRs may subscribe to the JanusGraph commits list so that they will see CTRs as they come through. If another committer responds with a -1, the commit should be rolled back and the formal RTC process should be followed. Merging of Pull Requests A pull request is ready to be merged when it has been approved (see Review-Then-Commit (RTC) ). It can either be merged manually with git commands or through the GitHub UI with the Merge pull request button. If the pull request targets a release branch that is upstream of other release branches (e.g., v0.2 is upstream of master ), then it is important to make sure that the change also lands in the downstream release branches. This is the responsibility of the committer who merges the pull request. Therefore, merge the pull request first into its target branch and then merge that branch (e.g., v0.2 ) into the next downstream branch (e.g., v0.3 ), and so on until you merge the last release branch into master . Afterwards push all release branches, ideally with an atomic commit: git push --atomic origin master v0.3 v0.2 This approach keeps merge conflicts to a minimum when a release branch is merged into a downstream release branch. Release Policy Any JanusGraph committer may propose a release. To propose a release, simple start a new RELEASE thread on janusgraph-dev proposing the new release and requesting feedback on what should be included in the release. After consensus is reached the release manager will perform the following tasks: Create a release branch so that work may continue on master Prepare the release artifacts Call a vote to approve the release on janusgraph-dev Committers will be given 72 hours to review and vote on the release artifacts Three +1 votes are required for a release to be approved One or more -1 votes with explanation will veto the release until the noted issues are addressed and the -1 votes are withdrawn Building JanusGraph To build JanusGraph you need git and Maven . Clone the JanusGraph repository from GitHub to a local directory. In that directory, execute mvn clean install . This will build JanusGraph and run the internal test suite. The internal test suite has no external dependencies. Note, that running all test cases requires a significant amount of time. To skip the tests when building JanusGraph, execute mvn clean install -DskipTests For comprehensive test coverage, execute mvn clean test -P comprehensive . This will run additional test covering communication to external storage backends, performance tests and concurrency tests. The comprehensive test suite uses Cassandra and HBase as external databases and requires that Cassandra and HBase are installed. Note, that running the comprehensive test suite requires a significant amount of of time (> 1 hour). Depending on JanusGraph Snapshots For developing against the most current version of JanusGraph, depend on JanusGraph snapshot releases. Note, that these releases are development releases and therefore unstable and likely to change. Unless one is interested in the most recent development status of JanusGraph, we recommend to use the stable JanusGraph release instead. Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.4.2-SNAPSHOT </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.4.2-SNAPSHOT\" Check the master branch for the most current release version. SNAPSHOTs will be available through the Sonatype repository . When adding this dependency, be sure to add the following repository to build file: Maven <repository> <id> ossrh </id> <name> Sonatype Nexus Snapshots </name> <url> https://oss.sonatype.org/content/repositories/snapshots </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </repository> Gradle maven { url \"https://oss.sonatype.org/content/repositories/snapshots\" mavenContent { snapshotsOnly () } } FAQs Maven build causes dozens of \"[WARNING] We have a duplicate\u2026\" errors Make sure to use the maven-assembly-plugin when building or depending on JanusGraph.","title":"Development"},{"location":"development/#development-decisions","text":"Many development decisions will be made during the day-to-day work of JanusGraph contributors without any extra process overhead. However, for larger bodies of work and significant updates and additions, the following process shall be followed. Significant work may include, but is not limited to: A major new feature or subproject, e.g., a new storage adapter Incrementing the version of a core dependency such as a Apache TinkerPop Addition or deprecation of a public API Internal shared data structure or API change Addition of a new major dependency For these sorts of changes, contributors will: Create one or more issues in the GitHub issue tracker Start a DISCUSS thread on the janusgraph-dev list where the proposed change may be discussed by committers and other community members When the proposer feels it appropriate, a VOTE shall be called Two +1 votes are required for the change to be accepted","title":"Development Decisions"},{"location":"development/#branching","text":"For features that involve only one developer, developers will work in their own JanusGraph forks, managing their own branches, and submitting pull requests when ready. If multiple developers wish to collaborate on a feature, they may request that a feature branch be created in JanusGraph repository. If the developers are not committers, a JanusGraph committer will be assigned as the shepherd for that branch. The shepherd will be responsible for merging pull requests to that branch.","title":"Branching"},{"location":"development/#branch-naming-conventions","text":"All branch names hosted in the JanusGraph repository shall be prepended with Issue_#_ .","title":"Branch Naming Conventions"},{"location":"development/#pull-requests","text":"Users wishing to contribute to JanusGraph should fork the JanusGraph repository and then submit pull requests using the GitHub pull request process . Every pull request must be associated with an existing issue. Be sure to include the relevant issue number in the title of your pull request, complete the pull request template checklist, and provide a description of what test suites were run to validate the pull request. Pull requests commit messages should clearly describe what work was accomplished. Intermediate work-in-progress commits should be squashed prior to pull request submittal.","title":"Pull Requests"},{"location":"development/#review-then-commit-rtc","text":"Pull requests must be reviewed before being merged following a review-then-commit (RTC) process. The JanusGraph project uses the GitHub review process to review pull requests. Non-committers are welcomed and encouraged to review pull requests. Their review will be non-binding, but can be taken into consideration and are still very valuable community input. The following rules apply to the voting process. Approval flows 2 committer approvals are required to merge a pull request If a committer submits the pull request, it has their implicit approval so it requires 1 additional committer approval 1 committer approval followed a one week review period for objections at which point a lazy consensus is assumed One or more -1 votes within a change request will veto the pull request until the noted issue(s) are addressed and the -1 vote is withdrawn Change requests will not be considered valid without an explanation","title":"Review-Then-Commit (RTC)"},{"location":"development/#commit-then-review-ctr","text":"In instances where the committer deems the full RTC process unnecessary, a commit-then-review (CTR) process may be employed. The purpose of invoking CTR is to reduce the burden on the committers and minimize the turnaround time for merging trivial changes. Changes of this sort may include: Documentation typo or small documentation addition Addition of a new test case Merging approved fixes into an upstream branch Any commit that is made following CTR shall include the fact that it is a CTR in the commit comments. Community members who wish to review CTRs may subscribe to the JanusGraph commits list so that they will see CTRs as they come through. If another committer responds with a -1, the commit should be rolled back and the formal RTC process should be followed.","title":"Commit-Then-Review (CTR)"},{"location":"development/#merging-of-pull-requests","text":"A pull request is ready to be merged when it has been approved (see Review-Then-Commit (RTC) ). It can either be merged manually with git commands or through the GitHub UI with the Merge pull request button. If the pull request targets a release branch that is upstream of other release branches (e.g., v0.2 is upstream of master ), then it is important to make sure that the change also lands in the downstream release branches. This is the responsibility of the committer who merges the pull request. Therefore, merge the pull request first into its target branch and then merge that branch (e.g., v0.2 ) into the next downstream branch (e.g., v0.3 ), and so on until you merge the last release branch into master . Afterwards push all release branches, ideally with an atomic commit: git push --atomic origin master v0.3 v0.2 This approach keeps merge conflicts to a minimum when a release branch is merged into a downstream release branch.","title":"Merging of Pull Requests"},{"location":"development/#release-policy","text":"Any JanusGraph committer may propose a release. To propose a release, simple start a new RELEASE thread on janusgraph-dev proposing the new release and requesting feedback on what should be included in the release. After consensus is reached the release manager will perform the following tasks: Create a release branch so that work may continue on master Prepare the release artifacts Call a vote to approve the release on janusgraph-dev Committers will be given 72 hours to review and vote on the release artifacts Three +1 votes are required for a release to be approved One or more -1 votes with explanation will veto the release until the noted issues are addressed and the -1 votes are withdrawn","title":"Release Policy"},{"location":"development/#building-janusgraph","text":"To build JanusGraph you need git and Maven . Clone the JanusGraph repository from GitHub to a local directory. In that directory, execute mvn clean install . This will build JanusGraph and run the internal test suite. The internal test suite has no external dependencies. Note, that running all test cases requires a significant amount of time. To skip the tests when building JanusGraph, execute mvn clean install -DskipTests For comprehensive test coverage, execute mvn clean test -P comprehensive . This will run additional test covering communication to external storage backends, performance tests and concurrency tests. The comprehensive test suite uses Cassandra and HBase as external databases and requires that Cassandra and HBase are installed. Note, that running the comprehensive test suite requires a significant amount of of time (> 1 hour).","title":"Building JanusGraph"},{"location":"development/#depending-on-janusgraph-snapshots","text":"For developing against the most current version of JanusGraph, depend on JanusGraph snapshot releases. Note, that these releases are development releases and therefore unstable and likely to change. Unless one is interested in the most recent development status of JanusGraph, we recommend to use the stable JanusGraph release instead. Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.4.2-SNAPSHOT </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.4.2-SNAPSHOT\" Check the master branch for the most current release version. SNAPSHOTs will be available through the Sonatype repository . When adding this dependency, be sure to add the following repository to build file: Maven <repository> <id> ossrh </id> <name> Sonatype Nexus Snapshots </name> <url> https://oss.sonatype.org/content/repositories/snapshots </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </repository> Gradle maven { url \"https://oss.sonatype.org/content/repositories/snapshots\" mavenContent { snapshotsOnly () } }","title":"Depending on JanusGraph Snapshots"},{"location":"development/#faqs","text":"Maven build causes dozens of \"[WARNING] We have a duplicate\u2026\" errors Make sure to use the maven-assembly-plugin when building or depending on JanusGraph.","title":"FAQs"},{"location":"advanced-topics/advschema/","text":"Advanced Schema This page describes some of the advanced schema definition options that JanusGraph provides. For general information on JanusGraph\u2019s schema and how to define it, refer to Schema and Data Modeling . Static Vertices Vertex labels can be defined as static which means that vertices with that label cannot be modified outside the transaction in which they were created. mgmt = graph . openManagement () tweet = mgmt . makeVertexLabel ( 'tweet' ). setStatic (). make () mgmt . commit () Static vertex labels are a method of controlling the data lifecycle and useful when loading data into the graph that should not be modified after its creation. Edge and Vertex TTL Edge and vertex labels can be configured with a time-to-live (TTL) . Edges and vertices with such labels will automatically be removed from the graph when the configured TTL has passed after their initial creation. TTL configuration is useful when loading a large amount of data into the graph that is only of temporary use. Defining a TTL removes the need for manual clean up and handles the removal very efficiently. For example, it would make sense to TTL event edges such as user-page visits when those are summarized after a certain period of time or simply no longer needed for analytics or operational query processing. The following storage backends support edge and vertex TTL. Cassandra HBase Edge TTL Edge TTL is defined on a per-edge label basis, meaning that all edges of that label have the same time-to-live. Note that the backend must support cell level TTL. Currently only Cassandra and HBase support this. mgmt = graph . openManagement () visits = mgmt . makeEdgeLabel ( 'visits' ). make () mgmt . setTTL ( visits , Duration . ofDays ( 7 )) mgmt . commit () Note, that modifying an edge resets the TTL for that edge. Also note, that the TTL of an edge label can be modified but it might take some time for this change to propagate to all running JanusGraph instances which means that two different TTLs can be temporarily in use for the same label. Property TTL Property TTL is very similar to edge TTL and defined on a per-property key basis, meaning that all properties of that key have the same time-to-live. Note that the backend must support cell level TTL. Currently only Cassandra and HBase support this. mgmt = graph . openManagement () sensor = mgmt . makePropertyKey ( 'sensor' ). cardinality ( Cardinality . LIST ). dataType ( Double . class ). make () mgmt . setTTL ( sensor , Duration . ofDays ( 21 )) mgmt . commit () As with edge TTL, modifying an existing property resets the TTL for that property and modifying the TTL for a property key might not immediately take effect. Vertex TTL Vertex TTL is defined on a per-vertex label basis, meaning that all vertices of that label have the same time-to-live. The configured TTL applies to the vertex, its properties, and all incident edges to ensure that the entire vertex is removed from the graph. For this reason, a vertex label must be defined as static before a TTL can be set to rule out any modifications that would invalidate the vertex TTL. Vertex TTL only applies to static vertex labels. Note that the backend must support store level TTL. Currently only Cassandra and HBase support this. mgmt = graph . openManagement () tweet = mgmt . makeVertexLabel ( 'tweet' ). setStatic (). make () mgmt . setTTL ( tweet , Duration . ofHours ( 36 )) mgmt . commit () Note, that the TTL of a vertex label can be modified but it might take some time for this change to propagate to all running JanusGraph instances which means that two different TTLs can be temporarily in use for the same label. Multi-Properties As discussed in Schema and Data Modeling , JanusGraph supports property keys with SET and LIST cardinality. Hence, JanusGraph supports multiple properties with the same key on a single vertex. Furthermore, JanusGraph treats properties similarly to edges in that single-valued property annotations are allowed on properties as shown in the following example. mgmt = graph . openManagement () mgmt . makePropertyKey ( 'name' ). dataType ( String . class ). cardinality ( Cardinality . LIST ). make () mgmt . commit () v = graph . addVertex () p1 = v . property ( 'name' , 'Dan LaRocque' ) p1 . property ( 'source' , 'web' ) p2 = v . property ( 'name' , 'dalaro' ) p2 . property ( 'source' , 'github' ) graph . tx (). commit () v . properties ( 'name' ) ==> Iterable over all name properties These features are useful in a number of applications such as those where attaching provenance information (e.g. who added a property, when and from where?) to properties is necessary. Support for higher cardinality properties and property annotations on properties is also useful in high-concurrency, scale-out design patterns as described in Eventually-Consistent Storage Backends . Vertex-centric indexes and global graph indexes are supported for properties in the same manner as they are supported for edges. Refer to Indexing for Better Performance for information on defining these indexes for edges and use the corresponding API methods to define the same indexes for properties. Unidirected Edges Unidirected edges are edges that can only be traversed in the out-going direction. Unidirected edges have a lower storage footprint but are limited in the types of traversals they support. Unidirected edges are conceptually similar to hyperlinks in the world-wide-web in the sense that the out-vertex can traverse through the edge, but the in-vertex is unaware of its existence. mgmt = graph . openManagement () mgmt . makeEdgeLabel ( 'author' ). unidirected (). make () mgmt . commit () Note, that unidirected edges do not get automatically deleted when their in-vertices are deleted. The user must ensure that such inconsistencies do not arise or resolve them at query time by explicitly checking vertex existence in a transaction. See the discussion in Ghost Vertices for more information.","title":"Advanced Schema"},{"location":"advanced-topics/advschema/#advanced-schema","text":"This page describes some of the advanced schema definition options that JanusGraph provides. For general information on JanusGraph\u2019s schema and how to define it, refer to Schema and Data Modeling .","title":"Advanced Schema"},{"location":"advanced-topics/advschema/#static-vertices","text":"Vertex labels can be defined as static which means that vertices with that label cannot be modified outside the transaction in which they were created. mgmt = graph . openManagement () tweet = mgmt . makeVertexLabel ( 'tweet' ). setStatic (). make () mgmt . commit () Static vertex labels are a method of controlling the data lifecycle and useful when loading data into the graph that should not be modified after its creation.","title":"Static Vertices"},{"location":"advanced-topics/advschema/#edge-and-vertex-ttl","text":"Edge and vertex labels can be configured with a time-to-live (TTL) . Edges and vertices with such labels will automatically be removed from the graph when the configured TTL has passed after their initial creation. TTL configuration is useful when loading a large amount of data into the graph that is only of temporary use. Defining a TTL removes the need for manual clean up and handles the removal very efficiently. For example, it would make sense to TTL event edges such as user-page visits when those are summarized after a certain period of time or simply no longer needed for analytics or operational query processing. The following storage backends support edge and vertex TTL. Cassandra HBase","title":"Edge and Vertex TTL"},{"location":"advanced-topics/advschema/#edge-ttl","text":"Edge TTL is defined on a per-edge label basis, meaning that all edges of that label have the same time-to-live. Note that the backend must support cell level TTL. Currently only Cassandra and HBase support this. mgmt = graph . openManagement () visits = mgmt . makeEdgeLabel ( 'visits' ). make () mgmt . setTTL ( visits , Duration . ofDays ( 7 )) mgmt . commit () Note, that modifying an edge resets the TTL for that edge. Also note, that the TTL of an edge label can be modified but it might take some time for this change to propagate to all running JanusGraph instances which means that two different TTLs can be temporarily in use for the same label.","title":"Edge TTL"},{"location":"advanced-topics/advschema/#property-ttl","text":"Property TTL is very similar to edge TTL and defined on a per-property key basis, meaning that all properties of that key have the same time-to-live. Note that the backend must support cell level TTL. Currently only Cassandra and HBase support this. mgmt = graph . openManagement () sensor = mgmt . makePropertyKey ( 'sensor' ). cardinality ( Cardinality . LIST ). dataType ( Double . class ). make () mgmt . setTTL ( sensor , Duration . ofDays ( 21 )) mgmt . commit () As with edge TTL, modifying an existing property resets the TTL for that property and modifying the TTL for a property key might not immediately take effect.","title":"Property TTL"},{"location":"advanced-topics/advschema/#vertex-ttl","text":"Vertex TTL is defined on a per-vertex label basis, meaning that all vertices of that label have the same time-to-live. The configured TTL applies to the vertex, its properties, and all incident edges to ensure that the entire vertex is removed from the graph. For this reason, a vertex label must be defined as static before a TTL can be set to rule out any modifications that would invalidate the vertex TTL. Vertex TTL only applies to static vertex labels. Note that the backend must support store level TTL. Currently only Cassandra and HBase support this. mgmt = graph . openManagement () tweet = mgmt . makeVertexLabel ( 'tweet' ). setStatic (). make () mgmt . setTTL ( tweet , Duration . ofHours ( 36 )) mgmt . commit () Note, that the TTL of a vertex label can be modified but it might take some time for this change to propagate to all running JanusGraph instances which means that two different TTLs can be temporarily in use for the same label.","title":"Vertex TTL"},{"location":"advanced-topics/advschema/#multi-properties","text":"As discussed in Schema and Data Modeling , JanusGraph supports property keys with SET and LIST cardinality. Hence, JanusGraph supports multiple properties with the same key on a single vertex. Furthermore, JanusGraph treats properties similarly to edges in that single-valued property annotations are allowed on properties as shown in the following example. mgmt = graph . openManagement () mgmt . makePropertyKey ( 'name' ). dataType ( String . class ). cardinality ( Cardinality . LIST ). make () mgmt . commit () v = graph . addVertex () p1 = v . property ( 'name' , 'Dan LaRocque' ) p1 . property ( 'source' , 'web' ) p2 = v . property ( 'name' , 'dalaro' ) p2 . property ( 'source' , 'github' ) graph . tx (). commit () v . properties ( 'name' ) ==> Iterable over all name properties These features are useful in a number of applications such as those where attaching provenance information (e.g. who added a property, when and from where?) to properties is necessary. Support for higher cardinality properties and property annotations on properties is also useful in high-concurrency, scale-out design patterns as described in Eventually-Consistent Storage Backends . Vertex-centric indexes and global graph indexes are supported for properties in the same manner as they are supported for edges. Refer to Indexing for Better Performance for information on defining these indexes for edges and use the corresponding API methods to define the same indexes for properties.","title":"Multi-Properties"},{"location":"advanced-topics/advschema/#unidirected-edges","text":"Unidirected edges are edges that can only be traversed in the out-going direction. Unidirected edges have a lower storage footprint but are limited in the types of traversals they support. Unidirected edges are conceptually similar to hyperlinks in the world-wide-web in the sense that the out-vertex can traverse through the edge, but the in-vertex is unaware of its existence. mgmt = graph . openManagement () mgmt . makeEdgeLabel ( 'author' ). unidirected (). make () mgmt . commit () Note, that unidirected edges do not get automatically deleted when their in-vertices are deleted. The user must ensure that such inconsistencies do not arise or resolve them at query time by explicitly checking vertex existence in a transaction. See the discussion in Ghost Vertices for more information.","title":"Unidirected Edges"},{"location":"advanced-topics/bulk-loading/","text":"Bulk Loading There are a number of configuration options and tools that make ingesting large amounts of graph data into JanusGraph more efficient. Such ingestion is referred to as bulk loading in contrast to the default transactional loading where small amounts of data are added through individual transactions. There are a number of use cases for bulk loading data into JanusGraph, including: Introducing JanusGraph into an existing environment with existing data and migrating or duplicating this data into a new JanusGraph cluster. Using JanusGraph as an end point of an ETL process. Adding an existing or external graph datasets (e.g. publicly available RDF datasets ) to a running JanusGraph cluster. Updating a JanusGraph graph with results from a graph analytics job. This page describes configuration options and tools that make bulk loading more efficient in JanusGraph. Please observe the limitations and assumptions for each option carefully before proceeding to avoid data loss or data corruption. This documentation focuses on JanusGraph specific optimization. In addition, consider improving the chosen storage backend and (optional) index backend for high write performance. Please refer to the documentation of the respective backend for more information. Configuration Options Batch Loading Enabling the storage.batch-loading configuration option will have the biggest positive impact on bulk loading times for most applications. Enabling batch loading disables JanusGraph internal consistency checks in a number of places. Most importantly, it disables locking. In other words, JanusGraph assumes that the data to be loaded into JanusGraph is consistent with the graph and hence disables its own checks in the interest of performance. In many bulk loading scenarios it is significantly cheaper to ensure data consistency prior to loading the data then ensuring data consistency while loading it into the database. The storage.batch-loading configuration option exists because of this observation. For example, consider the use case of bulk loading existing user profiles into JanusGraph. Furthermore, assume that the username property key has a unique composite index defined on it, i.e. usernames must be unique across the entire graph. If the user profiles are imported from another database, username uniqueness might already guaranteed. If not, it is simple to sort the profiles by name and filter out duplicates or writing a Hadoop job that does such filtering. Now, we can enable storage.batch-loading which significantly reduces the bulk loading time because JanusGraph does not have to check for every added user whether the name already exists in the database. Important : Enabling storage.batch-loading requires the user to ensure that the loaded data is internally consistent and consistent with any data already in the graph. In particular, concurrent type creation can lead to severe data integrity issues when batch loading is enabled. Hence, we strongly encourage disabling automatic type creation by setting schema.default = none in the graph configuration. Optimizing ID Allocation ID Block Size Each newly added vertex or edge is assigned a unique id. JanusGraph\u2019s id pool manager acquires ids in blocks for a particular JanusGraph instance. The id block acquisition process is expensive because it needs to guarantee globally unique assignment of blocks. Increasing ids.block-size reduces the number of acquisitions but potentially leaves many ids unassigned and hence wasted. For transactional workloads the default block size is reasonable, but during bulk loading vertices and edges are added much more frequently and in rapid succession. Hence, it is generally advisable to increase the block size by a factor of 10 or more depending on the number of vertices to be added per machine. Rule of thumb : Set ids.block-size to the number of vertices you expect to add per JanusGraph instance per hour. Important: All JanusGraph instances MUST be configured with the same value for ids.block-size to ensure proper id allocation. Hence, be careful to shut down all JanusGraph instances prior to changing this value. ID Acquisition Process When id blocks are frequently allocated by many JanusGraph instances in parallel, allocation conflicts between instances will inevitably arise and slow down the allocation process. In addition, the increased write load due to bulk loading may further slow down the process to the point where JanusGraph considers it failed and throws an exception. There are three configuration options that can be tuned to avoid this. 1) ids.authority.wait-time configures the time in milliseconds the id pool manager waits for an id block application to be acknowledged by the storage backend. The shorter this time, the more likely it is that an application will fail on a congested storage cluster. Rule of thumb : Set this to the sum of the 95th percentile read and write times measured on the storage backend cluster under load. Important : This value should be the same across all JanusGraph instances. 2) ids.renew-timeout configures the number of milliseconds JanusGraph\u2019s id pool manager will wait in total while attempting to acquire a new id block before failing. Rule of thumb : Set this value to be as large feasible to not have to wait too long for unrecoverable failures. The only downside of increasing it is that JanusGraph will try for a long time on an unavailable storage backend cluster. Optimizing Writes and Reads Buffer Size JanusGraph buffers writes and executes them in small batches to reduce the number of requests against the storage backend. The size of these batches is controlled by storage.buffer-size . When executing a lot of writes in a short period of time, it is possible that the storage backend can become overloaded with write requests. In that case, increasing storage.buffer-size can avoid failure by increasing the number of writes per request and thereby lowering the number of requests. However, increasing the buffer size increases the latency of the write request and its likelihood of failure. Hence, it is not advisable to increase this setting for transactional loads and one should carefully experiment with this setting during bulk loading. Read and Write Robustness During bulk loading, the load on the cluster typically increases making it more likely for read and write operations to fail (in particular if the buffer size is increased as described above). storage.read-attempts and storage.write-attempts configure how many times JanusGraph will attempt to execute a read or write operation against the storage backend before giving up. If it is expected that there is a high load on the backend during bulk loading, it is generally advisable to increase these configuration options. storage.attempt-wait specifies the number of milliseconds that JanusGraph will wait before re-attempting a failed backend operation. A higher value can ensure that operation re-tries do not further increase the load on the backend. Strategies Parallelizing the Load By parallelizing the bulk loading across multiple machines, the load time can be greatly reduced if JanusGraph\u2019s storage backend cluster is large enough to serve the additional requests. This is essentially the approach JanusGraph with TinkerPop\u2019s Hadoop-Gremlin takes to bulk loading data into JanusGraph using MapReduce. If Hadoop cannot be used for parallelizing the bulk loading process, here are some high level guidelines for effectively parallelizing the loading process: In some cases, the graph data can be decomposed into multiple disconnected subgraphs. Those subgraphs can be loaded independently in parallel across multiple machines (for instance, using BatchGraph as described above). If the graph cannot be decomposed, it is often beneficial to load in multiple steps where the last two steps can be parallelized across multiple machines: Make sure the vertex and edge data sets are de-duplicated and consistent. Set batch-loading=true . Possibly optimize additional configuration settings described above. Add all the vertices with their properties to the graph (but no edges). Maintain a (distributed) map from vertex id (as defined by the loaded data) to JanusGraph\u2019s internal vertex id (i.e. vertex.getId() ) which is a 64 bit long id. Add all the edges using the map to look-up JanusGraph\u2019s vertex id and retrieving the vertices using that id. Q&A What should I do to avoid the following exception during batch-loading: java.io.IOException: ID renewal thread on partition [X] did not complete in time. ? This exception is mostly likely caused by repeated time-outs during the id allocation phase due to highly stressed storage backend. Refer to the section on ID Allocation Optimization above.","title":"Bulk Loading"},{"location":"advanced-topics/bulk-loading/#bulk-loading","text":"There are a number of configuration options and tools that make ingesting large amounts of graph data into JanusGraph more efficient. Such ingestion is referred to as bulk loading in contrast to the default transactional loading where small amounts of data are added through individual transactions. There are a number of use cases for bulk loading data into JanusGraph, including: Introducing JanusGraph into an existing environment with existing data and migrating or duplicating this data into a new JanusGraph cluster. Using JanusGraph as an end point of an ETL process. Adding an existing or external graph datasets (e.g. publicly available RDF datasets ) to a running JanusGraph cluster. Updating a JanusGraph graph with results from a graph analytics job. This page describes configuration options and tools that make bulk loading more efficient in JanusGraph. Please observe the limitations and assumptions for each option carefully before proceeding to avoid data loss or data corruption. This documentation focuses on JanusGraph specific optimization. In addition, consider improving the chosen storage backend and (optional) index backend for high write performance. Please refer to the documentation of the respective backend for more information.","title":"Bulk Loading"},{"location":"advanced-topics/bulk-loading/#configuration-options","text":"","title":"Configuration Options"},{"location":"advanced-topics/bulk-loading/#batch-loading","text":"Enabling the storage.batch-loading configuration option will have the biggest positive impact on bulk loading times for most applications. Enabling batch loading disables JanusGraph internal consistency checks in a number of places. Most importantly, it disables locking. In other words, JanusGraph assumes that the data to be loaded into JanusGraph is consistent with the graph and hence disables its own checks in the interest of performance. In many bulk loading scenarios it is significantly cheaper to ensure data consistency prior to loading the data then ensuring data consistency while loading it into the database. The storage.batch-loading configuration option exists because of this observation. For example, consider the use case of bulk loading existing user profiles into JanusGraph. Furthermore, assume that the username property key has a unique composite index defined on it, i.e. usernames must be unique across the entire graph. If the user profiles are imported from another database, username uniqueness might already guaranteed. If not, it is simple to sort the profiles by name and filter out duplicates or writing a Hadoop job that does such filtering. Now, we can enable storage.batch-loading which significantly reduces the bulk loading time because JanusGraph does not have to check for every added user whether the name already exists in the database. Important : Enabling storage.batch-loading requires the user to ensure that the loaded data is internally consistent and consistent with any data already in the graph. In particular, concurrent type creation can lead to severe data integrity issues when batch loading is enabled. Hence, we strongly encourage disabling automatic type creation by setting schema.default = none in the graph configuration.","title":"Batch Loading"},{"location":"advanced-topics/bulk-loading/#optimizing-id-allocation","text":"","title":"Optimizing ID Allocation"},{"location":"advanced-topics/bulk-loading/#id-block-size","text":"Each newly added vertex or edge is assigned a unique id. JanusGraph\u2019s id pool manager acquires ids in blocks for a particular JanusGraph instance. The id block acquisition process is expensive because it needs to guarantee globally unique assignment of blocks. Increasing ids.block-size reduces the number of acquisitions but potentially leaves many ids unassigned and hence wasted. For transactional workloads the default block size is reasonable, but during bulk loading vertices and edges are added much more frequently and in rapid succession. Hence, it is generally advisable to increase the block size by a factor of 10 or more depending on the number of vertices to be added per machine. Rule of thumb : Set ids.block-size to the number of vertices you expect to add per JanusGraph instance per hour. Important: All JanusGraph instances MUST be configured with the same value for ids.block-size to ensure proper id allocation. Hence, be careful to shut down all JanusGraph instances prior to changing this value.","title":"ID Block Size"},{"location":"advanced-topics/bulk-loading/#id-acquisition-process","text":"When id blocks are frequently allocated by many JanusGraph instances in parallel, allocation conflicts between instances will inevitably arise and slow down the allocation process. In addition, the increased write load due to bulk loading may further slow down the process to the point where JanusGraph considers it failed and throws an exception. There are three configuration options that can be tuned to avoid this. 1) ids.authority.wait-time configures the time in milliseconds the id pool manager waits for an id block application to be acknowledged by the storage backend. The shorter this time, the more likely it is that an application will fail on a congested storage cluster. Rule of thumb : Set this to the sum of the 95th percentile read and write times measured on the storage backend cluster under load. Important : This value should be the same across all JanusGraph instances. 2) ids.renew-timeout configures the number of milliseconds JanusGraph\u2019s id pool manager will wait in total while attempting to acquire a new id block before failing. Rule of thumb : Set this value to be as large feasible to not have to wait too long for unrecoverable failures. The only downside of increasing it is that JanusGraph will try for a long time on an unavailable storage backend cluster.","title":"ID Acquisition Process"},{"location":"advanced-topics/bulk-loading/#optimizing-writes-and-reads","text":"","title":"Optimizing Writes and Reads"},{"location":"advanced-topics/bulk-loading/#buffer-size","text":"JanusGraph buffers writes and executes them in small batches to reduce the number of requests against the storage backend. The size of these batches is controlled by storage.buffer-size . When executing a lot of writes in a short period of time, it is possible that the storage backend can become overloaded with write requests. In that case, increasing storage.buffer-size can avoid failure by increasing the number of writes per request and thereby lowering the number of requests. However, increasing the buffer size increases the latency of the write request and its likelihood of failure. Hence, it is not advisable to increase this setting for transactional loads and one should carefully experiment with this setting during bulk loading.","title":"Buffer Size"},{"location":"advanced-topics/bulk-loading/#read-and-write-robustness","text":"During bulk loading, the load on the cluster typically increases making it more likely for read and write operations to fail (in particular if the buffer size is increased as described above). storage.read-attempts and storage.write-attempts configure how many times JanusGraph will attempt to execute a read or write operation against the storage backend before giving up. If it is expected that there is a high load on the backend during bulk loading, it is generally advisable to increase these configuration options. storage.attempt-wait specifies the number of milliseconds that JanusGraph will wait before re-attempting a failed backend operation. A higher value can ensure that operation re-tries do not further increase the load on the backend.","title":"Read and Write Robustness"},{"location":"advanced-topics/bulk-loading/#strategies","text":"","title":"Strategies"},{"location":"advanced-topics/bulk-loading/#parallelizing-the-load","text":"By parallelizing the bulk loading across multiple machines, the load time can be greatly reduced if JanusGraph\u2019s storage backend cluster is large enough to serve the additional requests. This is essentially the approach JanusGraph with TinkerPop\u2019s Hadoop-Gremlin takes to bulk loading data into JanusGraph using MapReduce. If Hadoop cannot be used for parallelizing the bulk loading process, here are some high level guidelines for effectively parallelizing the loading process: In some cases, the graph data can be decomposed into multiple disconnected subgraphs. Those subgraphs can be loaded independently in parallel across multiple machines (for instance, using BatchGraph as described above). If the graph cannot be decomposed, it is often beneficial to load in multiple steps where the last two steps can be parallelized across multiple machines: Make sure the vertex and edge data sets are de-duplicated and consistent. Set batch-loading=true . Possibly optimize additional configuration settings described above. Add all the vertices with their properties to the graph (but no edges). Maintain a (distributed) map from vertex id (as defined by the loaded data) to JanusGraph\u2019s internal vertex id (i.e. vertex.getId() ) which is a 64 bit long id. Add all the edges using the map to look-up JanusGraph\u2019s vertex id and retrieving the vertices using that id.","title":"Parallelizing the Load"},{"location":"advanced-topics/bulk-loading/#qa","text":"What should I do to avoid the following exception during batch-loading: java.io.IOException: ID renewal thread on partition [X] did not complete in time. ? This exception is mostly likely caused by repeated time-outs during the id allocation phase due to highly stressed storage backend. Refer to the section on ID Allocation Optimization above.","title":"Q&amp;A"},{"location":"advanced-topics/data-model/","text":"JanusGraph Data Model JanusGraph stores graphs in adjacency list format which means that a graph is stored as a collection of vertices with their adjacency list. The adjacency list of a vertex contains all of the vertex\u2019s incident edges (and properties). By storing a graph in adjacency list format JanusGraph ensures that all of a vertex\u2019s incident edges and properties are stored compactly in the storage backend which speeds up traversals. The downside is that each edge has to be stored twice - once for each end vertex of the edge. In addition, JanusGraph maintains the adjacency list of each vertex in sort order with the order being defined by the sort key and sort order the edge labels. The sort order enables efficient retrievals of subsets of the adjacency list using vertex centric indices . JanusGraph stores the adjacency list representation of a graph in any storage backend that supports the Bigtable data model. Bigtable Data Model Under the Bigtable data model each table is a collection of rows. Each row is uniquely identified by a key. Each row is comprised of an arbitrary (large, but limited) number of cells. A cell is composed of a column and value. A cell is uniquely identified by a column within a given row. Rows in the Bigtable model are called \"wide rows\" because they support a large number of cells and the columns of those cells don\u2019t have to be defined up front as is required in relational databases. JanusGraph has an additional requirement for the Bigtable data model: The cells must be sorted by their columns and a subset of the cells specified by a column range must be efficiently retrievable (e.g. by using index structures, skip lists, or binary search). In addition, a particular Bigtable implementation may keep the rows sorted in the order of their key. JanusGraph can exploit such key-order to effectively partition the graph which provides better loading and traversal performance for very large graphs. However, this is not a requirement. JanusGraph Data Layout JanusGraph stores each adjacency list as a row in the underlying storage backend. The (64 bit) vertex id (which JanusGraph uniquely assigns to every vertex) is the key which points to the row containing the vertex\u2019s adjacency list. Each edge and property is stored as an individual cell in the row which allows for efficient insertions and deletions. The maximum number of cells allowed per row in a particular storage backend is therefore also the maximum degree of a vertex that JanusGraph can support against this backend. If the storage backend supports key-order, the adjacency lists will be ordered by vertex id, and JanusGraph can assign vertex ids such that the graph is effectively partitioned. Ids are assigned such that vertices which are frequently co-accessed have ids with small absolute difference. Individual Edge Layout Each edge and property is stored as one cell in the rows of its adjacent vertices. They are serialized such that the byte order of the column respects the sort key of the edge label. Variable id encoding schemes and compressed object serialization are used to keep the storage footprint of each edge/cell as small as possible. Consider the storage layout of an individual edge as visualized in the top row of the graphic above. The dark blue boxes represent numbers that are encoded with a variable length encoding scheme to reduce the number of bytes they consume. Red boxes represent one or multiple property values (i.e. objects) that are serialized with compressed meta data referenced in the associated property key. Grey boxes represent uncompressed property values (i.e. serialized objects). The serialized representation of an edge starts with the edge label\u2019s unique id (as assigned by JanusGraph). This is typically a small number and compressed well with variable id encoding. The last bit of this id is offset to store whether this is an incoming or outgoing edge. Next, the property value comprising the sort key are stored. The sort key is defined with the edge label and hence the sort key objects meta data can be referenced to the edge label. After that, the id of the adjacent vertex is stored. JanusGraph does not store the actual vertex id but the difference to the id of the vertex that owns this adjacency list. It is likely that the difference is a smaller number than the absolute id and hence compresses better. The vertex id is followed by the id of this edge. Each edge is assigned a unique id by JanusGraph. This concludes the column value of the edge\u2019s cell. The value of the edge\u2019s cell contains the compressed serialization of the signature properties of the edge (as defined by the label\u2019s signature key) and any other properties that have been added to the edge in uncompressed serialization. The serialized representation of a property is simpler and only contains the property\u2019s key id in the column. The property id and the property value are stored in the value. If the property key is defined as list() , however, the property id is stored in the column as well.","title":"JanusGraph Data model"},{"location":"advanced-topics/data-model/#janusgraph-data-model","text":"JanusGraph stores graphs in adjacency list format which means that a graph is stored as a collection of vertices with their adjacency list. The adjacency list of a vertex contains all of the vertex\u2019s incident edges (and properties). By storing a graph in adjacency list format JanusGraph ensures that all of a vertex\u2019s incident edges and properties are stored compactly in the storage backend which speeds up traversals. The downside is that each edge has to be stored twice - once for each end vertex of the edge. In addition, JanusGraph maintains the adjacency list of each vertex in sort order with the order being defined by the sort key and sort order the edge labels. The sort order enables efficient retrievals of subsets of the adjacency list using vertex centric indices . JanusGraph stores the adjacency list representation of a graph in any storage backend that supports the Bigtable data model.","title":"JanusGraph Data Model"},{"location":"advanced-topics/data-model/#bigtable-data-model","text":"Under the Bigtable data model each table is a collection of rows. Each row is uniquely identified by a key. Each row is comprised of an arbitrary (large, but limited) number of cells. A cell is composed of a column and value. A cell is uniquely identified by a column within a given row. Rows in the Bigtable model are called \"wide rows\" because they support a large number of cells and the columns of those cells don\u2019t have to be defined up front as is required in relational databases. JanusGraph has an additional requirement for the Bigtable data model: The cells must be sorted by their columns and a subset of the cells specified by a column range must be efficiently retrievable (e.g. by using index structures, skip lists, or binary search). In addition, a particular Bigtable implementation may keep the rows sorted in the order of their key. JanusGraph can exploit such key-order to effectively partition the graph which provides better loading and traversal performance for very large graphs. However, this is not a requirement.","title":"Bigtable Data Model"},{"location":"advanced-topics/data-model/#janusgraph-data-layout","text":"JanusGraph stores each adjacency list as a row in the underlying storage backend. The (64 bit) vertex id (which JanusGraph uniquely assigns to every vertex) is the key which points to the row containing the vertex\u2019s adjacency list. Each edge and property is stored as an individual cell in the row which allows for efficient insertions and deletions. The maximum number of cells allowed per row in a particular storage backend is therefore also the maximum degree of a vertex that JanusGraph can support against this backend. If the storage backend supports key-order, the adjacency lists will be ordered by vertex id, and JanusGraph can assign vertex ids such that the graph is effectively partitioned. Ids are assigned such that vertices which are frequently co-accessed have ids with small absolute difference.","title":"JanusGraph Data Layout"},{"location":"advanced-topics/data-model/#individual-edge-layout","text":"Each edge and property is stored as one cell in the rows of its adjacent vertices. They are serialized such that the byte order of the column respects the sort key of the edge label. Variable id encoding schemes and compressed object serialization are used to keep the storage footprint of each edge/cell as small as possible. Consider the storage layout of an individual edge as visualized in the top row of the graphic above. The dark blue boxes represent numbers that are encoded with a variable length encoding scheme to reduce the number of bytes they consume. Red boxes represent one or multiple property values (i.e. objects) that are serialized with compressed meta data referenced in the associated property key. Grey boxes represent uncompressed property values (i.e. serialized objects). The serialized representation of an edge starts with the edge label\u2019s unique id (as assigned by JanusGraph). This is typically a small number and compressed well with variable id encoding. The last bit of this id is offset to store whether this is an incoming or outgoing edge. Next, the property value comprising the sort key are stored. The sort key is defined with the edge label and hence the sort key objects meta data can be referenced to the edge label. After that, the id of the adjacent vertex is stored. JanusGraph does not store the actual vertex id but the difference to the id of the vertex that owns this adjacency list. It is likely that the difference is a smaller number than the absolute id and hence compresses better. The vertex id is followed by the id of this edge. Each edge is assigned a unique id by JanusGraph. This concludes the column value of the edge\u2019s cell. The value of the edge\u2019s cell contains the compressed serialization of the signature properties of the edge (as defined by the label\u2019s signature key) and any other properties that have been added to the edge in uncompressed serialization. The serialized representation of a property is simpler and only contains the property\u2019s key id in the column. The property id and the property value are stored in the value. If the property key is defined as list() , however, the property id is stored in the column as well.","title":"Individual Edge Layout"},{"location":"advanced-topics/eventual-consistency/","text":"Eventually-Consistent Storage Backends When running JanusGraph against an eventually consistent storage backend special JanusGraph features must be used to ensure data consistency and special considerations must be made regarding data degradation. This page summarizes some of the aspects to consider when running JanusGraph on top of an eventually consistent storage backend like Apache Cassandra or Apache HBase. Data Consistency On eventually consistent storage backends, JanusGraph must obtain locks in order to ensure consistency because the underlying storage backend does not provide transactional isolation. In the interest of efficiency, JanusGraph does not use locking by default. Hence, the user has to decide for each schema element that defines a consistency constraint whether or not to use locking. Use JanusGraphManagement.setConsistency(element, ConsistencyModifier.LOCK) to explicitly enable locking on a schema element as shown in the following examples. mgmt = graph . openManagement () name = mgmt . makePropertyKey ( 'consistentName' ). dataType ( String . class ). make () index = mgmt . buildIndex ( 'byConsistentName' , Vertex . class ). addKey ( name ). unique (). buildCompositeIndex () mgmt . setConsistency ( name , ConsistencyModifier . LOCK ) // Ensures only one name per vertex mgmt . setConsistency ( index , ConsistencyModifier . LOCK ) // Ensures name uniqueness in the graph mgmt . commit () When updating an element that is guarded by a uniqueness constraint, JanusGraph uses the following protocol at the end of a transaction when calling tx.commit() : Acquire a lock on all elements that have a consistency constraint Re-read those elements from the storage backend and verify that they match the state of the element in the current transaction prior to modification. If not, the element was concurrently modified and a PermanentLocking exception is thrown. Persist the state of the transaction against the storage backend. Release all locks. This is a brief description of the locking protocol which leaves out optimizations (e.g. local conflict detection) and detection of failure scenarios (e.g. expired locks). The actual lock application mechanism is abstracted such that JanusGraph can use multiple implementations of a locking provider. Currently, two locking providers are supported in the JanusGraph distribution: A locking implementation based on key-consistent read and write operations that is agnostic to the underlying storage backend as long as it supports key-consistent operations (which includes Cassandra and HBase). This is the default implementation and uses timestamp based lock applications to determine which transaction holds the lock. A Cassandra specific locking implementation based on the Astyanax locking recipe. Both locking providers require that clocks are synchronized across all machines in the cluster. Warning The locking implementation is not robust against all failure scenarios. For instance, when a Cassandra cluster drops below quorum, consistency is no longer ensured. Hence, it is suggested to use locking-based consistency constraints sparingly with eventually consistent storage backends. For use cases that require strict and or frequent consistency constraint enforcement, it is suggested to use a storage backend that provides transactional isolation. Data Consistency without Locks Because of the additional steps required to acquire a lock when committing a modifying transaction, locking is a fairly expensive way to ensure consistency and can lead to deadlock when very many concurrent transactions try to modify the same elements in the graph. Hence, locking should be used in situations where consistency is more important than write latency and the number of conflicting transactions is small. In other situations, it may be better to allow conflicting transactions to proceed and to resolve inconsistencies at read time. This is a design pattern commonly employed in large scale data systems and most effective when the actual likelihood of conflict is small. Hence, write transactions don\u2019t incur additional overhead and any (unlikely) conflict that does occur is detected and resolved at read time and later cleaned up. JanusGraph makes it easy to use this strategy through the following features. Forking Edges Because edge are stored as single records in the underlying storage backend, concurrently modifying a single edge would lead to conflict. Instead of locking, an edge label can be configured to use ConsistencyModifier.FORK . The following example creates a new edge label related and defines its consistency to FORK. mgmt = graph . openManagement () related = mgmt . makeEdgeLabel ( 'related' ). make () mgmt . setConsistency ( related , ConsistencyModifier . FORK ) mgmt . commit () When modifying an edge whose label is configured to FORK the edge is deleted and the modified edge is added as a new one. Hence, if two concurrent transactions modify the same edge, two modified copies of the edge will exist upon commit which can be resolved during querying traversals if needed. Note Edge forking only applies to MULTI edges. Edge labels with a multiplicity constraint cannot use this strategy since a constraint is built into the edge label definition that requires an explicit lock or use the conflict resolution mechanism of the underlying storage backend. Multi-Properties Modifying single valued properties on vertices concurrently can result in a conflict. Similarly to edges, one can allow an arbitrary number of properties on a vertex for a particular property key defined with cardinality LIST and FORK on modification. Hence, instead of conflict one reads multiple properties. Since JanusGraph allows properties on properties, provenance information like author can be added to the properties to facilitate resolution at read time. See multi-properties to learn how to define those. Data Inconsistency Temporary Inconsistency On eventually consistent storage backends, writes may not be immediately visible to the entire cluster causing temporary inconsistencies in the graph. This is an inherent property of eventual consistency, in the sense, that accepted updates must be propagated to other instances in the cluster and no guarantees are made with respect to read atomicity in the interest of performance. From JanusGraph\u2019s perspective, eventual consistency might cause the following temporary graph inconsistencies in addition the general inconsistency that some parts of a transaction are visible while others aren\u2019t yet. Stale Index entries Index entries might point to nonexistent vertices or edges. Similarly, a vertex or edge appears in the graph but is not yet indexed and hence ignored by global graph queries. Half-Edges Only one direction of an edge gets persisted or deleted which might lead to the edge not being or incorrectly being retrieved. Note In order to avoid that write failures result in permanent inconsistencies in the graph it is recommended to use storage backends that support batch write atomicity and to ensure that write atomicity is enabled. To get the benefit of write atomicity, the number modifications made in a single transaction must be smaller than the configured buffer-size option documented in Configuration Reference . The buffer size defines the maximum number of modifications that JanusGraph will persist in a single batch. If a transaction has more modifications, the persistence will be split into multiple batches which are persisted individually which is useful for batch loading but invalidates write atomicity. Ghost Vertices A permanent inconsistency that can arise when operating JanusGraph on eventually consistent storage backend is the phenomena of ghost vertices . If a vertex gets deleted while it is concurrently being modified, the vertex might re-appear as a ghost . The following strategies can be used to mitigate this issue: Existence checks Configure transactions to (double) check for the existence of vertices prior to returning them. Please see Transaction Configuration for more information and note that this can significantly decrease performance. Note, that this does not fix the inconsistencies but hides some of them from the user. Regular Clean-ups Run regular batch-jobs to repair inconsistencies in the graph using JanusGraph with TinkerPop\u2019s Hadoop-Gremlin . This is the only strategy that can address all inconsistencies and effectively repair them. We will provide increasing support for such repairs in future versions of Faunus. Soft Deletes Instead of deleting vertices, they are marked as deleted which keeps them in the graph for future analysis but hides them from user-facing transactions.","title":"Eventually-Consistent Storage Backends"},{"location":"advanced-topics/eventual-consistency/#eventually-consistent-storage-backends","text":"When running JanusGraph against an eventually consistent storage backend special JanusGraph features must be used to ensure data consistency and special considerations must be made regarding data degradation. This page summarizes some of the aspects to consider when running JanusGraph on top of an eventually consistent storage backend like Apache Cassandra or Apache HBase.","title":"Eventually-Consistent Storage Backends"},{"location":"advanced-topics/eventual-consistency/#data-consistency","text":"On eventually consistent storage backends, JanusGraph must obtain locks in order to ensure consistency because the underlying storage backend does not provide transactional isolation. In the interest of efficiency, JanusGraph does not use locking by default. Hence, the user has to decide for each schema element that defines a consistency constraint whether or not to use locking. Use JanusGraphManagement.setConsistency(element, ConsistencyModifier.LOCK) to explicitly enable locking on a schema element as shown in the following examples. mgmt = graph . openManagement () name = mgmt . makePropertyKey ( 'consistentName' ). dataType ( String . class ). make () index = mgmt . buildIndex ( 'byConsistentName' , Vertex . class ). addKey ( name ). unique (). buildCompositeIndex () mgmt . setConsistency ( name , ConsistencyModifier . LOCK ) // Ensures only one name per vertex mgmt . setConsistency ( index , ConsistencyModifier . LOCK ) // Ensures name uniqueness in the graph mgmt . commit () When updating an element that is guarded by a uniqueness constraint, JanusGraph uses the following protocol at the end of a transaction when calling tx.commit() : Acquire a lock on all elements that have a consistency constraint Re-read those elements from the storage backend and verify that they match the state of the element in the current transaction prior to modification. If not, the element was concurrently modified and a PermanentLocking exception is thrown. Persist the state of the transaction against the storage backend. Release all locks. This is a brief description of the locking protocol which leaves out optimizations (e.g. local conflict detection) and detection of failure scenarios (e.g. expired locks). The actual lock application mechanism is abstracted such that JanusGraph can use multiple implementations of a locking provider. Currently, two locking providers are supported in the JanusGraph distribution: A locking implementation based on key-consistent read and write operations that is agnostic to the underlying storage backend as long as it supports key-consistent operations (which includes Cassandra and HBase). This is the default implementation and uses timestamp based lock applications to determine which transaction holds the lock. A Cassandra specific locking implementation based on the Astyanax locking recipe. Both locking providers require that clocks are synchronized across all machines in the cluster. Warning The locking implementation is not robust against all failure scenarios. For instance, when a Cassandra cluster drops below quorum, consistency is no longer ensured. Hence, it is suggested to use locking-based consistency constraints sparingly with eventually consistent storage backends. For use cases that require strict and or frequent consistency constraint enforcement, it is suggested to use a storage backend that provides transactional isolation.","title":"Data Consistency"},{"location":"advanced-topics/eventual-consistency/#data-consistency-without-locks","text":"Because of the additional steps required to acquire a lock when committing a modifying transaction, locking is a fairly expensive way to ensure consistency and can lead to deadlock when very many concurrent transactions try to modify the same elements in the graph. Hence, locking should be used in situations where consistency is more important than write latency and the number of conflicting transactions is small. In other situations, it may be better to allow conflicting transactions to proceed and to resolve inconsistencies at read time. This is a design pattern commonly employed in large scale data systems and most effective when the actual likelihood of conflict is small. Hence, write transactions don\u2019t incur additional overhead and any (unlikely) conflict that does occur is detected and resolved at read time and later cleaned up. JanusGraph makes it easy to use this strategy through the following features.","title":"Data Consistency without Locks"},{"location":"advanced-topics/eventual-consistency/#forking-edges","text":"Because edge are stored as single records in the underlying storage backend, concurrently modifying a single edge would lead to conflict. Instead of locking, an edge label can be configured to use ConsistencyModifier.FORK . The following example creates a new edge label related and defines its consistency to FORK. mgmt = graph . openManagement () related = mgmt . makeEdgeLabel ( 'related' ). make () mgmt . setConsistency ( related , ConsistencyModifier . FORK ) mgmt . commit () When modifying an edge whose label is configured to FORK the edge is deleted and the modified edge is added as a new one. Hence, if two concurrent transactions modify the same edge, two modified copies of the edge will exist upon commit which can be resolved during querying traversals if needed. Note Edge forking only applies to MULTI edges. Edge labels with a multiplicity constraint cannot use this strategy since a constraint is built into the edge label definition that requires an explicit lock or use the conflict resolution mechanism of the underlying storage backend.","title":"Forking Edges"},{"location":"advanced-topics/eventual-consistency/#multi-properties","text":"Modifying single valued properties on vertices concurrently can result in a conflict. Similarly to edges, one can allow an arbitrary number of properties on a vertex for a particular property key defined with cardinality LIST and FORK on modification. Hence, instead of conflict one reads multiple properties. Since JanusGraph allows properties on properties, provenance information like author can be added to the properties to facilitate resolution at read time. See multi-properties to learn how to define those.","title":"Multi-Properties"},{"location":"advanced-topics/eventual-consistency/#data-inconsistency","text":"","title":"Data Inconsistency"},{"location":"advanced-topics/eventual-consistency/#temporary-inconsistency","text":"On eventually consistent storage backends, writes may not be immediately visible to the entire cluster causing temporary inconsistencies in the graph. This is an inherent property of eventual consistency, in the sense, that accepted updates must be propagated to other instances in the cluster and no guarantees are made with respect to read atomicity in the interest of performance. From JanusGraph\u2019s perspective, eventual consistency might cause the following temporary graph inconsistencies in addition the general inconsistency that some parts of a transaction are visible while others aren\u2019t yet. Stale Index entries Index entries might point to nonexistent vertices or edges. Similarly, a vertex or edge appears in the graph but is not yet indexed and hence ignored by global graph queries. Half-Edges Only one direction of an edge gets persisted or deleted which might lead to the edge not being or incorrectly being retrieved. Note In order to avoid that write failures result in permanent inconsistencies in the graph it is recommended to use storage backends that support batch write atomicity and to ensure that write atomicity is enabled. To get the benefit of write atomicity, the number modifications made in a single transaction must be smaller than the configured buffer-size option documented in Configuration Reference . The buffer size defines the maximum number of modifications that JanusGraph will persist in a single batch. If a transaction has more modifications, the persistence will be split into multiple batches which are persisted individually which is useful for batch loading but invalidates write atomicity.","title":"Temporary Inconsistency"},{"location":"advanced-topics/eventual-consistency/#ghost-vertices","text":"A permanent inconsistency that can arise when operating JanusGraph on eventually consistent storage backend is the phenomena of ghost vertices . If a vertex gets deleted while it is concurrently being modified, the vertex might re-appear as a ghost . The following strategies can be used to mitigate this issue: Existence checks Configure transactions to (double) check for the existence of vertices prior to returning them. Please see Transaction Configuration for more information and note that this can significantly decrease performance. Note, that this does not fix the inconsistencies but hides some of them from the user. Regular Clean-ups Run regular batch-jobs to repair inconsistencies in the graph using JanusGraph with TinkerPop\u2019s Hadoop-Gremlin . This is the only strategy that can address all inconsistencies and effectively repair them. We will provide increasing support for such repairs in future versions of Faunus. Soft Deletes Instead of deleting vertices, they are marked as deleted which keeps them in the graph for future analysis but hides them from user-facing transactions.","title":"Ghost Vertices"},{"location":"advanced-topics/hadoop/","text":"JanusGraph with TinkerPop\u2019s Hadoop-Gremlin This chapter describes how to leverage Apache Hadoop and Apache Spark to configure JanusGraph for distributed graph processing. These steps will provide an overview on how to get started with those projects, but please refer to those project communities to become more deeply familiar with them. JanusGraph-Hadoop works with TinkerPop\u2019s hadoop-gremlin package for general-purpose OLAP. For the scope of the example below, Apache Spark is the computing framework and Apache Cassandra is the storage backend. The directions can be followed with other packages with minor changes to the configuration properties. Note The examples in this chapter are based on running Spark in local mode or standalone cluster mode. Additional configuration is required when using Spark on YARN or Mesos. Configuring Hadoop for Running OLAP For running OLAP queries from the Gremlin Console, a few prerequisites need to be fulfilled. You will need to add the Hadoop configuration directory into the CLASSPATH , and the configuration directory needs to point to a live Hadoop cluster. Hadoop provides a distributed access-controlled file system. The Hadoop file system is used by Spark workers running on different machines to have a common source for file based operations. The intermediate computations of various OLAP queries may be persisted on the Hadoop file system. For configuring a single node Hadoop cluster, please refer to official Apache Hadoop Docs Once you have a Hadoop cluster up and running, we will need to specify the Hadoop configuration files in the CLASSPATH . The below document expects that you have those configuration files located under /etc/hadoop/conf . Once verified, follow the below steps to add the Hadoop configuration to the CLASSPATH and start the Gremlin Console, which will play the role of the Spark driver program. export HADOOP_CONF_DIR = /etc/hadoop/conf export CLASSPATH = $HADOOP_CONF_DIR bin/gremlin.sh Once the path to Hadoop configuration has been added to the CLASSPATH , we can verify whether the Gremlin Console can access the Hadoop cluster by following these quick steps: gremlin > hdfs ==> storage [ org . apache . hadoop . fs . LocalFileSystem @ 65 bb9029 ] // BAD gremlin > hdfs ==> storage [ DFS [ DFSClient [ clientName = DFSClient_NONMAPREDUCE_1229457199_1 , ugi = user ( auth: SIMPLE )]]] // GOOD OLAP Traversals JanusGraph-Hadoop works with TinkerPop\u2019s hadoop-gremlin package for general-purpose OLAP to traverse over the graph, and parallelize queries by leveraging Apache Spark. OLAP Traversals with Spark Local The backend demonstrated here is Cassandra for the OLAP example below. Additional configuration will be needed that is specific to that storage backend. The configuration is specified by the gremlin.hadoop.graphReader property which specifies the class to read data from the storage backend. JanusGraph currently supports following graphReader classes: Cassandra3InputFormat for use with Cassandra 3 CassandraInputFormat for use with Cassandra 2 HBaseInputFormat and HBaseSnapshotInputFormat for use with HBase The following properties file can be used to connect a JanusGraph instance in Cassandra such that it can be used with HadoopGraph to run OLAP queries. # read-cassandra-3.properties # # Hadoop Graph Configuration # gremlin.graph=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph gremlin.hadoop.graphReader=org.janusgraph.hadoop.formats.cassandra.Cassandra3InputFormat gremlin.hadoop.graphWriter=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoOutputFormat gremlin.hadoop.jarsInDistributedCache=true gremlin.hadoop.inputLocation=none gremlin.hadoop.outputLocation=output gremlin.spark.persistContext=true # # JanusGraph Cassandra InputFormat configuration # # These properties defines the connection properties which were used while write data to JanusGraph. janusgraphmr.ioformat.conf.storage.backend=cassandra # This specifies the hostname & port for Cassandra data store. janusgraphmr.ioformat.conf.storage.hostname=127.0.0.1 janusgraphmr.ioformat.conf.storage.port=9160 # This specifies the keyspace where data is stored. janusgraphmr.ioformat.conf.storage.cassandra.keyspace=janusgraph # This defines the indexing backned configuration used while writing data to JanusGraph. janusgraphmr.ioformat.conf.index.search.backend=elasticsearch janusgraphmr.ioformat.conf.index.search.hostname=127.0.0.1 # Use the appropriate properties for the backend when using a different storage backend (HBase) or indexing backend (Solr). # # Apache Cassandra InputFormat configuration # cassandra.input.partitioner.class=org.apache.cassandra.dht.Murmur3Partitioner # # SparkGraphComputer Configuration # spark.master=local[*] spark.executor.memory=1g spark.serializer=org.apache.spark.serializer.KryoSerializer spark.kryo.registrator=org.apache.tinkerpop.gremlin.spark.structure.io.gryo.GryoRegistrator First create a properties file with above configurations, and load the same on the Gremlin Console to run OLAP queries as follows: bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- plugin activated: janusgraph.imports gremlin> :plugin use tinkerpop.hadoop == >tinkerpop.hadoop activated gremlin> :plugin use tinkerpop.spark == >tinkerpop.spark activated gremlin> // 1 . Open a the graph for OLAP processing reading in from Cassandra 3 gremlin> graph = GraphFactory.open ( 'conf/hadoop-graph/read-cassandra-3.properties' ) == >hadoopgraph [ cassandra3inputformat->gryooutputformat ] gremlin> // 2 . Configure the traversal to run with Spark gremlin> g = graph.traversal () .withComputer ( SparkGraphComputer ) == >graphtraversalsource [ hadoopgraph [ cassandra3inputformat->gryooutputformat ] , sparkgraphcomputer ] gremlin> // 3 . Run some OLAP traversals gremlin> g.V () .count () ...... == >808 gremlin> g.E () .count () ...... == > 8046 OLAP Traversals with Spark Standalone Cluster The steps followed in the previous section can also be used with a Spark standalone cluster with only minor changes: Update the spark.master property to point to the Spark master URL instead of local Update the spark.executor.extraClassPath to enable the Spark executor to find the JanusGraph dependency jars Copy the JanusGraph dependency jars into the location specified in the previous step on each Spark executor machine Note We have copied all the jars under janusgraph-distribution/lib into /opt/lib/janusgraph/ and the same directory structure is created across all workers, and jars are manually copied across all workers. The final properties file used for OLAP traversal is as follows: # read-cassandra-3.properties # # Hadoop Graph Configuration # gremlin.graph=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph gremlin.hadoop.graphReader=org.janusgraph.hadoop.formats.cassandra.Cassandra3InputFormat gremlin.hadoop.graphWriter=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoOutputFormat gremlin.hadoop.jarsInDistributedCache=true gremlin.hadoop.inputLocation=none gremlin.hadoop.outputLocation=output gremlin.spark.persistContext=true # # JanusGraph Cassandra InputFormat configuration # # These properties defines the connection properties which were used while write data to JanusGraph. janusgraphmr.ioformat.conf.storage.backend=cassandra # This specifies the hostname & port for Cassandra data store. janusgraphmr.ioformat.conf.storage.hostname=127.0.0.1 janusgraphmr.ioformat.conf.storage.port=9160 # This specifies the keyspace where data is stored. janusgraphmr.ioformat.conf.storage.cassandra.keyspace=janusgraph # This defines the indexing backned configuration used while writing data to JanusGraph. janusgraphmr.ioformat.conf.index.search.backend=elasticsearch janusgraphmr.ioformat.conf.index.search.hostname=127.0.0.1 # Use the appropriate properties for the backend when using a different storage backend (HBase) or indexing backend (Solr). # # Apache Cassandra InputFormat configuration # cassandra.input.partitioner.class=org.apache.cassandra.dht.Murmur3Partitioner # # SparkGraphComputer Configuration # spark.master=spark://127.0.0.1:7077 spark.executor.memory=1g spark.executor.extraClassPath=/opt/lib/janusgraph/* spark.serializer=org.apache.spark.serializer.KryoSerializer spark.kryo.registrator=org.apache.tinkerpop.gremlin.spark.structure.io.gryo.GryoRegistrator Then use the properties file as follows from the Gremlin Console: bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- plugin activated: janusgraph.imports gremlin> :plugin use tinkerpop.hadoop == >tinkerpop.hadoop activated gremlin> :plugin use tinkerpop.spark == >tinkerpop.spark activated gremlin> // 1 . Open a the graph for OLAP processing reading in from Cassandra 3 gremlin> graph = GraphFactory.open ( 'conf/hadoop-graph/read-cassandra-3.properties' ) == >hadoopgraph [ cassandra3inputformat->gryooutputformat ] gremlin> // 2 . Configure the traversal to run with Spark gremlin> g = graph.traversal () .withComputer ( SparkGraphComputer ) == >graphtraversalsource [ hadoopgraph [ cassandra3inputformat->gryooutputformat ] , sparkgraphcomputer ] gremlin> // 3 . Run some OLAP traversals gremlin> g.V () .count () ...... == >808 gremlin> g.E () .count () ...... == > 8046 Other Vertex Programs Apache TinkerPop provides various vertex programs. A vertex program runs on each vertex until either a termination criteria is attained or a fixed number of iterations has been reached. Due to the parallel nature of vertex programs, they can leverage parallel computing framework like Spark to improve their performance. Once you are familiar with how to configure JanusGraph to work with Spark, you can run all the other vertex programs provided by Apache TinkerPop, like Page Rank, Bulk Loading and Peer Pressure. See the TinkerPop VertexProgram docs for more details.","title":"JanusGraph with TinkerPop\u2019s Hadoop-Gremlin"},{"location":"advanced-topics/hadoop/#janusgraph-with-tinkerpops-hadoop-gremlin","text":"This chapter describes how to leverage Apache Hadoop and Apache Spark to configure JanusGraph for distributed graph processing. These steps will provide an overview on how to get started with those projects, but please refer to those project communities to become more deeply familiar with them. JanusGraph-Hadoop works with TinkerPop\u2019s hadoop-gremlin package for general-purpose OLAP. For the scope of the example below, Apache Spark is the computing framework and Apache Cassandra is the storage backend. The directions can be followed with other packages with minor changes to the configuration properties. Note The examples in this chapter are based on running Spark in local mode or standalone cluster mode. Additional configuration is required when using Spark on YARN or Mesos.","title":"JanusGraph with TinkerPop\u2019s Hadoop-Gremlin"},{"location":"advanced-topics/hadoop/#configuring-hadoop-for-running-olap","text":"For running OLAP queries from the Gremlin Console, a few prerequisites need to be fulfilled. You will need to add the Hadoop configuration directory into the CLASSPATH , and the configuration directory needs to point to a live Hadoop cluster. Hadoop provides a distributed access-controlled file system. The Hadoop file system is used by Spark workers running on different machines to have a common source for file based operations. The intermediate computations of various OLAP queries may be persisted on the Hadoop file system. For configuring a single node Hadoop cluster, please refer to official Apache Hadoop Docs Once you have a Hadoop cluster up and running, we will need to specify the Hadoop configuration files in the CLASSPATH . The below document expects that you have those configuration files located under /etc/hadoop/conf . Once verified, follow the below steps to add the Hadoop configuration to the CLASSPATH and start the Gremlin Console, which will play the role of the Spark driver program. export HADOOP_CONF_DIR = /etc/hadoop/conf export CLASSPATH = $HADOOP_CONF_DIR bin/gremlin.sh Once the path to Hadoop configuration has been added to the CLASSPATH , we can verify whether the Gremlin Console can access the Hadoop cluster by following these quick steps: gremlin > hdfs ==> storage [ org . apache . hadoop . fs . LocalFileSystem @ 65 bb9029 ] // BAD gremlin > hdfs ==> storage [ DFS [ DFSClient [ clientName = DFSClient_NONMAPREDUCE_1229457199_1 , ugi = user ( auth: SIMPLE )]]] // GOOD","title":"Configuring Hadoop for Running OLAP"},{"location":"advanced-topics/hadoop/#olap-traversals","text":"JanusGraph-Hadoop works with TinkerPop\u2019s hadoop-gremlin package for general-purpose OLAP to traverse over the graph, and parallelize queries by leveraging Apache Spark.","title":"OLAP Traversals"},{"location":"advanced-topics/hadoop/#olap-traversals-with-spark-local","text":"The backend demonstrated here is Cassandra for the OLAP example below. Additional configuration will be needed that is specific to that storage backend. The configuration is specified by the gremlin.hadoop.graphReader property which specifies the class to read data from the storage backend. JanusGraph currently supports following graphReader classes: Cassandra3InputFormat for use with Cassandra 3 CassandraInputFormat for use with Cassandra 2 HBaseInputFormat and HBaseSnapshotInputFormat for use with HBase The following properties file can be used to connect a JanusGraph instance in Cassandra such that it can be used with HadoopGraph to run OLAP queries. # read-cassandra-3.properties # # Hadoop Graph Configuration # gremlin.graph=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph gremlin.hadoop.graphReader=org.janusgraph.hadoop.formats.cassandra.Cassandra3InputFormat gremlin.hadoop.graphWriter=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoOutputFormat gremlin.hadoop.jarsInDistributedCache=true gremlin.hadoop.inputLocation=none gremlin.hadoop.outputLocation=output gremlin.spark.persistContext=true # # JanusGraph Cassandra InputFormat configuration # # These properties defines the connection properties which were used while write data to JanusGraph. janusgraphmr.ioformat.conf.storage.backend=cassandra # This specifies the hostname & port for Cassandra data store. janusgraphmr.ioformat.conf.storage.hostname=127.0.0.1 janusgraphmr.ioformat.conf.storage.port=9160 # This specifies the keyspace where data is stored. janusgraphmr.ioformat.conf.storage.cassandra.keyspace=janusgraph # This defines the indexing backned configuration used while writing data to JanusGraph. janusgraphmr.ioformat.conf.index.search.backend=elasticsearch janusgraphmr.ioformat.conf.index.search.hostname=127.0.0.1 # Use the appropriate properties for the backend when using a different storage backend (HBase) or indexing backend (Solr). # # Apache Cassandra InputFormat configuration # cassandra.input.partitioner.class=org.apache.cassandra.dht.Murmur3Partitioner # # SparkGraphComputer Configuration # spark.master=local[*] spark.executor.memory=1g spark.serializer=org.apache.spark.serializer.KryoSerializer spark.kryo.registrator=org.apache.tinkerpop.gremlin.spark.structure.io.gryo.GryoRegistrator First create a properties file with above configurations, and load the same on the Gremlin Console to run OLAP queries as follows: bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- plugin activated: janusgraph.imports gremlin> :plugin use tinkerpop.hadoop == >tinkerpop.hadoop activated gremlin> :plugin use tinkerpop.spark == >tinkerpop.spark activated gremlin> // 1 . Open a the graph for OLAP processing reading in from Cassandra 3 gremlin> graph = GraphFactory.open ( 'conf/hadoop-graph/read-cassandra-3.properties' ) == >hadoopgraph [ cassandra3inputformat->gryooutputformat ] gremlin> // 2 . Configure the traversal to run with Spark gremlin> g = graph.traversal () .withComputer ( SparkGraphComputer ) == >graphtraversalsource [ hadoopgraph [ cassandra3inputformat->gryooutputformat ] , sparkgraphcomputer ] gremlin> // 3 . Run some OLAP traversals gremlin> g.V () .count () ...... == >808 gremlin> g.E () .count () ...... == > 8046","title":"OLAP Traversals with Spark Local"},{"location":"advanced-topics/hadoop/#olap-traversals-with-spark-standalone-cluster","text":"The steps followed in the previous section can also be used with a Spark standalone cluster with only minor changes: Update the spark.master property to point to the Spark master URL instead of local Update the spark.executor.extraClassPath to enable the Spark executor to find the JanusGraph dependency jars Copy the JanusGraph dependency jars into the location specified in the previous step on each Spark executor machine Note We have copied all the jars under janusgraph-distribution/lib into /opt/lib/janusgraph/ and the same directory structure is created across all workers, and jars are manually copied across all workers. The final properties file used for OLAP traversal is as follows: # read-cassandra-3.properties # # Hadoop Graph Configuration # gremlin.graph=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph gremlin.hadoop.graphReader=org.janusgraph.hadoop.formats.cassandra.Cassandra3InputFormat gremlin.hadoop.graphWriter=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoOutputFormat gremlin.hadoop.jarsInDistributedCache=true gremlin.hadoop.inputLocation=none gremlin.hadoop.outputLocation=output gremlin.spark.persistContext=true # # JanusGraph Cassandra InputFormat configuration # # These properties defines the connection properties which were used while write data to JanusGraph. janusgraphmr.ioformat.conf.storage.backend=cassandra # This specifies the hostname & port for Cassandra data store. janusgraphmr.ioformat.conf.storage.hostname=127.0.0.1 janusgraphmr.ioformat.conf.storage.port=9160 # This specifies the keyspace where data is stored. janusgraphmr.ioformat.conf.storage.cassandra.keyspace=janusgraph # This defines the indexing backned configuration used while writing data to JanusGraph. janusgraphmr.ioformat.conf.index.search.backend=elasticsearch janusgraphmr.ioformat.conf.index.search.hostname=127.0.0.1 # Use the appropriate properties for the backend when using a different storage backend (HBase) or indexing backend (Solr). # # Apache Cassandra InputFormat configuration # cassandra.input.partitioner.class=org.apache.cassandra.dht.Murmur3Partitioner # # SparkGraphComputer Configuration # spark.master=spark://127.0.0.1:7077 spark.executor.memory=1g spark.executor.extraClassPath=/opt/lib/janusgraph/* spark.serializer=org.apache.spark.serializer.KryoSerializer spark.kryo.registrator=org.apache.tinkerpop.gremlin.spark.structure.io.gryo.GryoRegistrator Then use the properties file as follows from the Gremlin Console: bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- plugin activated: janusgraph.imports gremlin> :plugin use tinkerpop.hadoop == >tinkerpop.hadoop activated gremlin> :plugin use tinkerpop.spark == >tinkerpop.spark activated gremlin> // 1 . Open a the graph for OLAP processing reading in from Cassandra 3 gremlin> graph = GraphFactory.open ( 'conf/hadoop-graph/read-cassandra-3.properties' ) == >hadoopgraph [ cassandra3inputformat->gryooutputformat ] gremlin> // 2 . Configure the traversal to run with Spark gremlin> g = graph.traversal () .withComputer ( SparkGraphComputer ) == >graphtraversalsource [ hadoopgraph [ cassandra3inputformat->gryooutputformat ] , sparkgraphcomputer ] gremlin> // 3 . Run some OLAP traversals gremlin> g.V () .count () ...... == >808 gremlin> g.E () .count () ...... == > 8046","title":"OLAP Traversals with Spark Standalone Cluster"},{"location":"advanced-topics/hadoop/#other-vertex-programs","text":"Apache TinkerPop provides various vertex programs. A vertex program runs on each vertex until either a termination criteria is attained or a fixed number of iterations has been reached. Due to the parallel nature of vertex programs, they can leverage parallel computing framework like Spark to improve their performance. Once you are familiar with how to configure JanusGraph to work with Spark, you can run all the other vertex programs provided by Apache TinkerPop, like Page Rank, Bulk Loading and Peer Pressure. See the TinkerPop VertexProgram docs for more details.","title":"Other Vertex Programs"},{"location":"advanced-topics/janusgraph-bus/","text":"JanusGraph Bus The JanusGraph Bus describes a collection of configurable logs to which JanusGraph writes changes to the graph and its management. The JanusGraph Bus is used for internal (i.e. between multiple JanusGraph instances) and external (i.e. integration with other systems) communication. In particular, JanusGraph maintains three separate logs: Trigger Log The purpose of the trigger log is to capture the mutations of a transaction so that the resulting changes to the graph can trigger events in other system. Such events may be propagating the change to other data stores, view maintenance, or aggregate computation. The trigger log consists of multiple sub-logs as configured by the user. When opening a transaction, the identifier for the trigger sub-log can be specified: tx = g . buildTransaction (). logIdentifier ( \"purchase\" ). start (); In this case, the identifier is \"purchase\" which means that the mutations of this transaction will be written to a log with the name \"trigger_purchase\". This gives the user control over where transactional mutations are logged. If no trigger log is specified, no trigger log entry will be created. Transaction Log The transaction log is maintained by JanusGraph and contains two entries for each transaction if enabled: 1. Pre-Commit: Before the changes are persisted to the storage and indexing backends, the changes are compiled and written to the log. 2. Post-Commit: The success status of the transaction is written to the log. In this way, the transaction log functions as a Write-Ahead-Log (WAL). This log is not meant for consumption by the user or external systems - use trigger logs for that. It is used internally to store partial transaction persistence against eventually consistent backends. The transaction log can be enabled via the root-level configuration option \"log-tx\". Management Log The management log is maintained by JanusGraph internally to communicate and persist all changes to global configuration options or the graph schema.","title":"JanusGraph Bus"},{"location":"advanced-topics/janusgraph-bus/#janusgraph-bus","text":"The JanusGraph Bus describes a collection of configurable logs to which JanusGraph writes changes to the graph and its management. The JanusGraph Bus is used for internal (i.e. between multiple JanusGraph instances) and external (i.e. integration with other systems) communication. In particular, JanusGraph maintains three separate logs:","title":"JanusGraph Bus"},{"location":"advanced-topics/janusgraph-bus/#trigger-log","text":"The purpose of the trigger log is to capture the mutations of a transaction so that the resulting changes to the graph can trigger events in other system. Such events may be propagating the change to other data stores, view maintenance, or aggregate computation. The trigger log consists of multiple sub-logs as configured by the user. When opening a transaction, the identifier for the trigger sub-log can be specified: tx = g . buildTransaction (). logIdentifier ( \"purchase\" ). start (); In this case, the identifier is \"purchase\" which means that the mutations of this transaction will be written to a log with the name \"trigger_purchase\". This gives the user control over where transactional mutations are logged. If no trigger log is specified, no trigger log entry will be created.","title":"Trigger Log"},{"location":"advanced-topics/janusgraph-bus/#transaction-log","text":"The transaction log is maintained by JanusGraph and contains two entries for each transaction if enabled: 1. Pre-Commit: Before the changes are persisted to the storage and indexing backends, the changes are compiled and written to the log. 2. Post-Commit: The success status of the transaction is written to the log. In this way, the transaction log functions as a Write-Ahead-Log (WAL). This log is not meant for consumption by the user or external systems - use trigger logs for that. It is used internally to store partial transaction persistence against eventually consistent backends. The transaction log can be enabled via the root-level configuration option \"log-tx\".","title":"Transaction Log"},{"location":"advanced-topics/janusgraph-bus/#management-log","text":"The management log is maintained by JanusGraph internally to communicate and persist all changes to global configuration options or the graph schema.","title":"Management Log"},{"location":"advanced-topics/migrating/","text":"Migrating from Titan This page describes some of the Configuration options that JanusGraph provides to allow migration of data from a data store which had previously been created by Titan. Please note after migrating to version 0.3.0, or later, of JanusGraph you will not be able to connect to a graph using a Titan client. Configuration When connecting to an existing Titan data store the graph.titan-version property should already be set in the global configuration to Titan version 1.0.0 . The ID store name in JanusGraph is configurable via the ids.store-name property whereas in Titan it was a constant. If the graph.titan-version has been set in the existing global configuration, then you do not need to explicitly set the ID store as it will default to titan_ids . Cassandra The default keyspace used by Titan was titan and in order to reuse that existing keyspace the storage.cassandra.keyspace property needs to be set accordingly. storage.cassandra.keyspace=titan These configuration options allow JanusGraph to read data from a Cassandra database which had previously been created by Titan. However, once JanusGraph writes back to that database it will register additional serializers which mean that it will no longer be compatible with Titan. Users are therefore encouraged to backup the data in Casssandra before attempting to use it with the JanusGraph release. HBase The name of the table used by Titan was titan and in order to reuse that existing table the storage.hbase.table property needs to be set accordingly. storage.hbase.table=titan These configuration options allow JanusGraph to read data from an HBase database which had previously been created by Titan. However, once JanusGraph writes back to that database it will register additional serializers which mean that it will no longer be compatible with Titan. Users are therefore encouraged to backup the data in HBase before attempting to use it with the JanusGraph release. BerkeleyDB The BerkeleyDB version has been updated, and it contains changes to the file format stored on disk. This file format change is forward compatible with previous versions of BerkeleyDB, so existing graph data stored with Titan can be read in. However, once the data has been read in with the newer version of BerkeleyDB, those files can no longer be read by the older version. Users are encouraged to backup the BerkeleyDB storage directory before attempting to use it with the JanusGraph release.","title":"Migrating from Titan"},{"location":"advanced-topics/migrating/#migrating-from-titan","text":"This page describes some of the Configuration options that JanusGraph provides to allow migration of data from a data store which had previously been created by Titan. Please note after migrating to version 0.3.0, or later, of JanusGraph you will not be able to connect to a graph using a Titan client.","title":"Migrating from Titan"},{"location":"advanced-topics/migrating/#configuration","text":"When connecting to an existing Titan data store the graph.titan-version property should already be set in the global configuration to Titan version 1.0.0 . The ID store name in JanusGraph is configurable via the ids.store-name property whereas in Titan it was a constant. If the graph.titan-version has been set in the existing global configuration, then you do not need to explicitly set the ID store as it will default to titan_ids .","title":"Configuration"},{"location":"advanced-topics/migrating/#cassandra","text":"The default keyspace used by Titan was titan and in order to reuse that existing keyspace the storage.cassandra.keyspace property needs to be set accordingly. storage.cassandra.keyspace=titan These configuration options allow JanusGraph to read data from a Cassandra database which had previously been created by Titan. However, once JanusGraph writes back to that database it will register additional serializers which mean that it will no longer be compatible with Titan. Users are therefore encouraged to backup the data in Casssandra before attempting to use it with the JanusGraph release.","title":"Cassandra"},{"location":"advanced-topics/migrating/#hbase","text":"The name of the table used by Titan was titan and in order to reuse that existing table the storage.hbase.table property needs to be set accordingly. storage.hbase.table=titan These configuration options allow JanusGraph to read data from an HBase database which had previously been created by Titan. However, once JanusGraph writes back to that database it will register additional serializers which mean that it will no longer be compatible with Titan. Users are therefore encouraged to backup the data in HBase before attempting to use it with the JanusGraph release.","title":"HBase"},{"location":"advanced-topics/migrating/#berkeleydb","text":"The BerkeleyDB version has been updated, and it contains changes to the file format stored on disk. This file format change is forward compatible with previous versions of BerkeleyDB, so existing graph data stored with Titan can be read in. However, once the data has been read in with the newer version of BerkeleyDB, those files can no longer be read by the older version. Users are encouraged to backup the BerkeleyDB storage directory before attempting to use it with the JanusGraph release.","title":"BerkeleyDB"},{"location":"advanced-topics/monitoring/","text":"Monitoring JanusGraph Metrics in JanusGraph JanusGraph supports Metrics . JanusGraph can measure the following: The number of transactions begun, committed, and rolled back The number of attempts and failures of each storage backend operation type The response time distribution of each storage backend operation type Configuring Metrics Collection To enable Metrics collection, set the following in JanusGraph\u2019s properties file: # Required to enable Metrics in JanusGraph metrics.enabled = true This setting makes JanusGraph record measurements at runtime using Metrics classes like Timer, Counter, Histogram, etc. To access these measurements, one or more Metrics reporters must be configured as described in the section Configuring Metrics Reporting . Customizing the Default Metric Names JanusGraph prefixes all metric names with \"org.janusgraph\" by default. This prefix can be set through the metrics.prefix configuration property. For example, to shorten the default \"org.janusgraph\" prefix to just \"janusgraph\": # Optional metrics.prefix = janusgraph Transaction-Specific Metrics Names Each JanusGraph transaction may optionally specify its own Metrics name prefix, overriding both the default Metrics name prefix and the metrics.prefix configuration property. For example, the prefix could be changed to the name of the frontend application that opened the JanusGraph transaction. Note that Metrics maintains a ConcurrentHashMap of metric names and their associated objects in memory, so it\u2019s probably a good idea to keep the number of distinct metric prefixes small. To do this, call TransactionBuilder.setMetricsPrefix(String) : JanusGraph graph = ...; TransactionBuilder tbuilder = graph . buildTransaction (); JanusGraphTransaction tx = tbuilder . groupName ( \"foobar\" ). start (); Separating Metrics by Backend Store JanusGraph combines the Metrics for its various internal storage backend handles by default. All Metrics for storage backend interactions follow the pattern \"<prefix>.stores.<opname>\", regardless of whether they come from the ID store, edge store, etc. When metrics.merge-basic-metrics = false is set in JanusGraph\u2019s properties file, the \"stores\" string in metric names is replaced by \"idStore\", \"edgeStore\", \"vertexIndexStore\", or \"edgeIndexStore\". Configuring Metrics Reporting JanusGraph supports the following Metrics reporters: Console CSV Ganglia Graphite JMX Slf4j User-provided/Custom Each reporter type is independent of and can coexist with the others. For example, it\u2019s possible to configure Ganglia, JMX, and Slf4j Metrics reporters to operate simultaneously. Just set all their respective configuration keys in janusgraph.properties (and enable metrics as directed above). Console Reporter Metrics Console Reporter Configuration Options Config Key Required? Value Default metrics.console.interval yes Milliseconds to wait between dumping metrics to the console null Example janusgraph.properties snippet that prints metrics to the console once a minute: metrics.enabled = true # Required; specify logging interval in milliseconds metrics.console.interval = 60000 CSV File Reporter Metrics CSV Reporter Configuration Options Config Key Required? Value Default metrics.csv.interval yes Milliseconds to wait between writing CSV lines null metrics.csv.directory yes Directory in which CSV files are written (will be created if it does not exist) null Example janusgraph.properties snippet that writes CSV files once a minute to the directory ./foo/bar/ (relative to the process\u2019s working directory): metrics.enabled = true # Required; specify logging interval in milliseconds metrics.csv.interval = 60000 metrics.csv.directory = foo/bar Ganglia Reporter Note Configuration of Ganglia requires an additional library that is not packaged with JanusGraph due to its LGPL licensing that conflicts with the JanusGraph\u2019s Apache 2.0 License. To run with Ganglia monitoring, download the org.acplt:oncrpc jar from here and copy it to the JanusGraph /lib directory before starting the server. Metrics Ganglia Reporter Configuration Options Config Key Required? Value Default metrics.ganglia.hostname yes Unicast host or multicast group to which our Metrics are sent null metrics.ganglia.interval yes Milliseconds to wait between sending datagrams null metrics.ganglia.port no UDP port to which we send Metrics datagrams 8649 metrics.ganglia.addressing-mode no Must be \"unicast\" or \"multicast\" unicast metrics.ganglia.ttl no Multicast datagram TTL; ignore for unicast 1 metrics.ganglia.protocol-31 no Boolean; true to use Ganglia protocol 3.1, false to use 3.0 true metrics.ganglia.uuid no Host UUID to report instead of IP:hostname null metrics.ganglia.spoof no Override IP:hostname reported to Ganglia null Example janusgraph.properties snippet that sends unicast UDP datagrams to localhost on the default port once every 30 seconds: metrics.enabled = true # Required; IP or hostname string metrics.ganglia.hostname = 127.0.0.1 # Required; specify logging interval in milliseconds metrics.ganglia.interval = 30000 Example janusgraph.properties snippet that sends unicast UDP datagrams to a non-default destination port and which also spoofs the IP and hostname reported to Ganglia: metrics.enabled = true # Required; IP or hostname string metrics.ganglia.hostname = 1.2.3.4 # Required; specify logging interval in milliseconds metrics.ganglia.interval = 60000 # Optional metrics.ganglia.port = 6789 metrics.ganglia.spoof = 10.0.0.1:zombo.com Graphite Reporter Metrics Graphite Reporter Configuration Options Config Key Required? Value Default metrics.graphite.hostname yes IP address or hostname to which Graphite plaintext protocol data are sent null metrics.graphite.interval yes Milliseconds to wait between pushing data to Graphite null metrics.graphite.port no Port to which Graphite plaintext protocol reports are sent 2003 metrics.graphite.prefix no Arbitrary string prepended to all metric names sent to Graphite null Example janusgraph.properties snippet that sends metrics to a Graphite server on 192.168.0.1 every minute: metrics.enabled = true # Required; IP or hostname string metrics.graphite.hostname = 192.168.0.1 # Required; specify logging interval in milliseconds metrics.graphite.interval = 60000 JMX Reporter Metrics JMX Reporter Configuration Options Config Key Required? Value Default metrics.jmx.enabled yes Boolean false metrics.jmx.domain no Metrics will appear in this JMX domain Metrics\u2019s own default metrics.jmx.agentid no Metrics will be reported with this JMX agent ID Metrics\u2019s own default Example janusgraph.properties snippet: metrics.enabled = true # Required metrics.jmx.enabled = true # Optional; if omitted, then Metrics uses its default values metrics.jmx.domain = foo metrics.jmx.agentid = baz Slf4j Reporter Metrics Slf4j Reporter Configuration Options Config Key Required? Value Default metrics.slf4j.interval yes Milliseconds to wait between dumping metrics to the logger null metrics.slf4j.logger no Slf4j logger name to use \"metrics\" Example janusgraph.properties snippet that logs metrics once a minute to the logger named foo : metrics.enabled = true # Required; specify logging interval in milliseconds metrics.slf4j.interval = 60000 # Optional; uses Metrics default when unset metrics.slf4j.logger = foo User-Provided/Custom Reporter In case the Metrics reporter configuration options listed above are insufficient, JanusGraph provides a utility method to access the single MetricRegistry instance which holds all of its measurements. com . codahale . metrics . MetricRegistry janusgraphRegistry = org . janusgraph . util . stats . MetricManager . INSTANCE . getRegistry (); Code that accesses janusgraphRegistry this way can then attach non-standard reporter types or standard reporter types with exotic configurations to janusgraphRegistry . This approach is also useful if the surrounding application already has a framework for Metrics reporter configuration, or if the application needs multiple differently-configured instances of one of JanusGraph\u2019s supported reporter types. For instance, one could use this approach to setup multiple unicast Graphite reporters whereas JanusGraph\u2019s properties configuration is limited to just one Graphite reporter.","title":"Monitoring JanusGraph"},{"location":"advanced-topics/monitoring/#monitoring-janusgraph","text":"","title":"Monitoring JanusGraph"},{"location":"advanced-topics/monitoring/#metrics-in-janusgraph","text":"JanusGraph supports Metrics . JanusGraph can measure the following: The number of transactions begun, committed, and rolled back The number of attempts and failures of each storage backend operation type The response time distribution of each storage backend operation type","title":"Metrics in JanusGraph"},{"location":"advanced-topics/monitoring/#configuring-metrics-collection","text":"To enable Metrics collection, set the following in JanusGraph\u2019s properties file: # Required to enable Metrics in JanusGraph metrics.enabled = true This setting makes JanusGraph record measurements at runtime using Metrics classes like Timer, Counter, Histogram, etc. To access these measurements, one or more Metrics reporters must be configured as described in the section Configuring Metrics Reporting .","title":"Configuring Metrics Collection"},{"location":"advanced-topics/monitoring/#customizing-the-default-metric-names","text":"JanusGraph prefixes all metric names with \"org.janusgraph\" by default. This prefix can be set through the metrics.prefix configuration property. For example, to shorten the default \"org.janusgraph\" prefix to just \"janusgraph\": # Optional metrics.prefix = janusgraph","title":"Customizing the Default Metric Names"},{"location":"advanced-topics/monitoring/#transaction-specific-metrics-names","text":"Each JanusGraph transaction may optionally specify its own Metrics name prefix, overriding both the default Metrics name prefix and the metrics.prefix configuration property. For example, the prefix could be changed to the name of the frontend application that opened the JanusGraph transaction. Note that Metrics maintains a ConcurrentHashMap of metric names and their associated objects in memory, so it\u2019s probably a good idea to keep the number of distinct metric prefixes small. To do this, call TransactionBuilder.setMetricsPrefix(String) : JanusGraph graph = ...; TransactionBuilder tbuilder = graph . buildTransaction (); JanusGraphTransaction tx = tbuilder . groupName ( \"foobar\" ). start ();","title":"Transaction-Specific Metrics Names"},{"location":"advanced-topics/monitoring/#separating-metrics-by-backend-store","text":"JanusGraph combines the Metrics for its various internal storage backend handles by default. All Metrics for storage backend interactions follow the pattern \"<prefix>.stores.<opname>\", regardless of whether they come from the ID store, edge store, etc. When metrics.merge-basic-metrics = false is set in JanusGraph\u2019s properties file, the \"stores\" string in metric names is replaced by \"idStore\", \"edgeStore\", \"vertexIndexStore\", or \"edgeIndexStore\".","title":"Separating Metrics by Backend Store"},{"location":"advanced-topics/monitoring/#configuring-metrics-reporting","text":"JanusGraph supports the following Metrics reporters: Console CSV Ganglia Graphite JMX Slf4j User-provided/Custom Each reporter type is independent of and can coexist with the others. For example, it\u2019s possible to configure Ganglia, JMX, and Slf4j Metrics reporters to operate simultaneously. Just set all their respective configuration keys in janusgraph.properties (and enable metrics as directed above).","title":"Configuring Metrics Reporting"},{"location":"advanced-topics/monitoring/#console-reporter","text":"Metrics Console Reporter Configuration Options Config Key Required? Value Default metrics.console.interval yes Milliseconds to wait between dumping metrics to the console null Example janusgraph.properties snippet that prints metrics to the console once a minute: metrics.enabled = true # Required; specify logging interval in milliseconds metrics.console.interval = 60000","title":"Console Reporter"},{"location":"advanced-topics/monitoring/#csv-file-reporter","text":"Metrics CSV Reporter Configuration Options Config Key Required? Value Default metrics.csv.interval yes Milliseconds to wait between writing CSV lines null metrics.csv.directory yes Directory in which CSV files are written (will be created if it does not exist) null Example janusgraph.properties snippet that writes CSV files once a minute to the directory ./foo/bar/ (relative to the process\u2019s working directory): metrics.enabled = true # Required; specify logging interval in milliseconds metrics.csv.interval = 60000 metrics.csv.directory = foo/bar","title":"CSV File Reporter"},{"location":"advanced-topics/monitoring/#ganglia-reporter","text":"Note Configuration of Ganglia requires an additional library that is not packaged with JanusGraph due to its LGPL licensing that conflicts with the JanusGraph\u2019s Apache 2.0 License. To run with Ganglia monitoring, download the org.acplt:oncrpc jar from here and copy it to the JanusGraph /lib directory before starting the server. Metrics Ganglia Reporter Configuration Options Config Key Required? Value Default metrics.ganglia.hostname yes Unicast host or multicast group to which our Metrics are sent null metrics.ganglia.interval yes Milliseconds to wait between sending datagrams null metrics.ganglia.port no UDP port to which we send Metrics datagrams 8649 metrics.ganglia.addressing-mode no Must be \"unicast\" or \"multicast\" unicast metrics.ganglia.ttl no Multicast datagram TTL; ignore for unicast 1 metrics.ganglia.protocol-31 no Boolean; true to use Ganglia protocol 3.1, false to use 3.0 true metrics.ganglia.uuid no Host UUID to report instead of IP:hostname null metrics.ganglia.spoof no Override IP:hostname reported to Ganglia null Example janusgraph.properties snippet that sends unicast UDP datagrams to localhost on the default port once every 30 seconds: metrics.enabled = true # Required; IP or hostname string metrics.ganglia.hostname = 127.0.0.1 # Required; specify logging interval in milliseconds metrics.ganglia.interval = 30000 Example janusgraph.properties snippet that sends unicast UDP datagrams to a non-default destination port and which also spoofs the IP and hostname reported to Ganglia: metrics.enabled = true # Required; IP or hostname string metrics.ganglia.hostname = 1.2.3.4 # Required; specify logging interval in milliseconds metrics.ganglia.interval = 60000 # Optional metrics.ganglia.port = 6789 metrics.ganglia.spoof = 10.0.0.1:zombo.com","title":"Ganglia Reporter"},{"location":"advanced-topics/monitoring/#graphite-reporter","text":"Metrics Graphite Reporter Configuration Options Config Key Required? Value Default metrics.graphite.hostname yes IP address or hostname to which Graphite plaintext protocol data are sent null metrics.graphite.interval yes Milliseconds to wait between pushing data to Graphite null metrics.graphite.port no Port to which Graphite plaintext protocol reports are sent 2003 metrics.graphite.prefix no Arbitrary string prepended to all metric names sent to Graphite null Example janusgraph.properties snippet that sends metrics to a Graphite server on 192.168.0.1 every minute: metrics.enabled = true # Required; IP or hostname string metrics.graphite.hostname = 192.168.0.1 # Required; specify logging interval in milliseconds metrics.graphite.interval = 60000","title":"Graphite Reporter"},{"location":"advanced-topics/monitoring/#jmx-reporter","text":"Metrics JMX Reporter Configuration Options Config Key Required? Value Default metrics.jmx.enabled yes Boolean false metrics.jmx.domain no Metrics will appear in this JMX domain Metrics\u2019s own default metrics.jmx.agentid no Metrics will be reported with this JMX agent ID Metrics\u2019s own default Example janusgraph.properties snippet: metrics.enabled = true # Required metrics.jmx.enabled = true # Optional; if omitted, then Metrics uses its default values metrics.jmx.domain = foo metrics.jmx.agentid = baz","title":"JMX Reporter"},{"location":"advanced-topics/monitoring/#slf4j-reporter","text":"Metrics Slf4j Reporter Configuration Options Config Key Required? Value Default metrics.slf4j.interval yes Milliseconds to wait between dumping metrics to the logger null metrics.slf4j.logger no Slf4j logger name to use \"metrics\" Example janusgraph.properties snippet that logs metrics once a minute to the logger named foo : metrics.enabled = true # Required; specify logging interval in milliseconds metrics.slf4j.interval = 60000 # Optional; uses Metrics default when unset metrics.slf4j.logger = foo","title":"Slf4j Reporter"},{"location":"advanced-topics/monitoring/#user-providedcustom-reporter","text":"In case the Metrics reporter configuration options listed above are insufficient, JanusGraph provides a utility method to access the single MetricRegistry instance which holds all of its measurements. com . codahale . metrics . MetricRegistry janusgraphRegistry = org . janusgraph . util . stats . MetricManager . INSTANCE . getRegistry (); Code that accesses janusgraphRegistry this way can then attach non-standard reporter types or standard reporter types with exotic configurations to janusgraphRegistry . This approach is also useful if the surrounding application already has a framework for Metrics reporter configuration, or if the application needs multiple differently-configured instances of one of JanusGraph\u2019s supported reporter types. For instance, one could use this approach to setup multiple unicast Graphite reporters whereas JanusGraph\u2019s properties configuration is limited to just one Graphite reporter.","title":"User-Provided/Custom Reporter"},{"location":"advanced-topics/partitioning/","text":"Graph Partitioning When JanusGraph is deployed on a cluster of multiple storage backend instances, the graph is partitioned across those machines. Since JanusGraph stores the graph in an adjacency list representation the assignment of vertices to machines determines the partitioning. By default, JanusGraph uses a random partitioning strategy that randomly assigns vertices to machines. Random partitioning is very efficient, requires no configuration, and results in balanced partitions. Currently explicit partitioning is not supported. cluster.max-partitions = 32 id.placement = simple The configuration option max-partitions controls how many virtual partitions JanusGraph creates. This number should be roughly twice the number of storage backend instances. If the cluster of storage backend instances is expected to grow, estimate the size of the cluster in the foreseeable future and take this number as the baseline. Setting this number too large will unnecessarily fragment the cluster which can lead to poor performance. This number should be larger than the maximum expected number of nodes in the JanusGraph graph. It must be greater than 1 and a power of 2. There are two aspects to graph partitioning which can be individually controlled: edge cuts and vertex cuts. Edge Cut In assigning vertices to partitions one strives to optimize the assignment such that frequently co-traversed vertices are hosted on the same machine. Assume vertex A is assigned to machine 1 and vertex B is assigned to machine 2. An edge between the vertices is called a cut edge because its end points are hosted on separate machines. Traversing this edge as part of a graph query requires communication between the machines which slows down query processing. Hence, it is desirable to reduce the edge cut for frequently traversed edges. That, in turn, requires placing the adjacent vertices of frequently traversed edges in the same partition. Vertices are placed in a partition by way of the assigned vertex id. A partition is essentially a sequential range of vertex ids. To place a vertex in a particular partition, JanusGraph chooses an id from the partition\u2019s range of vertex ids. JanusGraph controls the vertex-to-partition assignment through the configured placement strategy. By default, vertices created in the same transaction are assigned to the same partition. This strategy is easy to reason about and works well in situations where frequently co-traversed vertices are created in the same transaction - either by optimizing the loading strategy to that effect or because vertices are naturally added to the graph that way. However, the strategy is limited, leads to imbalanced partitions when data is loaded in large transactions and not the optimal strategy for many use cases. The user can provide a use case specific vertex placement strategy by implementing the IDPlacementStrategy interface and registering it in the configuration through the ids.placement option. When implementing IDPlacementStrategy , note that partitions are identified by an integer id in the range from 0 to the number of configured virtual partitions minus 1. For our example configuration, there are partitions 0, 1, 2, 3, ..31. Partition ids are not the same as vertex ids. Edge cuts are more meaningful when the JanusGraph servers are on the same hosts as the storage backend. If you have to make a network call to a different host on each hop of a traversal, the benefit of edge cuts and custom placement strategies can be largely nullified. Vertex Cut While edge cut optimization aims to reduce the cross communication and thereby improve query execution, vertex cuts address the hotspot issue caused by vertices with a large number of incident edges. While vertex-centric indexes effectively address query performance for large degree vertices, vertex cuts are needed to address the hot spot issue on very large graphs. Cutting a vertex means storing a subset of that vertex\u2019s adjacency list on each partition in the graph. In other words, the vertex and its adjacency list is partitioned thereby effectively distributing the load on that single vertex across all of the instances in the cluster and removing the hot spot. JanusGraph cuts vertices by label. A vertex label can be defined as partitioned which means that all vertices of that label will be partitioned across the cluster in the manner described above. mgmt = graph . openManagement () mgmt . makeVertexLabel ( ' user ' ). make () mgmt . makeVertexLabel ( ' product ' ). partition (). make () mgmt . commit () In the example above, product is defined as a partitioned vertex label whereas user is a normal label. This configuration is beneficial for situations where there are thousands of products but millions of users and one records transactions between users and products. In that case, the product vertices will have a very high degree and the popular products turns into hot spots if they are not partitioned. Graph Partitioning FAQ Random vs. Explicit Partitioning When the graph is small or accommodated by a few storage instances, it is best to use random partitioning for its simplicity. As a rule of thumb, one should strongly consider enabling explicit graph partitioning and configure a suitable partitioning heuristic when the graph grows into the 10s of billions of edges.","title":"Graph Partitioning"},{"location":"advanced-topics/partitioning/#graph-partitioning","text":"When JanusGraph is deployed on a cluster of multiple storage backend instances, the graph is partitioned across those machines. Since JanusGraph stores the graph in an adjacency list representation the assignment of vertices to machines determines the partitioning. By default, JanusGraph uses a random partitioning strategy that randomly assigns vertices to machines. Random partitioning is very efficient, requires no configuration, and results in balanced partitions. Currently explicit partitioning is not supported. cluster.max-partitions = 32 id.placement = simple The configuration option max-partitions controls how many virtual partitions JanusGraph creates. This number should be roughly twice the number of storage backend instances. If the cluster of storage backend instances is expected to grow, estimate the size of the cluster in the foreseeable future and take this number as the baseline. Setting this number too large will unnecessarily fragment the cluster which can lead to poor performance. This number should be larger than the maximum expected number of nodes in the JanusGraph graph. It must be greater than 1 and a power of 2. There are two aspects to graph partitioning which can be individually controlled: edge cuts and vertex cuts.","title":"Graph Partitioning"},{"location":"advanced-topics/partitioning/#edge-cut","text":"In assigning vertices to partitions one strives to optimize the assignment such that frequently co-traversed vertices are hosted on the same machine. Assume vertex A is assigned to machine 1 and vertex B is assigned to machine 2. An edge between the vertices is called a cut edge because its end points are hosted on separate machines. Traversing this edge as part of a graph query requires communication between the machines which slows down query processing. Hence, it is desirable to reduce the edge cut for frequently traversed edges. That, in turn, requires placing the adjacent vertices of frequently traversed edges in the same partition. Vertices are placed in a partition by way of the assigned vertex id. A partition is essentially a sequential range of vertex ids. To place a vertex in a particular partition, JanusGraph chooses an id from the partition\u2019s range of vertex ids. JanusGraph controls the vertex-to-partition assignment through the configured placement strategy. By default, vertices created in the same transaction are assigned to the same partition. This strategy is easy to reason about and works well in situations where frequently co-traversed vertices are created in the same transaction - either by optimizing the loading strategy to that effect or because vertices are naturally added to the graph that way. However, the strategy is limited, leads to imbalanced partitions when data is loaded in large transactions and not the optimal strategy for many use cases. The user can provide a use case specific vertex placement strategy by implementing the IDPlacementStrategy interface and registering it in the configuration through the ids.placement option. When implementing IDPlacementStrategy , note that partitions are identified by an integer id in the range from 0 to the number of configured virtual partitions minus 1. For our example configuration, there are partitions 0, 1, 2, 3, ..31. Partition ids are not the same as vertex ids. Edge cuts are more meaningful when the JanusGraph servers are on the same hosts as the storage backend. If you have to make a network call to a different host on each hop of a traversal, the benefit of edge cuts and custom placement strategies can be largely nullified.","title":"Edge Cut"},{"location":"advanced-topics/partitioning/#vertex-cut","text":"While edge cut optimization aims to reduce the cross communication and thereby improve query execution, vertex cuts address the hotspot issue caused by vertices with a large number of incident edges. While vertex-centric indexes effectively address query performance for large degree vertices, vertex cuts are needed to address the hot spot issue on very large graphs. Cutting a vertex means storing a subset of that vertex\u2019s adjacency list on each partition in the graph. In other words, the vertex and its adjacency list is partitioned thereby effectively distributing the load on that single vertex across all of the instances in the cluster and removing the hot spot. JanusGraph cuts vertices by label. A vertex label can be defined as partitioned which means that all vertices of that label will be partitioned across the cluster in the manner described above. mgmt = graph . openManagement () mgmt . makeVertexLabel ( ' user ' ). make () mgmt . makeVertexLabel ( ' product ' ). partition (). make () mgmt . commit () In the example above, product is defined as a partitioned vertex label whereas user is a normal label. This configuration is beneficial for situations where there are thousands of products but millions of users and one records transactions between users and products. In that case, the product vertices will have a very high degree and the popular products turns into hot spots if they are not partitioned.","title":"Vertex Cut"},{"location":"advanced-topics/partitioning/#graph-partitioning-faq","text":"","title":"Graph Partitioning FAQ"},{"location":"advanced-topics/partitioning/#random-vs-explicit-partitioning","text":"When the graph is small or accommodated by a few storage instances, it is best to use random partitioning for its simplicity. As a rule of thumb, one should strongly consider enabling explicit graph partitioning and configure a suitable partitioning heuristic when the graph grows into the 10s of billions of edges.","title":"Random vs. Explicit Partitioning"},{"location":"advanced-topics/recovery/","text":"Failure & Recovery JanusGraph is a highly available and robust graph database. In large scale JanusGraph deployments failure is inevitable. This page describes some failure situations and how JanusGraph can handle them. Transaction Failure Transactions can fail for a number of reasons. If the transaction fails before the commit the changes will be discarded and the application can retry the transaction in coherence with the business logic. Likewise, locking or other consistency failures will cause an exception prior to persistence and hence can be retried. The persistence stage of a transaction is when JanusGraph starts persisting data to the various backend systems. JanusGraph first persists all graph mutations to the storage backend. This persistence is executed as one batch mutation to ensure that the mutation is committed atomically for those backends supporting atomicity. If the batch mutation fails due to an exception in the storage backend, the entire transaction is failed. If the primary persistence into the storage backend succeeds but secondary persistence into the indexing backends or the logging system fail, the transaction is still considered to be successful because the storage backend is the authoritative source of the graph. However, this can create inconsistencies with the indexes and logs. To automatically repair such inconsistencies, JanusGraph can maintain a transaction write-ahead log which is enabled through the configuration. tx.log-tx = true tx.max-commit-time = 10000 The max-commit-time property is used to determine when a transaction has failed. If the persistence stage of the transaction takes longer than this time, JanusGraph will attempt to recover it if necessary. Hence, this time out should be configured as a generous upper bound on the maximum duration of persistence. Note, that this does not include the time spent before commit. In addition, a separate process must be setup that reads the log to identify partially failed transaction and repair any inconsistencies caused. It is suggested to run the transaction repair process on a separate machine connected to the cluster to isolate failures. Configure a separately controlled process to run the following where the start time specifies the time since epoch where the recovery process should start reading from the write-ahead log. recovery = JanusGraphFactory . startTransactionRecovery ( graph , startTime , TimeUnit . MILLISECONDS ); Enabling the transaction write-ahead log causes an additional write operation for mutating transactions which increases the latency. Also note, that additional space is required to store the log. The transaction write-ahead log has a configurable time-to-live of 2 days which means that log entries expire after that time to keep the storage overhead small. Refer to Configuration Reference for a complete list of all log related configuration options to fine tune logging behavior. JanusGraph Instance Failure JanusGraph is robust against individual instance failure in that other instances of the JanusGraph cluster are not impacted by such failure and can continue processing transactions without loss of performance while the failed instance is restarted. However, some schema related operations - such as installing indexes - require the coordination of all JanusGraph instances. For this reason, JanusGraph maintains a record of all running instances. If an instance fails, i.e. is not properly shut down, JanusGraph considers it to be active and expects its participation in cluster-wide operations which subsequently fail because this instances did not participate in or did not acknowledge the operation. In this case, the user must manually remove the failed instance record from the cluster and then retry the operation. To remove the failed instance, open a management transaction against any of the running JanusGraph instances, inspect the list of running instances to identify the failed one, and finally remove it. mgmt = graph . openManagement () mgmt . getOpenInstances () //all open instances ==> 7 f0001016161 - dunwich1 ( current ) ==> 7 f0001016161 - atlantis1 mgmt . forceCloseInstance ( '7f0001016161-atlantis1' ) //remove an instance mgmt . commit () The unique identifier of the current JanusGraph instance is marked with the suffix (current) so that it can be easily identified. This instance cannot be closed via the forceCloseInstance method and instead should be closed via g.close() It must be ensured that the manually removed instance is indeed no longer active. Removing an active JanusGraph instance from a cluster can cause data inconsistencies. Hence, use this method with great care in particular when JanusGraph is operated in an environment where instances are automatically restarted.","title":"Failure & Recovery"},{"location":"advanced-topics/recovery/#failure-recovery","text":"JanusGraph is a highly available and robust graph database. In large scale JanusGraph deployments failure is inevitable. This page describes some failure situations and how JanusGraph can handle them.","title":"Failure &amp; Recovery"},{"location":"advanced-topics/recovery/#transaction-failure","text":"Transactions can fail for a number of reasons. If the transaction fails before the commit the changes will be discarded and the application can retry the transaction in coherence with the business logic. Likewise, locking or other consistency failures will cause an exception prior to persistence and hence can be retried. The persistence stage of a transaction is when JanusGraph starts persisting data to the various backend systems. JanusGraph first persists all graph mutations to the storage backend. This persistence is executed as one batch mutation to ensure that the mutation is committed atomically for those backends supporting atomicity. If the batch mutation fails due to an exception in the storage backend, the entire transaction is failed. If the primary persistence into the storage backend succeeds but secondary persistence into the indexing backends or the logging system fail, the transaction is still considered to be successful because the storage backend is the authoritative source of the graph. However, this can create inconsistencies with the indexes and logs. To automatically repair such inconsistencies, JanusGraph can maintain a transaction write-ahead log which is enabled through the configuration. tx.log-tx = true tx.max-commit-time = 10000 The max-commit-time property is used to determine when a transaction has failed. If the persistence stage of the transaction takes longer than this time, JanusGraph will attempt to recover it if necessary. Hence, this time out should be configured as a generous upper bound on the maximum duration of persistence. Note, that this does not include the time spent before commit. In addition, a separate process must be setup that reads the log to identify partially failed transaction and repair any inconsistencies caused. It is suggested to run the transaction repair process on a separate machine connected to the cluster to isolate failures. Configure a separately controlled process to run the following where the start time specifies the time since epoch where the recovery process should start reading from the write-ahead log. recovery = JanusGraphFactory . startTransactionRecovery ( graph , startTime , TimeUnit . MILLISECONDS ); Enabling the transaction write-ahead log causes an additional write operation for mutating transactions which increases the latency. Also note, that additional space is required to store the log. The transaction write-ahead log has a configurable time-to-live of 2 days which means that log entries expire after that time to keep the storage overhead small. Refer to Configuration Reference for a complete list of all log related configuration options to fine tune logging behavior.","title":"Transaction Failure"},{"location":"advanced-topics/recovery/#janusgraph-instance-failure","text":"JanusGraph is robust against individual instance failure in that other instances of the JanusGraph cluster are not impacted by such failure and can continue processing transactions without loss of performance while the failed instance is restarted. However, some schema related operations - such as installing indexes - require the coordination of all JanusGraph instances. For this reason, JanusGraph maintains a record of all running instances. If an instance fails, i.e. is not properly shut down, JanusGraph considers it to be active and expects its participation in cluster-wide operations which subsequently fail because this instances did not participate in or did not acknowledge the operation. In this case, the user must manually remove the failed instance record from the cluster and then retry the operation. To remove the failed instance, open a management transaction against any of the running JanusGraph instances, inspect the list of running instances to identify the failed one, and finally remove it. mgmt = graph . openManagement () mgmt . getOpenInstances () //all open instances ==> 7 f0001016161 - dunwich1 ( current ) ==> 7 f0001016161 - atlantis1 mgmt . forceCloseInstance ( '7f0001016161-atlantis1' ) //remove an instance mgmt . commit () The unique identifier of the current JanusGraph instance is marked with the suffix (current) so that it can be easily identified. This instance cannot be closed via the forceCloseInstance method and instead should be closed via g.close() It must be ensured that the manually removed instance is indeed no longer active. Removing an active JanusGraph instance from a cluster can cause data inconsistencies. Hence, use this method with great care in particular when JanusGraph is operated in an environment where instances are automatically restarted.","title":"JanusGraph Instance Failure"},{"location":"advanced-topics/serializer/","text":"Datatype and Attribute Serializer Configuration JanusGraph supports a number of classes for attribute values on properties. JanusGraph efficiently serializes primitives, primitive arrays and Geoshape , UUID , Date , ObjectNode and ArrayNode . JanusGraph supports serializing arbitrary objects as attribute values, but these require custom serializers to be defined. To configure a custom attribute class with a custom serializer, follow these steps: Implement a custom AttributeSerializer for the custom attribute class Add the following configuration options where [X] is the custom attribute id that must be larger than all attribute ids for already configured custom attributes: attributes.custom.attribute[X].attribute-class = [Full attribute class name] attributes.custom.attribute[X].serializer-class = [Full serializer class name] For example, suppose we want to register a special integer attribute class called SpecialInt and have implemented a custom serializer SpecialIntSerializer that implements AttributeSerializer . We already have 9 custom attributes configured in the configuration file, so we would add the following lines attributes.custom.attribute10.attribute-class = com.example.SpecialInt attributes.custom.attribute10.serializer-class = com.example.SpecialIntSerializer Custom Object Serialization JanusGraph supports arbitrary objects as property attributes and can serialize such objects to disk. For this default serializer to work for a custom class, the following conditions must be fulfilled: The class must implement AttributeSerializer The class must have a no-argument constructor The class must implement the equals(Object) method The last requirement is needed because JanusGraph will test both serialization and deserialization of a custom class before persisting data to disk.","title":"Datatype and Attribute Serializer Configuration"},{"location":"advanced-topics/serializer/#datatype-and-attribute-serializer-configuration","text":"JanusGraph supports a number of classes for attribute values on properties. JanusGraph efficiently serializes primitives, primitive arrays and Geoshape , UUID , Date , ObjectNode and ArrayNode . JanusGraph supports serializing arbitrary objects as attribute values, but these require custom serializers to be defined. To configure a custom attribute class with a custom serializer, follow these steps: Implement a custom AttributeSerializer for the custom attribute class Add the following configuration options where [X] is the custom attribute id that must be larger than all attribute ids for already configured custom attributes: attributes.custom.attribute[X].attribute-class = [Full attribute class name] attributes.custom.attribute[X].serializer-class = [Full serializer class name] For example, suppose we want to register a special integer attribute class called SpecialInt and have implemented a custom serializer SpecialIntSerializer that implements AttributeSerializer . We already have 9 custom attributes configured in the configuration file, so we would add the following lines attributes.custom.attribute10.attribute-class = com.example.SpecialInt attributes.custom.attribute10.serializer-class = com.example.SpecialIntSerializer","title":"Datatype and Attribute Serializer Configuration"},{"location":"advanced-topics/serializer/#custom-object-serialization","text":"JanusGraph supports arbitrary objects as property attributes and can serialize such objects to disk. For this default serializer to work for a custom class, the following conditions must be fulfilled: The class must implement AttributeSerializer The class must have a no-argument constructor The class must implement the equals(Object) method The last requirement is needed because JanusGraph will test both serialization and deserialization of a custom class before persisting data to disk.","title":"Custom Object Serialization"},{"location":"basics/cache/","text":"JanusGraph Cache Caching JanusGraph employs multiple layers of data caching to facilitate fast graph traversals. The caching layers are listed here in the order they are accessed from within a JanusGraph transaction. The closer the cache is to the transaction, the faster the cache access and the higher the memory footprint and maintenance overhead. Transaction-Level Caching Within an open transaction, JanusGraph maintains two caches: Vertex Cache: Caches accessed vertices and their adjacency list (or subsets thereof) so that subsequent access is significantly faster within the same transaction. Hence, this cache speeds up iterative traversals. Index Cache: Caches the results for index queries so that subsequent index calls can be served from memory instead of calling the index backend and (usually) waiting for one or more network round trips. The size of both of those is determined by the transaction cache size . The transaction cache size can be configured via cache.tx-cache-size or on a per transaction basis by opening a transaction via the transaction builder graph.buildTransaction() and using the setVertexCacheSize(int) method. Vertex Cache The vertex cache contains vertices and the subset of their adjacency list that has been retrieved in a particular transaction. The maximum number of vertices maintained in this cache is equal to the transaction cache size. If the transaction workload is an iterative traversal, the vertex cache will significantly speed it up. If the same vertex is not accessed again in the transaction, the transaction level cache will make no difference. Note, that the size of the vertex cache on heap is not only determined by the number of vertices it may hold but also by the size of their adjacency list. In other words, vertices with large adjacency lists (i.e. many incident edges) will consume more space in this cache than those with smaller lists. Furthermore note, that modified vertices are pinned in the cache, which means they cannot be evicted since that would entail loosing their changes. Therefore, transaction which contain a lot of modifications may end up with a larger than configured vertex cache. Index Cache The index cache contains the results of index queries executed in the context of this transaction. Subsequent identical index calls will be served from this cache and are therefore significantly cheaper. If the same index call never occurs twice in the same transaction, the index cache makes no difference. Each entry in the index cache is given a weight equal to 2 + result set size and the total weight of the cache will not exceed half of the transaction cache size. Database Level Caching The database level cache retains adjacency lists (or subsets thereof) across multiple transactions and beyond the duration of a single transaction. The database level cache is shared by all transactions across a database. It is more space efficient than the transaction level caches but also slightly slower to access. In contrast to the transaction level caches, the database level caches do not expire immediately after closing a transaction. Hence, the database level cache significantly speeds up graph traversals for read heavy workloads across transactions. Configuration Reference lists all of the configuration options that pertain to JanusGraph\u2019s database level cache. This page attempts to explain their usage. Most importantly, the database level cache is disabled by default in the current release version of JanusGraph. To enable it, set cache.db-cache=true . Cache Expiration Time The most important setting for performance and query behavior is the cache expiration time which is configured via cache.db-cache-time . The cache will hold graph elements for at most that many milliseconds. If an element expires, the data will be re-read from the storage backend on the next access. If there is only one JanusGraph instance accessing the storage backend or if this instance is the only one modifying the graph, the cache expiration can be set to 0 which disables cache expiration. This allows the cache to hold elements indefinitely (unless they are evicted due to space constraints or on update) which provides the best cache performance. Since no other JanusGraph instance is modifying the graph, there is no danger of holding on to stale data. If there are multiple JanusGraph instances accessing the storage backend, the time should be set to the maximum time that can be allowed between another JanusGraph instance modifying the graph and this JanusGraph instance seeing the data. If any change should be immediately visible to all JanusGraph instances, the database level cache should be disabled in a distributed setup. However, for most applications it is acceptable that a particular JanusGraph instance sees remote modifications with some delay. The larger the maximally allowed delay, the better the cache performance. Note, that a given JanusGraph instance will always immediately see its own modifications to the graph irrespective of the configured cache expiration time. Cache Size The configuration option cache.db-cache-size controls how much heap space JanusGraph\u2019s database level cache is allowed to consume. The larger the cache, the more effective it will be. However, large cache sizes can lead to excessive GC and poor performance. The cache size can be configured as a percentage (expressed as a decimal between 0 and 1) of the total heap space available to the JVM running JanusGraph or as an absolute number of bytes. Note, that the cache size refers to the amount of heap space that is exclusively occupied by the cache. JanusGraph\u2019s other data structures and each open transaction will occupy additional heap space. If additional software layers are running in the same JVM, those may occupy a significant amount of heap space as well (e.g. Gremlin Server, embedded Cassandra, etc). Be conservative in your heap memory estimation. Configuring a cache that is too large can lead to out-of-memory exceptions and excessive GC. Clean Up Wait Time When a vertex is locally modified (e.g. an edge is added) all of the vertex\u2019s related database level cache entries are marked as expired and eventually evicted. This will cause JanusGraph to refresh the vertex\u2019s data from the storage backend on the next access and re-populate the cache. However, when the storage backend is eventually consistent, the modifications that triggered the eviction may not yet be visible. By configuring cache.db-cache-clean-wait , the cache will wait for at least this many milliseconds before repopulating the cache with the entry retrieved from the storage backend. If JanusGraph runs locally or against a storage backend that guarantees immediate visibility of modifications, this value can be set to 0. Storage Backend Caching Each storage backend maintains its own data caching layer. These caches benefit from compression, data compactness, coordinated expiration and are often maintained off heap which means that large caches can be used without running into garbage collection issues. While these caches can be significantly larger than the database level cache, they are also slower to access. The exact type of caching and its properties depends on the particular storage backend . Please refer to the respective documentation for more information about the caching infrastructure and how to optimize it.","title":"JanusGraph Cache"},{"location":"basics/cache/#janusgraph-cache","text":"","title":"JanusGraph Cache"},{"location":"basics/cache/#caching","text":"JanusGraph employs multiple layers of data caching to facilitate fast graph traversals. The caching layers are listed here in the order they are accessed from within a JanusGraph transaction. The closer the cache is to the transaction, the faster the cache access and the higher the memory footprint and maintenance overhead.","title":"Caching"},{"location":"basics/cache/#transaction-level-caching","text":"Within an open transaction, JanusGraph maintains two caches: Vertex Cache: Caches accessed vertices and their adjacency list (or subsets thereof) so that subsequent access is significantly faster within the same transaction. Hence, this cache speeds up iterative traversals. Index Cache: Caches the results for index queries so that subsequent index calls can be served from memory instead of calling the index backend and (usually) waiting for one or more network round trips. The size of both of those is determined by the transaction cache size . The transaction cache size can be configured via cache.tx-cache-size or on a per transaction basis by opening a transaction via the transaction builder graph.buildTransaction() and using the setVertexCacheSize(int) method.","title":"Transaction-Level Caching"},{"location":"basics/cache/#vertex-cache","text":"The vertex cache contains vertices and the subset of their adjacency list that has been retrieved in a particular transaction. The maximum number of vertices maintained in this cache is equal to the transaction cache size. If the transaction workload is an iterative traversal, the vertex cache will significantly speed it up. If the same vertex is not accessed again in the transaction, the transaction level cache will make no difference. Note, that the size of the vertex cache on heap is not only determined by the number of vertices it may hold but also by the size of their adjacency list. In other words, vertices with large adjacency lists (i.e. many incident edges) will consume more space in this cache than those with smaller lists. Furthermore note, that modified vertices are pinned in the cache, which means they cannot be evicted since that would entail loosing their changes. Therefore, transaction which contain a lot of modifications may end up with a larger than configured vertex cache.","title":"Vertex Cache"},{"location":"basics/cache/#index-cache","text":"The index cache contains the results of index queries executed in the context of this transaction. Subsequent identical index calls will be served from this cache and are therefore significantly cheaper. If the same index call never occurs twice in the same transaction, the index cache makes no difference. Each entry in the index cache is given a weight equal to 2 + result set size and the total weight of the cache will not exceed half of the transaction cache size.","title":"Index Cache"},{"location":"basics/cache/#database-level-caching","text":"The database level cache retains adjacency lists (or subsets thereof) across multiple transactions and beyond the duration of a single transaction. The database level cache is shared by all transactions across a database. It is more space efficient than the transaction level caches but also slightly slower to access. In contrast to the transaction level caches, the database level caches do not expire immediately after closing a transaction. Hence, the database level cache significantly speeds up graph traversals for read heavy workloads across transactions. Configuration Reference lists all of the configuration options that pertain to JanusGraph\u2019s database level cache. This page attempts to explain their usage. Most importantly, the database level cache is disabled by default in the current release version of JanusGraph. To enable it, set cache.db-cache=true .","title":"Database Level Caching"},{"location":"basics/cache/#cache-expiration-time","text":"The most important setting for performance and query behavior is the cache expiration time which is configured via cache.db-cache-time . The cache will hold graph elements for at most that many milliseconds. If an element expires, the data will be re-read from the storage backend on the next access. If there is only one JanusGraph instance accessing the storage backend or if this instance is the only one modifying the graph, the cache expiration can be set to 0 which disables cache expiration. This allows the cache to hold elements indefinitely (unless they are evicted due to space constraints or on update) which provides the best cache performance. Since no other JanusGraph instance is modifying the graph, there is no danger of holding on to stale data. If there are multiple JanusGraph instances accessing the storage backend, the time should be set to the maximum time that can be allowed between another JanusGraph instance modifying the graph and this JanusGraph instance seeing the data. If any change should be immediately visible to all JanusGraph instances, the database level cache should be disabled in a distributed setup. However, for most applications it is acceptable that a particular JanusGraph instance sees remote modifications with some delay. The larger the maximally allowed delay, the better the cache performance. Note, that a given JanusGraph instance will always immediately see its own modifications to the graph irrespective of the configured cache expiration time.","title":"Cache Expiration Time"},{"location":"basics/cache/#cache-size","text":"The configuration option cache.db-cache-size controls how much heap space JanusGraph\u2019s database level cache is allowed to consume. The larger the cache, the more effective it will be. However, large cache sizes can lead to excessive GC and poor performance. The cache size can be configured as a percentage (expressed as a decimal between 0 and 1) of the total heap space available to the JVM running JanusGraph or as an absolute number of bytes. Note, that the cache size refers to the amount of heap space that is exclusively occupied by the cache. JanusGraph\u2019s other data structures and each open transaction will occupy additional heap space. If additional software layers are running in the same JVM, those may occupy a significant amount of heap space as well (e.g. Gremlin Server, embedded Cassandra, etc). Be conservative in your heap memory estimation. Configuring a cache that is too large can lead to out-of-memory exceptions and excessive GC.","title":"Cache Size"},{"location":"basics/cache/#clean-up-wait-time","text":"When a vertex is locally modified (e.g. an edge is added) all of the vertex\u2019s related database level cache entries are marked as expired and eventually evicted. This will cause JanusGraph to refresh the vertex\u2019s data from the storage backend on the next access and re-populate the cache. However, when the storage backend is eventually consistent, the modifications that triggered the eviction may not yet be visible. By configuring cache.db-cache-clean-wait , the cache will wait for at least this many milliseconds before repopulating the cache with the entry retrieved from the storage backend. If JanusGraph runs locally or against a storage backend that guarantees immediate visibility of modifications, this value can be set to 0.","title":"Clean Up Wait Time"},{"location":"basics/cache/#storage-backend-caching","text":"Each storage backend maintains its own data caching layer. These caches benefit from compression, data compactness, coordinated expiration and are often maintained off heap which means that large caches can be used without running into garbage collection issues. While these caches can be significantly larger than the database level cache, they are also slower to access. The exact type of caching and its properties depends on the particular storage backend . Please refer to the respective documentation for more information about the caching infrastructure and how to optimize it.","title":"Storage Backend Caching"},{"location":"basics/common-questions/","text":"Common Questions Accidental type creation By default, JanusGraph will automatically create property keys and edge labels when a new type is encountered. It is strongly encouraged that users explicitly schemata as documented in Schema and Data Modeling before loading any data and disable automatic type creation by setting the option schema.default = none . Automatic type creation can cause problems in multi-threaded or highly concurrent environments. Since JanusGraph needs to ensure that types are unique, multiple attempts at creating the same type will lead to locking or other exceptions. It is generally recommended to create all needed types up front or in one batch when new property keys and edge labels are needed. Custom Class Datatype JanusGraph supports arbitrary objects as attribute values on properties. To use a custom class as data type in JanusGraph, either register a custom serializer or ensure that the class has a no-argument constructor and implements the equals method because JanusGraph will verify that it can successfully de-/serialize objects of that class. Please see Datatype and Attribute Serializer Configuration for more information. Transactional Scope for Edges Edges should not be accessed outside the scope in which they were originally created or retrieved. Locking Exceptions When defining unique types with locking enabled (i.e. requesting that JanusGraph ensures uniqueness) it is likely to encounter locking exceptions of the type PermanentLockingException under concurrent modifications to the graph. Such exceptions are to be expected, since JanusGraph cannot know how to recover from a transactional state where an earlier read value has been modified by another transaction since this may invalidate the state of the transaction. In most cases it is sufficient to simply re-run the transaction. If locking exceptions are very frequent, try to analyze and remove the source of congestion. Ghost Vertices When the same vertex is concurrently removed in one transaction and modified in another, both transactions will successfully commit on eventually consistent storage backends and the vertex will still exist with only the modified properties or edges. This is referred to as a ghost vertex. It is possible to guard against ghost vertices on eventually consistent backends using key uniqueness but this is prohibitively expensive in most cases. A more scalable approach is to allow ghost vertices temporarily and clearing them out in regular time intervals. Another option is to detect them at read-time using the option checkInternalVertexExistence() documented in Transaction Configuration . Debug-level Logging Slows Execution When the log level is set to DEBUG JanusGraph produces a lot of logging output which is useful to understand how particular queries get compiled, optimized, and executed. However, the output is so large that it will impact the query performance noticeably. Hence, use INFO severity or higher for production systems or benchmarking. JanusGraph OutOfMemoryException or excessive Garbage Collection If you experience memory issues or excessive garbage collection while running JanusGraph it is likely that the caches are configured incorrectly. If the caches are too large, the heap may fill up with cache entries. Try reducing the size of the transaction level cache before tuning the database level cache, in particular if you have many concurrent transactions. See JanusGraph Cache for more information. JAMM Warning Messages When launching JanusGraph with embedded Cassandra, the following warnings may be displayed: 958 [MutationStage:25] WARN org.apache.cassandra.db.Memtable - MemoryMeter uninitialized (jamm not specified as java agent); assuming liveRatio of 10.0. Usually this means cassandra-env.sh disabled jamm because you are using a buggy JRE; upgrade to the Sun JRE instead Cassandra uses a Java agent called MemoryMeter which allows it to measure the actual memory use of an object, including JVM overhead. To use JAMM (Java Agent for Memory Measurements), the path to the JAMM jar must be specific in the Java javaagent parameter when launching the JVM (e.g. -javaagent:path/to/jamm.jar ) through either janusgraph.sh , gremlin.sh , or Gremlin Server: 1 export JANUSGRAPH_JAVA_OPTS=-javaagent:$JANUSGRAPH_HOME/lib/jamm-0.3.0.jar Cassandra Connection Problem By default, JanusGraph uses the Astyanax library to connect to Cassandra clusters. On EC2 and Rackspace, it has been reported that Astyanax was unable to establish a connection to the cluster. In those cases, changing the backend to storage.backend=cassandrathrift solved the problem. Elasticsearch OutOfMemoryException When numerous clients are connecting to Elasticsearch, it is likely that an OutOfMemoryException occurs. This is not due to a memory issue, but to the OS not allowing more threads to be spawned by the user (the user running Elasticsearch). To circumvent this issue, increase the number of allowed processes to the user running Elasticsearch. For example, increase the ulimit -u from the default 1024 to 10024. Dropping a Database To drop a database using the Gremlin Console you can call JanusGraphFactory.drop(graph) . The graph you want to drop needs to be defined prior to running the drop method. With ConfiguredGraphFactory graph = ConfiguredGraphFactory . open ( 'example' ) ConfiguredGraphFactory . drop ( 'example' ); With JanusGraphFactory graph = JanusGraphFactory . open ( 'path/to/configuration.properties' ) JanusGraphFactory . drop ( graph ); Note that on JanusGraph versions prior to 0.3.0 if multiple Gremlin Server instances are connecting to the graph that has been dropped it is reccomended to close the graph on all active nodes by running either JanusGraphFactory.close(graph) or ConfiguredGraphFactory.close(\"example\") depending on which graph manager is in use. Closing and reopening the graph on all active nodes will prevent cached(stale) references to the graph that has been dropped. ConfiguredGraphFactory graphs that are dropped may need to have their configurations recreated using the graph configuration singleton or template configuration .","title":"Common Questions"},{"location":"basics/common-questions/#common-questions","text":"","title":"Common Questions"},{"location":"basics/common-questions/#accidental-type-creation","text":"By default, JanusGraph will automatically create property keys and edge labels when a new type is encountered. It is strongly encouraged that users explicitly schemata as documented in Schema and Data Modeling before loading any data and disable automatic type creation by setting the option schema.default = none . Automatic type creation can cause problems in multi-threaded or highly concurrent environments. Since JanusGraph needs to ensure that types are unique, multiple attempts at creating the same type will lead to locking or other exceptions. It is generally recommended to create all needed types up front or in one batch when new property keys and edge labels are needed.","title":"Accidental type creation"},{"location":"basics/common-questions/#custom-class-datatype","text":"JanusGraph supports arbitrary objects as attribute values on properties. To use a custom class as data type in JanusGraph, either register a custom serializer or ensure that the class has a no-argument constructor and implements the equals method because JanusGraph will verify that it can successfully de-/serialize objects of that class. Please see Datatype and Attribute Serializer Configuration for more information.","title":"Custom Class Datatype"},{"location":"basics/common-questions/#transactional-scope-for-edges","text":"Edges should not be accessed outside the scope in which they were originally created or retrieved.","title":"Transactional Scope for Edges"},{"location":"basics/common-questions/#locking-exceptions","text":"When defining unique types with locking enabled (i.e. requesting that JanusGraph ensures uniqueness) it is likely to encounter locking exceptions of the type PermanentLockingException under concurrent modifications to the graph. Such exceptions are to be expected, since JanusGraph cannot know how to recover from a transactional state where an earlier read value has been modified by another transaction since this may invalidate the state of the transaction. In most cases it is sufficient to simply re-run the transaction. If locking exceptions are very frequent, try to analyze and remove the source of congestion.","title":"Locking Exceptions"},{"location":"basics/common-questions/#ghost-vertices","text":"When the same vertex is concurrently removed in one transaction and modified in another, both transactions will successfully commit on eventually consistent storage backends and the vertex will still exist with only the modified properties or edges. This is referred to as a ghost vertex. It is possible to guard against ghost vertices on eventually consistent backends using key uniqueness but this is prohibitively expensive in most cases. A more scalable approach is to allow ghost vertices temporarily and clearing them out in regular time intervals. Another option is to detect them at read-time using the option checkInternalVertexExistence() documented in Transaction Configuration .","title":"Ghost Vertices"},{"location":"basics/common-questions/#debug-level-logging-slows-execution","text":"When the log level is set to DEBUG JanusGraph produces a lot of logging output which is useful to understand how particular queries get compiled, optimized, and executed. However, the output is so large that it will impact the query performance noticeably. Hence, use INFO severity or higher for production systems or benchmarking.","title":"Debug-level Logging Slows Execution"},{"location":"basics/common-questions/#janusgraph-outofmemoryexception-or-excessive-garbage-collection","text":"If you experience memory issues or excessive garbage collection while running JanusGraph it is likely that the caches are configured incorrectly. If the caches are too large, the heap may fill up with cache entries. Try reducing the size of the transaction level cache before tuning the database level cache, in particular if you have many concurrent transactions. See JanusGraph Cache for more information.","title":"JanusGraph OutOfMemoryException or excessive Garbage Collection"},{"location":"basics/common-questions/#jamm-warning-messages","text":"When launching JanusGraph with embedded Cassandra, the following warnings may be displayed: 958 [MutationStage:25] WARN org.apache.cassandra.db.Memtable - MemoryMeter uninitialized (jamm not specified as java agent); assuming liveRatio of 10.0. Usually this means cassandra-env.sh disabled jamm because you are using a buggy JRE; upgrade to the Sun JRE instead Cassandra uses a Java agent called MemoryMeter which allows it to measure the actual memory use of an object, including JVM overhead. To use JAMM (Java Agent for Memory Measurements), the path to the JAMM jar must be specific in the Java javaagent parameter when launching the JVM (e.g. -javaagent:path/to/jamm.jar ) through either janusgraph.sh , gremlin.sh , or Gremlin Server: 1 export JANUSGRAPH_JAVA_OPTS=-javaagent:$JANUSGRAPH_HOME/lib/jamm-0.3.0.jar","title":"JAMM Warning Messages"},{"location":"basics/common-questions/#cassandra-connection-problem","text":"By default, JanusGraph uses the Astyanax library to connect to Cassandra clusters. On EC2 and Rackspace, it has been reported that Astyanax was unable to establish a connection to the cluster. In those cases, changing the backend to storage.backend=cassandrathrift solved the problem.","title":"Cassandra Connection Problem"},{"location":"basics/common-questions/#elasticsearch-outofmemoryexception","text":"When numerous clients are connecting to Elasticsearch, it is likely that an OutOfMemoryException occurs. This is not due to a memory issue, but to the OS not allowing more threads to be spawned by the user (the user running Elasticsearch). To circumvent this issue, increase the number of allowed processes to the user running Elasticsearch. For example, increase the ulimit -u from the default 1024 to 10024.","title":"Elasticsearch OutOfMemoryException"},{"location":"basics/common-questions/#dropping-a-database","text":"To drop a database using the Gremlin Console you can call JanusGraphFactory.drop(graph) . The graph you want to drop needs to be defined prior to running the drop method. With ConfiguredGraphFactory graph = ConfiguredGraphFactory . open ( 'example' ) ConfiguredGraphFactory . drop ( 'example' ); With JanusGraphFactory graph = JanusGraphFactory . open ( 'path/to/configuration.properties' ) JanusGraphFactory . drop ( graph ); Note that on JanusGraph versions prior to 0.3.0 if multiple Gremlin Server instances are connecting to the graph that has been dropped it is reccomended to close the graph on all active nodes by running either JanusGraphFactory.close(graph) or ConfiguredGraphFactory.close(\"example\") depending on which graph manager is in use. Closing and reopening the graph on all active nodes will prevent cached(stale) references to the graph that has been dropped. ConfiguredGraphFactory graphs that are dropped may need to have their configurations recreated using the graph configuration singleton or template configuration .","title":"Dropping a Database"},{"location":"basics/configuration-reference/","text":"Configuration Reference This section is the authoritative reference for JanusGraph configuration options. It includes all options for storage and indexing backends that are part of the official JanusGraph distribution. The table is automatically generated by traversing the keys and namespaces in JanusGraph\u2019s internal configuration management API. Hence, the configuration options as listed on this page are synchronized with a particular JanusGraph release. If a reference to a configuration option in other parts of this documentation is in conflict with its representation on this page, assume the version listed here to be correct. Mutability Levels Each configuration option has a certain mutability level that governs whether and how it can be modified after the database is opened for the first time. The following listing describes the mutability levels. FIXED Once the database has been opened, these configuration options cannot be changed for the entire life of the database GLOBAL_OFFLINE These options can only be changed for the entire database cluster at once when all instances are shut down GLOBAL These options can only be changed globally across the entire database cluster MASKABLE These options are global but can be overwritten by a local configuration file LOCAL These options can only be provided through a local configuration file Refer to Global Configuration for information on how to change non-local configuration options. Umbrella Namespace Namespaces marked with an asterisk are umbrella namespaces which means that they can accommodate an arbitrary number of sub-namespaces - each of which uniquely identified by its name. The configuration options listed under an umbrella namespace apply only to those sub-namespaces. Umbrella namespaces are used to configure multiple system components that are of the same type and hence have the same configuration options. For example, the log namespace is an umbrella namespace because JanusGraph can interface with multiple logging backends, such as the user log, each of which has the same core set of configuration options. To configure the send batch size of the user log to 100 transaction changes, one would have to set the following option in the configuration log.user.send-batch-size = 100 Configuration Namespaces and Options attributes.custom * Custom attribute serialization and handling Name Description Datatype Default Value Mutability attributes.custom.[X].attribute-class Class of the custom attribute to be registered String (no default value) GLOBAL_OFFLINE attributes.custom.[X].serializer-class Class of the custom attribute serializer to be registered String (no default value) GLOBAL_OFFLINE cache Configuration options that modify JanusGraph's caching behavior Name Description Datatype Default Value Mutability cache.db-cache Whether to enable JanusGraph's database-level cache, which is shared across all transactions. Enabling this option speeds up traversals by holding hot graph elements in memory, but also increases the likelihood of reading stale data. Disabling it forces each transaction to independently fetch graph elements from storage before reading/writing them. Boolean false MASKABLE cache.db-cache-clean-wait How long, in milliseconds, database-level cache will keep entries after flushing them. This option is only useful on distributed storage backends that are capable of acknowledging writes without necessarily making them immediately visible. Integer 50 GLOBAL_OFFLINE cache.db-cache-size Size of JanusGraph's database level cache. Values between 0 and 1 are interpreted as a percentage of VM heap, while larger values are interpreted as an absolute size in bytes. Double 0.3 MASKABLE cache.db-cache-time Default expiration time, in milliseconds, for entries in the database-level cache. Entries are evicted when they reach this age even if the cache has room to spare. Set to 0 to disable expiration (cache entries live forever or until memory pressure triggers eviction when set to 0). Long 10000 GLOBAL_OFFLINE cache.tx-cache-size Maximum size of the transaction-level cache of recently-used vertices. Integer 20000 MASKABLE cache.tx-dirty-size Initial size of the transaction-level cache of uncommitted dirty vertices. This is a performance hint for write-heavy, performance-sensitive transactional workloads. If set, it should roughly match the median vertices modified per transaction. Integer (no default value) MASKABLE cluster Configuration options for multi-machine deployments Name Description Datatype Default Value Mutability cluster.max-partitions The number of virtual partition blocks created in the partitioned graph. This should be larger than the maximum expected number of nodes in the JanusGraph graph cluster. Must be greater than 1 and a power of 2. Integer 32 FIXED computer GraphComputer related configuration Name Description Datatype Default Value Mutability computer.result-mode How the graph computer should return the computed results. 'persist' for writing them into the graph, 'localtx' for writing them into the local transaction, or 'none' (default) String none MASKABLE graph General configuration options Name Description Datatype Default Value Mutability graph.allow-stale-config Whether to allow the local and storage-backend-hosted copies of the configuration to contain conflicting values for options with any of the following types: FIXED, GLOBAL_OFFLINE, GLOBAL. These types are managed globally through the storage backend and cannot be overridden by changing the local configuration. This type of conflict usually indicates misconfiguration. When this option is true, JanusGraph will log these option conflicts, but continue normal operation using the storage-backend-hosted value for each conflicted option. When this option is false, JanusGraph will log these option conflicts, but then it will throw an exception, refusing to start. Boolean true MASKABLE graph.allow-upgrade Setting this to true will allow certain fixed values to be updated such as storage-version. This should only be used for upgrading. Boolean false MASKABLE graph.graphname This config option is an optional configuration setting that you may supply when opening a graph. The String value you provide will be the name of your graph. If you use the ConfigurationManagement APIs, then you will be able to access your graph by this String representation using the ConfiguredGraphFactory APIs. String (no default value) LOCAL graph.replace-instance-if-exists If a JanusGraph instance with the same instance identifier already exists, the usage of this configuration option results in the opening of this graph anwyay. Boolean false LOCAL graph.set-vertex-id Whether user provided vertex ids should be enabled and JanusGraph's automatic id allocation be disabled. Useful when operating JanusGraph in concert with another storage system that assigns long ids but disables some of JanusGraph's advanced features which can lead to inconsistent data. EXPERT FEATURE - USE WITH GREAT CARE. Boolean false FIXED graph.storage-version The version of JanusGraph storage schema with which this database was created. Automatically set on first start of graph. Should only ever be changed if upgraing to a new major release version of JanusGraph that contains schema changes String (no default value) FIXED graph.timestamps The timestamp resolution to use when writing to storage and indices. Sets the time granularity for the entire graph cluster. To avoid potential inaccuracies, the configured time resolution should match those of the backend systems. Some JanusGraph storage backends declare a preferred timestamp resolution that reflects design constraints in the underlying service. When the backend provides a preferred default, and when this setting is not explicitly declared in the config file, the backend default is used and the general default associated with this setting is ignored. An explicit declaration of this setting overrides both the general and backend-specific defaults. TimestampProviders MICRO FIXED graph.unique-instance-id Unique identifier for this JanusGraph instance. This must be unique among all instances concurrently accessing the same stores or indexes. It's automatically generated by concatenating the hostname, process id, and a static (process-wide) counter. Leaving it unset is recommended. String (no default value) LOCAL graph.unique-instance-id-suffix When this is set and unique-instance-id is not, this JanusGraph instance's unique identifier is generated by concatenating the hex encoded hostname to the provided number. Short (no default value) LOCAL graph.use-hostname-for-unique-instance-id When this is set, this JanusGraph's unique instance identifier is set to the hostname. If unique-instance-id-suffix is also set, then the identifier is set to . Boolean false LOCAL gremlin Gremlin configuration options Name Description Datatype Default Value Mutability gremlin.graph The implementation of graph factory that will be used by gremlin server String org.janusgraph.core.JanusGraphFactory LOCAL ids General configuration options for graph element IDs Name Description Datatype Default Value Mutability ids.block-size Globally reserve graph element IDs in chunks of this size. Setting this too low will make commits frequently block on slow reservation requests. Setting it too high will result in IDs wasted when a graph instance shuts down with reserved but mostly-unused blocks. Integer 10000 GLOBAL_OFFLINE ids.flush When true, vertices and edges are assigned IDs immediately upon creation. When false, IDs are assigned only when the transaction commits. Boolean true MASKABLE ids.num-partitions Number of partition block to allocate for placement of vertices Integer 10 MASKABLE ids.placement Name of the vertex placement strategy or full class name String simple MASKABLE ids.renew-percentage When the most-recently-reserved ID block has only this percentage of its total IDs remaining (expressed as a value between 0 and 1), JanusGraph asynchronously begins reserving another block. This helps avoid transaction commits waiting on ID reservation even if the block size is relatively small. Double 0.3 MASKABLE ids.renew-timeout The number of milliseconds that the JanusGraph id pool manager will wait before giving up on allocating a new block of ids Duration 120000 ms MASKABLE ids.store-name The name of the ID KCVStore. IDS_STORE_NAME is meant to be used only for backward compatibility with Titan, and should not be used explicitly in normal operations or in new graphs. String janusgraph_ids GLOBAL_OFFLINE ids.authority Configuration options for graph element ID reservation/allocation Name Description Datatype Default Value Mutability ids.authority.conflict-avoidance-mode This setting helps separate JanusGraph instances sharing a single graph storage backend avoid contention when reserving ID blocks, increasing overall throughput. ConflictAvoidanceMode NONE GLOBAL_OFFLINE ids.authority.conflict-avoidance-tag Conflict avoidance tag to be used by this JanusGraph instance when allocating IDs Integer 0 LOCAL ids.authority.conflict-avoidance-tag-bits Configures the number of bits of JanusGraph-assigned element IDs that are reserved for the conflict avoidance tag Integer 4 FIXED ids.authority.randomized-conflict-avoidance-retries Number of times the system attempts ID block reservations with random conflict avoidance tags before giving up and throwing an exception Integer 5 MASKABLE ids.authority.wait-time The number of milliseconds the system waits for an ID block reservation to be acknowledged by the storage backend Duration 300 ms GLOBAL_OFFLINE index * Configuration options for the individual indexing backends Name Description Datatype Default Value Mutability index.[X].backend The indexing backend used to extend and optimize JanusGraph's query functionality. This setting is optional. JanusGraph can use multiple heterogeneous index backends. Hence, this option can appear more than once, so long as the user-defined name between \"index\" and \"backend\" is unique among appearances.Similar to the storage backend, this should be set to one of JanusGraph's built-in shorthand names for its standard index backends (shorthands: lucene, elasticsearch, es, solr) or to the full package and classname of a custom/third-party IndexProvider implementation. String elasticsearch GLOBAL_OFFLINE index.[X].conf-file Path to a configuration file for those indexing backends that require/support a separate config file String (no default value) MASKABLE index.[X].directory Directory to store index data locally String (no default value) MASKABLE index.[X].hostname The hostname or comma-separated list of hostnames of index backend servers. This is only applicable to some index backends, such as elasticsearch and solr. String[] 127.0.0.1 MASKABLE index.[X].index-name Name of the index if required by the indexing backend String janusgraph GLOBAL_OFFLINE index.[X].map-name Whether to use the name of the property key as the field name in the index. It must be ensured, that theindexed property key names are valid field names. Renaming the property key will NOT rename the field and its the developers responsibility to avoid field collisions. Boolean true GLOBAL index.[X].max-result-set-size Maximum number of results to return if no limit is specified. For index backends that support scrolling, it represents the number of results in each batch Integer 50 MASKABLE index.[X].port The port on which to connect to index backend servers Integer (no default value) MASKABLE index.[X].elasticsearch Elasticsearch index configuration Name Description Datatype Default Value Mutability index.[X].elasticsearch.bulk-refresh Elasticsearch bulk API refresh setting used to control when changes made by this request are made visible to search String false MASKABLE index.[X].elasticsearch.health-request-timeout When JanusGraph initializes its ES backend, JanusGraph waits up to this duration for the ES cluster health to reach at least yellow status. This string should be formatted as a natural number followed by the lowercase letter \"s\", e.g. 3s or 60s. String 30s MASKABLE index.[X].elasticsearch.interface Interface for connecting to Elasticsearch. TRANSPORT_CLIENT and NODE were previously supported, but now are required to migrate to REST_CLIENT. See the JanusGraph upgrade instructions for more details. String REST_CLIENT MASKABLE index.[X].elasticsearch.max-retry-timeout Sets the maximum timeout (in milliseconds) to honour in case of multiple retries of the same request sent using the ElasticSearch Rest Client by JanusGraph. Integer (no default value) MASKABLE index.[X].elasticsearch.scroll-keep-alive How long (in seconds) elasticsearch should keep alive the scroll context. Integer 60 GLOBAL_OFFLINE index.[X].elasticsearch.use-all-field Whether JanusGraph should add an \"all\" field mapping. When enabled field mappings will include a \"copy_to\" parameter referencing the \"all\" field. This is supported since Elasticsearch 6.x and is required when using wildcard fields starting in Elasticsearch 6.x. Boolean true GLOBAL_OFFLINE index.[X].elasticsearch.use-deprecated-multitype-index Whether JanusGraph should group these indices into a single Elasticsearch index (requires Elasticsearch 5.x or earlier). Boolean false GLOBAL_OFFLINE index.[X].elasticsearch.create Settings related to index creation Name Description Datatype Default Value Mutability index.[X].elasticsearch.create.allow-mapping-update Whether JanusGraph should allow a mapping update when registering an index. Only applicable when use-external-mappings is true. Boolean false MASKABLE index.[X].elasticsearch.create.sleep How long to sleep, in milliseconds, between the successful completion of a (blocking) index creation request and the first use of that index. This only applies when creating an index in ES, which typically only happens the first time JanusGraph is started on top of ES. If the index JanusGraph is configured to use already exists, then this setting has no effect. Long 200 MASKABLE index.[X].elasticsearch.create.use-external-mappings Whether JanusGraph should make use of an external mapping when registering an index. Boolean false MASKABLE index.[X].elasticsearch.http.auth Configuration options for HTTP(S) authentication. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.type Authentication type to be used for HTTP(S) access. String NONE LOCAL index.[X].elasticsearch.http.auth.basic Configuration options for HTTP(S) Basic authentication. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.basic.password Password for HTTP(S) authentication. String LOCAL index.[X].elasticsearch.http.auth.basic.realm Realm value for HTTP(S) authentication. If empty, any realm is accepted. String LOCAL index.[X].elasticsearch.http.auth.basic.username Username for HTTP(S) authentication. String LOCAL index.[X].elasticsearch.http.auth.custom Configuration options for custom HTTP(S) authenticator. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.custom.authenticator-args Comma-separated custom authenticator constructor arguments. String[] LOCAL index.[X].elasticsearch.http.auth.custom.authenticator-class Authenticator fully qualified class name. String LOCAL index.[X].elasticsearch.ssl Elasticsearch SSL configuration Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.allow-self-signed-certificates Controls the accepting of the self-signed SSL certificates. Boolean false LOCAL index.[X].elasticsearch.ssl.disable-hostname-verification Disables the SSL hostname verification if set to true. Hostname verification is enabled by default. Boolean false LOCAL index.[X].elasticsearch.ssl.enabled Controls use of the SSL connection to Elasticsearch. Boolean false LOCAL index.[X].elasticsearch.ssl.keystore Configuration options for SSL Keystore. Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.keystore.keypassword The password to access the key in the SSL Keystore. If the option is not present, the value of \"storepassword\" is used. String LOCAL index.[X].elasticsearch.ssl.keystore.location Marks the location of the SSL Keystore. String LOCAL index.[X].elasticsearch.ssl.keystore.storepassword The password to access SSL Keystore. String LOCAL index.[X].elasticsearch.ssl.truststore Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL index.[X].elasticsearch.ssl.truststore.password The password to access SSL Truststore. String LOCAL index.[X].solr Solr index configuration Name Description Datatype Default Value Mutability index.[X].solr.configset If specified, the same solr configSet can be reused for each new Collection that is created in SolrCloud. String (no default value) MASKABLE index.[X].solr.dyn-fields Whether to use dynamic fields (which appends the data type to the field name). If dynamic fields is disabledthe user must map field names and define them explicitly in the schema. Boolean true GLOBAL_OFFLINE index.[X].solr.http-compression Enable/disable compression on the HTTP connections made to Solr. Boolean false MASKABLE index.[X].solr.http-connection-timeout Solr HTTP connection timeout. Integer 5000 MASKABLE index.[X].solr.http-max Maximum number of HTTP connections in total to all Solr servers. Integer 100 MASKABLE index.[X].solr.http-max-per-host Maximum number of HTTP connections per Solr host. Integer 20 MASKABLE index.[X].solr.http-urls List of URLs to use to connect to Solr Servers (LBHttpSolrClient is used), don't add core or collection name to the URL. String[] http://localhost:8983/solr MASKABLE index.[X].solr.kerberos-enabled Whether SOLR instance is Kerberized or not. Boolean false MASKABLE index.[X].solr.key-field-names Field name that uniquely identifies each document in Solr. Must be specified as a list of collection=field . String[] (no default value) GLOBAL index.[X].solr.max-shards-per-node Maximum number of shards per node. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.mode The operation mode for Solr which is either via HTTP ( http ) or using SolrCloud ( cloud ) String cloud GLOBAL_OFFLINE index.[X].solr.num-shards Number of shards for a collection. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.replication-factor Replication factor for a collection. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.ttl_field Name of the TTL field for Solr collections. String ttl GLOBAL_OFFLINE index.[X].solr.wait-searcher When mutating - wait for the index to reflect new mutations before returning. This can have a negative impact on performance. Boolean false LOCAL index.[X].solr.zookeeper-url URL of the Zookeeper instance coordinating the SolrCloud cluster String[] localhost:2181 MASKABLE log * Configuration options for JanusGraph's logging system Name Description Datatype Default Value Mutability log.[X].backend Define the log backed to use String default GLOBAL_OFFLINE log.[X].fixed-partition Whether all log entries are written to one fixed partition even if the backend store is partitioned.This can cause imbalanced loads and should only be used on low volume logs Boolean false GLOBAL_OFFLINE log.[X].key-consistent Whether to require consistency for log reading and writing messages to the storage backend Boolean false MASKABLE log.[X].max-partitions The maximum number of partitions to use for logging. Setting up this many actual or virtual partitions. Must be bigger than 0and a power of 2. Integer (no default value) FIXED log.[X].max-read-time Maximum time in ms to try reading log messages from the backend before failing. Duration 4000 ms MASKABLE log.[X].max-write-time Maximum time in ms to try persisting log messages against the backend before failing. Duration 10000 ms MASKABLE log.[X].num-buckets The number of buckets to split log entries into for load balancing Integer 1 GLOBAL_OFFLINE log.[X].read-batch-size Maximum number of log messages to read at a time for logging implementations that read messages in batches Integer 1024 MASKABLE log.[X].read-interval Time in ms between message readings from the backend for this logging implementations that read message in batch Duration 5000 ms MASKABLE log.[X].read-lag-time Maximum time in ms that it may take for reads to appear in the backend. If a write does not becomevisible in the storage backend in this amount of time, a log reader might miss the message. Duration 500 ms MASKABLE log.[X].read-threads Number of threads to be used in reading and processing log messages Integer 1 MASKABLE log.[X].send-batch-size Maximum number of log messages to batch up for sending for logging implementations that support batch sending Integer 256 MASKABLE log.[X].send-delay Maximum time in ms that messages can be buffered locally before sending in batch Duration 1000 ms MASKABLE log.[X].ttl Sets a TTL on all log entries, meaningthat all entries added to this log expire after the configured amount of time. Requiresthat the log implementation supports TTL. Duration (no default value) GLOBAL metrics Configuration options for metrics reporting Name Description Datatype Default Value Mutability metrics.enabled Whether to enable basic timing and operation count monitoring on backend Boolean false MASKABLE metrics.merge-stores Whether to aggregate measurements for the edge store, vertex index, edge index, and ID store Boolean true MASKABLE metrics.prefix The default name prefix for Metrics reported by JanusGraph. String org.janusgraph MASKABLE metrics.console Configuration options for metrics reporting to console Name Description Datatype Default Value Mutability metrics.console.interval Time between Metrics reports printing to the console, in milliseconds Duration (no default value) MASKABLE metrics.csv Configuration options for metrics reporting to CSV file Name Description Datatype Default Value Mutability metrics.csv.directory Metrics CSV output directory String (no default value) MASKABLE metrics.csv.interval Time between dumps of CSV files containing Metrics data, in milliseconds Duration (no default value) MASKABLE metrics.ganglia Configuration options for metrics reporting through Ganglia Name Description Datatype Default Value Mutability metrics.ganglia.addressing-mode Whether to communicate to Ganglia via uni- or multicast String unicast MASKABLE metrics.ganglia.hostname The unicast host or multicast group name to which Metrics will send Ganglia data String (no default value) MASKABLE metrics.ganglia.interval The number of milliseconds to wait between sending Metrics data to Ganglia Duration (no default value) MASKABLE metrics.ganglia.port The port to which Ganglia data are sent Integer 8649 MASKABLE metrics.ganglia.protocol-31 Whether to send data to Ganglia in the 3.1 protocol format Boolean true MASKABLE metrics.ganglia.spoof If non-null, it must be a valid Gmetric spoof string formatted as an IP:hostname pair. See https://github.com/ganglia/monitor-core/wiki/Gmetric-Spoofing for information about this setting. String (no default value) MASKABLE metrics.ganglia.ttl The multicast TTL to set on outgoing Ganglia datagrams Integer 1 MASKABLE metrics.ganglia.uuid The host UUID to set on outgoing Ganglia datagrams. See https://github.com/ganglia/monitor-core/wiki/UUIDSources for information about this setting. String (no default value) LOCAL metrics.graphite Configuration options for metrics reporting through Graphite Name Description Datatype Default Value Mutability metrics.graphite.hostname The hostname to receive Graphite plaintext protocol metric data String (no default value) MASKABLE metrics.graphite.interval The number of milliseconds to wait between sending Metrics data Duration (no default value) MASKABLE metrics.graphite.port The port to which Graphite data are sent Integer 2003 MASKABLE metrics.graphite.prefix A Graphite-specific prefix for reported metrics String (no default value) MASKABLE metrics.jmx Configuration options for metrics reporting through JMX Name Description Datatype Default Value Mutability metrics.jmx.agentid The JMX agentId used by Metrics String (no default value) MASKABLE metrics.jmx.domain The JMX domain in which to report Metrics String (no default value) MASKABLE metrics.jmx.enabled Whether to report Metrics through a JMX MBean Boolean false MASKABLE metrics.slf4j Configuration options for metrics reporting through slf4j Name Description Datatype Default Value Mutability metrics.slf4j.interval Time between slf4j logging reports of Metrics data, in milliseconds Duration (no default value) MASKABLE metrics.slf4j.logger The complete name of the Logger through which Metrics will report via Slf4j String (no default value) MASKABLE query Configuration options for query processing Name Description Datatype Default Value Mutability query.batch Whether traversal queries should be batched when executed against the storage backend. This can lead to significant performance improvement if there is a non-trivial latency to the backend. Boolean false MASKABLE query.batch-property-prefetch Whether to do a batched pre-fetch of all properties on adjacent vertices against the storage backend prior to evaluating a has condition against those vertices. Because these vertex properties will be loaded into the transaction-level cache of recently-used vertices when the condition is evaluated this can lead to significant performance improvement if there are many edges to adjacent vertices and there is a non-trivial latency to the backend. Boolean false MASKABLE query.fast-property Whether to pre-fetch all properties on first singular vertex property access. This can eliminate backend calls on subsequentproperty access for the same vertex at the expense of retrieving all properties at once. This can be expensive for vertices with many properties Boolean true MASKABLE query.force-index Whether JanusGraph should throw an exception if a graph query cannot be answered using an index. Doing solimits the functionality of JanusGraph's graph queries but ensures that slow graph queries are avoided on large graphs. Recommended for production use of JanusGraph. Boolean false MASKABLE query.ignore-unknown-index-key Whether to ignore undefined types encountered in user-provided index queries Boolean false MASKABLE query.smart-limit Whether the query optimizer should try to guess a smart limit for the query to ensure responsiveness in light of possibly large result sets. Those will be loaded incrementally if this option is enabled. Boolean true MASKABLE schema Schema related configuration options Name Description Datatype Default Value Mutability schema.constraints Configures the schema constraints to be used by this graph. If config 'schema.constraints' is set to 'true' and 'schema.default' is set to 'none', then an 'IllegalArgumentException' is thrown for schema constraint violations. If 'schema.constraints' is set to 'true' and 'schema.default' is not set 'none', schema constraints are automatically created as described in the config option 'schema.default'. If 'schema.constraints' is set to 'false' which is the default, then no schema constraints are applied. Boolean false GLOBAL_OFFLINE schema.default Configures the DefaultSchemaMaker to be used by this graph. If set to 'none', automatic schema creation is disabled. Defaults to a blueprints compatible schema maker with MULTI edge labels and SINGLE property keys String default MASKABLE storage Configuration options for the storage backend. Some options are applicable only for certain backends. Name Description Datatype Default Value Mutability storage.backend The primary persistence provider used by JanusGraph. This is required. It should be set one of JanusGraph's built-in shorthand names for its standard storage backends (shorthands: berkeleyje, cassandrathrift, cassandra, astyanax, embeddedcassandra, cql, hbase, inmemory) or to the full package and classname of a custom/third-party StoreManager implementation. String (no default value) LOCAL storage.batch-loading Whether to enable batch loading into the storage backend Boolean false LOCAL storage.buffer-size Size of the batch in which mutations are persisted Integer 1024 MASKABLE storage.conf-file Path to a configuration file for those storage backends which require/support a single separate config file. String (no default value) LOCAL storage.connection-timeout Default timeout, in milliseconds, when connecting to a remote database instance Duration 10000 ms MASKABLE storage.directory Storage directory for those storage backends that require local storage. String (no default value) LOCAL storage.drop-on-clear Whether to drop the graph database (true) or delete rows (false) when clearing storage. Note that some backends always drop the graph database when clearing storage. Also note that indices are always dropped when clearing storage. Boolean true MASKABLE storage.hostname The hostname or comma-separated list of hostnames of storage backend servers. This is only applicable to some storage backends, such as cassandra and hbase. String[] 127.0.0.1 LOCAL storage.page-size JanusGraph break requests that may return many results from distributed storage backends into a series of requests for small chunks/pages of results, where each chunk contains up to this many elements. Integer 100 MASKABLE storage.parallel-backend-ops Whether JanusGraph should attempt to parallelize storage operations Boolean true MASKABLE storage.password Password to authenticate against backend String (no default value) LOCAL storage.port The port on which to connect to storage backend servers. For HBase, it is the Zookeeper port. Integer (no default value) LOCAL storage.read-only Read-only database Boolean false LOCAL storage.read-time Maximum time (in ms) to wait for a backend read operation to complete successfully. If a backend read operationfails temporarily, JanusGraph will backoff exponentially and retry the operation until the wait time has been exhausted. Duration 10000 ms MASKABLE storage.root Storage root directory for those storage backends that require local storage. If you do not supply storage.directory and you do supply graph.graphname, then your data will be stored in the directory equivalent to / . String (no default value) LOCAL storage.setup-wait Time in milliseconds for backend manager to wait for the storage backends to become available when JanusGraph is run in server mode Duration 60000 ms MASKABLE storage.transactions Enables transactions on storage backends that support them Boolean true MASKABLE storage.username Username to authenticate against backend String (no default value) LOCAL storage.write-time Maximum time (in ms) to wait for a backend write operation to complete successfully. If a backend write operationfails temporarily, JanusGraph will backoff exponentially and retry the operation until the wait time has been exhausted. Duration 100000 ms MASKABLE storage.berkeleyje BerkeleyDB JE configuration options Name Description Datatype Default Value Mutability storage.berkeleyje.cache-percentage Percentage of JVM heap reserved for BerkeleyJE's cache Integer 65 MASKABLE storage.berkeleyje.isolation-level The isolation level used by transactions String REPEATABLE_READ MASKABLE storage.berkeleyje.lock-mode The BDB record lock mode used for read operations String LockMode.DEFAULT MASKABLE storage.cassandra Cassandra storage backend options Name Description Datatype Default Value Mutability storage.cassandra.atomic-batch-mutate True to use Cassandra atomic batch mutation, false to use non-atomic batches Boolean true MASKABLE storage.cassandra.compaction-strategy-class The compaction strategy to use for JanusGraph tables String (no default value) FIXED storage.cassandra.compaction-strategy-options Compaction strategy options. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. String[] (no default value) FIXED storage.cassandra.compression Whether the storage backend should use compression when storing the data Boolean true FIXED storage.cassandra.compression-block-size The size of the compression blocks in kilobytes Integer 64 FIXED storage.cassandra.compression-type The sstable_compression value JanusGraph uses when creating column families. This accepts any value allowed by Cassandra's sstable_compression option. Leave this unset to disable sstable_compression on JanusGraph-created CFs. String LZ4Compressor MASKABLE storage.cassandra.frame-size-mb The thrift frame size in megabytes Integer 15 MASKABLE storage.cassandra.keyspace The name of JanusGraph's keyspace. It will be created if it does not exist. If it is not supplied, but graph.graphname is, then the the keyspace will be set to that. String janusgraph LOCAL storage.cassandra.read-consistency-level The consistency level of read operations against Cassandra String QUORUM MASKABLE storage.cassandra.replication-factor The number of data replicas (including the original copy) that should be kept. This is only meaningful for storage backends that natively support data replication. Integer 1 GLOBAL_OFFLINE storage.cassandra.replication-strategy-class The replication strategy to use for JanusGraph keyspace String org.apache.cassandra.locator.SimpleStrategy FIXED storage.cassandra.replication-strategy-options Replication strategy options, e.g. factor or replicas per datacenter. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. A replication_factor set here takes precedence over one set with storage.cassandra.replication-factor String[] (no default value) FIXED storage.cassandra.write-consistency-level The consistency level of write operations against Cassandra String QUORUM MASKABLE storage.cassandra.astyanax Astyanax-specific Cassandra options Name Description Datatype Default Value Mutability storage.cassandra.astyanax.cluster-name Default name for the Cassandra cluster String JanusGraph Cluster MASKABLE storage.cassandra.astyanax.connection-pool-type Astyanax's connection pooler implementation String TOKEN_AWARE MASKABLE storage.cassandra.astyanax.frame-size The thrift frame size in mega bytes Integer 15 MASKABLE storage.cassandra.astyanax.host-supplier Host supplier to use when discovery type is set to DISCOVERY_SERVICE or TOKEN_AWARE String (no default value) MASKABLE storage.cassandra.astyanax.local-datacenter The name of the local or closest Cassandra datacenter. When set and not whitespace, this value will be passed into ConnectionPoolConfigurationImpl.setLocalDatacenter. When unset or set to whitespace, setLocalDatacenter will not be invoked. String (no default value) MASKABLE storage.cassandra.astyanax.max-cluster-connections-per-host Maximum pooled \"cluster\" connections per host Integer 3 MASKABLE storage.cassandra.astyanax.max-connections Maximum open connections allowed in the pool (counting all hosts) Integer -1 MASKABLE storage.cassandra.astyanax.max-connections-per-host Maximum pooled connections per host Integer 32 MASKABLE storage.cassandra.astyanax.max-operations-per-connection Maximum number of operations allowed per connection before the connection is closed Integer 100000 MASKABLE storage.cassandra.astyanax.node-discovery-type How Astyanax discovers Cassandra cluster nodes String RING_DESCRIBE MASKABLE storage.cassandra.astyanax.read-page-size The page size for Cassandra read operations Integer 4096 MASKABLE storage.cassandra.astyanax.retry-backoff-strategy Astyanax's retry backoff strategy with configuration parameters String com.netflix.astyanax.connectionpool.impl.FixedRetryBackoffStrategy,1000,5000 MASKABLE storage.cassandra.astyanax.retry-delay-slice Astyanax's connection pool \"retryDelaySlice\" parameter Integer 10000 MASKABLE storage.cassandra.astyanax.retry-max-delay-slice Astyanax's connection pool \"retryMaxDelaySlice\" parameter Integer 10 MASKABLE storage.cassandra.astyanax.retry-policy Astyanax's retry policy implementation with configuration parameters String com.netflix.astyanax.retry.BoundedExponentialBackoff,100,25000,8 MASKABLE storage.cassandra.astyanax.retry-suspend-window Astyanax's connection pool \"retryMaxDelaySlice\" parameter Integer 20000 MASKABLE storage.cassandra.ssl Configuration options for SSL Name Description Datatype Default Value Mutability storage.cassandra.ssl.enabled Controls use of the SSL connection to Cassandra Boolean false LOCAL storage.cassandra.ssl.truststore Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability storage.cassandra.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL storage.cassandra.ssl.truststore.password The password to access SSL Truststore. String LOCAL storage.cassandra.thrift.cpool Options for the Apache commons-pool connection manager Name Description Datatype Default Value Mutability storage.cassandra.thrift.cpool.evictor-period Approximate number of milliseconds between runs of the idle connection evictor. Set to -1 to never run the idle connection evictor. Long 30000 MASKABLE storage.cassandra.thrift.cpool.idle-test Whether the idle connection evictor validates idle connections and drops those that fail to validate Boolean false MASKABLE storage.cassandra.thrift.cpool.idle-tests-per-eviction-run When the value is negative, e.g. -n, roughly one nth of the idle connections are tested per run. When the value is positive, e.g. n, the min(idle-count, n) connections are tested per run. Integer 0 MASKABLE storage.cassandra.thrift.cpool.max-active Maximum number of concurrently in-use connections (-1 to leave undefined) Integer 16 MASKABLE storage.cassandra.thrift.cpool.max-idle Maximum number of concurrently idle connections (-1 to leave undefined) Integer 4 MASKABLE storage.cassandra.thrift.cpool.max-total Max number of allowed Thrift connections, idle or active (-1 to leave undefined) Integer -1 MASKABLE storage.cassandra.thrift.cpool.max-wait Maximum number of milliseconds to block when storage.cassandra.thrift.cpool.when-exhausted is set to BLOCK. Has no effect when set to actions besides BLOCK. Set to -1 to wait indefinitely. Long -1 MASKABLE storage.cassandra.thrift.cpool.min-evictable-idle-time Minimum number of milliseconds a connection must be idle before it is eligible for eviction. See also storage.cassandra.thrift.cpool.evictor-period. Set to -1 to never evict idle connections. Long 60000 MASKABLE storage.cassandra.thrift.cpool.min-idle Minimum number of idle connections the pool attempts to maintain Integer 0 MASKABLE storage.cassandra.thrift.cpool.when-exhausted What to do when clients concurrently request more active connections than are allowed by the pool. The value must be one of BLOCK, FAIL, or GROW. String BLOCK MASKABLE storage.cql CQL storage backend options Name Description Datatype Default Value Mutability storage.cql.atomic-batch-mutate True to use Cassandra atomic batch mutation, false to use non-atomic batches Boolean false MASKABLE storage.cql.batch-statement-size The number of statements in each batch Integer 20 MASKABLE storage.cql.cluster-name Default name for the Cassandra cluster String JanusGraph Cluster MASKABLE storage.cql.compact-storage Whether the storage backend should use compact storage on tables. This option is only available for Cassandra 2 and earlier and defaults to true. Boolean true FIXED storage.cql.compaction-strategy-class The compaction strategy to use for JanusGraph tables String (no default value) FIXED storage.cql.compaction-strategy-options Compaction strategy options. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. String[] (no default value) FIXED storage.cql.compression Whether the storage backend should use compression when storing the data Boolean true FIXED storage.cql.compression-block-size The size of the compression blocks in kilobytes Integer 64 FIXED storage.cql.compression-type The sstable_compression value JanusGraph uses when creating column families. This accepts any value allowed by Cassandra's sstable_compression option. Leave this unset to disable sstable_compression on JanusGraph-created CFs. String LZ4Compressor MASKABLE storage.cql.keyspace The name of JanusGraph's keyspace. It will be created if it does not exist. String janusgraph LOCAL storage.cql.local-core-connections-per-host The number of connections initially created and kept open to each host for local datacenter Integer 1 FIXED storage.cql.local-datacenter The name of the local or closest Cassandra datacenter. When set and not whitespace, this value will be passed into ConnectionPoolConfigurationImpl.setLocalDatacenter. When unset or set to whitespace, setLocalDatacenter will not be invoked. String (no default value) MASKABLE storage.cql.local-max-connections-per-host The maximum number of connections that can be created per host for local datacenter Integer 1 FIXED storage.cql.local-max-requests-per-connection The maximum number of requests per connection for local datacenter Integer 1024 FIXED storage.cql.only-use-local-consistency-for-system-operations True to prevent any system queries from using QUORUM consistency and always use LOCAL_QUORUM instead Boolean false MASKABLE storage.cql.protocol-version The protocol version used to connect to the Cassandra database. If no value is supplied then the driver will negotiate with the server. Integer 0 LOCAL storage.cql.read-consistency-level The consistency level of read operations against Cassandra String QUORUM MASKABLE storage.cql.remote-core-connections-per-host The number of connections initially created and kept open to each host for remote datacenter Integer 1 FIXED storage.cql.remote-max-connections-per-host The maximum number of connections that can be created per host for remote datacenter Integer 1 FIXED storage.cql.remote-max-requests-per-connection The maximum number of requests per connection for remote datacenter Integer 256 FIXED storage.cql.replication-factor The number of data replicas (including the original copy) that should be kept Integer 1 GLOBAL_OFFLINE storage.cql.replication-strategy-class The replication strategy to use for JanusGraph keyspace String SimpleStrategy FIXED storage.cql.replication-strategy-options Replication strategy options, e.g. factor or replicas per datacenter. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. A replication_factor set here takes precedence over one set with storage.cql.replication-factor String[] (no default value) FIXED storage.cql.use-external-locking True to prevent JanusGraph from using its own locking mechanism. Setting this to true eliminates redundant checks when using an external locking mechanism outside of JanusGraph. Be aware that when use-external-locking is set to true, that failure to employ a locking algorithm which locks all columns that participate in a transaction upfront and unlocks them when the transaction ends, will result in a 'read uncommitted' transaction isolation level guarantee. If set to true without an appropriate external locking mechanism in place side effects such as dirty/non-repeatable/phantom reads should be expected. Boolean false MASKABLE storage.cql.write-consistency-level The consistency level of write operations against Cassandra String QUORUM MASKABLE storage.cql.ssl Configuration options for SSL Name Description Datatype Default Value Mutability storage.cql.ssl.enabled Controls use of the SSL connection to Cassandra Boolean false LOCAL storage.cql.ssl.truststore Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability storage.cql.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL storage.cql.ssl.truststore.password The password to access SSL Truststore. String LOCAL storage.hbase HBase storage options Name Description Datatype Default Value Mutability storage.hbase.compat-class The package and class name of the HBaseCompat implementation. HBaseCompat masks version-specific HBase API differences. When this option is unset, JanusGraph calls HBase's VersionInfo.getVersion() and loads the matching compat class at runtime. Setting this option forces JanusGraph to instead reflectively load and instantiate the specified class. String (no default value) MASKABLE storage.hbase.compression-algorithm An HBase Compression.Algorithm enum string which will be applied to newly created column families. The compression algorithm must be installed and available on the HBase cluster. JanusGraph cannot install and configure new compression algorithms on the HBase cluster by itself. String GZ MASKABLE storage.hbase.region-count The number of initial regions set when creating JanusGraph's HBase table Integer (no default value) MASKABLE storage.hbase.regions-per-server The number of regions per regionserver to set when creating JanusGraph's HBase table Integer (no default value) MASKABLE storage.hbase.short-cf-names Whether to shorten the names of JanusGraph's column families to one-character mnemonics to conserve storage space Boolean true FIXED storage.hbase.skip-schema-check Assume that JanusGraph's HBase table and column families already exist. When this is true, JanusGraph will not check for the existence of its table/CFs, nor will it attempt to create them under any circumstances. This is useful when running JanusGraph without HBase admin privileges. Boolean false MASKABLE storage.hbase.snapshot-name The name of an exising HBase snapshot to be used by HBaseSnapshotInputFormat String janusgraph-snapshot LOCAL storage.hbase.snapshot-restore-dir The tempoary directory to be used by HBaseSnapshotInputFormat to restore a snapshot. This directory should be on the same File System as the HBase root dir. String /tmp LOCAL storage.hbase.table The name of the table JanusGraph will use. When storage.hbase.skip-schema-check is false, JanusGraph will automatically create this table if it does not already exist. If this configuration option is not provided but graph.graphname is, the table will be set to that value. String janusgraph LOCAL storage.lock Options for locking on eventually-consistent stores Name Description Datatype Default Value Mutability storage.lock.backend Locker type to use String consistentkey GLOBAL_OFFLINE storage.lock.clean-expired Whether to delete expired locks from the storage backend Boolean false MASKABLE storage.lock.expiry-time Number of milliseconds after which a lock is considered to have expired. Lock applications that were not released are considered expired after this time and released. This value should be larger than the maximum time a transaction can take in order to guarantee that no correctly held applications are expired pre-maturely and as small as possible to avoid dead lock. Duration 300000 ms GLOBAL_OFFLINE storage.lock.local-mediator-group This option determines the LocalLockMediator instance used for early detection of lock contention between concurrent JanusGraph graph instances within the same process which are connected to the same storage backend. JanusGraph instances that have the same value for this variable will attempt to discover lock contention among themselves in memory before proceeding with the general-case distributed locking code. JanusGraph generates an appropriate default value for this option at startup. Overridding the default is generally only useful in testing. String (no default value) LOCAL storage.lock.retries Number of times the system attempts to acquire a lock before giving up and throwing an exception Integer 3 MASKABLE storage.lock.wait-time Number of milliseconds the system waits for a lock application to be acknowledged by the storage backend. Also, the time waited at the end of all lock applications before verifying that the applications were successful. This value should be a small multiple of the average consistent write time. Duration 100 ms GLOBAL_OFFLINE storage.meta * Meta data to include in storage backend retrievals Name Description Datatype Default Value Mutability storage.meta.[X].timestamps Whether to include timestamps in retrieved entries for storage backends that automatically annotated entries with timestamps Boolean false GLOBAL storage.meta.[X].ttl Whether to include ttl in retrieved entries for storage backends that support storage and retrieval of cell level TTL Boolean false GLOBAL storage.meta.[X].visibility Whether to include visibility in retrieved entries for storage backends that support cell level visibility Boolean true GLOBAL tx Configuration options for transaction handling Name Description Datatype Default Value Mutability tx.log-tx Whether transaction mutations should be logged to JanusGraph's write-ahead transaction log which can be used for recovery of partially failed transactions Boolean false GLOBAL tx.max-commit-time Maximum time (in ms) that a transaction might take to commit against all backends. This is used by the distributed write-ahead log processing to determine when a transaction can be considered failed (i.e. after this time has elapsed).Must be longer than the maximum allowed write time. Duration 10000 ms GLOBAL tx.recovery Configuration options for transaction recovery processes Name Description Datatype Default Value Mutability tx.recovery.verbose Whether the transaction recovery system should print recovered transactions and other activity to standard output Boolean false MASKABLE","title":"Configuration Reference"},{"location":"basics/configuration-reference/#configuration-reference","text":"This section is the authoritative reference for JanusGraph configuration options. It includes all options for storage and indexing backends that are part of the official JanusGraph distribution. The table is automatically generated by traversing the keys and namespaces in JanusGraph\u2019s internal configuration management API. Hence, the configuration options as listed on this page are synchronized with a particular JanusGraph release. If a reference to a configuration option in other parts of this documentation is in conflict with its representation on this page, assume the version listed here to be correct.","title":"Configuration Reference"},{"location":"basics/configuration-reference/#mutability-levels","text":"Each configuration option has a certain mutability level that governs whether and how it can be modified after the database is opened for the first time. The following listing describes the mutability levels. FIXED Once the database has been opened, these configuration options cannot be changed for the entire life of the database GLOBAL_OFFLINE These options can only be changed for the entire database cluster at once when all instances are shut down GLOBAL These options can only be changed globally across the entire database cluster MASKABLE These options are global but can be overwritten by a local configuration file LOCAL These options can only be provided through a local configuration file Refer to Global Configuration for information on how to change non-local configuration options.","title":"Mutability Levels"},{"location":"basics/configuration-reference/#umbrella-namespace","text":"Namespaces marked with an asterisk are umbrella namespaces which means that they can accommodate an arbitrary number of sub-namespaces - each of which uniquely identified by its name. The configuration options listed under an umbrella namespace apply only to those sub-namespaces. Umbrella namespaces are used to configure multiple system components that are of the same type and hence have the same configuration options. For example, the log namespace is an umbrella namespace because JanusGraph can interface with multiple logging backends, such as the user log, each of which has the same core set of configuration options. To configure the send batch size of the user log to 100 transaction changes, one would have to set the following option in the configuration log.user.send-batch-size = 100","title":"Umbrella Namespace"},{"location":"basics/configuration-reference/#configuration-namespaces-and-options","text":"","title":"Configuration Namespaces and Options"},{"location":"basics/configuration-reference/#attributescustom","text":"Custom attribute serialization and handling Name Description Datatype Default Value Mutability attributes.custom.[X].attribute-class Class of the custom attribute to be registered String (no default value) GLOBAL_OFFLINE attributes.custom.[X].serializer-class Class of the custom attribute serializer to be registered String (no default value) GLOBAL_OFFLINE","title":"attributes.custom *"},{"location":"basics/configuration-reference/#cache","text":"Configuration options that modify JanusGraph's caching behavior Name Description Datatype Default Value Mutability cache.db-cache Whether to enable JanusGraph's database-level cache, which is shared across all transactions. Enabling this option speeds up traversals by holding hot graph elements in memory, but also increases the likelihood of reading stale data. Disabling it forces each transaction to independently fetch graph elements from storage before reading/writing them. Boolean false MASKABLE cache.db-cache-clean-wait How long, in milliseconds, database-level cache will keep entries after flushing them. This option is only useful on distributed storage backends that are capable of acknowledging writes without necessarily making them immediately visible. Integer 50 GLOBAL_OFFLINE cache.db-cache-size Size of JanusGraph's database level cache. Values between 0 and 1 are interpreted as a percentage of VM heap, while larger values are interpreted as an absolute size in bytes. Double 0.3 MASKABLE cache.db-cache-time Default expiration time, in milliseconds, for entries in the database-level cache. Entries are evicted when they reach this age even if the cache has room to spare. Set to 0 to disable expiration (cache entries live forever or until memory pressure triggers eviction when set to 0). Long 10000 GLOBAL_OFFLINE cache.tx-cache-size Maximum size of the transaction-level cache of recently-used vertices. Integer 20000 MASKABLE cache.tx-dirty-size Initial size of the transaction-level cache of uncommitted dirty vertices. This is a performance hint for write-heavy, performance-sensitive transactional workloads. If set, it should roughly match the median vertices modified per transaction. Integer (no default value) MASKABLE","title":"cache"},{"location":"basics/configuration-reference/#cluster","text":"Configuration options for multi-machine deployments Name Description Datatype Default Value Mutability cluster.max-partitions The number of virtual partition blocks created in the partitioned graph. This should be larger than the maximum expected number of nodes in the JanusGraph graph cluster. Must be greater than 1 and a power of 2. Integer 32 FIXED","title":"cluster"},{"location":"basics/configuration-reference/#computer","text":"GraphComputer related configuration Name Description Datatype Default Value Mutability computer.result-mode How the graph computer should return the computed results. 'persist' for writing them into the graph, 'localtx' for writing them into the local transaction, or 'none' (default) String none MASKABLE","title":"computer"},{"location":"basics/configuration-reference/#graph","text":"General configuration options Name Description Datatype Default Value Mutability graph.allow-stale-config Whether to allow the local and storage-backend-hosted copies of the configuration to contain conflicting values for options with any of the following types: FIXED, GLOBAL_OFFLINE, GLOBAL. These types are managed globally through the storage backend and cannot be overridden by changing the local configuration. This type of conflict usually indicates misconfiguration. When this option is true, JanusGraph will log these option conflicts, but continue normal operation using the storage-backend-hosted value for each conflicted option. When this option is false, JanusGraph will log these option conflicts, but then it will throw an exception, refusing to start. Boolean true MASKABLE graph.allow-upgrade Setting this to true will allow certain fixed values to be updated such as storage-version. This should only be used for upgrading. Boolean false MASKABLE graph.graphname This config option is an optional configuration setting that you may supply when opening a graph. The String value you provide will be the name of your graph. If you use the ConfigurationManagement APIs, then you will be able to access your graph by this String representation using the ConfiguredGraphFactory APIs. String (no default value) LOCAL graph.replace-instance-if-exists If a JanusGraph instance with the same instance identifier already exists, the usage of this configuration option results in the opening of this graph anwyay. Boolean false LOCAL graph.set-vertex-id Whether user provided vertex ids should be enabled and JanusGraph's automatic id allocation be disabled. Useful when operating JanusGraph in concert with another storage system that assigns long ids but disables some of JanusGraph's advanced features which can lead to inconsistent data. EXPERT FEATURE - USE WITH GREAT CARE. Boolean false FIXED graph.storage-version The version of JanusGraph storage schema with which this database was created. Automatically set on first start of graph. Should only ever be changed if upgraing to a new major release version of JanusGraph that contains schema changes String (no default value) FIXED graph.timestamps The timestamp resolution to use when writing to storage and indices. Sets the time granularity for the entire graph cluster. To avoid potential inaccuracies, the configured time resolution should match those of the backend systems. Some JanusGraph storage backends declare a preferred timestamp resolution that reflects design constraints in the underlying service. When the backend provides a preferred default, and when this setting is not explicitly declared in the config file, the backend default is used and the general default associated with this setting is ignored. An explicit declaration of this setting overrides both the general and backend-specific defaults. TimestampProviders MICRO FIXED graph.unique-instance-id Unique identifier for this JanusGraph instance. This must be unique among all instances concurrently accessing the same stores or indexes. It's automatically generated by concatenating the hostname, process id, and a static (process-wide) counter. Leaving it unset is recommended. String (no default value) LOCAL graph.unique-instance-id-suffix When this is set and unique-instance-id is not, this JanusGraph instance's unique identifier is generated by concatenating the hex encoded hostname to the provided number. Short (no default value) LOCAL graph.use-hostname-for-unique-instance-id When this is set, this JanusGraph's unique instance identifier is set to the hostname. If unique-instance-id-suffix is also set, then the identifier is set to . Boolean false LOCAL","title":"graph"},{"location":"basics/configuration-reference/#gremlin","text":"Gremlin configuration options Name Description Datatype Default Value Mutability gremlin.graph The implementation of graph factory that will be used by gremlin server String org.janusgraph.core.JanusGraphFactory LOCAL","title":"gremlin"},{"location":"basics/configuration-reference/#ids","text":"General configuration options for graph element IDs Name Description Datatype Default Value Mutability ids.block-size Globally reserve graph element IDs in chunks of this size. Setting this too low will make commits frequently block on slow reservation requests. Setting it too high will result in IDs wasted when a graph instance shuts down with reserved but mostly-unused blocks. Integer 10000 GLOBAL_OFFLINE ids.flush When true, vertices and edges are assigned IDs immediately upon creation. When false, IDs are assigned only when the transaction commits. Boolean true MASKABLE ids.num-partitions Number of partition block to allocate for placement of vertices Integer 10 MASKABLE ids.placement Name of the vertex placement strategy or full class name String simple MASKABLE ids.renew-percentage When the most-recently-reserved ID block has only this percentage of its total IDs remaining (expressed as a value between 0 and 1), JanusGraph asynchronously begins reserving another block. This helps avoid transaction commits waiting on ID reservation even if the block size is relatively small. Double 0.3 MASKABLE ids.renew-timeout The number of milliseconds that the JanusGraph id pool manager will wait before giving up on allocating a new block of ids Duration 120000 ms MASKABLE ids.store-name The name of the ID KCVStore. IDS_STORE_NAME is meant to be used only for backward compatibility with Titan, and should not be used explicitly in normal operations or in new graphs. String janusgraph_ids GLOBAL_OFFLINE","title":"ids"},{"location":"basics/configuration-reference/#idsauthority","text":"Configuration options for graph element ID reservation/allocation Name Description Datatype Default Value Mutability ids.authority.conflict-avoidance-mode This setting helps separate JanusGraph instances sharing a single graph storage backend avoid contention when reserving ID blocks, increasing overall throughput. ConflictAvoidanceMode NONE GLOBAL_OFFLINE ids.authority.conflict-avoidance-tag Conflict avoidance tag to be used by this JanusGraph instance when allocating IDs Integer 0 LOCAL ids.authority.conflict-avoidance-tag-bits Configures the number of bits of JanusGraph-assigned element IDs that are reserved for the conflict avoidance tag Integer 4 FIXED ids.authority.randomized-conflict-avoidance-retries Number of times the system attempts ID block reservations with random conflict avoidance tags before giving up and throwing an exception Integer 5 MASKABLE ids.authority.wait-time The number of milliseconds the system waits for an ID block reservation to be acknowledged by the storage backend Duration 300 ms GLOBAL_OFFLINE","title":"ids.authority"},{"location":"basics/configuration-reference/#index","text":"Configuration options for the individual indexing backends Name Description Datatype Default Value Mutability index.[X].backend The indexing backend used to extend and optimize JanusGraph's query functionality. This setting is optional. JanusGraph can use multiple heterogeneous index backends. Hence, this option can appear more than once, so long as the user-defined name between \"index\" and \"backend\" is unique among appearances.Similar to the storage backend, this should be set to one of JanusGraph's built-in shorthand names for its standard index backends (shorthands: lucene, elasticsearch, es, solr) or to the full package and classname of a custom/third-party IndexProvider implementation. String elasticsearch GLOBAL_OFFLINE index.[X].conf-file Path to a configuration file for those indexing backends that require/support a separate config file String (no default value) MASKABLE index.[X].directory Directory to store index data locally String (no default value) MASKABLE index.[X].hostname The hostname or comma-separated list of hostnames of index backend servers. This is only applicable to some index backends, such as elasticsearch and solr. String[] 127.0.0.1 MASKABLE index.[X].index-name Name of the index if required by the indexing backend String janusgraph GLOBAL_OFFLINE index.[X].map-name Whether to use the name of the property key as the field name in the index. It must be ensured, that theindexed property key names are valid field names. Renaming the property key will NOT rename the field and its the developers responsibility to avoid field collisions. Boolean true GLOBAL index.[X].max-result-set-size Maximum number of results to return if no limit is specified. For index backends that support scrolling, it represents the number of results in each batch Integer 50 MASKABLE index.[X].port The port on which to connect to index backend servers Integer (no default value) MASKABLE","title":"index *"},{"location":"basics/configuration-reference/#indexxelasticsearch","text":"Elasticsearch index configuration Name Description Datatype Default Value Mutability index.[X].elasticsearch.bulk-refresh Elasticsearch bulk API refresh setting used to control when changes made by this request are made visible to search String false MASKABLE index.[X].elasticsearch.health-request-timeout When JanusGraph initializes its ES backend, JanusGraph waits up to this duration for the ES cluster health to reach at least yellow status. This string should be formatted as a natural number followed by the lowercase letter \"s\", e.g. 3s or 60s. String 30s MASKABLE index.[X].elasticsearch.interface Interface for connecting to Elasticsearch. TRANSPORT_CLIENT and NODE were previously supported, but now are required to migrate to REST_CLIENT. See the JanusGraph upgrade instructions for more details. String REST_CLIENT MASKABLE index.[X].elasticsearch.max-retry-timeout Sets the maximum timeout (in milliseconds) to honour in case of multiple retries of the same request sent using the ElasticSearch Rest Client by JanusGraph. Integer (no default value) MASKABLE index.[X].elasticsearch.scroll-keep-alive How long (in seconds) elasticsearch should keep alive the scroll context. Integer 60 GLOBAL_OFFLINE index.[X].elasticsearch.use-all-field Whether JanusGraph should add an \"all\" field mapping. When enabled field mappings will include a \"copy_to\" parameter referencing the \"all\" field. This is supported since Elasticsearch 6.x and is required when using wildcard fields starting in Elasticsearch 6.x. Boolean true GLOBAL_OFFLINE index.[X].elasticsearch.use-deprecated-multitype-index Whether JanusGraph should group these indices into a single Elasticsearch index (requires Elasticsearch 5.x or earlier). Boolean false GLOBAL_OFFLINE","title":"index.[X].elasticsearch"},{"location":"basics/configuration-reference/#indexxelasticsearchcreate","text":"Settings related to index creation Name Description Datatype Default Value Mutability index.[X].elasticsearch.create.allow-mapping-update Whether JanusGraph should allow a mapping update when registering an index. Only applicable when use-external-mappings is true. Boolean false MASKABLE index.[X].elasticsearch.create.sleep How long to sleep, in milliseconds, between the successful completion of a (blocking) index creation request and the first use of that index. This only applies when creating an index in ES, which typically only happens the first time JanusGraph is started on top of ES. If the index JanusGraph is configured to use already exists, then this setting has no effect. Long 200 MASKABLE index.[X].elasticsearch.create.use-external-mappings Whether JanusGraph should make use of an external mapping when registering an index. Boolean false MASKABLE","title":"index.[X].elasticsearch.create"},{"location":"basics/configuration-reference/#indexxelasticsearchhttpauth","text":"Configuration options for HTTP(S) authentication. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.type Authentication type to be used for HTTP(S) access. String NONE LOCAL","title":"index.[X].elasticsearch.http.auth"},{"location":"basics/configuration-reference/#indexxelasticsearchhttpauthbasic","text":"Configuration options for HTTP(S) Basic authentication. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.basic.password Password for HTTP(S) authentication. String LOCAL index.[X].elasticsearch.http.auth.basic.realm Realm value for HTTP(S) authentication. If empty, any realm is accepted. String LOCAL index.[X].elasticsearch.http.auth.basic.username Username for HTTP(S) authentication. String LOCAL","title":"index.[X].elasticsearch.http.auth.basic"},{"location":"basics/configuration-reference/#indexxelasticsearchhttpauthcustom","text":"Configuration options for custom HTTP(S) authenticator. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.custom.authenticator-args Comma-separated custom authenticator constructor arguments. String[] LOCAL index.[X].elasticsearch.http.auth.custom.authenticator-class Authenticator fully qualified class name. String LOCAL","title":"index.[X].elasticsearch.http.auth.custom"},{"location":"basics/configuration-reference/#indexxelasticsearchssl","text":"Elasticsearch SSL configuration Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.allow-self-signed-certificates Controls the accepting of the self-signed SSL certificates. Boolean false LOCAL index.[X].elasticsearch.ssl.disable-hostname-verification Disables the SSL hostname verification if set to true. Hostname verification is enabled by default. Boolean false LOCAL index.[X].elasticsearch.ssl.enabled Controls use of the SSL connection to Elasticsearch. Boolean false LOCAL","title":"index.[X].elasticsearch.ssl"},{"location":"basics/configuration-reference/#indexxelasticsearchsslkeystore","text":"Configuration options for SSL Keystore. Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.keystore.keypassword The password to access the key in the SSL Keystore. If the option is not present, the value of \"storepassword\" is used. String LOCAL index.[X].elasticsearch.ssl.keystore.location Marks the location of the SSL Keystore. String LOCAL index.[X].elasticsearch.ssl.keystore.storepassword The password to access SSL Keystore. String LOCAL","title":"index.[X].elasticsearch.ssl.keystore"},{"location":"basics/configuration-reference/#indexxelasticsearchssltruststore","text":"Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL index.[X].elasticsearch.ssl.truststore.password The password to access SSL Truststore. String LOCAL","title":"index.[X].elasticsearch.ssl.truststore"},{"location":"basics/configuration-reference/#indexxsolr","text":"Solr index configuration Name Description Datatype Default Value Mutability index.[X].solr.configset If specified, the same solr configSet can be reused for each new Collection that is created in SolrCloud. String (no default value) MASKABLE index.[X].solr.dyn-fields Whether to use dynamic fields (which appends the data type to the field name). If dynamic fields is disabledthe user must map field names and define them explicitly in the schema. Boolean true GLOBAL_OFFLINE index.[X].solr.http-compression Enable/disable compression on the HTTP connections made to Solr. Boolean false MASKABLE index.[X].solr.http-connection-timeout Solr HTTP connection timeout. Integer 5000 MASKABLE index.[X].solr.http-max Maximum number of HTTP connections in total to all Solr servers. Integer 100 MASKABLE index.[X].solr.http-max-per-host Maximum number of HTTP connections per Solr host. Integer 20 MASKABLE index.[X].solr.http-urls List of URLs to use to connect to Solr Servers (LBHttpSolrClient is used), don't add core or collection name to the URL. String[] http://localhost:8983/solr MASKABLE index.[X].solr.kerberos-enabled Whether SOLR instance is Kerberized or not. Boolean false MASKABLE index.[X].solr.key-field-names Field name that uniquely identifies each document in Solr. Must be specified as a list of collection=field . String[] (no default value) GLOBAL index.[X].solr.max-shards-per-node Maximum number of shards per node. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.mode The operation mode for Solr which is either via HTTP ( http ) or using SolrCloud ( cloud ) String cloud GLOBAL_OFFLINE index.[X].solr.num-shards Number of shards for a collection. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.replication-factor Replication factor for a collection. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.ttl_field Name of the TTL field for Solr collections. String ttl GLOBAL_OFFLINE index.[X].solr.wait-searcher When mutating - wait for the index to reflect new mutations before returning. This can have a negative impact on performance. Boolean false LOCAL index.[X].solr.zookeeper-url URL of the Zookeeper instance coordinating the SolrCloud cluster String[] localhost:2181 MASKABLE","title":"index.[X].solr"},{"location":"basics/configuration-reference/#log","text":"Configuration options for JanusGraph's logging system Name Description Datatype Default Value Mutability log.[X].backend Define the log backed to use String default GLOBAL_OFFLINE log.[X].fixed-partition Whether all log entries are written to one fixed partition even if the backend store is partitioned.This can cause imbalanced loads and should only be used on low volume logs Boolean false GLOBAL_OFFLINE log.[X].key-consistent Whether to require consistency for log reading and writing messages to the storage backend Boolean false MASKABLE log.[X].max-partitions The maximum number of partitions to use for logging. Setting up this many actual or virtual partitions. Must be bigger than 0and a power of 2. Integer (no default value) FIXED log.[X].max-read-time Maximum time in ms to try reading log messages from the backend before failing. Duration 4000 ms MASKABLE log.[X].max-write-time Maximum time in ms to try persisting log messages against the backend before failing. Duration 10000 ms MASKABLE log.[X].num-buckets The number of buckets to split log entries into for load balancing Integer 1 GLOBAL_OFFLINE log.[X].read-batch-size Maximum number of log messages to read at a time for logging implementations that read messages in batches Integer 1024 MASKABLE log.[X].read-interval Time in ms between message readings from the backend for this logging implementations that read message in batch Duration 5000 ms MASKABLE log.[X].read-lag-time Maximum time in ms that it may take for reads to appear in the backend. If a write does not becomevisible in the storage backend in this amount of time, a log reader might miss the message. Duration 500 ms MASKABLE log.[X].read-threads Number of threads to be used in reading and processing log messages Integer 1 MASKABLE log.[X].send-batch-size Maximum number of log messages to batch up for sending for logging implementations that support batch sending Integer 256 MASKABLE log.[X].send-delay Maximum time in ms that messages can be buffered locally before sending in batch Duration 1000 ms MASKABLE log.[X].ttl Sets a TTL on all log entries, meaningthat all entries added to this log expire after the configured amount of time. Requiresthat the log implementation supports TTL. Duration (no default value) GLOBAL","title":"log *"},{"location":"basics/configuration-reference/#metrics","text":"Configuration options for metrics reporting Name Description Datatype Default Value Mutability metrics.enabled Whether to enable basic timing and operation count monitoring on backend Boolean false MASKABLE metrics.merge-stores Whether to aggregate measurements for the edge store, vertex index, edge index, and ID store Boolean true MASKABLE metrics.prefix The default name prefix for Metrics reported by JanusGraph. String org.janusgraph MASKABLE","title":"metrics"},{"location":"basics/configuration-reference/#metricsconsole","text":"Configuration options for metrics reporting to console Name Description Datatype Default Value Mutability metrics.console.interval Time between Metrics reports printing to the console, in milliseconds Duration (no default value) MASKABLE","title":"metrics.console"},{"location":"basics/configuration-reference/#metricscsv","text":"Configuration options for metrics reporting to CSV file Name Description Datatype Default Value Mutability metrics.csv.directory Metrics CSV output directory String (no default value) MASKABLE metrics.csv.interval Time between dumps of CSV files containing Metrics data, in milliseconds Duration (no default value) MASKABLE","title":"metrics.csv"},{"location":"basics/configuration-reference/#metricsganglia","text":"Configuration options for metrics reporting through Ganglia Name Description Datatype Default Value Mutability metrics.ganglia.addressing-mode Whether to communicate to Ganglia via uni- or multicast String unicast MASKABLE metrics.ganglia.hostname The unicast host or multicast group name to which Metrics will send Ganglia data String (no default value) MASKABLE metrics.ganglia.interval The number of milliseconds to wait between sending Metrics data to Ganglia Duration (no default value) MASKABLE metrics.ganglia.port The port to which Ganglia data are sent Integer 8649 MASKABLE metrics.ganglia.protocol-31 Whether to send data to Ganglia in the 3.1 protocol format Boolean true MASKABLE metrics.ganglia.spoof If non-null, it must be a valid Gmetric spoof string formatted as an IP:hostname pair. See https://github.com/ganglia/monitor-core/wiki/Gmetric-Spoofing for information about this setting. String (no default value) MASKABLE metrics.ganglia.ttl The multicast TTL to set on outgoing Ganglia datagrams Integer 1 MASKABLE metrics.ganglia.uuid The host UUID to set on outgoing Ganglia datagrams. See https://github.com/ganglia/monitor-core/wiki/UUIDSources for information about this setting. String (no default value) LOCAL","title":"metrics.ganglia"},{"location":"basics/configuration-reference/#metricsgraphite","text":"Configuration options for metrics reporting through Graphite Name Description Datatype Default Value Mutability metrics.graphite.hostname The hostname to receive Graphite plaintext protocol metric data String (no default value) MASKABLE metrics.graphite.interval The number of milliseconds to wait between sending Metrics data Duration (no default value) MASKABLE metrics.graphite.port The port to which Graphite data are sent Integer 2003 MASKABLE metrics.graphite.prefix A Graphite-specific prefix for reported metrics String (no default value) MASKABLE","title":"metrics.graphite"},{"location":"basics/configuration-reference/#metricsjmx","text":"Configuration options for metrics reporting through JMX Name Description Datatype Default Value Mutability metrics.jmx.agentid The JMX agentId used by Metrics String (no default value) MASKABLE metrics.jmx.domain The JMX domain in which to report Metrics String (no default value) MASKABLE metrics.jmx.enabled Whether to report Metrics through a JMX MBean Boolean false MASKABLE","title":"metrics.jmx"},{"location":"basics/configuration-reference/#metricsslf4j","text":"Configuration options for metrics reporting through slf4j Name Description Datatype Default Value Mutability metrics.slf4j.interval Time between slf4j logging reports of Metrics data, in milliseconds Duration (no default value) MASKABLE metrics.slf4j.logger The complete name of the Logger through which Metrics will report via Slf4j String (no default value) MASKABLE","title":"metrics.slf4j"},{"location":"basics/configuration-reference/#query","text":"Configuration options for query processing Name Description Datatype Default Value Mutability query.batch Whether traversal queries should be batched when executed against the storage backend. This can lead to significant performance improvement if there is a non-trivial latency to the backend. Boolean false MASKABLE query.batch-property-prefetch Whether to do a batched pre-fetch of all properties on adjacent vertices against the storage backend prior to evaluating a has condition against those vertices. Because these vertex properties will be loaded into the transaction-level cache of recently-used vertices when the condition is evaluated this can lead to significant performance improvement if there are many edges to adjacent vertices and there is a non-trivial latency to the backend. Boolean false MASKABLE query.fast-property Whether to pre-fetch all properties on first singular vertex property access. This can eliminate backend calls on subsequentproperty access for the same vertex at the expense of retrieving all properties at once. This can be expensive for vertices with many properties Boolean true MASKABLE query.force-index Whether JanusGraph should throw an exception if a graph query cannot be answered using an index. Doing solimits the functionality of JanusGraph's graph queries but ensures that slow graph queries are avoided on large graphs. Recommended for production use of JanusGraph. Boolean false MASKABLE query.ignore-unknown-index-key Whether to ignore undefined types encountered in user-provided index queries Boolean false MASKABLE query.smart-limit Whether the query optimizer should try to guess a smart limit for the query to ensure responsiveness in light of possibly large result sets. Those will be loaded incrementally if this option is enabled. Boolean true MASKABLE","title":"query"},{"location":"basics/configuration-reference/#schema","text":"Schema related configuration options Name Description Datatype Default Value Mutability schema.constraints Configures the schema constraints to be used by this graph. If config 'schema.constraints' is set to 'true' and 'schema.default' is set to 'none', then an 'IllegalArgumentException' is thrown for schema constraint violations. If 'schema.constraints' is set to 'true' and 'schema.default' is not set 'none', schema constraints are automatically created as described in the config option 'schema.default'. If 'schema.constraints' is set to 'false' which is the default, then no schema constraints are applied. Boolean false GLOBAL_OFFLINE schema.default Configures the DefaultSchemaMaker to be used by this graph. If set to 'none', automatic schema creation is disabled. Defaults to a blueprints compatible schema maker with MULTI edge labels and SINGLE property keys String default MASKABLE","title":"schema"},{"location":"basics/configuration-reference/#storage","text":"Configuration options for the storage backend. Some options are applicable only for certain backends. Name Description Datatype Default Value Mutability storage.backend The primary persistence provider used by JanusGraph. This is required. It should be set one of JanusGraph's built-in shorthand names for its standard storage backends (shorthands: berkeleyje, cassandrathrift, cassandra, astyanax, embeddedcassandra, cql, hbase, inmemory) or to the full package and classname of a custom/third-party StoreManager implementation. String (no default value) LOCAL storage.batch-loading Whether to enable batch loading into the storage backend Boolean false LOCAL storage.buffer-size Size of the batch in which mutations are persisted Integer 1024 MASKABLE storage.conf-file Path to a configuration file for those storage backends which require/support a single separate config file. String (no default value) LOCAL storage.connection-timeout Default timeout, in milliseconds, when connecting to a remote database instance Duration 10000 ms MASKABLE storage.directory Storage directory for those storage backends that require local storage. String (no default value) LOCAL storage.drop-on-clear Whether to drop the graph database (true) or delete rows (false) when clearing storage. Note that some backends always drop the graph database when clearing storage. Also note that indices are always dropped when clearing storage. Boolean true MASKABLE storage.hostname The hostname or comma-separated list of hostnames of storage backend servers. This is only applicable to some storage backends, such as cassandra and hbase. String[] 127.0.0.1 LOCAL storage.page-size JanusGraph break requests that may return many results from distributed storage backends into a series of requests for small chunks/pages of results, where each chunk contains up to this many elements. Integer 100 MASKABLE storage.parallel-backend-ops Whether JanusGraph should attempt to parallelize storage operations Boolean true MASKABLE storage.password Password to authenticate against backend String (no default value) LOCAL storage.port The port on which to connect to storage backend servers. For HBase, it is the Zookeeper port. Integer (no default value) LOCAL storage.read-only Read-only database Boolean false LOCAL storage.read-time Maximum time (in ms) to wait for a backend read operation to complete successfully. If a backend read operationfails temporarily, JanusGraph will backoff exponentially and retry the operation until the wait time has been exhausted. Duration 10000 ms MASKABLE storage.root Storage root directory for those storage backends that require local storage. If you do not supply storage.directory and you do supply graph.graphname, then your data will be stored in the directory equivalent to / . String (no default value) LOCAL storage.setup-wait Time in milliseconds for backend manager to wait for the storage backends to become available when JanusGraph is run in server mode Duration 60000 ms MASKABLE storage.transactions Enables transactions on storage backends that support them Boolean true MASKABLE storage.username Username to authenticate against backend String (no default value) LOCAL storage.write-time Maximum time (in ms) to wait for a backend write operation to complete successfully. If a backend write operationfails temporarily, JanusGraph will backoff exponentially and retry the operation until the wait time has been exhausted. Duration 100000 ms MASKABLE","title":"storage"},{"location":"basics/configuration-reference/#storageberkeleyje","text":"BerkeleyDB JE configuration options Name Description Datatype Default Value Mutability storage.berkeleyje.cache-percentage Percentage of JVM heap reserved for BerkeleyJE's cache Integer 65 MASKABLE storage.berkeleyje.isolation-level The isolation level used by transactions String REPEATABLE_READ MASKABLE storage.berkeleyje.lock-mode The BDB record lock mode used for read operations String LockMode.DEFAULT MASKABLE","title":"storage.berkeleyje"},{"location":"basics/configuration-reference/#storagecassandra","text":"Cassandra storage backend options Name Description Datatype Default Value Mutability storage.cassandra.atomic-batch-mutate True to use Cassandra atomic batch mutation, false to use non-atomic batches Boolean true MASKABLE storage.cassandra.compaction-strategy-class The compaction strategy to use for JanusGraph tables String (no default value) FIXED storage.cassandra.compaction-strategy-options Compaction strategy options. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. String[] (no default value) FIXED storage.cassandra.compression Whether the storage backend should use compression when storing the data Boolean true FIXED storage.cassandra.compression-block-size The size of the compression blocks in kilobytes Integer 64 FIXED storage.cassandra.compression-type The sstable_compression value JanusGraph uses when creating column families. This accepts any value allowed by Cassandra's sstable_compression option. Leave this unset to disable sstable_compression on JanusGraph-created CFs. String LZ4Compressor MASKABLE storage.cassandra.frame-size-mb The thrift frame size in megabytes Integer 15 MASKABLE storage.cassandra.keyspace The name of JanusGraph's keyspace. It will be created if it does not exist. If it is not supplied, but graph.graphname is, then the the keyspace will be set to that. String janusgraph LOCAL storage.cassandra.read-consistency-level The consistency level of read operations against Cassandra String QUORUM MASKABLE storage.cassandra.replication-factor The number of data replicas (including the original copy) that should be kept. This is only meaningful for storage backends that natively support data replication. Integer 1 GLOBAL_OFFLINE storage.cassandra.replication-strategy-class The replication strategy to use for JanusGraph keyspace String org.apache.cassandra.locator.SimpleStrategy FIXED storage.cassandra.replication-strategy-options Replication strategy options, e.g. factor or replicas per datacenter. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. A replication_factor set here takes precedence over one set with storage.cassandra.replication-factor String[] (no default value) FIXED storage.cassandra.write-consistency-level The consistency level of write operations against Cassandra String QUORUM MASKABLE","title":"storage.cassandra"},{"location":"basics/configuration-reference/#storagecassandraastyanax","text":"Astyanax-specific Cassandra options Name Description Datatype Default Value Mutability storage.cassandra.astyanax.cluster-name Default name for the Cassandra cluster String JanusGraph Cluster MASKABLE storage.cassandra.astyanax.connection-pool-type Astyanax's connection pooler implementation String TOKEN_AWARE MASKABLE storage.cassandra.astyanax.frame-size The thrift frame size in mega bytes Integer 15 MASKABLE storage.cassandra.astyanax.host-supplier Host supplier to use when discovery type is set to DISCOVERY_SERVICE or TOKEN_AWARE String (no default value) MASKABLE storage.cassandra.astyanax.local-datacenter The name of the local or closest Cassandra datacenter. When set and not whitespace, this value will be passed into ConnectionPoolConfigurationImpl.setLocalDatacenter. When unset or set to whitespace, setLocalDatacenter will not be invoked. String (no default value) MASKABLE storage.cassandra.astyanax.max-cluster-connections-per-host Maximum pooled \"cluster\" connections per host Integer 3 MASKABLE storage.cassandra.astyanax.max-connections Maximum open connections allowed in the pool (counting all hosts) Integer -1 MASKABLE storage.cassandra.astyanax.max-connections-per-host Maximum pooled connections per host Integer 32 MASKABLE storage.cassandra.astyanax.max-operations-per-connection Maximum number of operations allowed per connection before the connection is closed Integer 100000 MASKABLE storage.cassandra.astyanax.node-discovery-type How Astyanax discovers Cassandra cluster nodes String RING_DESCRIBE MASKABLE storage.cassandra.astyanax.read-page-size The page size for Cassandra read operations Integer 4096 MASKABLE storage.cassandra.astyanax.retry-backoff-strategy Astyanax's retry backoff strategy with configuration parameters String com.netflix.astyanax.connectionpool.impl.FixedRetryBackoffStrategy,1000,5000 MASKABLE storage.cassandra.astyanax.retry-delay-slice Astyanax's connection pool \"retryDelaySlice\" parameter Integer 10000 MASKABLE storage.cassandra.astyanax.retry-max-delay-slice Astyanax's connection pool \"retryMaxDelaySlice\" parameter Integer 10 MASKABLE storage.cassandra.astyanax.retry-policy Astyanax's retry policy implementation with configuration parameters String com.netflix.astyanax.retry.BoundedExponentialBackoff,100,25000,8 MASKABLE storage.cassandra.astyanax.retry-suspend-window Astyanax's connection pool \"retryMaxDelaySlice\" parameter Integer 20000 MASKABLE","title":"storage.cassandra.astyanax"},{"location":"basics/configuration-reference/#storagecassandrassl","text":"Configuration options for SSL Name Description Datatype Default Value Mutability storage.cassandra.ssl.enabled Controls use of the SSL connection to Cassandra Boolean false LOCAL","title":"storage.cassandra.ssl"},{"location":"basics/configuration-reference/#storagecassandrassltruststore","text":"Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability storage.cassandra.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL storage.cassandra.ssl.truststore.password The password to access SSL Truststore. String LOCAL","title":"storage.cassandra.ssl.truststore"},{"location":"basics/configuration-reference/#storagecassandrathriftcpool","text":"Options for the Apache commons-pool connection manager Name Description Datatype Default Value Mutability storage.cassandra.thrift.cpool.evictor-period Approximate number of milliseconds between runs of the idle connection evictor. Set to -1 to never run the idle connection evictor. Long 30000 MASKABLE storage.cassandra.thrift.cpool.idle-test Whether the idle connection evictor validates idle connections and drops those that fail to validate Boolean false MASKABLE storage.cassandra.thrift.cpool.idle-tests-per-eviction-run When the value is negative, e.g. -n, roughly one nth of the idle connections are tested per run. When the value is positive, e.g. n, the min(idle-count, n) connections are tested per run. Integer 0 MASKABLE storage.cassandra.thrift.cpool.max-active Maximum number of concurrently in-use connections (-1 to leave undefined) Integer 16 MASKABLE storage.cassandra.thrift.cpool.max-idle Maximum number of concurrently idle connections (-1 to leave undefined) Integer 4 MASKABLE storage.cassandra.thrift.cpool.max-total Max number of allowed Thrift connections, idle or active (-1 to leave undefined) Integer -1 MASKABLE storage.cassandra.thrift.cpool.max-wait Maximum number of milliseconds to block when storage.cassandra.thrift.cpool.when-exhausted is set to BLOCK. Has no effect when set to actions besides BLOCK. Set to -1 to wait indefinitely. Long -1 MASKABLE storage.cassandra.thrift.cpool.min-evictable-idle-time Minimum number of milliseconds a connection must be idle before it is eligible for eviction. See also storage.cassandra.thrift.cpool.evictor-period. Set to -1 to never evict idle connections. Long 60000 MASKABLE storage.cassandra.thrift.cpool.min-idle Minimum number of idle connections the pool attempts to maintain Integer 0 MASKABLE storage.cassandra.thrift.cpool.when-exhausted What to do when clients concurrently request more active connections than are allowed by the pool. The value must be one of BLOCK, FAIL, or GROW. String BLOCK MASKABLE","title":"storage.cassandra.thrift.cpool"},{"location":"basics/configuration-reference/#storagecql","text":"CQL storage backend options Name Description Datatype Default Value Mutability storage.cql.atomic-batch-mutate True to use Cassandra atomic batch mutation, false to use non-atomic batches Boolean false MASKABLE storage.cql.batch-statement-size The number of statements in each batch Integer 20 MASKABLE storage.cql.cluster-name Default name for the Cassandra cluster String JanusGraph Cluster MASKABLE storage.cql.compact-storage Whether the storage backend should use compact storage on tables. This option is only available for Cassandra 2 and earlier and defaults to true. Boolean true FIXED storage.cql.compaction-strategy-class The compaction strategy to use for JanusGraph tables String (no default value) FIXED storage.cql.compaction-strategy-options Compaction strategy options. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. String[] (no default value) FIXED storage.cql.compression Whether the storage backend should use compression when storing the data Boolean true FIXED storage.cql.compression-block-size The size of the compression blocks in kilobytes Integer 64 FIXED storage.cql.compression-type The sstable_compression value JanusGraph uses when creating column families. This accepts any value allowed by Cassandra's sstable_compression option. Leave this unset to disable sstable_compression on JanusGraph-created CFs. String LZ4Compressor MASKABLE storage.cql.keyspace The name of JanusGraph's keyspace. It will be created if it does not exist. String janusgraph LOCAL storage.cql.local-core-connections-per-host The number of connections initially created and kept open to each host for local datacenter Integer 1 FIXED storage.cql.local-datacenter The name of the local or closest Cassandra datacenter. When set and not whitespace, this value will be passed into ConnectionPoolConfigurationImpl.setLocalDatacenter. When unset or set to whitespace, setLocalDatacenter will not be invoked. String (no default value) MASKABLE storage.cql.local-max-connections-per-host The maximum number of connections that can be created per host for local datacenter Integer 1 FIXED storage.cql.local-max-requests-per-connection The maximum number of requests per connection for local datacenter Integer 1024 FIXED storage.cql.only-use-local-consistency-for-system-operations True to prevent any system queries from using QUORUM consistency and always use LOCAL_QUORUM instead Boolean false MASKABLE storage.cql.protocol-version The protocol version used to connect to the Cassandra database. If no value is supplied then the driver will negotiate with the server. Integer 0 LOCAL storage.cql.read-consistency-level The consistency level of read operations against Cassandra String QUORUM MASKABLE storage.cql.remote-core-connections-per-host The number of connections initially created and kept open to each host for remote datacenter Integer 1 FIXED storage.cql.remote-max-connections-per-host The maximum number of connections that can be created per host for remote datacenter Integer 1 FIXED storage.cql.remote-max-requests-per-connection The maximum number of requests per connection for remote datacenter Integer 256 FIXED storage.cql.replication-factor The number of data replicas (including the original copy) that should be kept Integer 1 GLOBAL_OFFLINE storage.cql.replication-strategy-class The replication strategy to use for JanusGraph keyspace String SimpleStrategy FIXED storage.cql.replication-strategy-options Replication strategy options, e.g. factor or replicas per datacenter. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. A replication_factor set here takes precedence over one set with storage.cql.replication-factor String[] (no default value) FIXED storage.cql.use-external-locking True to prevent JanusGraph from using its own locking mechanism. Setting this to true eliminates redundant checks when using an external locking mechanism outside of JanusGraph. Be aware that when use-external-locking is set to true, that failure to employ a locking algorithm which locks all columns that participate in a transaction upfront and unlocks them when the transaction ends, will result in a 'read uncommitted' transaction isolation level guarantee. If set to true without an appropriate external locking mechanism in place side effects such as dirty/non-repeatable/phantom reads should be expected. Boolean false MASKABLE storage.cql.write-consistency-level The consistency level of write operations against Cassandra String QUORUM MASKABLE","title":"storage.cql"},{"location":"basics/configuration-reference/#storagecqlssl","text":"Configuration options for SSL Name Description Datatype Default Value Mutability storage.cql.ssl.enabled Controls use of the SSL connection to Cassandra Boolean false LOCAL","title":"storage.cql.ssl"},{"location":"basics/configuration-reference/#storagecqlssltruststore","text":"Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability storage.cql.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL storage.cql.ssl.truststore.password The password to access SSL Truststore. String LOCAL","title":"storage.cql.ssl.truststore"},{"location":"basics/configuration-reference/#storagehbase","text":"HBase storage options Name Description Datatype Default Value Mutability storage.hbase.compat-class The package and class name of the HBaseCompat implementation. HBaseCompat masks version-specific HBase API differences. When this option is unset, JanusGraph calls HBase's VersionInfo.getVersion() and loads the matching compat class at runtime. Setting this option forces JanusGraph to instead reflectively load and instantiate the specified class. String (no default value) MASKABLE storage.hbase.compression-algorithm An HBase Compression.Algorithm enum string which will be applied to newly created column families. The compression algorithm must be installed and available on the HBase cluster. JanusGraph cannot install and configure new compression algorithms on the HBase cluster by itself. String GZ MASKABLE storage.hbase.region-count The number of initial regions set when creating JanusGraph's HBase table Integer (no default value) MASKABLE storage.hbase.regions-per-server The number of regions per regionserver to set when creating JanusGraph's HBase table Integer (no default value) MASKABLE storage.hbase.short-cf-names Whether to shorten the names of JanusGraph's column families to one-character mnemonics to conserve storage space Boolean true FIXED storage.hbase.skip-schema-check Assume that JanusGraph's HBase table and column families already exist. When this is true, JanusGraph will not check for the existence of its table/CFs, nor will it attempt to create them under any circumstances. This is useful when running JanusGraph without HBase admin privileges. Boolean false MASKABLE storage.hbase.snapshot-name The name of an exising HBase snapshot to be used by HBaseSnapshotInputFormat String janusgraph-snapshot LOCAL storage.hbase.snapshot-restore-dir The tempoary directory to be used by HBaseSnapshotInputFormat to restore a snapshot. This directory should be on the same File System as the HBase root dir. String /tmp LOCAL storage.hbase.table The name of the table JanusGraph will use. When storage.hbase.skip-schema-check is false, JanusGraph will automatically create this table if it does not already exist. If this configuration option is not provided but graph.graphname is, the table will be set to that value. String janusgraph LOCAL","title":"storage.hbase"},{"location":"basics/configuration-reference/#storagelock","text":"Options for locking on eventually-consistent stores Name Description Datatype Default Value Mutability storage.lock.backend Locker type to use String consistentkey GLOBAL_OFFLINE storage.lock.clean-expired Whether to delete expired locks from the storage backend Boolean false MASKABLE storage.lock.expiry-time Number of milliseconds after which a lock is considered to have expired. Lock applications that were not released are considered expired after this time and released. This value should be larger than the maximum time a transaction can take in order to guarantee that no correctly held applications are expired pre-maturely and as small as possible to avoid dead lock. Duration 300000 ms GLOBAL_OFFLINE storage.lock.local-mediator-group This option determines the LocalLockMediator instance used for early detection of lock contention between concurrent JanusGraph graph instances within the same process which are connected to the same storage backend. JanusGraph instances that have the same value for this variable will attempt to discover lock contention among themselves in memory before proceeding with the general-case distributed locking code. JanusGraph generates an appropriate default value for this option at startup. Overridding the default is generally only useful in testing. String (no default value) LOCAL storage.lock.retries Number of times the system attempts to acquire a lock before giving up and throwing an exception Integer 3 MASKABLE storage.lock.wait-time Number of milliseconds the system waits for a lock application to be acknowledged by the storage backend. Also, the time waited at the end of all lock applications before verifying that the applications were successful. This value should be a small multiple of the average consistent write time. Duration 100 ms GLOBAL_OFFLINE","title":"storage.lock"},{"location":"basics/configuration-reference/#storagemeta","text":"Meta data to include in storage backend retrievals Name Description Datatype Default Value Mutability storage.meta.[X].timestamps Whether to include timestamps in retrieved entries for storage backends that automatically annotated entries with timestamps Boolean false GLOBAL storage.meta.[X].ttl Whether to include ttl in retrieved entries for storage backends that support storage and retrieval of cell level TTL Boolean false GLOBAL storage.meta.[X].visibility Whether to include visibility in retrieved entries for storage backends that support cell level visibility Boolean true GLOBAL","title":"storage.meta *"},{"location":"basics/configuration-reference/#tx","text":"Configuration options for transaction handling Name Description Datatype Default Value Mutability tx.log-tx Whether transaction mutations should be logged to JanusGraph's write-ahead transaction log which can be used for recovery of partially failed transactions Boolean false GLOBAL tx.max-commit-time Maximum time (in ms) that a transaction might take to commit against all backends. This is used by the distributed write-ahead log processing to determine when a transaction can be considered failed (i.e. after this time has elapsed).Must be longer than the maximum allowed write time. Duration 10000 ms GLOBAL","title":"tx"},{"location":"basics/configuration-reference/#txrecovery","text":"Configuration options for transaction recovery processes Name Description Datatype Default Value Mutability tx.recovery.verbose Whether the transaction recovery system should print recovered transactions and other activity to standard output Boolean false MASKABLE","title":"tx.recovery"},{"location":"basics/configuration/","text":"Configuration A JanusGraph graph database cluster consists of one or multiple JanusGraph instances. To open a JanusGraph instance, a configuration has to be provided which specifies how JanusGraph should be set up. A JanusGraph configuration specifies which components JanusGraph should use, controls all operational aspects of a JanusGraph deployment, and provides a number of tuning options to get maximum performance from a JanusGraph cluster. At a minimum, a JanusGraph configuration must define the persistence engine that JanusGraph should use as a storage backend. Storage Backends lists all supported persistence engines and how to configure them respectively. If advanced graph query support (e.g full-text search, geo search, or range queries) is required an additional indexing backend must be configured. See Index Backends for details. If query performance is a concern, then caching should be enabled. Cache configuration and tuning is described in JanusGraph Cache . Example Configurations Below are some example configuration files to demonstrate how to configure the most commonly used storage backends, indexing systems, and performance components. This covers only a tiny portion of the available configuration options. Refer to Configuration Reference for the complete list of all options. Cassandra+Elasticsearch Sets up JanusGraph to use the Cassandra persistence engine running locally and a remote Elastic search indexing system: storage.backend=cql storage.hostname=localhost index.search.backend=elasticsearch index.search.hostname=100.100.101.1, 100.100.101.2 index.search.elasticsearch.client-only=true HBase+Caching Sets up JanusGraph to use the HBase persistence engine running remotely and uses JanusGraph\u2019s caching component for better performance. storage.backend=hbase storage.hostname=100.100.101.1 storage.port=2181 cache.db-cache = true cache.db-cache-clean-wait = 20 cache.db-cache-time = 180000 cache.db-cache-size = 0.5 BerkeleyDB Sets up JanusGraph to use BerkeleyDB as an embedded persistence engine with Elasticsearch as an embedded indexing system. storage.backend=berkeleyje storage.directory=/tmp/graph index.search.backend=elasticsearch index.search.directory=/tmp/searchindex index.search.elasticsearch.client-only=false index.search.elasticsearch.local-mode=true Configuration Reference describes all of these configuration options in detail. The conf directory of the JanusGraph distribution contains additional configuration examples. Further Examples There are several example configuration files in the conf/ directory that can be used to get started with JanusGraph quickly. Paths to these files can be passed to JanusGraphFactory.open(...) as shown below: // Connect to Cassandra on localhost using a default configuration graph = JanusGraphFactory . open ( \"conf/janusgraph-cql.properties\" ) // Connect to HBase on localhost using a default configuration graph = JanusGraphFactory . open ( \"conf/janusgraph-hbase.properties\" ) Using Configuration How the configuration is provided to JanusGraph depends on the instantiation mode. JanusGraphFactory Gremlin Console The JanusGraph distribution contains a command line Gremlin Console which makes it easy to get started and interact with JanusGraph. Invoke bin/gremlin.sh (Unix/Linux) or bin/gremlin.bat (Windows) to start the Console and then open a JanusGraph graph using the factory with the configuration stored in an accessible properties configuration file: graph = JanusGraphFactory . open ( 'path/to/configuration.properties' ) JanusGraph Embedded JanusGraphFactory can also be used to open an embedded JanusGraph graph instance from within a JVM-based user application. In that case, JanusGraph is part of the user application and the application can call upon JanusGraph directly through its public API. Short Codes If the JanusGraph graph cluster has been previously configured and/or only the storage backend needs to be defined, JanusGraphFactory accepts a colon-separated string representation of the storage backend name and hostname or directory. graph = JanusGraphFactory . open ( 'cql:localhost' ) graph = JanusGraphFactory . open ( 'berkeleyje:/tmp/graph' ) JanusGraph Server JanusGraph, by itself, is simply a set of jar files with no thread of execution. There are two basic patterns for connecting to, and using a JanusGraph database: JanusGraph can be used by embedding JanusGraph calls in a client program where the program provides the thread of execution. JanusGraph packages a long running server process that, when started, allows a remote client or logic running in a separate program to make JanusGraph calls. This long running server process is called JanusGraph Server . For the JanusGraph Server, JanusGraph uses Gremlin Server of the Apache TinkerPop stack to service client requests. JanusGraph provides an out-of-the-box configuration for a quick start with JanusGraph Server, but the configuration can be changed to provide a wide range of server capabilities. Configuring JanusGraph Server is accomplished through a JanusGraph Server yaml configuration file located in the ./conf/gremlin-server directory in the JanusGraph distribution. To configure JanusGraph Server with a graph instance ( JanusGraph ), the JanusGraph Server configuration file requires the following settings: ... graphs : { graph : conf/janusgraph-berkeleyje.properties } scriptEngines : { gremlin-groovy : { plugins : { org.janusgraph.graphdb.tinkerpop.plugin.JanusGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.server.jsr223.GremlinServerGremlinPlugin : {}, org.apache.tinkerpop.gremlin.tinkergraph.jsr223.TinkerGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.jsr223.ImportGremlinPlugin : { classImports : [ java.lang.Math ], methodImports : [ java.lang.Math#* ]}, org.apache.tinkerpop.gremlin.jsr223.ScriptFileGremlinPlugin : { files : [ scripts/empty-sample.groovy ]}}}} ... The entry for graphs defines the bindings to specific JanusGraph configurations. In the above case it binds graph to a JanusGraph configuration at conf/janusgraph-berkeleyje.properties . The plugins entry enables the JanusGraph Gremlin Plugin, which enables auto-imports of JanusGraph classes so that they can be referenced in remotely submitted scripts. Learn more about configuring and using JanusGraph Server in JanusGraph Server . Server Distribution The JanusGraph zip file contains a quick start server component that helps make it easier to get started with Gremlin Server and JanusGraph. Invoke bin/janusgraph.sh start to start Gremlin Server with Cassandra and Elasticsearch. Note For security reasons Elasticsearch and therefore janusgraph.sh must be run under a non-root account Global Configuration JanusGraph distinguishes between local and global configuration options. Local configuration options apply to an individual JanusGraph instance. Global configuration options apply to all instances in a cluster. More specifically, JanusGraph distinguishes the following five scopes for configuration options: LOCAL : These options only apply to an individual JanusGraph instance and are specified in the configuration provided when initializing the JanusGraph instance. MASKABLE : These configuration options can be overwritten for an individual JanusGraph instance by the local configuration file. If the local configuration file does not specify the option, its value is read from the global JanusGraph cluster configuration. GLOBAL : These options are always read from the cluster configuration and cannot be overwritten on an instance basis. GLOBAL_OFFLINE : Like GLOBAL , but changing these options requires a cluster restart to ensure that the value is the same across the entire cluster. FIXED : Like GLOBAL , but the value cannot be changed once the JanusGraph cluster is initialized. When the first JanusGraph instance in a cluster is started, the global configuration options are initialized from the provided local configuration file. Subsequently changing global configuration options is done through JanusGraph\u2019s management API. To access the management API, call g.getManagementSystem() on an open JanusGraph instance handle g . For example, to change the default caching behavior on a JanusGraph cluster: mgmt = graph . openManagement () mgmt . get ( 'cache.db-cache' ) // Prints the current config setting mgmt . set ( 'cache.db-cache' , true ) // Changes option mgmt . get ( 'cache.db-cache' ) // Prints 'true' mgmt . commit () // Changes take effect Changing Offline Options Changing configuration options does not affect running instances and only applies to newly started ones. Changing GLOBAL_OFFLINE configuration options requires restarting the cluster so that the changes take effect immediately for all instances. To change GLOBAL_OFFLINE options follow these steps: Close all but one JanusGraph instance in the cluster Connect to the single instance Ensure all running transactions are closed Ensure no new transactions are started (i.e. the cluster must be offline) Open the management API Change the configuration option(s) Call commit which will automatically shut down the graph instance Restart all instances Refer to the full list of configuration options in Configuration Reference for more information including the configuration scope of each option.","title":"Configuration"},{"location":"basics/configuration/#configuration","text":"A JanusGraph graph database cluster consists of one or multiple JanusGraph instances. To open a JanusGraph instance, a configuration has to be provided which specifies how JanusGraph should be set up. A JanusGraph configuration specifies which components JanusGraph should use, controls all operational aspects of a JanusGraph deployment, and provides a number of tuning options to get maximum performance from a JanusGraph cluster. At a minimum, a JanusGraph configuration must define the persistence engine that JanusGraph should use as a storage backend. Storage Backends lists all supported persistence engines and how to configure them respectively. If advanced graph query support (e.g full-text search, geo search, or range queries) is required an additional indexing backend must be configured. See Index Backends for details. If query performance is a concern, then caching should be enabled. Cache configuration and tuning is described in JanusGraph Cache .","title":"Configuration"},{"location":"basics/configuration/#example-configurations","text":"Below are some example configuration files to demonstrate how to configure the most commonly used storage backends, indexing systems, and performance components. This covers only a tiny portion of the available configuration options. Refer to Configuration Reference for the complete list of all options.","title":"Example Configurations"},{"location":"basics/configuration/#cassandraelasticsearch","text":"Sets up JanusGraph to use the Cassandra persistence engine running locally and a remote Elastic search indexing system: storage.backend=cql storage.hostname=localhost index.search.backend=elasticsearch index.search.hostname=100.100.101.1, 100.100.101.2 index.search.elasticsearch.client-only=true","title":"Cassandra+Elasticsearch"},{"location":"basics/configuration/#hbasecaching","text":"Sets up JanusGraph to use the HBase persistence engine running remotely and uses JanusGraph\u2019s caching component for better performance. storage.backend=hbase storage.hostname=100.100.101.1 storage.port=2181 cache.db-cache = true cache.db-cache-clean-wait = 20 cache.db-cache-time = 180000 cache.db-cache-size = 0.5","title":"HBase+Caching"},{"location":"basics/configuration/#berkeleydb","text":"Sets up JanusGraph to use BerkeleyDB as an embedded persistence engine with Elasticsearch as an embedded indexing system. storage.backend=berkeleyje storage.directory=/tmp/graph index.search.backend=elasticsearch index.search.directory=/tmp/searchindex index.search.elasticsearch.client-only=false index.search.elasticsearch.local-mode=true Configuration Reference describes all of these configuration options in detail. The conf directory of the JanusGraph distribution contains additional configuration examples.","title":"BerkeleyDB"},{"location":"basics/configuration/#further-examples","text":"There are several example configuration files in the conf/ directory that can be used to get started with JanusGraph quickly. Paths to these files can be passed to JanusGraphFactory.open(...) as shown below: // Connect to Cassandra on localhost using a default configuration graph = JanusGraphFactory . open ( \"conf/janusgraph-cql.properties\" ) // Connect to HBase on localhost using a default configuration graph = JanusGraphFactory . open ( \"conf/janusgraph-hbase.properties\" )","title":"Further Examples"},{"location":"basics/configuration/#using-configuration","text":"How the configuration is provided to JanusGraph depends on the instantiation mode.","title":"Using Configuration"},{"location":"basics/configuration/#janusgraphfactory","text":"","title":"JanusGraphFactory"},{"location":"basics/configuration/#gremlin-console","text":"The JanusGraph distribution contains a command line Gremlin Console which makes it easy to get started and interact with JanusGraph. Invoke bin/gremlin.sh (Unix/Linux) or bin/gremlin.bat (Windows) to start the Console and then open a JanusGraph graph using the factory with the configuration stored in an accessible properties configuration file: graph = JanusGraphFactory . open ( 'path/to/configuration.properties' )","title":"Gremlin Console"},{"location":"basics/configuration/#janusgraph-embedded","text":"JanusGraphFactory can also be used to open an embedded JanusGraph graph instance from within a JVM-based user application. In that case, JanusGraph is part of the user application and the application can call upon JanusGraph directly through its public API.","title":"JanusGraph Embedded"},{"location":"basics/configuration/#short-codes","text":"If the JanusGraph graph cluster has been previously configured and/or only the storage backend needs to be defined, JanusGraphFactory accepts a colon-separated string representation of the storage backend name and hostname or directory. graph = JanusGraphFactory . open ( 'cql:localhost' ) graph = JanusGraphFactory . open ( 'berkeleyje:/tmp/graph' )","title":"Short Codes"},{"location":"basics/configuration/#janusgraph-server","text":"JanusGraph, by itself, is simply a set of jar files with no thread of execution. There are two basic patterns for connecting to, and using a JanusGraph database: JanusGraph can be used by embedding JanusGraph calls in a client program where the program provides the thread of execution. JanusGraph packages a long running server process that, when started, allows a remote client or logic running in a separate program to make JanusGraph calls. This long running server process is called JanusGraph Server . For the JanusGraph Server, JanusGraph uses Gremlin Server of the Apache TinkerPop stack to service client requests. JanusGraph provides an out-of-the-box configuration for a quick start with JanusGraph Server, but the configuration can be changed to provide a wide range of server capabilities. Configuring JanusGraph Server is accomplished through a JanusGraph Server yaml configuration file located in the ./conf/gremlin-server directory in the JanusGraph distribution. To configure JanusGraph Server with a graph instance ( JanusGraph ), the JanusGraph Server configuration file requires the following settings: ... graphs : { graph : conf/janusgraph-berkeleyje.properties } scriptEngines : { gremlin-groovy : { plugins : { org.janusgraph.graphdb.tinkerpop.plugin.JanusGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.server.jsr223.GremlinServerGremlinPlugin : {}, org.apache.tinkerpop.gremlin.tinkergraph.jsr223.TinkerGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.jsr223.ImportGremlinPlugin : { classImports : [ java.lang.Math ], methodImports : [ java.lang.Math#* ]}, org.apache.tinkerpop.gremlin.jsr223.ScriptFileGremlinPlugin : { files : [ scripts/empty-sample.groovy ]}}}} ... The entry for graphs defines the bindings to specific JanusGraph configurations. In the above case it binds graph to a JanusGraph configuration at conf/janusgraph-berkeleyje.properties . The plugins entry enables the JanusGraph Gremlin Plugin, which enables auto-imports of JanusGraph classes so that they can be referenced in remotely submitted scripts. Learn more about configuring and using JanusGraph Server in JanusGraph Server .","title":"JanusGraph Server"},{"location":"basics/configuration/#server-distribution","text":"The JanusGraph zip file contains a quick start server component that helps make it easier to get started with Gremlin Server and JanusGraph. Invoke bin/janusgraph.sh start to start Gremlin Server with Cassandra and Elasticsearch. Note For security reasons Elasticsearch and therefore janusgraph.sh must be run under a non-root account","title":"Server Distribution"},{"location":"basics/configuration/#global-configuration","text":"JanusGraph distinguishes between local and global configuration options. Local configuration options apply to an individual JanusGraph instance. Global configuration options apply to all instances in a cluster. More specifically, JanusGraph distinguishes the following five scopes for configuration options: LOCAL : These options only apply to an individual JanusGraph instance and are specified in the configuration provided when initializing the JanusGraph instance. MASKABLE : These configuration options can be overwritten for an individual JanusGraph instance by the local configuration file. If the local configuration file does not specify the option, its value is read from the global JanusGraph cluster configuration. GLOBAL : These options are always read from the cluster configuration and cannot be overwritten on an instance basis. GLOBAL_OFFLINE : Like GLOBAL , but changing these options requires a cluster restart to ensure that the value is the same across the entire cluster. FIXED : Like GLOBAL , but the value cannot be changed once the JanusGraph cluster is initialized. When the first JanusGraph instance in a cluster is started, the global configuration options are initialized from the provided local configuration file. Subsequently changing global configuration options is done through JanusGraph\u2019s management API. To access the management API, call g.getManagementSystem() on an open JanusGraph instance handle g . For example, to change the default caching behavior on a JanusGraph cluster: mgmt = graph . openManagement () mgmt . get ( 'cache.db-cache' ) // Prints the current config setting mgmt . set ( 'cache.db-cache' , true ) // Changes option mgmt . get ( 'cache.db-cache' ) // Prints 'true' mgmt . commit () // Changes take effect","title":"Global Configuration"},{"location":"basics/configuration/#changing-offline-options","text":"Changing configuration options does not affect running instances and only applies to newly started ones. Changing GLOBAL_OFFLINE configuration options requires restarting the cluster so that the changes take effect immediately for all instances. To change GLOBAL_OFFLINE options follow these steps: Close all but one JanusGraph instance in the cluster Connect to the single instance Ensure all running transactions are closed Ensure no new transactions are started (i.e. the cluster must be offline) Open the management API Change the configuration option(s) Call commit which will automatically shut down the graph instance Restart all instances Refer to the full list of configuration options in Configuration Reference for more information including the configuration scope of each option.","title":"Changing Offline Options"},{"location":"basics/configured-graph-factory/","text":"ConfiguredGraphFactory The JanusGraph Server can be configured to use the ConfiguredGraphFactory . The ConfiguredGraphFactory is an access point to your graphs, similar to the JanusGraphFactory . These graph factories provide methods for dynamically managing the graphs hosted on the server. Overview JanusGraphFactory is a class that provides an access point to your graphs by providing a Configuration object each time you access the graph. ConfiguredGraphFactory provides an access point to your graphs for which you have previously created configurations using the ConfigurationManagementGraph . It also offers an access point to manage graph configurations. ConfigurationManagementGraph allows you to manage graph configurations. JanusGraphManager is an internal server component that tracks graph references, provided your graphs are configured to use it. ConfiguredGraphFactory versus JanusGraphFactory However, there is an important distinction between these two graph factories: The ConfiguredGraphFactory can only be used if you have configured your server to use the ConfigurationManagementGraph APIs at server start. The benefits of using the ConfiguredGraphFactory are that: You only need to supply a String to access your graphs, as opposed to the JanusGraphFactory -- which requires you to specify information about the backend you wish to use when accessing a graph-- every time you open a graph. If your ConfigurationManagementGraph is configured with a distributed storage backend then your graph configurations are available to all JanusGraph nodes in your cluster. How Does the ConfiguredGraphFactory Work? The ConfiguredGraphFactory provides an access point to graphs under two scenarios: You have already created a configuration for your specific graph object using the ConfigurationManagementGraph#createConfiguration . In this scenario, your graph is opened using the previously created configuration for this graph. You have already created a template configuration using the ConfigurationManagementGraph#createTemplateConfiguration . In this scenario, we create a configuration for the graph you are creating by copying over all attributes stored in your template configuration and appending the relevant graphName attribute, and we then open the graph according to that specific configuration. Accessing the Graphs You can either use ConfiguredGraphFactory.create(\"graphName\") or ConfiguredGraphFactory.open(\"graphName\") . Learn more about the difference between these two options by reading the section below about the ConfigurationManagementGraph . You can also access your graphs by using the bindings. Read more about this in the Graph and Traversal Bindings section. Listing the Graphs ConfiguredGraphFactory.getGraphNames() will return a set of graph names for which you have created configurations using the ConfigurationManagementGraph APIs. JanusGraphFactory.getGraphNames() on the other hand returns a set of graph names for which you have instantiated and the references are stored inside the JanusGraphManager . Dropping a Graph ConfiguredGraphFactory.drop(\"graphName\") will drop the graph database, deleting all data in storage and indexing backends. The graph can be open or closed (will be closed as part of the drop operation). Furthermore, this will also remove any existing graph configuration in the ConfigurationManagementGraph . Important This is an irreversible operation that will delete all graph and index data. Important To ensure all graph representations are consistent across all JanusGraph nodes in your cluster, this removes the graph from the JanusGraphManager graph cache on every node in the cluster, assuming each node has been properly configured to use the JanusGraphManager . Learn more about this feature and how to configure your server to use said feature here . Configuring JanusGraph Server for ConfiguredGraphFactory To be able to use the ConfiguredGraphFactory , you must configure your server to use the ConfigurationManagementGraph APIs. To do this, you have to inject a graph variable named \"ConfigurationManagementGraph\" in your server\u2019s YAML\u2019s graphs map. For example: graphManager : org.janusgraph.graphdb.management.JanusGraphManager graphs : { ConfigurationManagementGraph : conf/JanusGraph-configurationmanagement.properties } In this example, our ConfigurationManagementGraph graph will be configured using the properties stored inside conf/JanusGraph-configurationmanagement.properties , which for example, look like: gremlin.graph=org.janusgraph.core.ConfiguredGraphFactory storage.backend=cql graph.graphname=ConfigurationManagementGraph storage.hostname=127.0.0.1 Assuming the GremlinServer started successfully and the ConfigurationManagementGraph was successfully instantiated, then all the APIs available on the ConfigurationManagementGraph Singleton will also act upon said graph. Furthermore, this is the graph that will be used to access the configurations used to create/open graphs using the ConfiguredGraphFactory . Important The pom.xml included in the JanusGraph distribution lists this dependency as optional, but the ConfiguredGraphFactory makes use of the JanusGraphManager , which requires a declared dependency on the org.apache.tinkerpop:gremlin-server . So if you run into NoClassDefFoundError errors, then be sure to update according to this message. ConfigurationManagementGraph The ConfigurationManagementGraph is a Singleton that allows you to create/update/remove configurations that you can use to access your graphs using the ConfiguredGraphFactory . See above on configuring your server to enable use of these APIs. Important The ConfiguredGraphFactory offers an access point to manage your graph configurations managed by the ConfigurationManagementGraph , so instead of acting upon the Singleton itself, you may act upon the corresponding ConfiguredGraphFactory static methods. For example, you may use ConfiguredGraphFactory.removeTemplateConfiguration() instead of ConfiguredGraphFactory.getInstance().removeTemplateConfiguration() . Graph Configurations The ConfigurationManagementGraph singleton allows you to create configurations used to open specific graphs, referenced by the graph.graphname property. For example: map = new HashMap < String , Object >(); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); map . put ( \"graph.graphname\" , \"graph1\" ); ConfiguredGraphFactory . createConfiguration ( new MapConfiguration ( map )); Then you could access this graph on any JanusGraph node using: ConfiguredGraphFactory . open ( \"graph1\" ); Template Configuration The ConfigurationManagementGraph also allows you to create one template configuration, which you can use to create many graphs using the same configuration template. For example: map = new HashMap < String , Object >(); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); After doing this, you can create graphs using the template configuration: ConfiguredGraphFactory . create ( \"graph2\" ); This method will first create a new configuration for \"graph2\" by copying over all the properties associated with the template configuration and storing it on a configuration for this specific graph. This means that this graph can be accessed in, on any JanusGraph node, in the future by doing: ConfiguredGraphFactory . open ( \"graph2\" ); Updating Configurations All interactions with both the JanusGraphFactory and the ConfiguredGraphFactory that interact with configurations that define the property graph.graphname go through the JanusGraphManager which keeps track of graph references created on the given JVM. Think of it as a graph cache. For this reason: Important Any updates to a graph configuration results in the eviction of the relevant graph from the graph cache on every node in the JanusGraph cluster, assuming each node has been configured properly to use the JanusGraphManager . Learn more about this feature and how to configure your server to use said feature here . Since graphs created using the template configuration first create a configuration for that graph in question using a copy and create method, this means that: Important Any updates to a specific graph created using the template configuration are not guaranteed to take effect on the specific graph until: 1. The relevant configuration is removed: ConfiguredGraphFactory.removeConfiguration(\"graph2\"); 2. The graph is recreated using the template configuration: ConfiguredGraphFactory.create(\"graph2\"); Update Examples 1) We migrated our Cassandra data to a new server with a new IP address: map = new HashMap (); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); map . put ( \"graph.graphname\" , \"graph1\" ); ConfiguredGraphFactory . createConfiguration ( new MapConfiguration ( map )); g1 = ConfiguredGraphFactory . open ( \"graph1\" ); // Update configuration map = new HashMap (); map . put ( \"storage.hostname\" , \"10.0.0.1\" ); ConfiguredGraphFactory . updateConfiguration ( \"graph1\" , map ); // We are now guaranteed to use the updated configuration g1 = ConfiguredGraphFactory . open ( \"graph1\" ); 2) We added an Elasticsearch node to our setup: map = new HashMap (); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); map . put ( \"graph.graphname\" , \"graph1\" ); ConfiguredGraphFactory . createConfiguration ( new MapConfiguration ( map )); g1 = ConfiguredGraphFactory . open ( \"graph1\" ); // Update configuration map = new HashMap (); map . put ( \"index.search.backend\" , \"elasticsearch\" ); map . put ( \"index.search.hostname\" , \"127.0.0.1\" ); map . put ( \"index.search.elasticsearch.transport-scheme\" , \"http\" ); ConfiguredGraphFactory . updateConfiguration ( \"graph1\" , map ); // We are now guaranteed to use the updated configuration g1 = ConfiguredGraphFactory . open ( \"graph1\" ); 3) Update a graph configuration that was created using a template configuration that has been updated: map = new HashMap (); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); g1 = ConfiguredGraphFactory . create ( \"graph1\" ); // Update template configuration map = new HashMap (); map . put ( \"index.search.backend\" , \"elasticsearch\" ); map . put ( \"index.search.hostname\" , \"127.0.0.1\" ); map . put ( \"index.search.elasticsearch.transport-scheme\" , \"http\" ); ConfiguredGraphFactory . updateTemplateConfiguration ( new MapConfiguration ( map )); // Remove Configuration ConfiguredGraphFactory . removeConfiguration ( \"graph1\" ); // Recreate ConfiguredGraphFactory . create ( \"graph1\" ); // Now this graph's configuration is guaranteed to be updated JanusGraphManager The JanusGraphManager is a Singleton adhering to the TinkerPop graphManager specifications. In particular, the JanusGraphManager provides: a coordinated mechanism by which to instantiate graph references on a given JanusGraph node a graph reference tracker (or cache) Any graph you create using the graph.graphname property will go through the JanusGraphManager and thus be instantiated in a coordinated fashion. The graph reference will also be placed in the graph cache on the JVM in question. Thus, any graph you open using the graph.graphname property that has already been instantiated on the JVM in question will be retrieved from the graph cache. This is why updates to your configurations require a few steps to guarantee correctness. How To Use The JanusGraphManager This is a new configuration option you can use when defining a property in your configuration that defines how to access a graph. All configurations that include this property will result in the graph instantiation happening through the JanusGraphManager (process explained above). For backwards compatibility, any graphs that do not supply this parameter but supplied at server start in your graphs object in your .yaml file, these graphs will be bound through the JanusGraphManager denoted by their key supplied for that graph. For example, if your .yaml graphs object looks like: graphManager : org.janusgraph.graphdb.management.JanusGraphManager graphs { graph1 : conf/graph1.properties, graph2 : conf/graph2.properties } but conf/graph1.properties and conf/graph2.properties do not include the property graph.graphname , then these graphs will be stored in the JanusGraphManager and thus bound in your gremlin script executions as graph1 and graph2 , respectively. Important For convenience, if your configuration used to open a graph specifies graph.graphname , but does not specify the backend\u2019s storage directory, tablename, or keyspacename, then the relevant parameter will automatically be set to the value of graph.graphname . However, if you supply one of those parameters, that value will always take precedence. And if you supply neither, they default to the configuration option\u2019s default value. One special case is storage.root configuration option. This is a new configuration option used to specify the base of the directory that will be used for any backend requiring local storage directory access. If you supply this parameter, you must also supply the graph.graphname property, and the absolute storage directory will be equal to the value of the graph.graphname property appended to the value of the storage.root property. Below are some example use cases: 1) Create a template configuration for my Cassandra backend such that each graph created using this configuration gets a unique keyspace equivalent to the String <graphName> provided to the factory: map = new HashMap (); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); g1 = ConfiguredGraphFactory . create ( \"graph1\" ); //keyspace === graph1 g2 = ConfiguredGraphFactory . create ( \"graph2\" ); //keyspace === graph2 g3 = ConfiguredGraphFactory . create ( \"graph3\" ); //keyspace === graph3 2) Create a template configuration for my BerkeleyJE backend such that each graph created using this configuration gets a unique storage directory equivalent to the \"<storage.root>/<graph.graphname>\": map = new HashMap (); map . put ( \"storage.backend\" , \"berkeleyje\" ); map . put ( \"storage.root\" , \"/data/graphs\" ); ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); g1 = ConfiguredGraphFactory . create ( \"graph1\" ); //storage directory === /data/graphs/graph1 g2 = ConfiguredGraphFactory . create ( \"graph2\" ); //storage directory === /data/graphs/graph2 g3 = ConfiguredGraphFactory . create ( \"graph3\" ); //storage directory === /data/graphs/graph3 Graph and Traversal Bindings Graphs created using the ConfiguredGraphFactory are bound to the executor context on the Gremlin Server by the \"graph.graphname\" property, and the graph's traversal reference is bound to the context by \" <graphname>_traversal \". This means, on subsequent connections to the server after the first time you create/open a graph, you can access the graph and traversal references by the \" <graphname> \" and \" <graphname>_traversal \" properties. Learn more about this feature and how to configure your server to use said feature here . Important If you are connected to a remote Gremlin Server using the Gremlin Console and a sessioned connection, then you will have to reconnect to the server to bind the variables. This is also true for any sessioned WebSocket connection. Important The JanusGraphManager rebinds every graph stored on the ConfigurationManagementGraph (or those for which you have created configurations) every 20 seconds. This means your graph and traversal bindings for graphs created using the ConfigredGraphFactory will be available on all JanusGraph nodes with a maximum of a 20 second lag. It also means that a binding will still be available on a node after a server restart. Binding Example gremlin > : remote connect tinkerpop . server conf /remote.yaml ==>Configured localhost/ 127.0 . 0.1 : 8182 gremlin > : remote console ==> All scripts will now be sent to Gremlin Server - [ localhost / 127.0 . 0.1 : 8182 ] - type ':remote console' to return to local mode gremlin > ConfiguredGraphFactory . open ( \"graph1\" ) ==> standardjanusgraph [ cassandrathrift: [ 127.0 . 0.1 ]] gremlin > graph1 ==> standardjanusgraph [ cassandrathrift: [ 127.0 . 0.1 ]] gremlin > graph1_traversal ==> graphtraversalsource [ standardjanusgraph [ cassandrathrift: [ 127.0 . 0.1 ]], standard ] Examples It is reccomended to use a sessioned connection when creating a Configured Graph Factory template. If a sessioned connection is not used the Configured Graph Factory Template creation must be sent to the server as a single line using semi-colons. See details on sessions can be found in Connecting to Gremlin Server . gremlin > : remote connect tinkerpop . server conf /remote.yaml session ==>Configured localhost/ 127.0 . 0.1 : 8182 gremlin > : remote console ==> All scripts will now be sent to Gremlin Server - [ localhost: 8182 ]-[ 5206 cdde - b231 - 41 fa - 9 e6c - 69 feac0fe2b2 ] - type ':remote console' to return to local mode gremlin > ConfiguredGraphFactory . open ( \"graph\" ); Please create configuration for this graph using the ConfigurationManagementGraph API . gremlin > ConfiguredGraphFactory . create ( \"graph\" ); Please create a template Configuration using the ConfigurationManagementGraph API . gremlin > map = new HashMap (); gremlin > map . put ( \"storage.backend\" , \"cql\" ); gremlin > map . put ( \"storage.hostname\" , \"127.0.0.1\" ); gremlin > map . put ( \"GraphName\" , \"graph1\" ); gremlin > ConfiguredGraphFactory . createConfiguration ( new MapConfiguration ( map )); Please include in your configuration the property \"graph.graphname\" . gremlin > map = new HashMap (); gremlin > map . put ( \"storage.backend\" , \"cql\" ); gremlin > map . put ( \"storage.hostname\" , \"127.0.0.1\" ); gremlin > map . put ( \"graph.graphname\" , \"graph1\" ); gremlin > ConfiguredGraphFactory . createConfiguration ( new MapConfiguration ( map )); ==> null gremlin > ConfiguredGraphFactory . open ( \"graph1\" ). vertices (); gremlin > map = new HashMap (); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); gremlin > map . put ( \"graph.graphname\" , \"graph1\" ); gremlin > ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); Your template configuration may not contain the property \"graph.graphname\" . gremlin > map = new HashMap (); gremlin > map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); gremlin > ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); ==> null // Each graph is now acting in unique keyspaces equivalent to the graphnames . gremlin > g1 = ConfiguredGraphFactory . open ( \"graph1\" ); gremlin > g2 = ConfiguredGraphFactory . create ( \"graph2\" ); gremlin > g3 = ConfiguredGraphFactory . create ( \"graph3\" ); gremlin > g2 . addVertex (); gremlin > l = []; gremlin > l << g1 . vertices (). size (); ==> 0 gremlin > l << g2 . vertices (). size (); ==> 1 gremlin > l << g3 . vertices (). size (); ==> 0 // After a graph is created, you must access it using .open() gremlin > g2 = ConfiguredGraphFactory . create ( \"graph2\" ); g2 . vertices (). size (); Configuration for graph \"graph2\" already exists . gremlin > g2 = ConfiguredGraphFactory . open ( \"graph2\" ); g2 . vertices (). size (); ==> 1","title":"ConfiguredGraphFactory"},{"location":"basics/configured-graph-factory/#configuredgraphfactory","text":"The JanusGraph Server can be configured to use the ConfiguredGraphFactory . The ConfiguredGraphFactory is an access point to your graphs, similar to the JanusGraphFactory . These graph factories provide methods for dynamically managing the graphs hosted on the server.","title":"ConfiguredGraphFactory"},{"location":"basics/configured-graph-factory/#overview","text":"JanusGraphFactory is a class that provides an access point to your graphs by providing a Configuration object each time you access the graph. ConfiguredGraphFactory provides an access point to your graphs for which you have previously created configurations using the ConfigurationManagementGraph . It also offers an access point to manage graph configurations. ConfigurationManagementGraph allows you to manage graph configurations. JanusGraphManager is an internal server component that tracks graph references, provided your graphs are configured to use it.","title":"Overview"},{"location":"basics/configured-graph-factory/#configuredgraphfactory-versus-janusgraphfactory","text":"However, there is an important distinction between these two graph factories: The ConfiguredGraphFactory can only be used if you have configured your server to use the ConfigurationManagementGraph APIs at server start. The benefits of using the ConfiguredGraphFactory are that: You only need to supply a String to access your graphs, as opposed to the JanusGraphFactory -- which requires you to specify information about the backend you wish to use when accessing a graph-- every time you open a graph. If your ConfigurationManagementGraph is configured with a distributed storage backend then your graph configurations are available to all JanusGraph nodes in your cluster.","title":"ConfiguredGraphFactory versus JanusGraphFactory"},{"location":"basics/configured-graph-factory/#how-does-the-configuredgraphfactory-work","text":"The ConfiguredGraphFactory provides an access point to graphs under two scenarios: You have already created a configuration for your specific graph object using the ConfigurationManagementGraph#createConfiguration . In this scenario, your graph is opened using the previously created configuration for this graph. You have already created a template configuration using the ConfigurationManagementGraph#createTemplateConfiguration . In this scenario, we create a configuration for the graph you are creating by copying over all attributes stored in your template configuration and appending the relevant graphName attribute, and we then open the graph according to that specific configuration.","title":"How Does the ConfiguredGraphFactory Work?"},{"location":"basics/configured-graph-factory/#accessing-the-graphs","text":"You can either use ConfiguredGraphFactory.create(\"graphName\") or ConfiguredGraphFactory.open(\"graphName\") . Learn more about the difference between these two options by reading the section below about the ConfigurationManagementGraph . You can also access your graphs by using the bindings. Read more about this in the Graph and Traversal Bindings section. Listing the Graphs ConfiguredGraphFactory.getGraphNames() will return a set of graph names for which you have created configurations using the ConfigurationManagementGraph APIs. JanusGraphFactory.getGraphNames() on the other hand returns a set of graph names for which you have instantiated and the references are stored inside the JanusGraphManager .","title":"Accessing the Graphs"},{"location":"basics/configured-graph-factory/#dropping-a-graph","text":"ConfiguredGraphFactory.drop(\"graphName\") will drop the graph database, deleting all data in storage and indexing backends. The graph can be open or closed (will be closed as part of the drop operation). Furthermore, this will also remove any existing graph configuration in the ConfigurationManagementGraph . Important This is an irreversible operation that will delete all graph and index data. Important To ensure all graph representations are consistent across all JanusGraph nodes in your cluster, this removes the graph from the JanusGraphManager graph cache on every node in the cluster, assuming each node has been properly configured to use the JanusGraphManager . Learn more about this feature and how to configure your server to use said feature here .","title":"Dropping a Graph"},{"location":"basics/configured-graph-factory/#configuring-janusgraph-server-for-configuredgraphfactory","text":"To be able to use the ConfiguredGraphFactory , you must configure your server to use the ConfigurationManagementGraph APIs. To do this, you have to inject a graph variable named \"ConfigurationManagementGraph\" in your server\u2019s YAML\u2019s graphs map. For example: graphManager : org.janusgraph.graphdb.management.JanusGraphManager graphs : { ConfigurationManagementGraph : conf/JanusGraph-configurationmanagement.properties } In this example, our ConfigurationManagementGraph graph will be configured using the properties stored inside conf/JanusGraph-configurationmanagement.properties , which for example, look like: gremlin.graph=org.janusgraph.core.ConfiguredGraphFactory storage.backend=cql graph.graphname=ConfigurationManagementGraph storage.hostname=127.0.0.1 Assuming the GremlinServer started successfully and the ConfigurationManagementGraph was successfully instantiated, then all the APIs available on the ConfigurationManagementGraph Singleton will also act upon said graph. Furthermore, this is the graph that will be used to access the configurations used to create/open graphs using the ConfiguredGraphFactory . Important The pom.xml included in the JanusGraph distribution lists this dependency as optional, but the ConfiguredGraphFactory makes use of the JanusGraphManager , which requires a declared dependency on the org.apache.tinkerpop:gremlin-server . So if you run into NoClassDefFoundError errors, then be sure to update according to this message.","title":"Configuring JanusGraph Server for ConfiguredGraphFactory"},{"location":"basics/configured-graph-factory/#configurationmanagementgraph","text":"The ConfigurationManagementGraph is a Singleton that allows you to create/update/remove configurations that you can use to access your graphs using the ConfiguredGraphFactory . See above on configuring your server to enable use of these APIs. Important The ConfiguredGraphFactory offers an access point to manage your graph configurations managed by the ConfigurationManagementGraph , so instead of acting upon the Singleton itself, you may act upon the corresponding ConfiguredGraphFactory static methods. For example, you may use ConfiguredGraphFactory.removeTemplateConfiguration() instead of ConfiguredGraphFactory.getInstance().removeTemplateConfiguration() .","title":"ConfigurationManagementGraph"},{"location":"basics/configured-graph-factory/#graph-configurations","text":"The ConfigurationManagementGraph singleton allows you to create configurations used to open specific graphs, referenced by the graph.graphname property. For example: map = new HashMap < String , Object >(); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); map . put ( \"graph.graphname\" , \"graph1\" ); ConfiguredGraphFactory . createConfiguration ( new MapConfiguration ( map )); Then you could access this graph on any JanusGraph node using: ConfiguredGraphFactory . open ( \"graph1\" );","title":"Graph Configurations"},{"location":"basics/configured-graph-factory/#template-configuration","text":"The ConfigurationManagementGraph also allows you to create one template configuration, which you can use to create many graphs using the same configuration template. For example: map = new HashMap < String , Object >(); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); After doing this, you can create graphs using the template configuration: ConfiguredGraphFactory . create ( \"graph2\" ); This method will first create a new configuration for \"graph2\" by copying over all the properties associated with the template configuration and storing it on a configuration for this specific graph. This means that this graph can be accessed in, on any JanusGraph node, in the future by doing: ConfiguredGraphFactory . open ( \"graph2\" );","title":"Template Configuration"},{"location":"basics/configured-graph-factory/#updating-configurations","text":"All interactions with both the JanusGraphFactory and the ConfiguredGraphFactory that interact with configurations that define the property graph.graphname go through the JanusGraphManager which keeps track of graph references created on the given JVM. Think of it as a graph cache. For this reason: Important Any updates to a graph configuration results in the eviction of the relevant graph from the graph cache on every node in the JanusGraph cluster, assuming each node has been configured properly to use the JanusGraphManager . Learn more about this feature and how to configure your server to use said feature here . Since graphs created using the template configuration first create a configuration for that graph in question using a copy and create method, this means that: Important Any updates to a specific graph created using the template configuration are not guaranteed to take effect on the specific graph until: 1. The relevant configuration is removed: ConfiguredGraphFactory.removeConfiguration(\"graph2\"); 2. The graph is recreated using the template configuration: ConfiguredGraphFactory.create(\"graph2\");","title":"Updating Configurations"},{"location":"basics/configured-graph-factory/#update-examples","text":"1) We migrated our Cassandra data to a new server with a new IP address: map = new HashMap (); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); map . put ( \"graph.graphname\" , \"graph1\" ); ConfiguredGraphFactory . createConfiguration ( new MapConfiguration ( map )); g1 = ConfiguredGraphFactory . open ( \"graph1\" ); // Update configuration map = new HashMap (); map . put ( \"storage.hostname\" , \"10.0.0.1\" ); ConfiguredGraphFactory . updateConfiguration ( \"graph1\" , map ); // We are now guaranteed to use the updated configuration g1 = ConfiguredGraphFactory . open ( \"graph1\" ); 2) We added an Elasticsearch node to our setup: map = new HashMap (); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); map . put ( \"graph.graphname\" , \"graph1\" ); ConfiguredGraphFactory . createConfiguration ( new MapConfiguration ( map )); g1 = ConfiguredGraphFactory . open ( \"graph1\" ); // Update configuration map = new HashMap (); map . put ( \"index.search.backend\" , \"elasticsearch\" ); map . put ( \"index.search.hostname\" , \"127.0.0.1\" ); map . put ( \"index.search.elasticsearch.transport-scheme\" , \"http\" ); ConfiguredGraphFactory . updateConfiguration ( \"graph1\" , map ); // We are now guaranteed to use the updated configuration g1 = ConfiguredGraphFactory . open ( \"graph1\" ); 3) Update a graph configuration that was created using a template configuration that has been updated: map = new HashMap (); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); g1 = ConfiguredGraphFactory . create ( \"graph1\" ); // Update template configuration map = new HashMap (); map . put ( \"index.search.backend\" , \"elasticsearch\" ); map . put ( \"index.search.hostname\" , \"127.0.0.1\" ); map . put ( \"index.search.elasticsearch.transport-scheme\" , \"http\" ); ConfiguredGraphFactory . updateTemplateConfiguration ( new MapConfiguration ( map )); // Remove Configuration ConfiguredGraphFactory . removeConfiguration ( \"graph1\" ); // Recreate ConfiguredGraphFactory . create ( \"graph1\" ); // Now this graph's configuration is guaranteed to be updated","title":"Update Examples"},{"location":"basics/configured-graph-factory/#janusgraphmanager","text":"The JanusGraphManager is a Singleton adhering to the TinkerPop graphManager specifications. In particular, the JanusGraphManager provides: a coordinated mechanism by which to instantiate graph references on a given JanusGraph node a graph reference tracker (or cache) Any graph you create using the graph.graphname property will go through the JanusGraphManager and thus be instantiated in a coordinated fashion. The graph reference will also be placed in the graph cache on the JVM in question. Thus, any graph you open using the graph.graphname property that has already been instantiated on the JVM in question will be retrieved from the graph cache. This is why updates to your configurations require a few steps to guarantee correctness.","title":"JanusGraphManager"},{"location":"basics/configured-graph-factory/#how-to-use-the-janusgraphmanager","text":"This is a new configuration option you can use when defining a property in your configuration that defines how to access a graph. All configurations that include this property will result in the graph instantiation happening through the JanusGraphManager (process explained above). For backwards compatibility, any graphs that do not supply this parameter but supplied at server start in your graphs object in your .yaml file, these graphs will be bound through the JanusGraphManager denoted by their key supplied for that graph. For example, if your .yaml graphs object looks like: graphManager : org.janusgraph.graphdb.management.JanusGraphManager graphs { graph1 : conf/graph1.properties, graph2 : conf/graph2.properties } but conf/graph1.properties and conf/graph2.properties do not include the property graph.graphname , then these graphs will be stored in the JanusGraphManager and thus bound in your gremlin script executions as graph1 and graph2 , respectively.","title":"How To Use The JanusGraphManager"},{"location":"basics/configured-graph-factory/#important","text":"For convenience, if your configuration used to open a graph specifies graph.graphname , but does not specify the backend\u2019s storage directory, tablename, or keyspacename, then the relevant parameter will automatically be set to the value of graph.graphname . However, if you supply one of those parameters, that value will always take precedence. And if you supply neither, they default to the configuration option\u2019s default value. One special case is storage.root configuration option. This is a new configuration option used to specify the base of the directory that will be used for any backend requiring local storage directory access. If you supply this parameter, you must also supply the graph.graphname property, and the absolute storage directory will be equal to the value of the graph.graphname property appended to the value of the storage.root property. Below are some example use cases: 1) Create a template configuration for my Cassandra backend such that each graph created using this configuration gets a unique keyspace equivalent to the String <graphName> provided to the factory: map = new HashMap (); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); g1 = ConfiguredGraphFactory . create ( \"graph1\" ); //keyspace === graph1 g2 = ConfiguredGraphFactory . create ( \"graph2\" ); //keyspace === graph2 g3 = ConfiguredGraphFactory . create ( \"graph3\" ); //keyspace === graph3 2) Create a template configuration for my BerkeleyJE backend such that each graph created using this configuration gets a unique storage directory equivalent to the \"<storage.root>/<graph.graphname>\": map = new HashMap (); map . put ( \"storage.backend\" , \"berkeleyje\" ); map . put ( \"storage.root\" , \"/data/graphs\" ); ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); g1 = ConfiguredGraphFactory . create ( \"graph1\" ); //storage directory === /data/graphs/graph1 g2 = ConfiguredGraphFactory . create ( \"graph2\" ); //storage directory === /data/graphs/graph2 g3 = ConfiguredGraphFactory . create ( \"graph3\" ); //storage directory === /data/graphs/graph3","title":"Important"},{"location":"basics/configured-graph-factory/#graph-and-traversal-bindings","text":"Graphs created using the ConfiguredGraphFactory are bound to the executor context on the Gremlin Server by the \"graph.graphname\" property, and the graph's traversal reference is bound to the context by \" <graphname>_traversal \". This means, on subsequent connections to the server after the first time you create/open a graph, you can access the graph and traversal references by the \" <graphname> \" and \" <graphname>_traversal \" properties. Learn more about this feature and how to configure your server to use said feature here . Important If you are connected to a remote Gremlin Server using the Gremlin Console and a sessioned connection, then you will have to reconnect to the server to bind the variables. This is also true for any sessioned WebSocket connection. Important The JanusGraphManager rebinds every graph stored on the ConfigurationManagementGraph (or those for which you have created configurations) every 20 seconds. This means your graph and traversal bindings for graphs created using the ConfigredGraphFactory will be available on all JanusGraph nodes with a maximum of a 20 second lag. It also means that a binding will still be available on a node after a server restart.","title":"Graph and Traversal Bindings"},{"location":"basics/configured-graph-factory/#binding-example","text":"gremlin > : remote connect tinkerpop . server conf /remote.yaml ==>Configured localhost/ 127.0 . 0.1 : 8182 gremlin > : remote console ==> All scripts will now be sent to Gremlin Server - [ localhost / 127.0 . 0.1 : 8182 ] - type ':remote console' to return to local mode gremlin > ConfiguredGraphFactory . open ( \"graph1\" ) ==> standardjanusgraph [ cassandrathrift: [ 127.0 . 0.1 ]] gremlin > graph1 ==> standardjanusgraph [ cassandrathrift: [ 127.0 . 0.1 ]] gremlin > graph1_traversal ==> graphtraversalsource [ standardjanusgraph [ cassandrathrift: [ 127.0 . 0.1 ]], standard ]","title":"Binding Example"},{"location":"basics/configured-graph-factory/#examples","text":"It is reccomended to use a sessioned connection when creating a Configured Graph Factory template. If a sessioned connection is not used the Configured Graph Factory Template creation must be sent to the server as a single line using semi-colons. See details on sessions can be found in Connecting to Gremlin Server . gremlin > : remote connect tinkerpop . server conf /remote.yaml session ==>Configured localhost/ 127.0 . 0.1 : 8182 gremlin > : remote console ==> All scripts will now be sent to Gremlin Server - [ localhost: 8182 ]-[ 5206 cdde - b231 - 41 fa - 9 e6c - 69 feac0fe2b2 ] - type ':remote console' to return to local mode gremlin > ConfiguredGraphFactory . open ( \"graph\" ); Please create configuration for this graph using the ConfigurationManagementGraph API . gremlin > ConfiguredGraphFactory . create ( \"graph\" ); Please create a template Configuration using the ConfigurationManagementGraph API . gremlin > map = new HashMap (); gremlin > map . put ( \"storage.backend\" , \"cql\" ); gremlin > map . put ( \"storage.hostname\" , \"127.0.0.1\" ); gremlin > map . put ( \"GraphName\" , \"graph1\" ); gremlin > ConfiguredGraphFactory . createConfiguration ( new MapConfiguration ( map )); Please include in your configuration the property \"graph.graphname\" . gremlin > map = new HashMap (); gremlin > map . put ( \"storage.backend\" , \"cql\" ); gremlin > map . put ( \"storage.hostname\" , \"127.0.0.1\" ); gremlin > map . put ( \"graph.graphname\" , \"graph1\" ); gremlin > ConfiguredGraphFactory . createConfiguration ( new MapConfiguration ( map )); ==> null gremlin > ConfiguredGraphFactory . open ( \"graph1\" ). vertices (); gremlin > map = new HashMap (); map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); gremlin > map . put ( \"graph.graphname\" , \"graph1\" ); gremlin > ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); Your template configuration may not contain the property \"graph.graphname\" . gremlin > map = new HashMap (); gremlin > map . put ( \"storage.backend\" , \"cql\" ); map . put ( \"storage.hostname\" , \"127.0.0.1\" ); gremlin > ConfiguredGraphFactory . createTemplateConfiguration ( new MapConfiguration ( map )); ==> null // Each graph is now acting in unique keyspaces equivalent to the graphnames . gremlin > g1 = ConfiguredGraphFactory . open ( \"graph1\" ); gremlin > g2 = ConfiguredGraphFactory . create ( \"graph2\" ); gremlin > g3 = ConfiguredGraphFactory . create ( \"graph3\" ); gremlin > g2 . addVertex (); gremlin > l = []; gremlin > l << g1 . vertices (). size (); ==> 0 gremlin > l << g2 . vertices (). size (); ==> 1 gremlin > l << g3 . vertices (). size (); ==> 0 // After a graph is created, you must access it using .open() gremlin > g2 = ConfiguredGraphFactory . create ( \"graph2\" ); g2 . vertices (). size (); Configuration for graph \"graph2\" already exists . gremlin > g2 = ConfiguredGraphFactory . open ( \"graph2\" ); g2 . vertices (). size (); ==> 1","title":"Examples"},{"location":"basics/deployment/","text":"Deployment Scenarios JanusGraph offers a wide choice of storage and index backends which results in great flexibility of how it can be deployed. This chapter presents a few possible deployment scenarios to help with the complexity that comes with this flexibility. Before discussing the different deployment scenarios, it is important to understand the roles of JanusGraph itself and that of the backends. First of all, applications only communicate directly with JanusGraph, mostly by sending Gremlin traversals for execution. JanusGraph then communicates with the configured backends to execute the received traversal. When JanusGraph is used in the form of JanusGraph Server, then there is nothing like a master JanusGraph Server. Applications can therefore connect to any JanusGraph Server instance. They can also use a load-balancer to schedule requests to the different instances. The JanusGraph Server instances themselves don\u2019t communicate to each other directly which makes it easy to scale them when the need arises to process more traversals. Note The scenarios presented in this chapter are only examples of how JanusGraph can be deployed. Each deployment needs to take into account the concrete use cases and production needs. Getting Started Scenario This scenario is the scenario most users probably want to choose when they are just getting started with JanusGraph. It offers scalability and fault tolerance with a minimum number of servers required. JanusGraph Server runs together with an instance of the storage backend and optionally also an instance of the index backend on every server. A setup like this can be extended by simply adding more servers of the same kind or by moving one of the components onto dedicated servers. The latter describes a growth path to transform the deployment into the Advanced Scenario . Any of the scalable storage backends can be used with this scenario. Note however that for Scylla some configuration is required when it is hosted co-located with other services like in this scenario. When an index backend should be used in this scenario then it also needs to be one that is scalable. Advanced Scenario The advanced scenario is an evolution of the Getting Started Scenario . Instead of hosting the JanusGraph Server instances together with the storage backend and optionally also the index backend, they are now separated on different servers. The advantage of hosting the different components (JanusGraph Server, storage/index backend) on different servers is that they can be scaled and managed independently of each other. This offers a higher flexibility at the cost of having to maintain more servers. Since this scenario offers independent scalability of the different components, it of course makes most sense to also use scalable backends. Minimalist Scenario It is also possible to host JanusGraph Server together with the backend(s) on just one server. This is especially attractive for testing purposes or for example when JanusGraph just supports a single application which can then also run on the same server. Opposed to the previous scenarios, it makes most sense to use backends for this scenario that are not scalable. The in-memory backend can be used for testing purposes or Berkeley DB for production and Lucene as the optional index backend. Embedded JanusGraph Instead of connecting to the JanusGraph Server from an application it is also possible to embed JanusGraph as a library inside a JVM based application. While this reduces the administrative overhead, it makes it impossible to scale JanusGraph independently of the application. Embedded JanusGraph can be deployed as a variation of any of the other scenarios. JanusGraph just moves from the server(s) directly into the application as its now just used as a library instead of an independent service.","title":"Deployment Scenarios"},{"location":"basics/deployment/#deployment-scenarios","text":"JanusGraph offers a wide choice of storage and index backends which results in great flexibility of how it can be deployed. This chapter presents a few possible deployment scenarios to help with the complexity that comes with this flexibility. Before discussing the different deployment scenarios, it is important to understand the roles of JanusGraph itself and that of the backends. First of all, applications only communicate directly with JanusGraph, mostly by sending Gremlin traversals for execution. JanusGraph then communicates with the configured backends to execute the received traversal. When JanusGraph is used in the form of JanusGraph Server, then there is nothing like a master JanusGraph Server. Applications can therefore connect to any JanusGraph Server instance. They can also use a load-balancer to schedule requests to the different instances. The JanusGraph Server instances themselves don\u2019t communicate to each other directly which makes it easy to scale them when the need arises to process more traversals. Note The scenarios presented in this chapter are only examples of how JanusGraph can be deployed. Each deployment needs to take into account the concrete use cases and production needs.","title":"Deployment Scenarios"},{"location":"basics/deployment/#getting-started-scenario","text":"This scenario is the scenario most users probably want to choose when they are just getting started with JanusGraph. It offers scalability and fault tolerance with a minimum number of servers required. JanusGraph Server runs together with an instance of the storage backend and optionally also an instance of the index backend on every server. A setup like this can be extended by simply adding more servers of the same kind or by moving one of the components onto dedicated servers. The latter describes a growth path to transform the deployment into the Advanced Scenario . Any of the scalable storage backends can be used with this scenario. Note however that for Scylla some configuration is required when it is hosted co-located with other services like in this scenario. When an index backend should be used in this scenario then it also needs to be one that is scalable.","title":"Getting Started Scenario"},{"location":"basics/deployment/#advanced-scenario","text":"The advanced scenario is an evolution of the Getting Started Scenario . Instead of hosting the JanusGraph Server instances together with the storage backend and optionally also the index backend, they are now separated on different servers. The advantage of hosting the different components (JanusGraph Server, storage/index backend) on different servers is that they can be scaled and managed independently of each other. This offers a higher flexibility at the cost of having to maintain more servers. Since this scenario offers independent scalability of the different components, it of course makes most sense to also use scalable backends.","title":"Advanced Scenario"},{"location":"basics/deployment/#minimalist-scenario","text":"It is also possible to host JanusGraph Server together with the backend(s) on just one server. This is especially attractive for testing purposes or for example when JanusGraph just supports a single application which can then also run on the same server. Opposed to the previous scenarios, it makes most sense to use backends for this scenario that are not scalable. The in-memory backend can be used for testing purposes or Berkeley DB for production and Lucene as the optional index backend.","title":"Minimalist Scenario"},{"location":"basics/deployment/#embedded-janusgraph","text":"Instead of connecting to the JanusGraph Server from an application it is also possible to embed JanusGraph as a library inside a JVM based application. While this reduces the administrative overhead, it makes it impossible to scale JanusGraph independently of the application. Embedded JanusGraph can be deployed as a variation of any of the other scenarios. JanusGraph just moves from the server(s) directly into the application as its now just used as a library instead of an independent service.","title":"Embedded JanusGraph"},{"location":"basics/example-config/","text":"Example Graph Configuration This page illustrates a number of common graph configurations. Please refer to Configuration Reference and the pages of the respective storage backend , index backend for more information. Also, note that the JanusGraph distribution includes local configuration files in the conf/ directory. BerkeleyDB storage.backend=berkeleyje storage.directory=/tmp/graph index.search.backend=elasticsearch index.search.directory=/tmp/searchindex index.search.elasticsearch.client-only=false index.search.elasticsearch.local-mode=true This configuration file configures JanusGraph to use BerkeleyDB as an embedded storage backend, meaning, JanusGraph will start BerkeleyDB internally. The primary data will be stored in the directory /tmp/graph . In addition, this configures an embedded Elasticsearch index backend with the name search . JanusGraph will start Elasticsearch internally and it will not be externally accessible since local-mode is enabled. Elasticsearch stores all data for the search index in /tmp/searchindex . Configuring an index backend is optional. Cassandra Cassandra Remote storage.backend=cql storage.hostname=100.100.100.1, 100.100.100.2 index.search.backend=elasticsearch index.search.hostname=100.100.101.1, 100.100.101.2 index.search.elasticsearch.client-only=true This configuration file configures JanusGraph to use Cassandra as a remote storage backend. It assumes that a Cassandra cluster is running and accessible at the given IP addresses. If Cassandra is running locally, use the IP address 127.0.0.1 . In addition, this configures a remote Elasticsearch index backend with the name search . It assumes that an Elasticsearch cluster is running and accessible at the given IP addresses. Enabling client-only ensures that the local instance does not join the existing Elasticsearch cluster as another node but only connects to it. Configuring an index backend is optional. Embedded Cassandra storage.backend=embeddedcassandra storage.conf-file=config/cassandra.yaml index.search.backend=elasticsearch index.search.directory=/tmp/searchindex index.search.elasticsearch.client-only=false index.search.elasticsearch.local-mode=true This configuration file configures JanusGraph to start Cassandra internally embedded in JanusGraph and specifies the yaml configuration file for Cassandra. Cassandra is still accessible externally and can connect to other available Cassandra nodes to form a cluster as configured in the yaml file. The optional index backend configuration is identical to embedded index configuration described above. HBase storage.backend=hbase storage.hostname=127.0.0.1 storage.port=2181 index.search.backend=elasticsearch index.search.hostname=127.0.0.1 index.search.elasticsearch.client-only=true This configuration file configures JanusGraph to use HBase as a remote storage backend. It assumes that an HBase cluster is running and accessible at the given IP addresses through the configured port. If HBase is running locally, use the IP address 127.0.0.1 . The optional index backend configuration is identical to remote index configuration described above.","title":"Config Example"},{"location":"basics/example-config/#example-graph-configuration","text":"This page illustrates a number of common graph configurations. Please refer to Configuration Reference and the pages of the respective storage backend , index backend for more information. Also, note that the JanusGraph distribution includes local configuration files in the conf/ directory.","title":"Example Graph Configuration"},{"location":"basics/example-config/#berkeleydb","text":"storage.backend=berkeleyje storage.directory=/tmp/graph index.search.backend=elasticsearch index.search.directory=/tmp/searchindex index.search.elasticsearch.client-only=false index.search.elasticsearch.local-mode=true This configuration file configures JanusGraph to use BerkeleyDB as an embedded storage backend, meaning, JanusGraph will start BerkeleyDB internally. The primary data will be stored in the directory /tmp/graph . In addition, this configures an embedded Elasticsearch index backend with the name search . JanusGraph will start Elasticsearch internally and it will not be externally accessible since local-mode is enabled. Elasticsearch stores all data for the search index in /tmp/searchindex . Configuring an index backend is optional.","title":"BerkeleyDB"},{"location":"basics/example-config/#cassandra","text":"","title":"Cassandra"},{"location":"basics/example-config/#cassandra-remote","text":"storage.backend=cql storage.hostname=100.100.100.1, 100.100.100.2 index.search.backend=elasticsearch index.search.hostname=100.100.101.1, 100.100.101.2 index.search.elasticsearch.client-only=true This configuration file configures JanusGraph to use Cassandra as a remote storage backend. It assumes that a Cassandra cluster is running and accessible at the given IP addresses. If Cassandra is running locally, use the IP address 127.0.0.1 . In addition, this configures a remote Elasticsearch index backend with the name search . It assumes that an Elasticsearch cluster is running and accessible at the given IP addresses. Enabling client-only ensures that the local instance does not join the existing Elasticsearch cluster as another node but only connects to it. Configuring an index backend is optional.","title":"Cassandra Remote"},{"location":"basics/example-config/#embedded-cassandra","text":"storage.backend=embeddedcassandra storage.conf-file=config/cassandra.yaml index.search.backend=elasticsearch index.search.directory=/tmp/searchindex index.search.elasticsearch.client-only=false index.search.elasticsearch.local-mode=true This configuration file configures JanusGraph to start Cassandra internally embedded in JanusGraph and specifies the yaml configuration file for Cassandra. Cassandra is still accessible externally and can connect to other available Cassandra nodes to form a cluster as configured in the yaml file. The optional index backend configuration is identical to embedded index configuration described above.","title":"Embedded Cassandra"},{"location":"basics/example-config/#hbase","text":"storage.backend=hbase storage.hostname=127.0.0.1 storage.port=2181 index.search.backend=elasticsearch index.search.hostname=127.0.0.1 index.search.elasticsearch.client-only=true This configuration file configures JanusGraph to use HBase as a remote storage backend. It assumes that an HBase cluster is running and accessible at the given IP addresses through the configured port. If HBase is running locally, use the IP address 127.0.0.1 . The optional index backend configuration is identical to remote index configuration described above.","title":"HBase"},{"location":"basics/gremlin/","text":"Gremlin Query Language Gremlin is JanusGraph\u2019s query language used to retrieve data from and modify data in the graph. Gremlin is a path-oriented language which succinctly expresses complex graph traversals and mutation operations. Gremlin is a functional language whereby traversal operators are chained together to form path-like expressions. For example, \"from Hercules, traverse to his father and then his father\u2019s father and return the grandfather\u2019s name.\" Gremlin is a component of Apache TinkerPop . It is developed independently from JanusGraph and is supported by most graph databases. By building applications on top of JanusGraph through the Gremlin query language, users avoid vendor-lock in because their application can be migrated to other graph databases supporting Gremlin. This section is a brief overview of the Gremlin query language. For more information on Gremlin, refer to the following resources: Practical Gremlin : An online book by Kelvin R. Lawrence providing an in-depth overview of Gremlin and it's interaction with JanusGraph. Complete Gremlin Manual : Reference manual for all of the Gremlin steps. Gremlin Console Tutorial : Learn how to use the Gremlin Console effectively to traverse and analyze a graph interactively. Gremlin Recipes : A collection of best practices and common traversal patterns for Gremlin. Gremlin Language Drivers : Connect to a Gremlin Server with different programming languages, including Go, JavaScript, .NET/C#, PHP, Python, Ruby, Scala, and TypeScript. Gremlin Language Variants : Learn how to embed Gremlin in a host programming language. Gremlin for SQL developers : Learn Gremlin using typical patterns found when querying data with SQL. In addition to these resources, Connecting to JanusGraph explains how Gremlin can be used in different programming languages to query a JanusGraph Server. Introductory Traversals A Gremlin query is a chain of operations/functions that are evaluated from left to right. A simple grandfather query is provided below over the Graph of the Gods dataset discussed in Getting Started . gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ). out ( 'father' ). values ( 'name' ) ==> saturn The query above can be read: g : for the current graph traversal. V : for all vertices in the graph has('name', 'hercules') : filters the vertices down to those with name property \"hercules\" (there is only one). out('father') : traverse outgoing father edge\u2019s from Hercules. \u2018out('father')`: traverse outgoing father edge\u2019s from Hercules\u2019 father\u2019s vertex (i.e. Jupiter). name : get the name property of the \"hercules\" vertex\u2019s grandfather. Taken together, these steps form a path-like traversal query. Each step can be decomposed and its results demonstrated. This style of building up a traversal/query is useful when constructing larger, complex query chains. gremlin > g ==> graphtraversalsource [ janusgraph [ cql: 127.0 . 0.1 ], standard ] gremlin > g . V (). has ( 'name' , 'hercules' ) ==> v [ 24 ] gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ) ==> v [ 16 ] gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ). out ( 'father' ) ==> v [ 20 ] gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ). out ( 'father' ). values ( 'name' ) ==> saturn For a sanity check, it is usually good to look at the properties of each return, not the assigned long id. gremlin > g . V (). has ( 'name' , 'hercules' ). values ( 'name' ) ==> hercules gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ). values ( 'name' ) ==> jupiter gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ). out ( 'father' ). values ( 'name' ) ==> saturn Note the related traversal that shows the entire father family tree branch of Hercules. This more complicated traversal is provided in order to demonstrate the flexibility and expressivity of the language. A competent grasp of Gremlin provides the JanusGraph user the ability to fluently navigate the underlying graph structure. gremlin > g . V (). has ( 'name' , 'hercules' ). repeat ( out ( 'father' )). emit (). values ( 'name' ) ==> jupiter ==> saturn Some more traversal examples are provided below. gremlin > hercules = g . V (). has ( 'name' , 'hercules' ). next () ==> v [ 1536 ] gremlin > g . V ( hercules ). out ( 'father' , 'mother' ). label () ==> god ==> human gremlin > g . V ( hercules ). out ( 'battled' ). label () ==> monster ==> monster ==> monster gremlin > g . V ( hercules ). out ( 'battled' ). valueMap () ==>{ name = nemean } ==>{ name = hydra } ==>{ name = cerberus } Each step (denoted by a separating .) is a function that operates on the objects emitted from the previous step. There are numerous steps in the Gremlin language (see Gremlin Steps ). By simply changing a step or order of the steps, different traversal semantics are enacted. The example below returns the name of all the people that have battled the same monsters as Hercules who themselves are not Hercules (i.e. \"co-battlers\" or perhaps, \"allies\"). Given that The Graph of the Gods only has one battler (Hercules), another battler (for the sake of example) is added to the graph with Gremlin showcasing how vertices and edges are added to the graph. gremlin > theseus = graph . addVertex ( 'human' ) ==> v [ 3328 ] gremlin > theseus . property ( 'name' , 'theseus' ) ==> null gremlin > cerberus = g . V (). has ( 'name' , 'cerberus' ). next () ==> v [ 2816 ] gremlin > battle = theseus . addEdge ( 'battled' , cerberus , 'time' , 22 ) ==> e [ 7 eo - 2 kg - iz9 - 268 ][ 3328 - battled -> 2816 ] gremlin > battle . values ( 'time' ) ==> 22 When adding a vertex, an optional vertex label can be provided. An edge label must be specified when adding edges. Properties as key-value pairs can be set on both vertices and edges. When a property key is defined with SET or LIST cardinality, addProperty must be used when adding a respective property to a vertex. gremlin > g . V ( hercules ). as ( 'h' ). out ( 'battled' ). in ( 'battled' ). where ( neq ( 'h' )). values ( 'name' ) ==> theseus The example above has 4 chained functions: out , in , except , and values (i.e. name is shorthand for values('name') ). The function signatures of each are itemized below, where V is vertex and U is any object, where V is a subset of U . out: V -> V in: V -> V except: U -> U values: V -> U When chaining together functions, the incoming type must match the outgoing type, where U matches anything. Thus, the \"co-battled/ally\" traversal above is correct. Note The Gremlin overview presented in this section focused on the Gremlin-Groovy language implementation used in the Gremlin Console. Refer to Connecting to JanusGraph for information about connecting to JanusGraph with other languages than Groovy and independent of the Gremlin Console. Iterating the Traversal One convenient feature of the Gremlin Console is that it automatically iterates all results from a query executed from the gremlin> prompt. This works well within the REPL environment as it shows you the results as a String. As you transition towards writing a Gremlin application, it is important to understand how to iterate a traversal explicitly because your application\u2019s traversals will not iterate automatically. These are some of the common ways to iterate the Traversal : iterate() - Zero results are expected or can be ignored. next() - Get one result. Make sure to check hasNext() first. next(int n) - Get the next n results. Make sure to check hasNext() first. toList() - Get all results as a list. If there are no results, an empty list is returned. A Java code example is shown below to demonstrate these concepts: Traversal t = g . V (). has ( \"name\" , \"pluto\" ); // Define a traversal // Note the traversal is not executed/iterated yet Vertex pluto = null ; if ( t . hasNext ()) { // Check if results are available pluto = g . V (). has ( \"name\" , \"pluto\" ). next (); // Get one result g . V ( pluto ). drop (). iterate (); // Execute a traversal to drop pluto from graph } // Note the traversal can be cloned for reuse Traversal tt = t . asAdmin (). clone (); if ( tt . hasNext ()) { System . err . println ( \"pluto was not dropped!\" ); } List < Vertex > gods = g . V (). hasLabel ( \"god\" ). toList (); // Find all the gods","title":"Gremlin Query Language"},{"location":"basics/gremlin/#gremlin-query-language","text":"Gremlin is JanusGraph\u2019s query language used to retrieve data from and modify data in the graph. Gremlin is a path-oriented language which succinctly expresses complex graph traversals and mutation operations. Gremlin is a functional language whereby traversal operators are chained together to form path-like expressions. For example, \"from Hercules, traverse to his father and then his father\u2019s father and return the grandfather\u2019s name.\" Gremlin is a component of Apache TinkerPop . It is developed independently from JanusGraph and is supported by most graph databases. By building applications on top of JanusGraph through the Gremlin query language, users avoid vendor-lock in because their application can be migrated to other graph databases supporting Gremlin. This section is a brief overview of the Gremlin query language. For more information on Gremlin, refer to the following resources: Practical Gremlin : An online book by Kelvin R. Lawrence providing an in-depth overview of Gremlin and it's interaction with JanusGraph. Complete Gremlin Manual : Reference manual for all of the Gremlin steps. Gremlin Console Tutorial : Learn how to use the Gremlin Console effectively to traverse and analyze a graph interactively. Gremlin Recipes : A collection of best practices and common traversal patterns for Gremlin. Gremlin Language Drivers : Connect to a Gremlin Server with different programming languages, including Go, JavaScript, .NET/C#, PHP, Python, Ruby, Scala, and TypeScript. Gremlin Language Variants : Learn how to embed Gremlin in a host programming language. Gremlin for SQL developers : Learn Gremlin using typical patterns found when querying data with SQL. In addition to these resources, Connecting to JanusGraph explains how Gremlin can be used in different programming languages to query a JanusGraph Server.","title":"Gremlin Query Language"},{"location":"basics/gremlin/#introductory-traversals","text":"A Gremlin query is a chain of operations/functions that are evaluated from left to right. A simple grandfather query is provided below over the Graph of the Gods dataset discussed in Getting Started . gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ). out ( 'father' ). values ( 'name' ) ==> saturn The query above can be read: g : for the current graph traversal. V : for all vertices in the graph has('name', 'hercules') : filters the vertices down to those with name property \"hercules\" (there is only one). out('father') : traverse outgoing father edge\u2019s from Hercules. \u2018out('father')`: traverse outgoing father edge\u2019s from Hercules\u2019 father\u2019s vertex (i.e. Jupiter). name : get the name property of the \"hercules\" vertex\u2019s grandfather. Taken together, these steps form a path-like traversal query. Each step can be decomposed and its results demonstrated. This style of building up a traversal/query is useful when constructing larger, complex query chains. gremlin > g ==> graphtraversalsource [ janusgraph [ cql: 127.0 . 0.1 ], standard ] gremlin > g . V (). has ( 'name' , 'hercules' ) ==> v [ 24 ] gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ) ==> v [ 16 ] gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ). out ( 'father' ) ==> v [ 20 ] gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ). out ( 'father' ). values ( 'name' ) ==> saturn For a sanity check, it is usually good to look at the properties of each return, not the assigned long id. gremlin > g . V (). has ( 'name' , 'hercules' ). values ( 'name' ) ==> hercules gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ). values ( 'name' ) ==> jupiter gremlin > g . V (). has ( 'name' , 'hercules' ). out ( 'father' ). out ( 'father' ). values ( 'name' ) ==> saturn Note the related traversal that shows the entire father family tree branch of Hercules. This more complicated traversal is provided in order to demonstrate the flexibility and expressivity of the language. A competent grasp of Gremlin provides the JanusGraph user the ability to fluently navigate the underlying graph structure. gremlin > g . V (). has ( 'name' , 'hercules' ). repeat ( out ( 'father' )). emit (). values ( 'name' ) ==> jupiter ==> saturn Some more traversal examples are provided below. gremlin > hercules = g . V (). has ( 'name' , 'hercules' ). next () ==> v [ 1536 ] gremlin > g . V ( hercules ). out ( 'father' , 'mother' ). label () ==> god ==> human gremlin > g . V ( hercules ). out ( 'battled' ). label () ==> monster ==> monster ==> monster gremlin > g . V ( hercules ). out ( 'battled' ). valueMap () ==>{ name = nemean } ==>{ name = hydra } ==>{ name = cerberus } Each step (denoted by a separating .) is a function that operates on the objects emitted from the previous step. There are numerous steps in the Gremlin language (see Gremlin Steps ). By simply changing a step or order of the steps, different traversal semantics are enacted. The example below returns the name of all the people that have battled the same monsters as Hercules who themselves are not Hercules (i.e. \"co-battlers\" or perhaps, \"allies\"). Given that The Graph of the Gods only has one battler (Hercules), another battler (for the sake of example) is added to the graph with Gremlin showcasing how vertices and edges are added to the graph. gremlin > theseus = graph . addVertex ( 'human' ) ==> v [ 3328 ] gremlin > theseus . property ( 'name' , 'theseus' ) ==> null gremlin > cerberus = g . V (). has ( 'name' , 'cerberus' ). next () ==> v [ 2816 ] gremlin > battle = theseus . addEdge ( 'battled' , cerberus , 'time' , 22 ) ==> e [ 7 eo - 2 kg - iz9 - 268 ][ 3328 - battled -> 2816 ] gremlin > battle . values ( 'time' ) ==> 22 When adding a vertex, an optional vertex label can be provided. An edge label must be specified when adding edges. Properties as key-value pairs can be set on both vertices and edges. When a property key is defined with SET or LIST cardinality, addProperty must be used when adding a respective property to a vertex. gremlin > g . V ( hercules ). as ( 'h' ). out ( 'battled' ). in ( 'battled' ). where ( neq ( 'h' )). values ( 'name' ) ==> theseus The example above has 4 chained functions: out , in , except , and values (i.e. name is shorthand for values('name') ). The function signatures of each are itemized below, where V is vertex and U is any object, where V is a subset of U . out: V -> V in: V -> V except: U -> U values: V -> U When chaining together functions, the incoming type must match the outgoing type, where U matches anything. Thus, the \"co-battled/ally\" traversal above is correct. Note The Gremlin overview presented in this section focused on the Gremlin-Groovy language implementation used in the Gremlin Console. Refer to Connecting to JanusGraph for information about connecting to JanusGraph with other languages than Groovy and independent of the Gremlin Console.","title":"Introductory Traversals"},{"location":"basics/gremlin/#iterating-the-traversal","text":"One convenient feature of the Gremlin Console is that it automatically iterates all results from a query executed from the gremlin> prompt. This works well within the REPL environment as it shows you the results as a String. As you transition towards writing a Gremlin application, it is important to understand how to iterate a traversal explicitly because your application\u2019s traversals will not iterate automatically. These are some of the common ways to iterate the Traversal : iterate() - Zero results are expected or can be ignored. next() - Get one result. Make sure to check hasNext() first. next(int n) - Get the next n results. Make sure to check hasNext() first. toList() - Get all results as a list. If there are no results, an empty list is returned. A Java code example is shown below to demonstrate these concepts: Traversal t = g . V (). has ( \"name\" , \"pluto\" ); // Define a traversal // Note the traversal is not executed/iterated yet Vertex pluto = null ; if ( t . hasNext ()) { // Check if results are available pluto = g . V (). has ( \"name\" , \"pluto\" ). next (); // Get one result g . V ( pluto ). drop (). iterate (); // Execute a traversal to drop pluto from graph } // Note the traversal can be cloned for reuse Traversal tt = t . asAdmin (). clone (); if ( tt . hasNext ()) { System . err . println ( \"pluto was not dropped!\" ); } List < Vertex > gods = g . V (). hasLabel ( \"god\" ). toList (); // Find all the gods","title":"Iterating the Traversal"},{"location":"basics/janusgraph-cfg/","text":"attributes.custom * Custom attribute serialization and handling Name Description Datatype Default Value Mutability attributes.custom.[X].attribute-class Class of the custom attribute to be registered String (no default value) GLOBAL_OFFLINE attributes.custom.[X].serializer-class Class of the custom attribute serializer to be registered String (no default value) GLOBAL_OFFLINE cache Configuration options that modify JanusGraph's caching behavior Name Description Datatype Default Value Mutability cache.db-cache Whether to enable JanusGraph's database-level cache, which is shared across all transactions. Enabling this option speeds up traversals by holding hot graph elements in memory, but also increases the likelihood of reading stale data. Disabling it forces each transaction to independently fetch graph elements from storage before reading/writing them. Boolean false MASKABLE cache.db-cache-clean-wait How long, in milliseconds, database-level cache will keep entries after flushing them. This option is only useful on distributed storage backends that are capable of acknowledging writes without necessarily making them immediately visible. Integer 50 GLOBAL_OFFLINE cache.db-cache-size Size of JanusGraph's database level cache. Values between 0 and 1 are interpreted as a percentage of VM heap, while larger values are interpreted as an absolute size in bytes. Double 0.3 MASKABLE cache.db-cache-time Default expiration time, in milliseconds, for entries in the database-level cache. Entries are evicted when they reach this age even if the cache has room to spare. Set to 0 to disable expiration (cache entries live forever or until memory pressure triggers eviction when set to 0). Long 10000 GLOBAL_OFFLINE cache.tx-cache-size Maximum size of the transaction-level cache of recently-used vertices. Integer 20000 MASKABLE cache.tx-dirty-size Initial size of the transaction-level cache of uncommitted dirty vertices. This is a performance hint for write-heavy, performance-sensitive transactional workloads. If set, it should roughly match the median vertices modified per transaction. Integer (no default value) MASKABLE cluster Configuration options for multi-machine deployments Name Description Datatype Default Value Mutability cluster.max-partitions The number of virtual partition blocks created in the partitioned graph. This should be larger than the maximum expected number of nodes in the JanusGraph graph cluster. Must be greater than 1 and a power of 2. Integer 32 FIXED computer GraphComputer related configuration Name Description Datatype Default Value Mutability computer.result-mode How the graph computer should return the computed results. 'persist' for writing them into the graph, 'localtx' for writing them into the local transaction, or 'none' (default) String none MASKABLE graph General configuration options Name Description Datatype Default Value Mutability graph.allow-stale-config Whether to allow the local and storage-backend-hosted copies of the configuration to contain conflicting values for options with any of the following types: FIXED, GLOBAL_OFFLINE, GLOBAL. These types are managed globally through the storage backend and cannot be overridden by changing the local configuration. This type of conflict usually indicates misconfiguration. When this option is true, JanusGraph will log these option conflicts, but continue normal operation using the storage-backend-hosted value for each conflicted option. When this option is false, JanusGraph will log these option conflicts, but then it will throw an exception, refusing to start. Boolean true MASKABLE graph.allow-upgrade Setting this to true will allow certain fixed values to be updated such as storage-version. This should only be used for upgrading. Boolean false MASKABLE graph.graphname This config option is an optional configuration setting that you may supply when opening a graph. The String value you provide will be the name of your graph. If you use the ConfigurationManagement APIs, then you will be able to access your graph by this String representation using the ConfiguredGraphFactory APIs. String (no default value) LOCAL graph.replace-instance-if-exists If a JanusGraph instance with the same instance identifier already exists, the usage of this configuration option results in the opening of this graph anwyay. Boolean false LOCAL graph.set-vertex-id Whether user provided vertex ids should be enabled and JanusGraph's automatic id allocation be disabled. Useful when operating JanusGraph in concert with another storage system that assigns long ids but disables some of JanusGraph's advanced features which can lead to inconsistent data. EXPERT FEATURE - USE WITH GREAT CARE. Boolean false FIXED graph.storage-version The version of JanusGraph storage schema with which this database was created. Automatically set on first start of graph. Should only ever be changed if upgraing to a new major release version of JanusGraph that contains schema changes String (no default value) FIXED graph.timestamps The timestamp resolution to use when writing to storage and indices. Sets the time granularity for the entire graph cluster. To avoid potential inaccuracies, the configured time resolution should match those of the backend systems. Some JanusGraph storage backends declare a preferred timestamp resolution that reflects design constraints in the underlying service. When the backend provides a preferred default, and when this setting is not explicitly declared in the config file, the backend default is used and the general default associated with this setting is ignored. An explicit declaration of this setting overrides both the general and backend-specific defaults. TimestampProviders MICRO FIXED graph.unique-instance-id Unique identifier for this JanusGraph instance. This must be unique among all instances concurrently accessing the same stores or indexes. It's automatically generated by concatenating the hostname, process id, and a static (process-wide) counter. Leaving it unset is recommended. String (no default value) LOCAL graph.unique-instance-id-suffix When this is set and unique-instance-id is not, this JanusGraph instance's unique identifier is generated by concatenating the hex encoded hostname to the provided number. Short (no default value) LOCAL graph.use-hostname-for-unique-instance-id When this is set, this JanusGraph's unique instance identifier is set to the hostname. If unique-instance-id-suffix is also set, then the identifier is set to . Boolean false LOCAL gremlin Gremlin configuration options Name Description Datatype Default Value Mutability gremlin.graph The implementation of graph factory that will be used by gremlin server String org.janusgraph.core.JanusGraphFactory LOCAL ids General configuration options for graph element IDs Name Description Datatype Default Value Mutability ids.block-size Globally reserve graph element IDs in chunks of this size. Setting this too low will make commits frequently block on slow reservation requests. Setting it too high will result in IDs wasted when a graph instance shuts down with reserved but mostly-unused blocks. Integer 10000 GLOBAL_OFFLINE ids.flush When true, vertices and edges are assigned IDs immediately upon creation. When false, IDs are assigned only when the transaction commits. Boolean true MASKABLE ids.num-partitions Number of partition block to allocate for placement of vertices Integer 10 MASKABLE ids.placement Name of the vertex placement strategy or full class name String simple MASKABLE ids.renew-percentage When the most-recently-reserved ID block has only this percentage of its total IDs remaining (expressed as a value between 0 and 1), JanusGraph asynchronously begins reserving another block. This helps avoid transaction commits waiting on ID reservation even if the block size is relatively small. Double 0.3 MASKABLE ids.renew-timeout The number of milliseconds that the JanusGraph id pool manager will wait before giving up on allocating a new block of ids Duration 120000 ms MASKABLE ids.store-name The name of the ID KCVStore. IDS_STORE_NAME is meant to be used only for backward compatibility with Titan, and should not be used explicitly in normal operations or in new graphs. String janusgraph_ids GLOBAL_OFFLINE ids.authority Configuration options for graph element ID reservation/allocation Name Description Datatype Default Value Mutability ids.authority.conflict-avoidance-mode This setting helps separate JanusGraph instances sharing a single graph storage backend avoid contention when reserving ID blocks, increasing overall throughput. ConflictAvoidanceMode NONE GLOBAL_OFFLINE ids.authority.conflict-avoidance-tag Conflict avoidance tag to be used by this JanusGraph instance when allocating IDs Integer 0 LOCAL ids.authority.conflict-avoidance-tag-bits Configures the number of bits of JanusGraph-assigned element IDs that are reserved for the conflict avoidance tag Integer 4 FIXED ids.authority.randomized-conflict-avoidance-retries Number of times the system attempts ID block reservations with random conflict avoidance tags before giving up and throwing an exception Integer 5 MASKABLE ids.authority.wait-time The number of milliseconds the system waits for an ID block reservation to be acknowledged by the storage backend Duration 300 ms GLOBAL_OFFLINE index * Configuration options for the individual indexing backends Name Description Datatype Default Value Mutability index.[X].backend The indexing backend used to extend and optimize JanusGraph's query functionality. This setting is optional. JanusGraph can use multiple heterogeneous index backends. Hence, this option can appear more than once, so long as the user-defined name between \"index\" and \"backend\" is unique among appearances.Similar to the storage backend, this should be set to one of JanusGraph's built-in shorthand names for its standard index backends (shorthands: lucene, elasticsearch, es, solr) or to the full package and classname of a custom/third-party IndexProvider implementation. String elasticsearch GLOBAL_OFFLINE index.[X].conf-file Path to a configuration file for those indexing backends that require/support a separate config file String (no default value) MASKABLE index.[X].directory Directory to store index data locally String (no default value) MASKABLE index.[X].hostname The hostname or comma-separated list of hostnames of index backend servers. This is only applicable to some index backends, such as elasticsearch and solr. String[] 127.0.0.1 MASKABLE index.[X].index-name Name of the index if required by the indexing backend String janusgraph GLOBAL_OFFLINE index.[X].map-name Whether to use the name of the property key as the field name in the index. It must be ensured, that theindexed property key names are valid field names. Renaming the property key will NOT rename the field and its the developers responsibility to avoid field collisions. Boolean true GLOBAL index.[X].max-result-set-size Maximum number of results to return if no limit is specified. For index backends that support scrolling, it represents the number of results in each batch Integer 50 MASKABLE index.[X].port The port on which to connect to index backend servers Integer (no default value) MASKABLE index.[X].elasticsearch Elasticsearch index configuration Name Description Datatype Default Value Mutability index.[X].elasticsearch.bulk-refresh Elasticsearch bulk API refresh setting used to control when changes made by this request are made visible to search String false MASKABLE index.[X].elasticsearch.health-request-timeout When JanusGraph initializes its ES backend, JanusGraph waits up to this duration for the ES cluster health to reach at least yellow status. This string should be formatted as a natural number followed by the lowercase letter \"s\", e.g. 3s or 60s. String 30s MASKABLE index.[X].elasticsearch.interface Interface for connecting to Elasticsearch. TRANSPORT_CLIENT and NODE were previously supported, but now are required to migrate to REST_CLIENT. See the JanusGraph upgrade instructions for more details. String REST_CLIENT MASKABLE index.[X].elasticsearch.max-retry-timeout Sets the maximum timeout (in milliseconds) to honour in case of multiple retries of the same request sent using the ElasticSearch Rest Client by JanusGraph. Integer (no default value) MASKABLE index.[X].elasticsearch.scroll-keep-alive How long (in seconds) elasticsearch should keep alive the scroll context. Integer 60 GLOBAL_OFFLINE index.[X].elasticsearch.use-all-field Whether JanusGraph should add an \"all\" field mapping. When enabled field mappings will include a \"copy_to\" parameter referencing the \"all\" field. This is supported since Elasticsearch 6.x and is required when using wildcard fields starting in Elasticsearch 6.x. Boolean true GLOBAL_OFFLINE index.[X].elasticsearch.use-deprecated-multitype-index Whether JanusGraph should group these indices into a single Elasticsearch index (requires Elasticsearch 5.x or earlier). Boolean false GLOBAL_OFFLINE index.[X].elasticsearch.create Settings related to index creation Name Description Datatype Default Value Mutability index.[X].elasticsearch.create.allow-mapping-update Whether JanusGraph should allow a mapping update when registering an index. Only applicable when use-external-mappings is true. Boolean false MASKABLE index.[X].elasticsearch.create.sleep How long to sleep, in milliseconds, between the successful completion of a (blocking) index creation request and the first use of that index. This only applies when creating an index in ES, which typically only happens the first time JanusGraph is started on top of ES. If the index JanusGraph is configured to use already exists, then this setting has no effect. Long 200 MASKABLE index.[X].elasticsearch.create.use-external-mappings Whether JanusGraph should make use of an external mapping when registering an index. Boolean false MASKABLE index.[X].elasticsearch.http.auth Configuration options for HTTP(S) authentication. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.type Authentication type to be used for HTTP(S) access. String NONE LOCAL index.[X].elasticsearch.http.auth.basic Configuration options for HTTP(S) Basic authentication. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.basic.password Password for HTTP(S) authentication. String LOCAL index.[X].elasticsearch.http.auth.basic.realm Realm value for HTTP(S) authentication. If empty, any realm is accepted. String LOCAL index.[X].elasticsearch.http.auth.basic.username Username for HTTP(S) authentication. String LOCAL index.[X].elasticsearch.http.auth.custom Configuration options for custom HTTP(S) authenticator. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.custom.authenticator-args Comma-separated custom authenticator constructor arguments. String[] LOCAL index.[X].elasticsearch.http.auth.custom.authenticator-class Authenticator fully qualified class name. String LOCAL index.[X].elasticsearch.ssl Elasticsearch SSL configuration Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.allow-self-signed-certificates Controls the accepting of the self-signed SSL certificates. Boolean false LOCAL index.[X].elasticsearch.ssl.disable-hostname-verification Disables the SSL hostname verification if set to true. Hostname verification is enabled by default. Boolean false LOCAL index.[X].elasticsearch.ssl.enabled Controls use of the SSL connection to Elasticsearch. Boolean false LOCAL index.[X].elasticsearch.ssl.keystore Configuration options for SSL Keystore. Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.keystore.keypassword The password to access the key in the SSL Keystore. If the option is not present, the value of \"storepassword\" is used. String LOCAL index.[X].elasticsearch.ssl.keystore.location Marks the location of the SSL Keystore. String LOCAL index.[X].elasticsearch.ssl.keystore.storepassword The password to access SSL Keystore. String LOCAL index.[X].elasticsearch.ssl.truststore Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL index.[X].elasticsearch.ssl.truststore.password The password to access SSL Truststore. String LOCAL index.[X].solr Solr index configuration Name Description Datatype Default Value Mutability index.[X].solr.configset If specified, the same solr configSet can be reused for each new Collection that is created in SolrCloud. String (no default value) MASKABLE index.[X].solr.dyn-fields Whether to use dynamic fields (which appends the data type to the field name). If dynamic fields is disabledthe user must map field names and define them explicitly in the schema. Boolean true GLOBAL_OFFLINE index.[X].solr.http-compression Enable/disable compression on the HTTP connections made to Solr. Boolean false MASKABLE index.[X].solr.http-connection-timeout Solr HTTP connection timeout. Integer 5000 MASKABLE index.[X].solr.http-max Maximum number of HTTP connections in total to all Solr servers. Integer 100 MASKABLE index.[X].solr.http-max-per-host Maximum number of HTTP connections per Solr host. Integer 20 MASKABLE index.[X].solr.http-urls List of URLs to use to connect to Solr Servers (LBHttpSolrClient is used), don't add core or collection name to the URL. String[] http://localhost:8983/solr MASKABLE index.[X].solr.kerberos-enabled Whether SOLR instance is Kerberized or not. Boolean false MASKABLE index.[X].solr.key-field-names Field name that uniquely identifies each document in Solr. Must be specified as a list of collection=field . String[] (no default value) GLOBAL index.[X].solr.max-shards-per-node Maximum number of shards per node. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.mode The operation mode for Solr which is either via HTTP ( http ) or using SolrCloud ( cloud ) String cloud GLOBAL_OFFLINE index.[X].solr.num-shards Number of shards for a collection. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.replication-factor Replication factor for a collection. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.ttl_field Name of the TTL field for Solr collections. String ttl GLOBAL_OFFLINE index.[X].solr.wait-searcher When mutating - wait for the index to reflect new mutations before returning. This can have a negative impact on performance. Boolean false LOCAL index.[X].solr.zookeeper-url URL of the Zookeeper instance coordinating the SolrCloud cluster String[] localhost:2181 MASKABLE log * Configuration options for JanusGraph's logging system Name Description Datatype Default Value Mutability log.[X].backend Define the log backed to use String default GLOBAL_OFFLINE log.[X].fixed-partition Whether all log entries are written to one fixed partition even if the backend store is partitioned.This can cause imbalanced loads and should only be used on low volume logs Boolean false GLOBAL_OFFLINE log.[X].key-consistent Whether to require consistency for log reading and writing messages to the storage backend Boolean false MASKABLE log.[X].max-partitions The maximum number of partitions to use for logging. Setting up this many actual or virtual partitions. Must be bigger than 0and a power of 2. Integer (no default value) FIXED log.[X].max-read-time Maximum time in ms to try reading log messages from the backend before failing. Duration 4000 ms MASKABLE log.[X].max-write-time Maximum time in ms to try persisting log messages against the backend before failing. Duration 10000 ms MASKABLE log.[X].num-buckets The number of buckets to split log entries into for load balancing Integer 1 GLOBAL_OFFLINE log.[X].read-batch-size Maximum number of log messages to read at a time for logging implementations that read messages in batches Integer 1024 MASKABLE log.[X].read-interval Time in ms between message readings from the backend for this logging implementations that read message in batch Duration 5000 ms MASKABLE log.[X].read-lag-time Maximum time in ms that it may take for reads to appear in the backend. If a write does not becomevisible in the storage backend in this amount of time, a log reader might miss the message. Duration 500 ms MASKABLE log.[X].read-threads Number of threads to be used in reading and processing log messages Integer 1 MASKABLE log.[X].send-batch-size Maximum number of log messages to batch up for sending for logging implementations that support batch sending Integer 256 MASKABLE log.[X].send-delay Maximum time in ms that messages can be buffered locally before sending in batch Duration 1000 ms MASKABLE log.[X].ttl Sets a TTL on all log entries, meaningthat all entries added to this log expire after the configured amount of time. Requiresthat the log implementation supports TTL. Duration (no default value) GLOBAL metrics Configuration options for metrics reporting Name Description Datatype Default Value Mutability metrics.enabled Whether to enable basic timing and operation count monitoring on backend Boolean false MASKABLE metrics.merge-stores Whether to aggregate measurements for the edge store, vertex index, edge index, and ID store Boolean true MASKABLE metrics.prefix The default name prefix for Metrics reported by JanusGraph. String org.janusgraph MASKABLE metrics.console Configuration options for metrics reporting to console Name Description Datatype Default Value Mutability metrics.console.interval Time between Metrics reports printing to the console, in milliseconds Duration (no default value) MASKABLE metrics.csv Configuration options for metrics reporting to CSV file Name Description Datatype Default Value Mutability metrics.csv.directory Metrics CSV output directory String (no default value) MASKABLE metrics.csv.interval Time between dumps of CSV files containing Metrics data, in milliseconds Duration (no default value) MASKABLE metrics.ganglia Configuration options for metrics reporting through Ganglia Name Description Datatype Default Value Mutability metrics.ganglia.addressing-mode Whether to communicate to Ganglia via uni- or multicast String unicast MASKABLE metrics.ganglia.hostname The unicast host or multicast group name to which Metrics will send Ganglia data String (no default value) MASKABLE metrics.ganglia.interval The number of milliseconds to wait between sending Metrics data to Ganglia Duration (no default value) MASKABLE metrics.ganglia.port The port to which Ganglia data are sent Integer 8649 MASKABLE metrics.ganglia.protocol-31 Whether to send data to Ganglia in the 3.1 protocol format Boolean true MASKABLE metrics.ganglia.spoof If non-null, it must be a valid Gmetric spoof string formatted as an IP:hostname pair. See https://github.com/ganglia/monitor-core/wiki/Gmetric-Spoofing for information about this setting. String (no default value) MASKABLE metrics.ganglia.ttl The multicast TTL to set on outgoing Ganglia datagrams Integer 1 MASKABLE metrics.ganglia.uuid The host UUID to set on outgoing Ganglia datagrams. See https://github.com/ganglia/monitor-core/wiki/UUIDSources for information about this setting. String (no default value) LOCAL metrics.graphite Configuration options for metrics reporting through Graphite Name Description Datatype Default Value Mutability metrics.graphite.hostname The hostname to receive Graphite plaintext protocol metric data String (no default value) MASKABLE metrics.graphite.interval The number of milliseconds to wait between sending Metrics data Duration (no default value) MASKABLE metrics.graphite.port The port to which Graphite data are sent Integer 2003 MASKABLE metrics.graphite.prefix A Graphite-specific prefix for reported metrics String (no default value) MASKABLE metrics.jmx Configuration options for metrics reporting through JMX Name Description Datatype Default Value Mutability metrics.jmx.agentid The JMX agentId used by Metrics String (no default value) MASKABLE metrics.jmx.domain The JMX domain in which to report Metrics String (no default value) MASKABLE metrics.jmx.enabled Whether to report Metrics through a JMX MBean Boolean false MASKABLE metrics.slf4j Configuration options for metrics reporting through slf4j Name Description Datatype Default Value Mutability metrics.slf4j.interval Time between slf4j logging reports of Metrics data, in milliseconds Duration (no default value) MASKABLE metrics.slf4j.logger The complete name of the Logger through which Metrics will report via Slf4j String (no default value) MASKABLE query Configuration options for query processing Name Description Datatype Default Value Mutability query.batch Whether traversal queries should be batched when executed against the storage backend. This can lead to significant performance improvement if there is a non-trivial latency to the backend. Boolean false MASKABLE query.batch-property-prefetch Whether to do a batched pre-fetch of all properties on adjacent vertices against the storage backend prior to evaluating a has condition against those vertices. Because these vertex properties will be loaded into the transaction-level cache of recently-used vertices when the condition is evaluated this can lead to significant performance improvement if there are many edges to adjacent vertices and there is a non-trivial latency to the backend. Boolean false MASKABLE query.fast-property Whether to pre-fetch all properties on first singular vertex property access. This can eliminate backend calls on subsequentproperty access for the same vertex at the expense of retrieving all properties at once. This can be expensive for vertices with many properties Boolean true MASKABLE query.force-index Whether JanusGraph should throw an exception if a graph query cannot be answered using an index. Doing solimits the functionality of JanusGraph's graph queries but ensures that slow graph queries are avoided on large graphs. Recommended for production use of JanusGraph. Boolean false MASKABLE query.ignore-unknown-index-key Whether to ignore undefined types encountered in user-provided index queries Boolean false MASKABLE query.smart-limit Whether the query optimizer should try to guess a smart limit for the query to ensure responsiveness in light of possibly large result sets. Those will be loaded incrementally if this option is enabled. Boolean true MASKABLE schema Schema related configuration options Name Description Datatype Default Value Mutability schema.constraints Configures the schema constraints to be used by this graph. If config 'schema.constraints' is set to 'true' and 'schema.default' is set to 'none', then an 'IllegalArgumentException' is thrown for schema constraint violations. If 'schema.constraints' is set to 'true' and 'schema.default' is not set 'none', schema constraints are automatically created as described in the config option 'schema.default'. If 'schema.constraints' is set to 'false' which is the default, then no schema constraints are applied. Boolean false GLOBAL_OFFLINE schema.default Configures the DefaultSchemaMaker to be used by this graph. If set to 'none', automatic schema creation is disabled. Defaults to a blueprints compatible schema maker with MULTI edge labels and SINGLE property keys String default MASKABLE storage Configuration options for the storage backend. Some options are applicable only for certain backends. Name Description Datatype Default Value Mutability storage.backend The primary persistence provider used by JanusGraph. This is required. It should be set one of JanusGraph's built-in shorthand names for its standard storage backends (shorthands: berkeleyje, cassandrathrift, cassandra, astyanax, embeddedcassandra, cql, hbase, inmemory) or to the full package and classname of a custom/third-party StoreManager implementation. String (no default value) LOCAL storage.batch-loading Whether to enable batch loading into the storage backend Boolean false LOCAL storage.buffer-size Size of the batch in which mutations are persisted Integer 1024 MASKABLE storage.conf-file Path to a configuration file for those storage backends which require/support a single separate config file. String (no default value) LOCAL storage.connection-timeout Default timeout, in milliseconds, when connecting to a remote database instance Duration 10000 ms MASKABLE storage.directory Storage directory for those storage backends that require local storage. String (no default value) LOCAL storage.drop-on-clear Whether to drop the graph database (true) or delete rows (false) when clearing storage. Note that some backends always drop the graph database when clearing storage. Also note that indices are always dropped when clearing storage. Boolean true MASKABLE storage.hostname The hostname or comma-separated list of hostnames of storage backend servers. This is only applicable to some storage backends, such as cassandra and hbase. String[] 127.0.0.1 LOCAL storage.page-size JanusGraph break requests that may return many results from distributed storage backends into a series of requests for small chunks/pages of results, where each chunk contains up to this many elements. Integer 100 MASKABLE storage.parallel-backend-ops Whether JanusGraph should attempt to parallelize storage operations Boolean true MASKABLE storage.password Password to authenticate against backend String (no default value) LOCAL storage.port The port on which to connect to storage backend servers. For HBase, it is the Zookeeper port. Integer (no default value) LOCAL storage.read-only Read-only database Boolean false LOCAL storage.read-time Maximum time (in ms) to wait for a backend read operation to complete successfully. If a backend read operationfails temporarily, JanusGraph will backoff exponentially and retry the operation until the wait time has been exhausted. Duration 10000 ms MASKABLE storage.root Storage root directory for those storage backends that require local storage. If you do not supply storage.directory and you do supply graph.graphname, then your data will be stored in the directory equivalent to / . String (no default value) LOCAL storage.setup-wait Time in milliseconds for backend manager to wait for the storage backends to become available when JanusGraph is run in server mode Duration 60000 ms MASKABLE storage.transactions Enables transactions on storage backends that support them Boolean true MASKABLE storage.username Username to authenticate against backend String (no default value) LOCAL storage.write-time Maximum time (in ms) to wait for a backend write operation to complete successfully. If a backend write operationfails temporarily, JanusGraph will backoff exponentially and retry the operation until the wait time has been exhausted. Duration 100000 ms MASKABLE storage.berkeleyje BerkeleyDB JE configuration options Name Description Datatype Default Value Mutability storage.berkeleyje.cache-percentage Percentage of JVM heap reserved for BerkeleyJE's cache Integer 65 MASKABLE storage.berkeleyje.isolation-level The isolation level used by transactions String REPEATABLE_READ MASKABLE storage.berkeleyje.lock-mode The BDB record lock mode used for read operations String LockMode.DEFAULT MASKABLE storage.cassandra Cassandra storage backend options Name Description Datatype Default Value Mutability storage.cassandra.atomic-batch-mutate True to use Cassandra atomic batch mutation, false to use non-atomic batches Boolean true MASKABLE storage.cassandra.compaction-strategy-class The compaction strategy to use for JanusGraph tables String (no default value) FIXED storage.cassandra.compaction-strategy-options Compaction strategy options. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. String[] (no default value) FIXED storage.cassandra.compression Whether the storage backend should use compression when storing the data Boolean true FIXED storage.cassandra.compression-block-size The size of the compression blocks in kilobytes Integer 64 FIXED storage.cassandra.compression-type The sstable_compression value JanusGraph uses when creating column families. This accepts any value allowed by Cassandra's sstable_compression option. Leave this unset to disable sstable_compression on JanusGraph-created CFs. String LZ4Compressor MASKABLE storage.cassandra.frame-size-mb The thrift frame size in megabytes Integer 15 MASKABLE storage.cassandra.keyspace The name of JanusGraph's keyspace. It will be created if it does not exist. If it is not supplied, but graph.graphname is, then the the keyspace will be set to that. String janusgraph LOCAL storage.cassandra.read-consistency-level The consistency level of read operations against Cassandra String QUORUM MASKABLE storage.cassandra.replication-factor The number of data replicas (including the original copy) that should be kept. This is only meaningful for storage backends that natively support data replication. Integer 1 GLOBAL_OFFLINE storage.cassandra.replication-strategy-class The replication strategy to use for JanusGraph keyspace String org.apache.cassandra.locator.SimpleStrategy FIXED storage.cassandra.replication-strategy-options Replication strategy options, e.g. factor or replicas per datacenter. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. A replication_factor set here takes precedence over one set with storage.cassandra.replication-factor String[] (no default value) FIXED storage.cassandra.write-consistency-level The consistency level of write operations against Cassandra String QUORUM MASKABLE storage.cassandra.astyanax Astyanax-specific Cassandra options Name Description Datatype Default Value Mutability storage.cassandra.astyanax.cluster-name Default name for the Cassandra cluster String JanusGraph Cluster MASKABLE storage.cassandra.astyanax.connection-pool-type Astyanax's connection pooler implementation String TOKEN_AWARE MASKABLE storage.cassandra.astyanax.frame-size The thrift frame size in mega bytes Integer 15 MASKABLE storage.cassandra.astyanax.host-supplier Host supplier to use when discovery type is set to DISCOVERY_SERVICE or TOKEN_AWARE String (no default value) MASKABLE storage.cassandra.astyanax.local-datacenter The name of the local or closest Cassandra datacenter. When set and not whitespace, this value will be passed into ConnectionPoolConfigurationImpl.setLocalDatacenter. When unset or set to whitespace, setLocalDatacenter will not be invoked. String (no default value) MASKABLE storage.cassandra.astyanax.max-cluster-connections-per-host Maximum pooled \"cluster\" connections per host Integer 3 MASKABLE storage.cassandra.astyanax.max-connections Maximum open connections allowed in the pool (counting all hosts) Integer -1 MASKABLE storage.cassandra.astyanax.max-connections-per-host Maximum pooled connections per host Integer 32 MASKABLE storage.cassandra.astyanax.max-operations-per-connection Maximum number of operations allowed per connection before the connection is closed Integer 100000 MASKABLE storage.cassandra.astyanax.node-discovery-type How Astyanax discovers Cassandra cluster nodes String RING_DESCRIBE MASKABLE storage.cassandra.astyanax.read-page-size The page size for Cassandra read operations Integer 4096 MASKABLE storage.cassandra.astyanax.retry-backoff-strategy Astyanax's retry backoff strategy with configuration parameters String com.netflix.astyanax.connectionpool.impl.FixedRetryBackoffStrategy,1000,5000 MASKABLE storage.cassandra.astyanax.retry-delay-slice Astyanax's connection pool \"retryDelaySlice\" parameter Integer 10000 MASKABLE storage.cassandra.astyanax.retry-max-delay-slice Astyanax's connection pool \"retryMaxDelaySlice\" parameter Integer 10 MASKABLE storage.cassandra.astyanax.retry-policy Astyanax's retry policy implementation with configuration parameters String com.netflix.astyanax.retry.BoundedExponentialBackoff,100,25000,8 MASKABLE storage.cassandra.astyanax.retry-suspend-window Astyanax's connection pool \"retryMaxDelaySlice\" parameter Integer 20000 MASKABLE storage.cassandra.ssl Configuration options for SSL Name Description Datatype Default Value Mutability storage.cassandra.ssl.enabled Controls use of the SSL connection to Cassandra Boolean false LOCAL storage.cassandra.ssl.truststore Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability storage.cassandra.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL storage.cassandra.ssl.truststore.password The password to access SSL Truststore. String LOCAL storage.cassandra.thrift.cpool Options for the Apache commons-pool connection manager Name Description Datatype Default Value Mutability storage.cassandra.thrift.cpool.evictor-period Approximate number of milliseconds between runs of the idle connection evictor. Set to -1 to never run the idle connection evictor. Long 30000 MASKABLE storage.cassandra.thrift.cpool.idle-test Whether the idle connection evictor validates idle connections and drops those that fail to validate Boolean false MASKABLE storage.cassandra.thrift.cpool.idle-tests-per-eviction-run When the value is negative, e.g. -n, roughly one nth of the idle connections are tested per run. When the value is positive, e.g. n, the min(idle-count, n) connections are tested per run. Integer 0 MASKABLE storage.cassandra.thrift.cpool.max-active Maximum number of concurrently in-use connections (-1 to leave undefined) Integer 16 MASKABLE storage.cassandra.thrift.cpool.max-idle Maximum number of concurrently idle connections (-1 to leave undefined) Integer 4 MASKABLE storage.cassandra.thrift.cpool.max-total Max number of allowed Thrift connections, idle or active (-1 to leave undefined) Integer -1 MASKABLE storage.cassandra.thrift.cpool.max-wait Maximum number of milliseconds to block when storage.cassandra.thrift.cpool.when-exhausted is set to BLOCK. Has no effect when set to actions besides BLOCK. Set to -1 to wait indefinitely. Long -1 MASKABLE storage.cassandra.thrift.cpool.min-evictable-idle-time Minimum number of milliseconds a connection must be idle before it is eligible for eviction. See also storage.cassandra.thrift.cpool.evictor-period. Set to -1 to never evict idle connections. Long 60000 MASKABLE storage.cassandra.thrift.cpool.min-idle Minimum number of idle connections the pool attempts to maintain Integer 0 MASKABLE storage.cassandra.thrift.cpool.when-exhausted What to do when clients concurrently request more active connections than are allowed by the pool. The value must be one of BLOCK, FAIL, or GROW. String BLOCK MASKABLE storage.cql CQL storage backend options Name Description Datatype Default Value Mutability storage.cql.atomic-batch-mutate True to use Cassandra atomic batch mutation, false to use non-atomic batches Boolean false MASKABLE storage.cql.batch-statement-size The number of statements in each batch Integer 20 MASKABLE storage.cql.cluster-name Default name for the Cassandra cluster String JanusGraph Cluster MASKABLE storage.cql.compact-storage Whether the storage backend should use compact storage on tables. This option is only available for Cassandra 2 and earlier and defaults to true. Boolean true FIXED storage.cql.compaction-strategy-class The compaction strategy to use for JanusGraph tables String (no default value) FIXED storage.cql.compaction-strategy-options Compaction strategy options. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. String[] (no default value) FIXED storage.cql.compression Whether the storage backend should use compression when storing the data Boolean true FIXED storage.cql.compression-block-size The size of the compression blocks in kilobytes Integer 64 FIXED storage.cql.compression-type The sstable_compression value JanusGraph uses when creating column families. This accepts any value allowed by Cassandra's sstable_compression option. Leave this unset to disable sstable_compression on JanusGraph-created CFs. String LZ4Compressor MASKABLE storage.cql.keyspace The name of JanusGraph's keyspace. It will be created if it does not exist. String janusgraph LOCAL storage.cql.local-core-connections-per-host The number of connections initially created and kept open to each host for local datacenter Integer 1 FIXED storage.cql.local-datacenter The name of the local or closest Cassandra datacenter. When set and not whitespace, this value will be passed into ConnectionPoolConfigurationImpl.setLocalDatacenter. When unset or set to whitespace, setLocalDatacenter will not be invoked. String (no default value) MASKABLE storage.cql.local-max-connections-per-host The maximum number of connections that can be created per host for local datacenter Integer 1 FIXED storage.cql.local-max-requests-per-connection The maximum number of requests per connection for local datacenter Integer 1024 FIXED storage.cql.only-use-local-consistency-for-system-operations True to prevent any system queries from using QUORUM consistency and always use LOCAL_QUORUM instead Boolean false MASKABLE storage.cql.protocol-version The protocol version used to connect to the Cassandra database. If no value is supplied then the driver will negotiate with the server. Integer 0 LOCAL storage.cql.read-consistency-level The consistency level of read operations against Cassandra String QUORUM MASKABLE storage.cql.remote-core-connections-per-host The number of connections initially created and kept open to each host for remote datacenter Integer 1 FIXED storage.cql.remote-max-connections-per-host The maximum number of connections that can be created per host for remote datacenter Integer 1 FIXED storage.cql.remote-max-requests-per-connection The maximum number of requests per connection for remote datacenter Integer 256 FIXED storage.cql.replication-factor The number of data replicas (including the original copy) that should be kept Integer 1 GLOBAL_OFFLINE storage.cql.replication-strategy-class The replication strategy to use for JanusGraph keyspace String SimpleStrategy FIXED storage.cql.replication-strategy-options Replication strategy options, e.g. factor or replicas per datacenter. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. A replication_factor set here takes precedence over one set with storage.cql.replication-factor String[] (no default value) FIXED storage.cql.use-external-locking True to prevent JanusGraph from using its own locking mechanism. Setting this to true eliminates redundant checks when using an external locking mechanism outside of JanusGraph. Be aware that when use-external-locking is set to true, that failure to employ a locking algorithm which locks all columns that participate in a transaction upfront and unlocks them when the transaction ends, will result in a 'read uncommitted' transaction isolation level guarantee. If set to true without an appropriate external locking mechanism in place side effects such as dirty/non-repeatable/phantom reads should be expected. Boolean false MASKABLE storage.cql.write-consistency-level The consistency level of write operations against Cassandra String QUORUM MASKABLE storage.cql.ssl Configuration options for SSL Name Description Datatype Default Value Mutability storage.cql.ssl.enabled Controls use of the SSL connection to Cassandra Boolean false LOCAL storage.cql.ssl.truststore Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability storage.cql.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL storage.cql.ssl.truststore.password The password to access SSL Truststore. String LOCAL storage.hbase HBase storage options Name Description Datatype Default Value Mutability storage.hbase.compat-class The package and class name of the HBaseCompat implementation. HBaseCompat masks version-specific HBase API differences. When this option is unset, JanusGraph calls HBase's VersionInfo.getVersion() and loads the matching compat class at runtime. Setting this option forces JanusGraph to instead reflectively load and instantiate the specified class. String (no default value) MASKABLE storage.hbase.compression-algorithm An HBase Compression.Algorithm enum string which will be applied to newly created column families. The compression algorithm must be installed and available on the HBase cluster. JanusGraph cannot install and configure new compression algorithms on the HBase cluster by itself. String GZ MASKABLE storage.hbase.region-count The number of initial regions set when creating JanusGraph's HBase table Integer (no default value) MASKABLE storage.hbase.regions-per-server The number of regions per regionserver to set when creating JanusGraph's HBase table Integer (no default value) MASKABLE storage.hbase.short-cf-names Whether to shorten the names of JanusGraph's column families to one-character mnemonics to conserve storage space Boolean true FIXED storage.hbase.skip-schema-check Assume that JanusGraph's HBase table and column families already exist. When this is true, JanusGraph will not check for the existence of its table/CFs, nor will it attempt to create them under any circumstances. This is useful when running JanusGraph without HBase admin privileges. Boolean false MASKABLE storage.hbase.snapshot-name The name of an exising HBase snapshot to be used by HBaseSnapshotInputFormat String janusgraph-snapshot LOCAL storage.hbase.snapshot-restore-dir The tempoary directory to be used by HBaseSnapshotInputFormat to restore a snapshot. This directory should be on the same File System as the HBase root dir. String /tmp LOCAL storage.hbase.table The name of the table JanusGraph will use. When storage.hbase.skip-schema-check is false, JanusGraph will automatically create this table if it does not already exist. If this configuration option is not provided but graph.graphname is, the table will be set to that value. String janusgraph LOCAL storage.lock Options for locking on eventually-consistent stores Name Description Datatype Default Value Mutability storage.lock.backend Locker type to use String consistentkey GLOBAL_OFFLINE storage.lock.clean-expired Whether to delete expired locks from the storage backend Boolean false MASKABLE storage.lock.expiry-time Number of milliseconds after which a lock is considered to have expired. Lock applications that were not released are considered expired after this time and released. This value should be larger than the maximum time a transaction can take in order to guarantee that no correctly held applications are expired pre-maturely and as small as possible to avoid dead lock. Duration 300000 ms GLOBAL_OFFLINE storage.lock.local-mediator-group This option determines the LocalLockMediator instance used for early detection of lock contention between concurrent JanusGraph graph instances within the same process which are connected to the same storage backend. JanusGraph instances that have the same value for this variable will attempt to discover lock contention among themselves in memory before proceeding with the general-case distributed locking code. JanusGraph generates an appropriate default value for this option at startup. Overridding the default is generally only useful in testing. String (no default value) LOCAL storage.lock.retries Number of times the system attempts to acquire a lock before giving up and throwing an exception Integer 3 MASKABLE storage.lock.wait-time Number of milliseconds the system waits for a lock application to be acknowledged by the storage backend. Also, the time waited at the end of all lock applications before verifying that the applications were successful. This value should be a small multiple of the average consistent write time. Duration 100 ms GLOBAL_OFFLINE storage.meta * Meta data to include in storage backend retrievals Name Description Datatype Default Value Mutability storage.meta.[X].timestamps Whether to include timestamps in retrieved entries for storage backends that automatically annotated entries with timestamps Boolean false GLOBAL storage.meta.[X].ttl Whether to include ttl in retrieved entries for storage backends that support storage and retrieval of cell level TTL Boolean false GLOBAL storage.meta.[X].visibility Whether to include visibility in retrieved entries for storage backends that support cell level visibility Boolean true GLOBAL tx Configuration options for transaction handling Name Description Datatype Default Value Mutability tx.log-tx Whether transaction mutations should be logged to JanusGraph's write-ahead transaction log which can be used for recovery of partially failed transactions Boolean false GLOBAL tx.max-commit-time Maximum time (in ms) that a transaction might take to commit against all backends. This is used by the distributed write-ahead log processing to determine when a transaction can be considered failed (i.e. after this time has elapsed).Must be longer than the maximum allowed write time. Duration 10000 ms GLOBAL tx.recovery Configuration options for transaction recovery processes Name Description Datatype Default Value Mutability tx.recovery.verbose Whether the transaction recovery system should print recovered transactions and other activity to standard output Boolean false MASKABLE","title":"Janusgraph cfg"},{"location":"basics/janusgraph-cfg/#attributescustom","text":"Custom attribute serialization and handling Name Description Datatype Default Value Mutability attributes.custom.[X].attribute-class Class of the custom attribute to be registered String (no default value) GLOBAL_OFFLINE attributes.custom.[X].serializer-class Class of the custom attribute serializer to be registered String (no default value) GLOBAL_OFFLINE","title":"attributes.custom *"},{"location":"basics/janusgraph-cfg/#cache","text":"Configuration options that modify JanusGraph's caching behavior Name Description Datatype Default Value Mutability cache.db-cache Whether to enable JanusGraph's database-level cache, which is shared across all transactions. Enabling this option speeds up traversals by holding hot graph elements in memory, but also increases the likelihood of reading stale data. Disabling it forces each transaction to independently fetch graph elements from storage before reading/writing them. Boolean false MASKABLE cache.db-cache-clean-wait How long, in milliseconds, database-level cache will keep entries after flushing them. This option is only useful on distributed storage backends that are capable of acknowledging writes without necessarily making them immediately visible. Integer 50 GLOBAL_OFFLINE cache.db-cache-size Size of JanusGraph's database level cache. Values between 0 and 1 are interpreted as a percentage of VM heap, while larger values are interpreted as an absolute size in bytes. Double 0.3 MASKABLE cache.db-cache-time Default expiration time, in milliseconds, for entries in the database-level cache. Entries are evicted when they reach this age even if the cache has room to spare. Set to 0 to disable expiration (cache entries live forever or until memory pressure triggers eviction when set to 0). Long 10000 GLOBAL_OFFLINE cache.tx-cache-size Maximum size of the transaction-level cache of recently-used vertices. Integer 20000 MASKABLE cache.tx-dirty-size Initial size of the transaction-level cache of uncommitted dirty vertices. This is a performance hint for write-heavy, performance-sensitive transactional workloads. If set, it should roughly match the median vertices modified per transaction. Integer (no default value) MASKABLE","title":"cache"},{"location":"basics/janusgraph-cfg/#cluster","text":"Configuration options for multi-machine deployments Name Description Datatype Default Value Mutability cluster.max-partitions The number of virtual partition blocks created in the partitioned graph. This should be larger than the maximum expected number of nodes in the JanusGraph graph cluster. Must be greater than 1 and a power of 2. Integer 32 FIXED","title":"cluster"},{"location":"basics/janusgraph-cfg/#computer","text":"GraphComputer related configuration Name Description Datatype Default Value Mutability computer.result-mode How the graph computer should return the computed results. 'persist' for writing them into the graph, 'localtx' for writing them into the local transaction, or 'none' (default) String none MASKABLE","title":"computer"},{"location":"basics/janusgraph-cfg/#graph","text":"General configuration options Name Description Datatype Default Value Mutability graph.allow-stale-config Whether to allow the local and storage-backend-hosted copies of the configuration to contain conflicting values for options with any of the following types: FIXED, GLOBAL_OFFLINE, GLOBAL. These types are managed globally through the storage backend and cannot be overridden by changing the local configuration. This type of conflict usually indicates misconfiguration. When this option is true, JanusGraph will log these option conflicts, but continue normal operation using the storage-backend-hosted value for each conflicted option. When this option is false, JanusGraph will log these option conflicts, but then it will throw an exception, refusing to start. Boolean true MASKABLE graph.allow-upgrade Setting this to true will allow certain fixed values to be updated such as storage-version. This should only be used for upgrading. Boolean false MASKABLE graph.graphname This config option is an optional configuration setting that you may supply when opening a graph. The String value you provide will be the name of your graph. If you use the ConfigurationManagement APIs, then you will be able to access your graph by this String representation using the ConfiguredGraphFactory APIs. String (no default value) LOCAL graph.replace-instance-if-exists If a JanusGraph instance with the same instance identifier already exists, the usage of this configuration option results in the opening of this graph anwyay. Boolean false LOCAL graph.set-vertex-id Whether user provided vertex ids should be enabled and JanusGraph's automatic id allocation be disabled. Useful when operating JanusGraph in concert with another storage system that assigns long ids but disables some of JanusGraph's advanced features which can lead to inconsistent data. EXPERT FEATURE - USE WITH GREAT CARE. Boolean false FIXED graph.storage-version The version of JanusGraph storage schema with which this database was created. Automatically set on first start of graph. Should only ever be changed if upgraing to a new major release version of JanusGraph that contains schema changes String (no default value) FIXED graph.timestamps The timestamp resolution to use when writing to storage and indices. Sets the time granularity for the entire graph cluster. To avoid potential inaccuracies, the configured time resolution should match those of the backend systems. Some JanusGraph storage backends declare a preferred timestamp resolution that reflects design constraints in the underlying service. When the backend provides a preferred default, and when this setting is not explicitly declared in the config file, the backend default is used and the general default associated with this setting is ignored. An explicit declaration of this setting overrides both the general and backend-specific defaults. TimestampProviders MICRO FIXED graph.unique-instance-id Unique identifier for this JanusGraph instance. This must be unique among all instances concurrently accessing the same stores or indexes. It's automatically generated by concatenating the hostname, process id, and a static (process-wide) counter. Leaving it unset is recommended. String (no default value) LOCAL graph.unique-instance-id-suffix When this is set and unique-instance-id is not, this JanusGraph instance's unique identifier is generated by concatenating the hex encoded hostname to the provided number. Short (no default value) LOCAL graph.use-hostname-for-unique-instance-id When this is set, this JanusGraph's unique instance identifier is set to the hostname. If unique-instance-id-suffix is also set, then the identifier is set to . Boolean false LOCAL","title":"graph"},{"location":"basics/janusgraph-cfg/#gremlin","text":"Gremlin configuration options Name Description Datatype Default Value Mutability gremlin.graph The implementation of graph factory that will be used by gremlin server String org.janusgraph.core.JanusGraphFactory LOCAL","title":"gremlin"},{"location":"basics/janusgraph-cfg/#ids","text":"General configuration options for graph element IDs Name Description Datatype Default Value Mutability ids.block-size Globally reserve graph element IDs in chunks of this size. Setting this too low will make commits frequently block on slow reservation requests. Setting it too high will result in IDs wasted when a graph instance shuts down with reserved but mostly-unused blocks. Integer 10000 GLOBAL_OFFLINE ids.flush When true, vertices and edges are assigned IDs immediately upon creation. When false, IDs are assigned only when the transaction commits. Boolean true MASKABLE ids.num-partitions Number of partition block to allocate for placement of vertices Integer 10 MASKABLE ids.placement Name of the vertex placement strategy or full class name String simple MASKABLE ids.renew-percentage When the most-recently-reserved ID block has only this percentage of its total IDs remaining (expressed as a value between 0 and 1), JanusGraph asynchronously begins reserving another block. This helps avoid transaction commits waiting on ID reservation even if the block size is relatively small. Double 0.3 MASKABLE ids.renew-timeout The number of milliseconds that the JanusGraph id pool manager will wait before giving up on allocating a new block of ids Duration 120000 ms MASKABLE ids.store-name The name of the ID KCVStore. IDS_STORE_NAME is meant to be used only for backward compatibility with Titan, and should not be used explicitly in normal operations or in new graphs. String janusgraph_ids GLOBAL_OFFLINE","title":"ids"},{"location":"basics/janusgraph-cfg/#idsauthority","text":"Configuration options for graph element ID reservation/allocation Name Description Datatype Default Value Mutability ids.authority.conflict-avoidance-mode This setting helps separate JanusGraph instances sharing a single graph storage backend avoid contention when reserving ID blocks, increasing overall throughput. ConflictAvoidanceMode NONE GLOBAL_OFFLINE ids.authority.conflict-avoidance-tag Conflict avoidance tag to be used by this JanusGraph instance when allocating IDs Integer 0 LOCAL ids.authority.conflict-avoidance-tag-bits Configures the number of bits of JanusGraph-assigned element IDs that are reserved for the conflict avoidance tag Integer 4 FIXED ids.authority.randomized-conflict-avoidance-retries Number of times the system attempts ID block reservations with random conflict avoidance tags before giving up and throwing an exception Integer 5 MASKABLE ids.authority.wait-time The number of milliseconds the system waits for an ID block reservation to be acknowledged by the storage backend Duration 300 ms GLOBAL_OFFLINE","title":"ids.authority"},{"location":"basics/janusgraph-cfg/#index","text":"Configuration options for the individual indexing backends Name Description Datatype Default Value Mutability index.[X].backend The indexing backend used to extend and optimize JanusGraph's query functionality. This setting is optional. JanusGraph can use multiple heterogeneous index backends. Hence, this option can appear more than once, so long as the user-defined name between \"index\" and \"backend\" is unique among appearances.Similar to the storage backend, this should be set to one of JanusGraph's built-in shorthand names for its standard index backends (shorthands: lucene, elasticsearch, es, solr) or to the full package and classname of a custom/third-party IndexProvider implementation. String elasticsearch GLOBAL_OFFLINE index.[X].conf-file Path to a configuration file for those indexing backends that require/support a separate config file String (no default value) MASKABLE index.[X].directory Directory to store index data locally String (no default value) MASKABLE index.[X].hostname The hostname or comma-separated list of hostnames of index backend servers. This is only applicable to some index backends, such as elasticsearch and solr. String[] 127.0.0.1 MASKABLE index.[X].index-name Name of the index if required by the indexing backend String janusgraph GLOBAL_OFFLINE index.[X].map-name Whether to use the name of the property key as the field name in the index. It must be ensured, that theindexed property key names are valid field names. Renaming the property key will NOT rename the field and its the developers responsibility to avoid field collisions. Boolean true GLOBAL index.[X].max-result-set-size Maximum number of results to return if no limit is specified. For index backends that support scrolling, it represents the number of results in each batch Integer 50 MASKABLE index.[X].port The port on which to connect to index backend servers Integer (no default value) MASKABLE","title":"index *"},{"location":"basics/janusgraph-cfg/#indexxelasticsearch","text":"Elasticsearch index configuration Name Description Datatype Default Value Mutability index.[X].elasticsearch.bulk-refresh Elasticsearch bulk API refresh setting used to control when changes made by this request are made visible to search String false MASKABLE index.[X].elasticsearch.health-request-timeout When JanusGraph initializes its ES backend, JanusGraph waits up to this duration for the ES cluster health to reach at least yellow status. This string should be formatted as a natural number followed by the lowercase letter \"s\", e.g. 3s or 60s. String 30s MASKABLE index.[X].elasticsearch.interface Interface for connecting to Elasticsearch. TRANSPORT_CLIENT and NODE were previously supported, but now are required to migrate to REST_CLIENT. See the JanusGraph upgrade instructions for more details. String REST_CLIENT MASKABLE index.[X].elasticsearch.max-retry-timeout Sets the maximum timeout (in milliseconds) to honour in case of multiple retries of the same request sent using the ElasticSearch Rest Client by JanusGraph. Integer (no default value) MASKABLE index.[X].elasticsearch.scroll-keep-alive How long (in seconds) elasticsearch should keep alive the scroll context. Integer 60 GLOBAL_OFFLINE index.[X].elasticsearch.use-all-field Whether JanusGraph should add an \"all\" field mapping. When enabled field mappings will include a \"copy_to\" parameter referencing the \"all\" field. This is supported since Elasticsearch 6.x and is required when using wildcard fields starting in Elasticsearch 6.x. Boolean true GLOBAL_OFFLINE index.[X].elasticsearch.use-deprecated-multitype-index Whether JanusGraph should group these indices into a single Elasticsearch index (requires Elasticsearch 5.x or earlier). Boolean false GLOBAL_OFFLINE","title":"index.[X].elasticsearch"},{"location":"basics/janusgraph-cfg/#indexxelasticsearchcreate","text":"Settings related to index creation Name Description Datatype Default Value Mutability index.[X].elasticsearch.create.allow-mapping-update Whether JanusGraph should allow a mapping update when registering an index. Only applicable when use-external-mappings is true. Boolean false MASKABLE index.[X].elasticsearch.create.sleep How long to sleep, in milliseconds, between the successful completion of a (blocking) index creation request and the first use of that index. This only applies when creating an index in ES, which typically only happens the first time JanusGraph is started on top of ES. If the index JanusGraph is configured to use already exists, then this setting has no effect. Long 200 MASKABLE index.[X].elasticsearch.create.use-external-mappings Whether JanusGraph should make use of an external mapping when registering an index. Boolean false MASKABLE","title":"index.[X].elasticsearch.create"},{"location":"basics/janusgraph-cfg/#indexxelasticsearchhttpauth","text":"Configuration options for HTTP(S) authentication. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.type Authentication type to be used for HTTP(S) access. String NONE LOCAL","title":"index.[X].elasticsearch.http.auth"},{"location":"basics/janusgraph-cfg/#indexxelasticsearchhttpauthbasic","text":"Configuration options for HTTP(S) Basic authentication. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.basic.password Password for HTTP(S) authentication. String LOCAL index.[X].elasticsearch.http.auth.basic.realm Realm value for HTTP(S) authentication. If empty, any realm is accepted. String LOCAL index.[X].elasticsearch.http.auth.basic.username Username for HTTP(S) authentication. String LOCAL","title":"index.[X].elasticsearch.http.auth.basic"},{"location":"basics/janusgraph-cfg/#indexxelasticsearchhttpauthcustom","text":"Configuration options for custom HTTP(S) authenticator. Name Description Datatype Default Value Mutability index.[X].elasticsearch.http.auth.custom.authenticator-args Comma-separated custom authenticator constructor arguments. String[] LOCAL index.[X].elasticsearch.http.auth.custom.authenticator-class Authenticator fully qualified class name. String LOCAL","title":"index.[X].elasticsearch.http.auth.custom"},{"location":"basics/janusgraph-cfg/#indexxelasticsearchssl","text":"Elasticsearch SSL configuration Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.allow-self-signed-certificates Controls the accepting of the self-signed SSL certificates. Boolean false LOCAL index.[X].elasticsearch.ssl.disable-hostname-verification Disables the SSL hostname verification if set to true. Hostname verification is enabled by default. Boolean false LOCAL index.[X].elasticsearch.ssl.enabled Controls use of the SSL connection to Elasticsearch. Boolean false LOCAL","title":"index.[X].elasticsearch.ssl"},{"location":"basics/janusgraph-cfg/#indexxelasticsearchsslkeystore","text":"Configuration options for SSL Keystore. Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.keystore.keypassword The password to access the key in the SSL Keystore. If the option is not present, the value of \"storepassword\" is used. String LOCAL index.[X].elasticsearch.ssl.keystore.location Marks the location of the SSL Keystore. String LOCAL index.[X].elasticsearch.ssl.keystore.storepassword The password to access SSL Keystore. String LOCAL","title":"index.[X].elasticsearch.ssl.keystore"},{"location":"basics/janusgraph-cfg/#indexxelasticsearchssltruststore","text":"Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability index.[X].elasticsearch.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL index.[X].elasticsearch.ssl.truststore.password The password to access SSL Truststore. String LOCAL","title":"index.[X].elasticsearch.ssl.truststore"},{"location":"basics/janusgraph-cfg/#indexxsolr","text":"Solr index configuration Name Description Datatype Default Value Mutability index.[X].solr.configset If specified, the same solr configSet can be reused for each new Collection that is created in SolrCloud. String (no default value) MASKABLE index.[X].solr.dyn-fields Whether to use dynamic fields (which appends the data type to the field name). If dynamic fields is disabledthe user must map field names and define them explicitly in the schema. Boolean true GLOBAL_OFFLINE index.[X].solr.http-compression Enable/disable compression on the HTTP connections made to Solr. Boolean false MASKABLE index.[X].solr.http-connection-timeout Solr HTTP connection timeout. Integer 5000 MASKABLE index.[X].solr.http-max Maximum number of HTTP connections in total to all Solr servers. Integer 100 MASKABLE index.[X].solr.http-max-per-host Maximum number of HTTP connections per Solr host. Integer 20 MASKABLE index.[X].solr.http-urls List of URLs to use to connect to Solr Servers (LBHttpSolrClient is used), don't add core or collection name to the URL. String[] http://localhost:8983/solr MASKABLE index.[X].solr.kerberos-enabled Whether SOLR instance is Kerberized or not. Boolean false MASKABLE index.[X].solr.key-field-names Field name that uniquely identifies each document in Solr. Must be specified as a list of collection=field . String[] (no default value) GLOBAL index.[X].solr.max-shards-per-node Maximum number of shards per node. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.mode The operation mode for Solr which is either via HTTP ( http ) or using SolrCloud ( cloud ) String cloud GLOBAL_OFFLINE index.[X].solr.num-shards Number of shards for a collection. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.replication-factor Replication factor for a collection. This applies when creating a new collection which is only supported under the SolrCloud operation mode. Integer 1 GLOBAL_OFFLINE index.[X].solr.ttl_field Name of the TTL field for Solr collections. String ttl GLOBAL_OFFLINE index.[X].solr.wait-searcher When mutating - wait for the index to reflect new mutations before returning. This can have a negative impact on performance. Boolean false LOCAL index.[X].solr.zookeeper-url URL of the Zookeeper instance coordinating the SolrCloud cluster String[] localhost:2181 MASKABLE","title":"index.[X].solr"},{"location":"basics/janusgraph-cfg/#log","text":"Configuration options for JanusGraph's logging system Name Description Datatype Default Value Mutability log.[X].backend Define the log backed to use String default GLOBAL_OFFLINE log.[X].fixed-partition Whether all log entries are written to one fixed partition even if the backend store is partitioned.This can cause imbalanced loads and should only be used on low volume logs Boolean false GLOBAL_OFFLINE log.[X].key-consistent Whether to require consistency for log reading and writing messages to the storage backend Boolean false MASKABLE log.[X].max-partitions The maximum number of partitions to use for logging. Setting up this many actual or virtual partitions. Must be bigger than 0and a power of 2. Integer (no default value) FIXED log.[X].max-read-time Maximum time in ms to try reading log messages from the backend before failing. Duration 4000 ms MASKABLE log.[X].max-write-time Maximum time in ms to try persisting log messages against the backend before failing. Duration 10000 ms MASKABLE log.[X].num-buckets The number of buckets to split log entries into for load balancing Integer 1 GLOBAL_OFFLINE log.[X].read-batch-size Maximum number of log messages to read at a time for logging implementations that read messages in batches Integer 1024 MASKABLE log.[X].read-interval Time in ms between message readings from the backend for this logging implementations that read message in batch Duration 5000 ms MASKABLE log.[X].read-lag-time Maximum time in ms that it may take for reads to appear in the backend. If a write does not becomevisible in the storage backend in this amount of time, a log reader might miss the message. Duration 500 ms MASKABLE log.[X].read-threads Number of threads to be used in reading and processing log messages Integer 1 MASKABLE log.[X].send-batch-size Maximum number of log messages to batch up for sending for logging implementations that support batch sending Integer 256 MASKABLE log.[X].send-delay Maximum time in ms that messages can be buffered locally before sending in batch Duration 1000 ms MASKABLE log.[X].ttl Sets a TTL on all log entries, meaningthat all entries added to this log expire after the configured amount of time. Requiresthat the log implementation supports TTL. Duration (no default value) GLOBAL","title":"log *"},{"location":"basics/janusgraph-cfg/#metrics","text":"Configuration options for metrics reporting Name Description Datatype Default Value Mutability metrics.enabled Whether to enable basic timing and operation count monitoring on backend Boolean false MASKABLE metrics.merge-stores Whether to aggregate measurements for the edge store, vertex index, edge index, and ID store Boolean true MASKABLE metrics.prefix The default name prefix for Metrics reported by JanusGraph. String org.janusgraph MASKABLE","title":"metrics"},{"location":"basics/janusgraph-cfg/#metricsconsole","text":"Configuration options for metrics reporting to console Name Description Datatype Default Value Mutability metrics.console.interval Time between Metrics reports printing to the console, in milliseconds Duration (no default value) MASKABLE","title":"metrics.console"},{"location":"basics/janusgraph-cfg/#metricscsv","text":"Configuration options for metrics reporting to CSV file Name Description Datatype Default Value Mutability metrics.csv.directory Metrics CSV output directory String (no default value) MASKABLE metrics.csv.interval Time between dumps of CSV files containing Metrics data, in milliseconds Duration (no default value) MASKABLE","title":"metrics.csv"},{"location":"basics/janusgraph-cfg/#metricsganglia","text":"Configuration options for metrics reporting through Ganglia Name Description Datatype Default Value Mutability metrics.ganglia.addressing-mode Whether to communicate to Ganglia via uni- or multicast String unicast MASKABLE metrics.ganglia.hostname The unicast host or multicast group name to which Metrics will send Ganglia data String (no default value) MASKABLE metrics.ganglia.interval The number of milliseconds to wait between sending Metrics data to Ganglia Duration (no default value) MASKABLE metrics.ganglia.port The port to which Ganglia data are sent Integer 8649 MASKABLE metrics.ganglia.protocol-31 Whether to send data to Ganglia in the 3.1 protocol format Boolean true MASKABLE metrics.ganglia.spoof If non-null, it must be a valid Gmetric spoof string formatted as an IP:hostname pair. See https://github.com/ganglia/monitor-core/wiki/Gmetric-Spoofing for information about this setting. String (no default value) MASKABLE metrics.ganglia.ttl The multicast TTL to set on outgoing Ganglia datagrams Integer 1 MASKABLE metrics.ganglia.uuid The host UUID to set on outgoing Ganglia datagrams. See https://github.com/ganglia/monitor-core/wiki/UUIDSources for information about this setting. String (no default value) LOCAL","title":"metrics.ganglia"},{"location":"basics/janusgraph-cfg/#metricsgraphite","text":"Configuration options for metrics reporting through Graphite Name Description Datatype Default Value Mutability metrics.graphite.hostname The hostname to receive Graphite plaintext protocol metric data String (no default value) MASKABLE metrics.graphite.interval The number of milliseconds to wait between sending Metrics data Duration (no default value) MASKABLE metrics.graphite.port The port to which Graphite data are sent Integer 2003 MASKABLE metrics.graphite.prefix A Graphite-specific prefix for reported metrics String (no default value) MASKABLE","title":"metrics.graphite"},{"location":"basics/janusgraph-cfg/#metricsjmx","text":"Configuration options for metrics reporting through JMX Name Description Datatype Default Value Mutability metrics.jmx.agentid The JMX agentId used by Metrics String (no default value) MASKABLE metrics.jmx.domain The JMX domain in which to report Metrics String (no default value) MASKABLE metrics.jmx.enabled Whether to report Metrics through a JMX MBean Boolean false MASKABLE","title":"metrics.jmx"},{"location":"basics/janusgraph-cfg/#metricsslf4j","text":"Configuration options for metrics reporting through slf4j Name Description Datatype Default Value Mutability metrics.slf4j.interval Time between slf4j logging reports of Metrics data, in milliseconds Duration (no default value) MASKABLE metrics.slf4j.logger The complete name of the Logger through which Metrics will report via Slf4j String (no default value) MASKABLE","title":"metrics.slf4j"},{"location":"basics/janusgraph-cfg/#query","text":"Configuration options for query processing Name Description Datatype Default Value Mutability query.batch Whether traversal queries should be batched when executed against the storage backend. This can lead to significant performance improvement if there is a non-trivial latency to the backend. Boolean false MASKABLE query.batch-property-prefetch Whether to do a batched pre-fetch of all properties on adjacent vertices against the storage backend prior to evaluating a has condition against those vertices. Because these vertex properties will be loaded into the transaction-level cache of recently-used vertices when the condition is evaluated this can lead to significant performance improvement if there are many edges to adjacent vertices and there is a non-trivial latency to the backend. Boolean false MASKABLE query.fast-property Whether to pre-fetch all properties on first singular vertex property access. This can eliminate backend calls on subsequentproperty access for the same vertex at the expense of retrieving all properties at once. This can be expensive for vertices with many properties Boolean true MASKABLE query.force-index Whether JanusGraph should throw an exception if a graph query cannot be answered using an index. Doing solimits the functionality of JanusGraph's graph queries but ensures that slow graph queries are avoided on large graphs. Recommended for production use of JanusGraph. Boolean false MASKABLE query.ignore-unknown-index-key Whether to ignore undefined types encountered in user-provided index queries Boolean false MASKABLE query.smart-limit Whether the query optimizer should try to guess a smart limit for the query to ensure responsiveness in light of possibly large result sets. Those will be loaded incrementally if this option is enabled. Boolean true MASKABLE","title":"query"},{"location":"basics/janusgraph-cfg/#schema","text":"Schema related configuration options Name Description Datatype Default Value Mutability schema.constraints Configures the schema constraints to be used by this graph. If config 'schema.constraints' is set to 'true' and 'schema.default' is set to 'none', then an 'IllegalArgumentException' is thrown for schema constraint violations. If 'schema.constraints' is set to 'true' and 'schema.default' is not set 'none', schema constraints are automatically created as described in the config option 'schema.default'. If 'schema.constraints' is set to 'false' which is the default, then no schema constraints are applied. Boolean false GLOBAL_OFFLINE schema.default Configures the DefaultSchemaMaker to be used by this graph. If set to 'none', automatic schema creation is disabled. Defaults to a blueprints compatible schema maker with MULTI edge labels and SINGLE property keys String default MASKABLE","title":"schema"},{"location":"basics/janusgraph-cfg/#storage","text":"Configuration options for the storage backend. Some options are applicable only for certain backends. Name Description Datatype Default Value Mutability storage.backend The primary persistence provider used by JanusGraph. This is required. It should be set one of JanusGraph's built-in shorthand names for its standard storage backends (shorthands: berkeleyje, cassandrathrift, cassandra, astyanax, embeddedcassandra, cql, hbase, inmemory) or to the full package and classname of a custom/third-party StoreManager implementation. String (no default value) LOCAL storage.batch-loading Whether to enable batch loading into the storage backend Boolean false LOCAL storage.buffer-size Size of the batch in which mutations are persisted Integer 1024 MASKABLE storage.conf-file Path to a configuration file for those storage backends which require/support a single separate config file. String (no default value) LOCAL storage.connection-timeout Default timeout, in milliseconds, when connecting to a remote database instance Duration 10000 ms MASKABLE storage.directory Storage directory for those storage backends that require local storage. String (no default value) LOCAL storage.drop-on-clear Whether to drop the graph database (true) or delete rows (false) when clearing storage. Note that some backends always drop the graph database when clearing storage. Also note that indices are always dropped when clearing storage. Boolean true MASKABLE storage.hostname The hostname or comma-separated list of hostnames of storage backend servers. This is only applicable to some storage backends, such as cassandra and hbase. String[] 127.0.0.1 LOCAL storage.page-size JanusGraph break requests that may return many results from distributed storage backends into a series of requests for small chunks/pages of results, where each chunk contains up to this many elements. Integer 100 MASKABLE storage.parallel-backend-ops Whether JanusGraph should attempt to parallelize storage operations Boolean true MASKABLE storage.password Password to authenticate against backend String (no default value) LOCAL storage.port The port on which to connect to storage backend servers. For HBase, it is the Zookeeper port. Integer (no default value) LOCAL storage.read-only Read-only database Boolean false LOCAL storage.read-time Maximum time (in ms) to wait for a backend read operation to complete successfully. If a backend read operationfails temporarily, JanusGraph will backoff exponentially and retry the operation until the wait time has been exhausted. Duration 10000 ms MASKABLE storage.root Storage root directory for those storage backends that require local storage. If you do not supply storage.directory and you do supply graph.graphname, then your data will be stored in the directory equivalent to / . String (no default value) LOCAL storage.setup-wait Time in milliseconds for backend manager to wait for the storage backends to become available when JanusGraph is run in server mode Duration 60000 ms MASKABLE storage.transactions Enables transactions on storage backends that support them Boolean true MASKABLE storage.username Username to authenticate against backend String (no default value) LOCAL storage.write-time Maximum time (in ms) to wait for a backend write operation to complete successfully. If a backend write operationfails temporarily, JanusGraph will backoff exponentially and retry the operation until the wait time has been exhausted. Duration 100000 ms MASKABLE","title":"storage"},{"location":"basics/janusgraph-cfg/#storageberkeleyje","text":"BerkeleyDB JE configuration options Name Description Datatype Default Value Mutability storage.berkeleyje.cache-percentage Percentage of JVM heap reserved for BerkeleyJE's cache Integer 65 MASKABLE storage.berkeleyje.isolation-level The isolation level used by transactions String REPEATABLE_READ MASKABLE storage.berkeleyje.lock-mode The BDB record lock mode used for read operations String LockMode.DEFAULT MASKABLE","title":"storage.berkeleyje"},{"location":"basics/janusgraph-cfg/#storagecassandra","text":"Cassandra storage backend options Name Description Datatype Default Value Mutability storage.cassandra.atomic-batch-mutate True to use Cassandra atomic batch mutation, false to use non-atomic batches Boolean true MASKABLE storage.cassandra.compaction-strategy-class The compaction strategy to use for JanusGraph tables String (no default value) FIXED storage.cassandra.compaction-strategy-options Compaction strategy options. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. String[] (no default value) FIXED storage.cassandra.compression Whether the storage backend should use compression when storing the data Boolean true FIXED storage.cassandra.compression-block-size The size of the compression blocks in kilobytes Integer 64 FIXED storage.cassandra.compression-type The sstable_compression value JanusGraph uses when creating column families. This accepts any value allowed by Cassandra's sstable_compression option. Leave this unset to disable sstable_compression on JanusGraph-created CFs. String LZ4Compressor MASKABLE storage.cassandra.frame-size-mb The thrift frame size in megabytes Integer 15 MASKABLE storage.cassandra.keyspace The name of JanusGraph's keyspace. It will be created if it does not exist. If it is not supplied, but graph.graphname is, then the the keyspace will be set to that. String janusgraph LOCAL storage.cassandra.read-consistency-level The consistency level of read operations against Cassandra String QUORUM MASKABLE storage.cassandra.replication-factor The number of data replicas (including the original copy) that should be kept. This is only meaningful for storage backends that natively support data replication. Integer 1 GLOBAL_OFFLINE storage.cassandra.replication-strategy-class The replication strategy to use for JanusGraph keyspace String org.apache.cassandra.locator.SimpleStrategy FIXED storage.cassandra.replication-strategy-options Replication strategy options, e.g. factor or replicas per datacenter. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. A replication_factor set here takes precedence over one set with storage.cassandra.replication-factor String[] (no default value) FIXED storage.cassandra.write-consistency-level The consistency level of write operations against Cassandra String QUORUM MASKABLE","title":"storage.cassandra"},{"location":"basics/janusgraph-cfg/#storagecassandraastyanax","text":"Astyanax-specific Cassandra options Name Description Datatype Default Value Mutability storage.cassandra.astyanax.cluster-name Default name for the Cassandra cluster String JanusGraph Cluster MASKABLE storage.cassandra.astyanax.connection-pool-type Astyanax's connection pooler implementation String TOKEN_AWARE MASKABLE storage.cassandra.astyanax.frame-size The thrift frame size in mega bytes Integer 15 MASKABLE storage.cassandra.astyanax.host-supplier Host supplier to use when discovery type is set to DISCOVERY_SERVICE or TOKEN_AWARE String (no default value) MASKABLE storage.cassandra.astyanax.local-datacenter The name of the local or closest Cassandra datacenter. When set and not whitespace, this value will be passed into ConnectionPoolConfigurationImpl.setLocalDatacenter. When unset or set to whitespace, setLocalDatacenter will not be invoked. String (no default value) MASKABLE storage.cassandra.astyanax.max-cluster-connections-per-host Maximum pooled \"cluster\" connections per host Integer 3 MASKABLE storage.cassandra.astyanax.max-connections Maximum open connections allowed in the pool (counting all hosts) Integer -1 MASKABLE storage.cassandra.astyanax.max-connections-per-host Maximum pooled connections per host Integer 32 MASKABLE storage.cassandra.astyanax.max-operations-per-connection Maximum number of operations allowed per connection before the connection is closed Integer 100000 MASKABLE storage.cassandra.astyanax.node-discovery-type How Astyanax discovers Cassandra cluster nodes String RING_DESCRIBE MASKABLE storage.cassandra.astyanax.read-page-size The page size for Cassandra read operations Integer 4096 MASKABLE storage.cassandra.astyanax.retry-backoff-strategy Astyanax's retry backoff strategy with configuration parameters String com.netflix.astyanax.connectionpool.impl.FixedRetryBackoffStrategy,1000,5000 MASKABLE storage.cassandra.astyanax.retry-delay-slice Astyanax's connection pool \"retryDelaySlice\" parameter Integer 10000 MASKABLE storage.cassandra.astyanax.retry-max-delay-slice Astyanax's connection pool \"retryMaxDelaySlice\" parameter Integer 10 MASKABLE storage.cassandra.astyanax.retry-policy Astyanax's retry policy implementation with configuration parameters String com.netflix.astyanax.retry.BoundedExponentialBackoff,100,25000,8 MASKABLE storage.cassandra.astyanax.retry-suspend-window Astyanax's connection pool \"retryMaxDelaySlice\" parameter Integer 20000 MASKABLE","title":"storage.cassandra.astyanax"},{"location":"basics/janusgraph-cfg/#storagecassandrassl","text":"Configuration options for SSL Name Description Datatype Default Value Mutability storage.cassandra.ssl.enabled Controls use of the SSL connection to Cassandra Boolean false LOCAL","title":"storage.cassandra.ssl"},{"location":"basics/janusgraph-cfg/#storagecassandrassltruststore","text":"Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability storage.cassandra.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL storage.cassandra.ssl.truststore.password The password to access SSL Truststore. String LOCAL","title":"storage.cassandra.ssl.truststore"},{"location":"basics/janusgraph-cfg/#storagecassandrathriftcpool","text":"Options for the Apache commons-pool connection manager Name Description Datatype Default Value Mutability storage.cassandra.thrift.cpool.evictor-period Approximate number of milliseconds between runs of the idle connection evictor. Set to -1 to never run the idle connection evictor. Long 30000 MASKABLE storage.cassandra.thrift.cpool.idle-test Whether the idle connection evictor validates idle connections and drops those that fail to validate Boolean false MASKABLE storage.cassandra.thrift.cpool.idle-tests-per-eviction-run When the value is negative, e.g. -n, roughly one nth of the idle connections are tested per run. When the value is positive, e.g. n, the min(idle-count, n) connections are tested per run. Integer 0 MASKABLE storage.cassandra.thrift.cpool.max-active Maximum number of concurrently in-use connections (-1 to leave undefined) Integer 16 MASKABLE storage.cassandra.thrift.cpool.max-idle Maximum number of concurrently idle connections (-1 to leave undefined) Integer 4 MASKABLE storage.cassandra.thrift.cpool.max-total Max number of allowed Thrift connections, idle or active (-1 to leave undefined) Integer -1 MASKABLE storage.cassandra.thrift.cpool.max-wait Maximum number of milliseconds to block when storage.cassandra.thrift.cpool.when-exhausted is set to BLOCK. Has no effect when set to actions besides BLOCK. Set to -1 to wait indefinitely. Long -1 MASKABLE storage.cassandra.thrift.cpool.min-evictable-idle-time Minimum number of milliseconds a connection must be idle before it is eligible for eviction. See also storage.cassandra.thrift.cpool.evictor-period. Set to -1 to never evict idle connections. Long 60000 MASKABLE storage.cassandra.thrift.cpool.min-idle Minimum number of idle connections the pool attempts to maintain Integer 0 MASKABLE storage.cassandra.thrift.cpool.when-exhausted What to do when clients concurrently request more active connections than are allowed by the pool. The value must be one of BLOCK, FAIL, or GROW. String BLOCK MASKABLE","title":"storage.cassandra.thrift.cpool"},{"location":"basics/janusgraph-cfg/#storagecql","text":"CQL storage backend options Name Description Datatype Default Value Mutability storage.cql.atomic-batch-mutate True to use Cassandra atomic batch mutation, false to use non-atomic batches Boolean false MASKABLE storage.cql.batch-statement-size The number of statements in each batch Integer 20 MASKABLE storage.cql.cluster-name Default name for the Cassandra cluster String JanusGraph Cluster MASKABLE storage.cql.compact-storage Whether the storage backend should use compact storage on tables. This option is only available for Cassandra 2 and earlier and defaults to true. Boolean true FIXED storage.cql.compaction-strategy-class The compaction strategy to use for JanusGraph tables String (no default value) FIXED storage.cql.compaction-strategy-options Compaction strategy options. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. String[] (no default value) FIXED storage.cql.compression Whether the storage backend should use compression when storing the data Boolean true FIXED storage.cql.compression-block-size The size of the compression blocks in kilobytes Integer 64 FIXED storage.cql.compression-type The sstable_compression value JanusGraph uses when creating column families. This accepts any value allowed by Cassandra's sstable_compression option. Leave this unset to disable sstable_compression on JanusGraph-created CFs. String LZ4Compressor MASKABLE storage.cql.keyspace The name of JanusGraph's keyspace. It will be created if it does not exist. String janusgraph LOCAL storage.cql.local-core-connections-per-host The number of connections initially created and kept open to each host for local datacenter Integer 1 FIXED storage.cql.local-datacenter The name of the local or closest Cassandra datacenter. When set and not whitespace, this value will be passed into ConnectionPoolConfigurationImpl.setLocalDatacenter. When unset or set to whitespace, setLocalDatacenter will not be invoked. String (no default value) MASKABLE storage.cql.local-max-connections-per-host The maximum number of connections that can be created per host for local datacenter Integer 1 FIXED storage.cql.local-max-requests-per-connection The maximum number of requests per connection for local datacenter Integer 1024 FIXED storage.cql.only-use-local-consistency-for-system-operations True to prevent any system queries from using QUORUM consistency and always use LOCAL_QUORUM instead Boolean false MASKABLE storage.cql.protocol-version The protocol version used to connect to the Cassandra database. If no value is supplied then the driver will negotiate with the server. Integer 0 LOCAL storage.cql.read-consistency-level The consistency level of read operations against Cassandra String QUORUM MASKABLE storage.cql.remote-core-connections-per-host The number of connections initially created and kept open to each host for remote datacenter Integer 1 FIXED storage.cql.remote-max-connections-per-host The maximum number of connections that can be created per host for remote datacenter Integer 1 FIXED storage.cql.remote-max-requests-per-connection The maximum number of requests per connection for remote datacenter Integer 256 FIXED storage.cql.replication-factor The number of data replicas (including the original copy) that should be kept Integer 1 GLOBAL_OFFLINE storage.cql.replication-strategy-class The replication strategy to use for JanusGraph keyspace String SimpleStrategy FIXED storage.cql.replication-strategy-options Replication strategy options, e.g. factor or replicas per datacenter. This list is interpreted as a map. It must have an even number of elements in [key,val,key,val,...] form. A replication_factor set here takes precedence over one set with storage.cql.replication-factor String[] (no default value) FIXED storage.cql.use-external-locking True to prevent JanusGraph from using its own locking mechanism. Setting this to true eliminates redundant checks when using an external locking mechanism outside of JanusGraph. Be aware that when use-external-locking is set to true, that failure to employ a locking algorithm which locks all columns that participate in a transaction upfront and unlocks them when the transaction ends, will result in a 'read uncommitted' transaction isolation level guarantee. If set to true without an appropriate external locking mechanism in place side effects such as dirty/non-repeatable/phantom reads should be expected. Boolean false MASKABLE storage.cql.write-consistency-level The consistency level of write operations against Cassandra String QUORUM MASKABLE","title":"storage.cql"},{"location":"basics/janusgraph-cfg/#storagecqlssl","text":"Configuration options for SSL Name Description Datatype Default Value Mutability storage.cql.ssl.enabled Controls use of the SSL connection to Cassandra Boolean false LOCAL","title":"storage.cql.ssl"},{"location":"basics/janusgraph-cfg/#storagecqlssltruststore","text":"Configuration options for SSL Truststore. Name Description Datatype Default Value Mutability storage.cql.ssl.truststore.location Marks the location of the SSL Truststore. String LOCAL storage.cql.ssl.truststore.password The password to access SSL Truststore. String LOCAL","title":"storage.cql.ssl.truststore"},{"location":"basics/janusgraph-cfg/#storagehbase","text":"HBase storage options Name Description Datatype Default Value Mutability storage.hbase.compat-class The package and class name of the HBaseCompat implementation. HBaseCompat masks version-specific HBase API differences. When this option is unset, JanusGraph calls HBase's VersionInfo.getVersion() and loads the matching compat class at runtime. Setting this option forces JanusGraph to instead reflectively load and instantiate the specified class. String (no default value) MASKABLE storage.hbase.compression-algorithm An HBase Compression.Algorithm enum string which will be applied to newly created column families. The compression algorithm must be installed and available on the HBase cluster. JanusGraph cannot install and configure new compression algorithms on the HBase cluster by itself. String GZ MASKABLE storage.hbase.region-count The number of initial regions set when creating JanusGraph's HBase table Integer (no default value) MASKABLE storage.hbase.regions-per-server The number of regions per regionserver to set when creating JanusGraph's HBase table Integer (no default value) MASKABLE storage.hbase.short-cf-names Whether to shorten the names of JanusGraph's column families to one-character mnemonics to conserve storage space Boolean true FIXED storage.hbase.skip-schema-check Assume that JanusGraph's HBase table and column families already exist. When this is true, JanusGraph will not check for the existence of its table/CFs, nor will it attempt to create them under any circumstances. This is useful when running JanusGraph without HBase admin privileges. Boolean false MASKABLE storage.hbase.snapshot-name The name of an exising HBase snapshot to be used by HBaseSnapshotInputFormat String janusgraph-snapshot LOCAL storage.hbase.snapshot-restore-dir The tempoary directory to be used by HBaseSnapshotInputFormat to restore a snapshot. This directory should be on the same File System as the HBase root dir. String /tmp LOCAL storage.hbase.table The name of the table JanusGraph will use. When storage.hbase.skip-schema-check is false, JanusGraph will automatically create this table if it does not already exist. If this configuration option is not provided but graph.graphname is, the table will be set to that value. String janusgraph LOCAL","title":"storage.hbase"},{"location":"basics/janusgraph-cfg/#storagelock","text":"Options for locking on eventually-consistent stores Name Description Datatype Default Value Mutability storage.lock.backend Locker type to use String consistentkey GLOBAL_OFFLINE storage.lock.clean-expired Whether to delete expired locks from the storage backend Boolean false MASKABLE storage.lock.expiry-time Number of milliseconds after which a lock is considered to have expired. Lock applications that were not released are considered expired after this time and released. This value should be larger than the maximum time a transaction can take in order to guarantee that no correctly held applications are expired pre-maturely and as small as possible to avoid dead lock. Duration 300000 ms GLOBAL_OFFLINE storage.lock.local-mediator-group This option determines the LocalLockMediator instance used for early detection of lock contention between concurrent JanusGraph graph instances within the same process which are connected to the same storage backend. JanusGraph instances that have the same value for this variable will attempt to discover lock contention among themselves in memory before proceeding with the general-case distributed locking code. JanusGraph generates an appropriate default value for this option at startup. Overridding the default is generally only useful in testing. String (no default value) LOCAL storage.lock.retries Number of times the system attempts to acquire a lock before giving up and throwing an exception Integer 3 MASKABLE storage.lock.wait-time Number of milliseconds the system waits for a lock application to be acknowledged by the storage backend. Also, the time waited at the end of all lock applications before verifying that the applications were successful. This value should be a small multiple of the average consistent write time. Duration 100 ms GLOBAL_OFFLINE","title":"storage.lock"},{"location":"basics/janusgraph-cfg/#storagemeta","text":"Meta data to include in storage backend retrievals Name Description Datatype Default Value Mutability storage.meta.[X].timestamps Whether to include timestamps in retrieved entries for storage backends that automatically annotated entries with timestamps Boolean false GLOBAL storage.meta.[X].ttl Whether to include ttl in retrieved entries for storage backends that support storage and retrieval of cell level TTL Boolean false GLOBAL storage.meta.[X].visibility Whether to include visibility in retrieved entries for storage backends that support cell level visibility Boolean true GLOBAL","title":"storage.meta *"},{"location":"basics/janusgraph-cfg/#tx","text":"Configuration options for transaction handling Name Description Datatype Default Value Mutability tx.log-tx Whether transaction mutations should be logged to JanusGraph's write-ahead transaction log which can be used for recovery of partially failed transactions Boolean false GLOBAL tx.max-commit-time Maximum time (in ms) that a transaction might take to commit against all backends. This is used by the distributed write-ahead log processing to determine when a transaction can be considered failed (i.e. after this time has elapsed).Must be longer than the maximum allowed write time. Duration 10000 ms GLOBAL","title":"tx"},{"location":"basics/janusgraph-cfg/#txrecovery","text":"Configuration options for transaction recovery processes Name Description Datatype Default Value Mutability tx.recovery.verbose Whether the transaction recovery system should print recovered transactions and other activity to standard output Boolean false MASKABLE","title":"tx.recovery"},{"location":"basics/multi-node/","text":"Things to Consider in a Multi-Node JanusGraph Cluster JanusGraph is a distributed graph database, which means it can be setup in a multi-node cluster. However, when working in such an environment, there are important things to consider. Furthermore, if configured properly, JanusGraph handles some of these special considerations for the user. Dynamic Graphs JanusGraph supports dynamically creating graphs . This is deviation from the way in which standard Gremlin Server implementations allow one to access a graph. Traditionally, users create bindings to graphs at server-start, by configuring the gremlin-server.yaml file accordingly. For example, if the graphs section of your yaml file looks like this: graphs { graph1 : conf/graph1.properties, graph2 : conf/graph2.properties } then you will access your graphs on the Gremlin Server using the fact that the String graph1 will be bound to the graph opened on the server as per its supplied properties file, and the same holds true for graph2 . However, if we use the ConfiguredGraphFactory to dynamically create graphs, then those graphs are managed by the JanusGraphManager and the graph configurations are managed by the ConfigurationManagementGraph . This is especially useful because it 1. allows you to define graph configurations post-server-start and 2. allows the graph configurations to be managed in a persisted and distributed nature across your JanusGraph cluster. To properly use the ConfiguredGraphFactory , you must configure every Gremlin Server in your cluster to use the JanusGraphManager and the ConfigurationManagementGraph . This procedure is explained in detail here . Graph Reference Consistency If you configure all your JanusGraph servers to use the ConfiguredGraphFactory , JanusGraph will ensure all graph representations are-up-to-date across all JanusGraph nodes in your cluster. For example, if you update or delete the configuration to a graph on one JanusGraph node, then we must evict that graph from the cache on every JanusGraph node in the cluster . Otherwise, we may have inconsistent graph representations across your cluster. JanusGraph automatically handles this eviction using a messaging log queue through the backend system that the graph in question is configured to use. If one of your servers is configured incorrectly, then it may not be able to successfully remove the graph from the cache. Important Any updates to your TemplateConfiguration will not result in the updating of graphs/graph configurations previously created using said template configuration. If you want to update the individual graph configurations, you must do so using the available update APIs . These update APIs will then result in the graphe cache eviction across all JanusGraph nodes in your cluster. Dynamic Graph and Traversal Bindings JanusGraph has the ability to bind dynamically created graphs and their traversal references to <graph.graphname> and <graph.graphname>_traversal , respectively, across all JanusGraph nodes in your cluster, with a maximum of a 20s lag for the binding to take effect on any node in the cluster. Read more about this here . JanusGraph accomplishes this by having each node in your cluster poll the ConfigurationManagementGraph for all graphs for which you have created configurations. The JanusGraphManager will then open said graph with its persisted configuration, store it in its graph cache, and bind the <graph.graphname> to the graph reference on the GremlinExecutor as well as bind <graph.graphname>_traversal to the graph\u2019s traversal reference on the GremlinExecutor . This allows you to access a dynamically created graph and its traversal reference by their string bindings, on every node in your JanusGraph cluster. This is particularly important to be able to work with Gremlin Server clients and use TinkerPops\u2019s withRemote functionality . Set Up To set up your cluster to bind dynamically created graphs and their traversal references, you must: Configure each node to use the ConfiguredGraphFactory . Configure each node to use a JanusGraphChannelizer , which injects lower-level Gremlin Server components, like the GremlinExecutor, into the JanusGraph project, giving us greater control of the Gremlin Server. To configure each node to use a JanusGraphChannelizer , we must update the gremlin-server.yaml to do so: 1 channelizer : org . janusgraph . channelizers . JanusGraphWebSocketChannelizer There are a few channelizers you can choose from: org.janusgraph.channelizers.JanusGraphWebSocketChannelizer org.janusgraph.channelizers.JanusGraphHttpChannelizer org.janusgraph.channelizers.JanusGraphNioChannelizer org.janusgraph.channelizers.JanusGraphWsAndHttpChannelizer All of the channelizers share the exact same functionality as their TinkerPop counterparts. Using TinkerPop\u2019s withRemote Functionality Since traversal references are bound on the JanusGraph servers, we can make use of TinkerPop\u2019s withRemote functionality . This will allow one to run gremlin queries locally, against a remote graph reference. Traditionally, one runs queries against remote Gremlin Servers by sending String script representations, which are processed on the remote server and the response serialized and sent back. However, TinkerPop also allows for the use of remoteGraph , which could be useful if you are building a TinkerPop compliant graph infrastructure that is easily transferable to multiple implementations. To use this functionality in JanusGraph, we must first ensure we have created a graph on the remote JanusGraph cluster: ConfiguredGraphFactory.create(\"graph1\"); Next, we must wait 20 seconds to ensure the traversal reference is bound on every JanusGraph node in the remote cluster. Finally, we can locally make use of the withRemote method to access a local reference to a remote graph: gremlin > cluster = Cluster . open ( 'conf/remote-objects.yaml' ) ==> localhost / 127.0 . 0.1 : 8182 gremlin > graph = EmptyGraph . instance () ==> emptygraph [ empty ] gremlin > g = graph . traversal (). withRemote ( DriverRemoteConnection . using ( cluster , \"graph1_traversal\" )) ==> graphtraversalsource [ emptygraph [ empty ], standard ] For completion, the above conf/remote-objects.yaml should tell the Cluster API how to access the remote JanusGraph servers; for example, it may look like: hosts : [ remoteaddress1.com , remoteaddress2.com ] port : 8182 username : admin password : password connectionPool : { enableSsl : true } serializer : { className : org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 , config : { ioRegistries : [ org.janusgraph.graphdb.tinkerpop.JanusGraphIoRegistry ] }}","title":"Things to Consider in a Multi-Node JanusGraph Cluster"},{"location":"basics/multi-node/#things-to-consider-in-a-multi-node-janusgraph-cluster","text":"JanusGraph is a distributed graph database, which means it can be setup in a multi-node cluster. However, when working in such an environment, there are important things to consider. Furthermore, if configured properly, JanusGraph handles some of these special considerations for the user.","title":"Things to Consider in a Multi-Node JanusGraph Cluster"},{"location":"basics/multi-node/#dynamic-graphs","text":"JanusGraph supports dynamically creating graphs . This is deviation from the way in which standard Gremlin Server implementations allow one to access a graph. Traditionally, users create bindings to graphs at server-start, by configuring the gremlin-server.yaml file accordingly. For example, if the graphs section of your yaml file looks like this: graphs { graph1 : conf/graph1.properties, graph2 : conf/graph2.properties } then you will access your graphs on the Gremlin Server using the fact that the String graph1 will be bound to the graph opened on the server as per its supplied properties file, and the same holds true for graph2 . However, if we use the ConfiguredGraphFactory to dynamically create graphs, then those graphs are managed by the JanusGraphManager and the graph configurations are managed by the ConfigurationManagementGraph . This is especially useful because it 1. allows you to define graph configurations post-server-start and 2. allows the graph configurations to be managed in a persisted and distributed nature across your JanusGraph cluster. To properly use the ConfiguredGraphFactory , you must configure every Gremlin Server in your cluster to use the JanusGraphManager and the ConfigurationManagementGraph . This procedure is explained in detail here .","title":"Dynamic Graphs"},{"location":"basics/multi-node/#graph-reference-consistency","text":"If you configure all your JanusGraph servers to use the ConfiguredGraphFactory , JanusGraph will ensure all graph representations are-up-to-date across all JanusGraph nodes in your cluster. For example, if you update or delete the configuration to a graph on one JanusGraph node, then we must evict that graph from the cache on every JanusGraph node in the cluster . Otherwise, we may have inconsistent graph representations across your cluster. JanusGraph automatically handles this eviction using a messaging log queue through the backend system that the graph in question is configured to use. If one of your servers is configured incorrectly, then it may not be able to successfully remove the graph from the cache. Important Any updates to your TemplateConfiguration will not result in the updating of graphs/graph configurations previously created using said template configuration. If you want to update the individual graph configurations, you must do so using the available update APIs . These update APIs will then result in the graphe cache eviction across all JanusGraph nodes in your cluster.","title":"Graph Reference Consistency"},{"location":"basics/multi-node/#dynamic-graph-and-traversal-bindings","text":"JanusGraph has the ability to bind dynamically created graphs and their traversal references to <graph.graphname> and <graph.graphname>_traversal , respectively, across all JanusGraph nodes in your cluster, with a maximum of a 20s lag for the binding to take effect on any node in the cluster. Read more about this here . JanusGraph accomplishes this by having each node in your cluster poll the ConfigurationManagementGraph for all graphs for which you have created configurations. The JanusGraphManager will then open said graph with its persisted configuration, store it in its graph cache, and bind the <graph.graphname> to the graph reference on the GremlinExecutor as well as bind <graph.graphname>_traversal to the graph\u2019s traversal reference on the GremlinExecutor . This allows you to access a dynamically created graph and its traversal reference by their string bindings, on every node in your JanusGraph cluster. This is particularly important to be able to work with Gremlin Server clients and use TinkerPops\u2019s withRemote functionality .","title":"Dynamic Graph and Traversal Bindings"},{"location":"basics/multi-node/#set-up","text":"To set up your cluster to bind dynamically created graphs and their traversal references, you must: Configure each node to use the ConfiguredGraphFactory . Configure each node to use a JanusGraphChannelizer , which injects lower-level Gremlin Server components, like the GremlinExecutor, into the JanusGraph project, giving us greater control of the Gremlin Server. To configure each node to use a JanusGraphChannelizer , we must update the gremlin-server.yaml to do so: 1 channelizer : org . janusgraph . channelizers . JanusGraphWebSocketChannelizer There are a few channelizers you can choose from: org.janusgraph.channelizers.JanusGraphWebSocketChannelizer org.janusgraph.channelizers.JanusGraphHttpChannelizer org.janusgraph.channelizers.JanusGraphNioChannelizer org.janusgraph.channelizers.JanusGraphWsAndHttpChannelizer All of the channelizers share the exact same functionality as their TinkerPop counterparts.","title":"Set Up"},{"location":"basics/multi-node/#using-tinkerpops-withremote-functionality","text":"Since traversal references are bound on the JanusGraph servers, we can make use of TinkerPop\u2019s withRemote functionality . This will allow one to run gremlin queries locally, against a remote graph reference. Traditionally, one runs queries against remote Gremlin Servers by sending String script representations, which are processed on the remote server and the response serialized and sent back. However, TinkerPop also allows for the use of remoteGraph , which could be useful if you are building a TinkerPop compliant graph infrastructure that is easily transferable to multiple implementations. To use this functionality in JanusGraph, we must first ensure we have created a graph on the remote JanusGraph cluster: ConfiguredGraphFactory.create(\"graph1\"); Next, we must wait 20 seconds to ensure the traversal reference is bound on every JanusGraph node in the remote cluster. Finally, we can locally make use of the withRemote method to access a local reference to a remote graph: gremlin > cluster = Cluster . open ( 'conf/remote-objects.yaml' ) ==> localhost / 127.0 . 0.1 : 8182 gremlin > graph = EmptyGraph . instance () ==> emptygraph [ empty ] gremlin > g = graph . traversal (). withRemote ( DriverRemoteConnection . using ( cluster , \"graph1_traversal\" )) ==> graphtraversalsource [ emptygraph [ empty ], standard ] For completion, the above conf/remote-objects.yaml should tell the Cluster API how to access the remote JanusGraph servers; for example, it may look like: hosts : [ remoteaddress1.com , remoteaddress2.com ] port : 8182 username : admin password : password connectionPool : { enableSsl : true } serializer : { className : org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 , config : { ioRegistries : [ org.janusgraph.graphdb.tinkerpop.JanusGraphIoRegistry ] }}","title":"Using TinkerPop\u2019s withRemote Functionality"},{"location":"basics/schema/","text":"Schema and Data Modeling Each JanusGraph graph has a schema comprised of the edge labels, property keys, and vertex labels used therein. A JanusGraph schema can either be explicitly or implicitly defined. Users are encouraged to explicitly define the graph schema during application development. An explicitly defined schema is an important component of a robust graph application and greatly improves collaborative software development. Note, that a JanusGraph schema can be evolved over time without any interruption of normal database operations. Extending the schema does not slow down query answering and does not require database downtime. The schema type - i.e. edge label, property key, or vertex label - is assigned to elements in the graph - i.e. edge, properties or vertices respectively - when they are first created. The assigned schema type cannot be changed for a particular element. This ensures a stable type system that is easy to reason about. Beyond the schema definition options explained in this section, schema types provide performance tuning options that are discussed in Advanced Schema . Displaying Schema Information There are methods to view specific elements of the graph schema within the management API. These methods are mgmt.printIndexes() , mgmt.printPropertyKeys() , mgmt.printVertexLabels() , and mgmt.printEdgeLabels() . There is also a method that displays all the combined output named printSchema() . mgmt = graph . openManagement () mgmt . printSchema () Defining Edge Labels Each edge connecting two vertices has a label which defines the semantics of the relationship. For instance, an edge labeled friend between vertices A and B encodes a friendship between the two individuals. To define an edge label, call makeEdgeLabel(String) on an open graph or management transaction and provide the name of the edge label as the argument. Edge label names must be unique in the graph. This method returns a builder for edge labels that allows to define its multiplicity. The multiplicity of an edge label defines a multiplicity constraint on all edges of this label, that is, a maximum number of edges between pairs of vertices. JanusGraph recognizes the following multiplicity settings. Edge Label Multiplicity MULTI : Allows multiple edges of the same label between any pair of vertices. In other words, the graph is a multi graph with respect to such edge label. There is no constraint on edge multiplicity. SIMPLE : Allows at most one edge of such label between any pair of vertices. In other words, the graph is a simple graph with respect to the label. Ensures that edges are unique for a given label and pairs of vertices. MANY2ONE : Allows at most one outgoing edge of such label on any vertex in the graph but places no constraint on incoming edges. The edge label mother is an example with MANY2ONE multiplicity since each person has at most one mother but mothers can have multiple children. ONE2MANY : Allows at most one incoming edge of such label on any vertex in the graph but places no constraint on outgoing edges. The edge label winnerOf is an example with ONE2MANY multiplicity since each contest is won by at most one person but a person can win multiple contests. ONE2ONE : Allows at most one incoming and one outgoing edge of such label on any vertex in the graph. The edge label marriedTo is an example with ONE2ONE multiplicity since a person is married to exactly one other person. The default multiplicity is MULTI. The definition of an edge label is completed by calling the make() method on the builder which returns the defined edge label as shown in the following example. mgmt = graph . openManagement () follow = mgmt . makeEdgeLabel ( 'follow' ). multiplicity ( MULTI ). make () mother = mgmt . makeEdgeLabel ( 'mother' ). multiplicity ( MANY2ONE ). make () mgmt . commit () Defining Property Keys Properties on vertices and edges are key-value pairs. For instance, the property name='Daniel' has the key name and the value 'Daniel' . Property keys are part of the JanusGraph schema and can constrain the allowed data types and cardinality of values. To define a property key, call makePropertyKey(String) on an open graph or management transaction and provide the name of the property key as the argument. Property key names must be unique in the graph, and it is recommended to avoid spaces or special characters in property names. This method returns a builder for the property keys. Note During property key creation, consider creating also graph indices for better performance, see Index Performance . Property Key Data Type Use dataType(Class) to define the data type of a property key. JanusGraph will enforce that all values associated with the key have the configured data type and thereby ensures that data added to the graph is valid. For instance, one can define that the name key has a String data type. Define the data type as Object.class in order to allow any (serializable) value to be associated with a key. However, it is encouraged to use concrete data types whenever possible. Configured data types must be concrete classes and not interfaces or abstract classes. JanusGraph enforces class equality, so adding a sub-class of a configured data type is not allowed. JanusGraph natively supports the following data types. Native JanusGraph Data Types Name Description String Character sequence Character Individual character Boolean true or false Byte byte value Short short value Integer integer value Long long value Float 4 byte floating point number Double 8 byte floating point number Date Specific instant in time ( java.util.Date ) Geoshape Geographic shape like point, circle or box UUID Universally unique identifier ( java.util.UUID ) Property Key Cardinality Use cardinality(Cardinality) to define the allowed cardinality of the values associated with the key on any given vertex. SINGLE : Allows at most one value per element for such key. In other words, the key\u2192value mapping is unique for all elements in the graph. The property key birthDate is an example with SINGLE cardinality since each person has exactly one birth date. LIST : Allows an arbitrary number of values per element for such key. In other words, the key is associated with a list of values allowing duplicate values. Assuming we model sensors as vertices in a graph, the property key sensorReading is an example with LIST cardinality to allow lots of (potentially duplicate) sensor readings to be recorded. SET : Allows multiple values but no duplicate values per element for such key. In other words, the key is associated with a set of values. The property key name has SET cardinality if we want to capture all names of an individual (including nick name, maiden name, etc). The default cardinality setting is SINGLE. Note, that property keys used on edges and properties have cardinality SINGLE. Attaching multiple values for a single key on an edge or property is not supported. mgmt = graph . openManagement () birthDate = mgmt . makePropertyKey ( ' birthDate ' ). dataType ( Long . class ). cardinality ( Cardinality . SINGLE ). make () name = mgmt . makePropertyKey ( ' name ' ). dataType ( String . class ). cardinality ( Cardinality . SET ). make () sensorReading = mgmt . makePropertyKey ( ' sensorReading ' ). dataType ( Double . class ). cardinality ( Cardinality . LIST ). make () mgmt . commit () Relation Types Edge labels and property keys are jointly referred to as relation types . Names of relation types must be unique in the graph which means that property keys and edge labels cannot have the same name. There are methods in the JanusGraph API to query for the existence or retrieve relation types which encompasses both property keys and edge labels. mgmt = graph . openManagement () if ( mgmt . containsRelationType ( ' name ' )) name = mgmt . getPropertyKey ( ' name ' ) mgmt . getRelationTypes ( EdgeLabel . class ) mgmt . commit () Defining Vertex Labels Like edges, vertices have labels. Unlike edge labels, vertex labels are optional. Vertex labels are useful to distinguish different types of vertices, e.g. user vertices and product vertices. Although labels are optional at the conceptual and data model level, JanusGraph assigns all vertices a label as an internal implementation detail. Vertices created by the addVertex methods use JanusGraph\u2019s default label. To create a label, call makeVertexLabel(String).make() on an open graph or management transaction and provide the name of the vertex label as the argument. Vertex label names must be unique in the graph. mgmt = graph . openManagement () person = mgmt . makeVertexLabel ( ' person ' ). make () mgmt . commit () // Create a labeled vertex person = graph . addVertex ( label , ' person ' ) // Create an unlabeled vertex v = graph . addVertex () graph . tx (). commit () Automatic Schema Maker If an edge label, property key, or vertex label has not been defined explicitly, it will be defined implicitly when it is first used during the addition of an edge, vertex or the setting of a property. The DefaultSchemaMaker configured for the JanusGraph graph defines such types. By default, implicitly created edge labels have multiplicity MULTI and implicitly created property keys have cardinality SINGLE and data type Object.class . Users can control automatic schema element creation by implementing and registering their own DefaultSchemaMaker . When defining a cardinality for a vertex property which differs from SINGLE, the cardinality should be used for all values of the vertex property in the first query (i.e. the query which defines a new vertex property key). It is strongly encouraged to explicitly define all schema elements and to disable automatic schema creation by setting schema.default=none in the JanusGraph graph configuration. Changing Schema Elements The definition of an edge label, property key, or vertex label cannot be changed once its committed into the graph. However, the names of schema elements can be changed via JanusGraphManagement.changeName(JanusGraphSchemaElement, String) as shown in the following example where the property key place is renamed to location . mgmt = graph . openManagement () place = mgmt . getPropertyKey ( ' place ' ) mgmt . changeName ( place , ' location ' ) mgmt . commit () Note, that schema name changes may not be immediately visible in currently running transactions and other JanusGraph graph instances in the cluster. While schema name changes are announced to all JanusGraph instances through the storage backend, it may take a while for the schema changes to take effect and it may require a instance restart in the event of certain failure conditions - like network partitions - if they coincide with the rename. Hence, the user must ensure that either of the following holds: The renamed label or key is not currently in active use (i.e. written or read) and will not be in use until all JanusGraph instances are aware of the name change. Running transactions actively accommodate the brief intermediate period where either the old or new name is valid based on the specific JanusGraph instance and status of the name-change announcement. For instance, that could mean transactions query for both names simultaneously. Should the need arise to re-define an existing schema type, it is recommended to change the name of this type to a name that is not currently (and will never be) in use. After that, a new label or key can be defined with the original name, thereby effectively replacing the old one. However, note that this would not affect vertices, edges, or properties previously written with the existing type. Redefining existing graph elements is not supported online and must be accomplished through a batch graph transformation. Schema Constraints The definition of the schema allows users to configure explicit property and connection constraints. Properties can be bound to specific vertex label and/or edge labels. Moreover, connection constraints allow users to explicitly define which two vertex labels can be connected by an edge label. These constraints can be used to ensure that a graph matches a given domain model. For example for the graph of the gods, a god can be a brother of another god , but not of a monster and a god can have a property age , but location can not have a property age . These constraints are disabled by default. Enable these schema constraints by setting schema.constraints=true . This setting depends on the setting schema.default . If config schema.default is set to none , then an IllegalArgumentException is thrown for schema constraint violations. If schema.default is not set none , schema constraints are automatically created, but no exception is thrown. Activating schema constraints has no impact on the existing data, because these schema constraints are only applied during the insertion process. So reading of data is not affected at all by those constraints. Multiple properties can be bound to a vertex using JanusGraphManagement.addProperties(VertexLabel, PropertyKey...) , for example: mgmt = graph . openManagement () person = mgmt . makeVertexLabel ( ' person ' ). make () name = mgmt . makePropertyKey ( ' name ' ). dataType ( String . class ). cardinality ( Cardinality . SET ). make () birthDate = mgmt . makePropertyKey ( ' birthDate ' ). dataType ( Long . class ). cardinality ( Cardinality . SINGLE ). make () mgmt . addProperties ( person , name , birthDate ) mgmt . commit () Multiple properties can be bound to an edge using JanusGraphManagement.addProperties(EdgeLabel, PropertyKey...) , for example: mgmt = graph . openManagement () follow = mgmt . makeEdgeLabel ( ' follow ' ). multiplicity ( MULTI ). make () name = mgmt . makePropertyKey ( ' name ' ). dataType ( String . class ). cardinality ( Cardinality . SET ). make () mgmt . addProperties ( follow , name ) mgmt . commit () Connections can be defined using JanusGraphManagement.addConnection(EdgeLabel, VertexLabel out, VertexLabel in) between an outgoing, an incoming and an edge, for example: mgmt = graph . openManagement () person = mgmt . makeVertexLabel ( ' person ' ). make () company = mgmt . makeVertexLabel ( ' company ' ). make () works = mgmt . makeEdgeLabel ( ' works ' ). multiplicity ( MULTI ). make () mgmt . addConnection ( works , person , company ) mgmt . commit ()","title":"Schema and Data Modeling"},{"location":"basics/schema/#schema-and-data-modeling","text":"Each JanusGraph graph has a schema comprised of the edge labels, property keys, and vertex labels used therein. A JanusGraph schema can either be explicitly or implicitly defined. Users are encouraged to explicitly define the graph schema during application development. An explicitly defined schema is an important component of a robust graph application and greatly improves collaborative software development. Note, that a JanusGraph schema can be evolved over time without any interruption of normal database operations. Extending the schema does not slow down query answering and does not require database downtime. The schema type - i.e. edge label, property key, or vertex label - is assigned to elements in the graph - i.e. edge, properties or vertices respectively - when they are first created. The assigned schema type cannot be changed for a particular element. This ensures a stable type system that is easy to reason about. Beyond the schema definition options explained in this section, schema types provide performance tuning options that are discussed in Advanced Schema .","title":"Schema and Data Modeling"},{"location":"basics/schema/#displaying-schema-information","text":"There are methods to view specific elements of the graph schema within the management API. These methods are mgmt.printIndexes() , mgmt.printPropertyKeys() , mgmt.printVertexLabels() , and mgmt.printEdgeLabels() . There is also a method that displays all the combined output named printSchema() . mgmt = graph . openManagement () mgmt . printSchema ()","title":"Displaying Schema Information"},{"location":"basics/schema/#defining-edge-labels","text":"Each edge connecting two vertices has a label which defines the semantics of the relationship. For instance, an edge labeled friend between vertices A and B encodes a friendship between the two individuals. To define an edge label, call makeEdgeLabel(String) on an open graph or management transaction and provide the name of the edge label as the argument. Edge label names must be unique in the graph. This method returns a builder for edge labels that allows to define its multiplicity. The multiplicity of an edge label defines a multiplicity constraint on all edges of this label, that is, a maximum number of edges between pairs of vertices. JanusGraph recognizes the following multiplicity settings.","title":"Defining Edge Labels"},{"location":"basics/schema/#edge-label-multiplicity","text":"MULTI : Allows multiple edges of the same label between any pair of vertices. In other words, the graph is a multi graph with respect to such edge label. There is no constraint on edge multiplicity. SIMPLE : Allows at most one edge of such label between any pair of vertices. In other words, the graph is a simple graph with respect to the label. Ensures that edges are unique for a given label and pairs of vertices. MANY2ONE : Allows at most one outgoing edge of such label on any vertex in the graph but places no constraint on incoming edges. The edge label mother is an example with MANY2ONE multiplicity since each person has at most one mother but mothers can have multiple children. ONE2MANY : Allows at most one incoming edge of such label on any vertex in the graph but places no constraint on outgoing edges. The edge label winnerOf is an example with ONE2MANY multiplicity since each contest is won by at most one person but a person can win multiple contests. ONE2ONE : Allows at most one incoming and one outgoing edge of such label on any vertex in the graph. The edge label marriedTo is an example with ONE2ONE multiplicity since a person is married to exactly one other person. The default multiplicity is MULTI. The definition of an edge label is completed by calling the make() method on the builder which returns the defined edge label as shown in the following example. mgmt = graph . openManagement () follow = mgmt . makeEdgeLabel ( 'follow' ). multiplicity ( MULTI ). make () mother = mgmt . makeEdgeLabel ( 'mother' ). multiplicity ( MANY2ONE ). make () mgmt . commit ()","title":"Edge Label Multiplicity"},{"location":"basics/schema/#defining-property-keys","text":"Properties on vertices and edges are key-value pairs. For instance, the property name='Daniel' has the key name and the value 'Daniel' . Property keys are part of the JanusGraph schema and can constrain the allowed data types and cardinality of values. To define a property key, call makePropertyKey(String) on an open graph or management transaction and provide the name of the property key as the argument. Property key names must be unique in the graph, and it is recommended to avoid spaces or special characters in property names. This method returns a builder for the property keys. Note During property key creation, consider creating also graph indices for better performance, see Index Performance .","title":"Defining Property Keys"},{"location":"basics/schema/#property-key-data-type","text":"Use dataType(Class) to define the data type of a property key. JanusGraph will enforce that all values associated with the key have the configured data type and thereby ensures that data added to the graph is valid. For instance, one can define that the name key has a String data type. Define the data type as Object.class in order to allow any (serializable) value to be associated with a key. However, it is encouraged to use concrete data types whenever possible. Configured data types must be concrete classes and not interfaces or abstract classes. JanusGraph enforces class equality, so adding a sub-class of a configured data type is not allowed. JanusGraph natively supports the following data types. Native JanusGraph Data Types Name Description String Character sequence Character Individual character Boolean true or false Byte byte value Short short value Integer integer value Long long value Float 4 byte floating point number Double 8 byte floating point number Date Specific instant in time ( java.util.Date ) Geoshape Geographic shape like point, circle or box UUID Universally unique identifier ( java.util.UUID )","title":"Property Key Data Type"},{"location":"basics/schema/#property-key-cardinality","text":"Use cardinality(Cardinality) to define the allowed cardinality of the values associated with the key on any given vertex. SINGLE : Allows at most one value per element for such key. In other words, the key\u2192value mapping is unique for all elements in the graph. The property key birthDate is an example with SINGLE cardinality since each person has exactly one birth date. LIST : Allows an arbitrary number of values per element for such key. In other words, the key is associated with a list of values allowing duplicate values. Assuming we model sensors as vertices in a graph, the property key sensorReading is an example with LIST cardinality to allow lots of (potentially duplicate) sensor readings to be recorded. SET : Allows multiple values but no duplicate values per element for such key. In other words, the key is associated with a set of values. The property key name has SET cardinality if we want to capture all names of an individual (including nick name, maiden name, etc). The default cardinality setting is SINGLE. Note, that property keys used on edges and properties have cardinality SINGLE. Attaching multiple values for a single key on an edge or property is not supported. mgmt = graph . openManagement () birthDate = mgmt . makePropertyKey ( ' birthDate ' ). dataType ( Long . class ). cardinality ( Cardinality . SINGLE ). make () name = mgmt . makePropertyKey ( ' name ' ). dataType ( String . class ). cardinality ( Cardinality . SET ). make () sensorReading = mgmt . makePropertyKey ( ' sensorReading ' ). dataType ( Double . class ). cardinality ( Cardinality . LIST ). make () mgmt . commit ()","title":"Property Key Cardinality"},{"location":"basics/schema/#relation-types","text":"Edge labels and property keys are jointly referred to as relation types . Names of relation types must be unique in the graph which means that property keys and edge labels cannot have the same name. There are methods in the JanusGraph API to query for the existence or retrieve relation types which encompasses both property keys and edge labels. mgmt = graph . openManagement () if ( mgmt . containsRelationType ( ' name ' )) name = mgmt . getPropertyKey ( ' name ' ) mgmt . getRelationTypes ( EdgeLabel . class ) mgmt . commit ()","title":"Relation Types"},{"location":"basics/schema/#defining-vertex-labels","text":"Like edges, vertices have labels. Unlike edge labels, vertex labels are optional. Vertex labels are useful to distinguish different types of vertices, e.g. user vertices and product vertices. Although labels are optional at the conceptual and data model level, JanusGraph assigns all vertices a label as an internal implementation detail. Vertices created by the addVertex methods use JanusGraph\u2019s default label. To create a label, call makeVertexLabel(String).make() on an open graph or management transaction and provide the name of the vertex label as the argument. Vertex label names must be unique in the graph. mgmt = graph . openManagement () person = mgmt . makeVertexLabel ( ' person ' ). make () mgmt . commit () // Create a labeled vertex person = graph . addVertex ( label , ' person ' ) // Create an unlabeled vertex v = graph . addVertex () graph . tx (). commit ()","title":"Defining Vertex Labels"},{"location":"basics/schema/#automatic-schema-maker","text":"If an edge label, property key, or vertex label has not been defined explicitly, it will be defined implicitly when it is first used during the addition of an edge, vertex or the setting of a property. The DefaultSchemaMaker configured for the JanusGraph graph defines such types. By default, implicitly created edge labels have multiplicity MULTI and implicitly created property keys have cardinality SINGLE and data type Object.class . Users can control automatic schema element creation by implementing and registering their own DefaultSchemaMaker . When defining a cardinality for a vertex property which differs from SINGLE, the cardinality should be used for all values of the vertex property in the first query (i.e. the query which defines a new vertex property key). It is strongly encouraged to explicitly define all schema elements and to disable automatic schema creation by setting schema.default=none in the JanusGraph graph configuration.","title":"Automatic Schema Maker"},{"location":"basics/schema/#changing-schema-elements","text":"The definition of an edge label, property key, or vertex label cannot be changed once its committed into the graph. However, the names of schema elements can be changed via JanusGraphManagement.changeName(JanusGraphSchemaElement, String) as shown in the following example where the property key place is renamed to location . mgmt = graph . openManagement () place = mgmt . getPropertyKey ( ' place ' ) mgmt . changeName ( place , ' location ' ) mgmt . commit () Note, that schema name changes may not be immediately visible in currently running transactions and other JanusGraph graph instances in the cluster. While schema name changes are announced to all JanusGraph instances through the storage backend, it may take a while for the schema changes to take effect and it may require a instance restart in the event of certain failure conditions - like network partitions - if they coincide with the rename. Hence, the user must ensure that either of the following holds: The renamed label or key is not currently in active use (i.e. written or read) and will not be in use until all JanusGraph instances are aware of the name change. Running transactions actively accommodate the brief intermediate period where either the old or new name is valid based on the specific JanusGraph instance and status of the name-change announcement. For instance, that could mean transactions query for both names simultaneously. Should the need arise to re-define an existing schema type, it is recommended to change the name of this type to a name that is not currently (and will never be) in use. After that, a new label or key can be defined with the original name, thereby effectively replacing the old one. However, note that this would not affect vertices, edges, or properties previously written with the existing type. Redefining existing graph elements is not supported online and must be accomplished through a batch graph transformation.","title":"Changing Schema Elements"},{"location":"basics/schema/#schema-constraints","text":"The definition of the schema allows users to configure explicit property and connection constraints. Properties can be bound to specific vertex label and/or edge labels. Moreover, connection constraints allow users to explicitly define which two vertex labels can be connected by an edge label. These constraints can be used to ensure that a graph matches a given domain model. For example for the graph of the gods, a god can be a brother of another god , but not of a monster and a god can have a property age , but location can not have a property age . These constraints are disabled by default. Enable these schema constraints by setting schema.constraints=true . This setting depends on the setting schema.default . If config schema.default is set to none , then an IllegalArgumentException is thrown for schema constraint violations. If schema.default is not set none , schema constraints are automatically created, but no exception is thrown. Activating schema constraints has no impact on the existing data, because these schema constraints are only applied during the insertion process. So reading of data is not affected at all by those constraints. Multiple properties can be bound to a vertex using JanusGraphManagement.addProperties(VertexLabel, PropertyKey...) , for example: mgmt = graph . openManagement () person = mgmt . makeVertexLabel ( ' person ' ). make () name = mgmt . makePropertyKey ( ' name ' ). dataType ( String . class ). cardinality ( Cardinality . SET ). make () birthDate = mgmt . makePropertyKey ( ' birthDate ' ). dataType ( Long . class ). cardinality ( Cardinality . SINGLE ). make () mgmt . addProperties ( person , name , birthDate ) mgmt . commit () Multiple properties can be bound to an edge using JanusGraphManagement.addProperties(EdgeLabel, PropertyKey...) , for example: mgmt = graph . openManagement () follow = mgmt . makeEdgeLabel ( ' follow ' ). multiplicity ( MULTI ). make () name = mgmt . makePropertyKey ( ' name ' ). dataType ( String . class ). cardinality ( Cardinality . SET ). make () mgmt . addProperties ( follow , name ) mgmt . commit () Connections can be defined using JanusGraphManagement.addConnection(EdgeLabel, VertexLabel out, VertexLabel in) between an outgoing, an incoming and an edge, for example: mgmt = graph . openManagement () person = mgmt . makeVertexLabel ( ' person ' ). make () company = mgmt . makeVertexLabel ( ' company ' ). make () works = mgmt . makeEdgeLabel ( ' works ' ). multiplicity ( MULTI ). make () mgmt . addConnection ( works , person , company ) mgmt . commit ()","title":"Schema Constraints"},{"location":"basics/server/","text":"JanusGraph Server JanusGraph uses the Gremlin Server engine as the server component to process and answer client queries. When packaged in JanusGraph, Gremlin Server is called JanusGraph Server. JanusGraph Server must be started manually in order to use it. JanusGraph Server provides a way to remotely execute Gremlin traversals against one or more JanusGraph instances hosted within it. This section will describe how to use the WebSocket configuration, as well as describe how to configure JanusGraph Server to handle HTTP endpoint interactions. For information about how to connect to a JanusGraph Server from different languages refer to Connecting to JanusGraph . Getting Started Using the Pre-Packaged Distribution The JanusGraph release comes pre-configured to run JanusGraph Server out of the box leveraging a sample Cassandra and Elasticsearch configuration to allow users to get started quickly with JanusGraph Server. This configuration defaults to client applications that can connect to JanusGraph Server via WebSocket with a custom subprotocol. There are a number of clients developed in different languages to help support the subprotocol. The most familiar client to use the WebSocket interface is the Gremlin Console. The quick-start bundle is not intended to be representative of a production installation, but does provide a way to perform development with JanusGraph Server, run tests and see how the components are wired together. To use this default configuration: Download a copy of the current janusgraph-$VERSION.zip file from the Releases page Unzip it and enter the janusgraph-$VERSION directory Run bin/janusgraph.sh start . This step will start Gremlin Server with Cassandra/ES forked into a separate process. Note for security reasons Elasticsearch and therefore janusgraph.sh must be run under a non-root account. $ bin/janusgraph.sh start Forking Cassandra... Running ` nodetool statusthrift ` .. OK ( returned exit status 0 and printed string \"running\" ) . Forking Elasticsearch... Connecting to Elasticsearch ( 127 .0.0.1:9300 ) ... OK ( connected to 127 .0.0.1:9300 ) . Forking Gremlin-Server... Connecting to Gremlin-Server ( 127 .0.0.1:8182 ) ... OK ( connected to 127 .0.0.1:8182 ) . Run gremlin.sh to connect. Connecting to Gremlin Server After running janusgraph.sh , Gremlin Server will be ready to listen for WebSocket connections. The easiest way to test the connection is with Gremlin Console. Start Gremlin Console with bin/gremlin.sh and use the :remote and :> commands to issue Gremlin to Gremlin Server: $ bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- plugin activated: tinkerpop.server plugin activated: tinkerpop.hadoop plugin activated: tinkerpop.utilities plugin activated: janusgraph.imports plugin activated: tinkerpop.tinkergraph gremlin> :remote connect tinkerpop.server conf/remote.yaml == >Connected - localhost/127.0.0.1:8182 gremlin> :> graph.addVertex ( \"name\" , \"stephen\" ) == >v [ 256 ] gremlin> :> g.V () .values ( 'name' ) == >stephen The :remote command tells the console to configure a remote connection to Gremlin Server using the conf/remote.yaml file to connect. That file points to a Gremlin Server instance running on localhost . The :> is the \"submit\" command which sends the Gremlin on that line to the currently active remote. Instead of prefixing every single script with :> , the command :remote console can be executed once to implicitly send all subsequent scripts to the current remote connection. By default remote conenctions are sessionless, meaning that each line sent in the console is interpreted as a single request. Multiple statements can be sent on a single line using a semicolon as the delimiter. gremlin > : remote connect tinkerpop . server conf /remote.yaml ==>Configured localhost/ 127.0 . 0.1 : 8182 gremlin > : remote console ==> All scripts will now be sent to Gremlin Server - [ localhost / 127.0 . 0.1 : 8182 ] - type ':remote console' to return to local mode gremlin > graph ==> standardjanusgraph [ cql: [ 127.0 . 0.1 ]] gremlin > g ==> graphtraversalsource [ standardjanusgraph [ cql: [ 127.0 . 0.1 ]], standard ] gremlin > g . V () gremlin > user = \"Chris\" ==> Chris gremlin > graph . addVertex ( \"name\" , user ) No such property: user for class: Script21 Type ':help' or ':h' for help . Display stack trace ? [ yN ] Alternatively, you can establish a console with a session by specifying session when creating the connection. A console session allows you to reuse variables across several lines of input. gremlin > : remote connect tinkerpop . server conf /remote.yaml session ==>Configured localhost/ 127.0 . 0.1 : 8182 -[ 9 acf239e - a3ed - 4301 - b33f - 55 c911e04052 ] gremlin > : remote console ==> All scripts will now be sent to Gremlin Server - [ localhost / 127.0 . 0.1 : 8182 ]-[ 9 acf239e - a3ed - 4301 - b33f - 55 c911e04052 ] - type ':remote console' to return to local mode gremlin > g . V () gremlin > user = \"Chris\" ==> Chris gremlin > user ==> Chris gremlin > graph . addVertex ( \"name\" , user ) ==> v [ 4344 ] gremlin > g . V (). values ( 'name' ) ==> Chris Cleaning up after the Pre-Packaged Distribution If you want to start fresh and remove the database and logs you can use the clean command with janusgraph.sh . The server should be stopped before running the clean operation. $ cd /Path/to/janusgraph/janusgraph-0.2.0-hadoop2/ $ ./bin/janusgraph.sh stop Killing Gremlin-Server ( pid 91505 ) ... Killing Elasticsearch ( pid 91402 ) ... Killing Cassandra ( pid 91219 ) ... $ ./bin/janusgraph.sh clean Are you sure you want to delete all stored data and logs? [ y/N ] y Deleted data in /Path/to/janusgraph/janusgraph-0.2.0-hadoop2/db Deleted logs in /Path/to/janusgraph/janusgraph-0.2.0-hadoop2/log JanusGraph Server as a WebSocket Endpoint The default configuration described in Getting Started is already a WebSocket configuration. If you want to alter the default configuration to work with your own Cassandra or HBase environment rather than use the quick start environment, follow these steps: To Configure JanusGraph Server For WebSocket Test a local connection to a JanusGraph database first. This step applies whether using the Gremlin Console to test the connection, or whether connecting from a program. Make appropriate changes in a properties file in the ./conf directory for your environment. For example, edit ./conf/janusgraph-hbase.properties and make sure the storage.backend, storage.hostname and storage.hbase.table parameters are specified correctly. For more information on configuring JanusGraph for various storage backends, see Storage Backends . Make sure the properties file contains the following line: gremlin.graph=org.janusgraph.core.JanusGraphFactory Once a local configuration is tested and you have a working properties file, copy the properties file from the ./conf directory to the ./conf/gremlin-server directory. cp conf/janusgraph-hbase.properties conf/gremlin-server/socket-janusgraph-hbase-server.properties Copy ./conf/gremlin-server/gremlin-server.yaml to a new file called socket-gremlin-server.yaml . Do this in case you need to refer to the original version of the file cp conf/gremlin-server/gremlin-server.yaml conf/gremlin-server/socket-gremlin-server.yaml Edit the socket-gremlin-server.yaml file and make the following updates: If you are planning to connect to JanusGraph Server from something other than localhost, update the IP address for host: host: 10.10.10.100 Update the graphs section to point to your new properties file so the JanusGraph Server can find and connect to your JanusGraph instance: graphs : { graph : conf/gremlin-server/socket-janusgraph-hbase-server.properties } Start the JanusGraph Server, specifying the yaml file you just configured: bin/gremlin-server.sh ./conf/gremlin-server/socket-gremlin-server.yaml The JanusGraph Server should now be running in WebSocket mode and can be tested by following the instructions in Connecting to Gremlin Server Important Do not use bin/janusgraph.sh . That starts the default configuration, which starts a separate Cassandra/Elasticsearch environment. JanusGraph Server as a HTTP Endpoint The default configuration described in Getting Started is a WebSocket configuration. If you want to alter the default configuration in order to use JanusGraph Server as an HTTP endpoint for your JanusGraph database, follow these steps: Test a local connection to a JanusGraph database first. This step applies whether using the Gremlin Console to test the connection, or whether connecting from a program. Make appropriate changes in a properties file in the ./conf directory for your environment. For example, edit ./conf/janusgraph-hbase.properties and make sure the storage.backend, storage.hostname and storage.hbase.table parameters are specified correctly. For more information on configuring JanusGraph for various storage backends, see Storage Backends . Make sure the properties file contains the following line: gremlin.graph=org.janusgraph.core.JanusGraphFactory Once a local configuration is tested and you have a working properties file, copy the properties file from the ./conf directory to the ./conf/gremlin-server directory. cp conf/janusgraph-hbase.properties conf/gremlin-server/http-janusgraph-hbase-server.properties Copy ./conf/gremlin-server/gremlin-server.yaml to a new file called http-gremlin-server.yaml . Do this in case you need to refer to the original version of the file cp conf/gremlin-server/gremlin-server.yaml conf/gremlin-server/http-gremlin-server.yaml Edit the http-gremlin-server.yaml file and make the following updates: If you are planning to connect to JanusGraph Server from something other than localhost, update the IP address for host: host: 10.10.10.100 Update the channelizer setting to specify the HttpChannelizer: channelizer : org.apache.tinkerpop.gremlin.server.channel.HttpChannelizer Update the graphs section to point to your new properties file so the JanusGraph Server can find and connect to your JanusGraph instance: graphs : { graph : conf/gremlin-server/http-janusgraph-hbase-server.properties } Start the JanusGraph Server, specifying the yaml file you just configured: bin/gremlin-server.sh ./conf/gremlin-server/http-gremlin-server.yaml The JanusGraph Server should now be running in HTTP mode and available for testing. curl can be used to verify the server is working: curl -XPOST -Hcontent-type:application/json -d * { \"gremlin\" : \"g.V().count()\" } * [ IP for JanusGraph server host ]( http:// ) :8182 JanusGraph Server as Both a WebSocket and HTTP Endpoint As of JanusGraph 0.2.0, you can configure your gremlin-server.yaml to accept both WebSocket and HTTP connections over the same port. This can be achieved by changing the channelizer in any of the previous examples as follows. channelizer : org.apache.tinkerpop.gremlin.server.channel.WsAndHttpChannelizer Advanced JanusGraph Server Configurations Authentication over HTTP Important In the following example, credentialsDb should be different from the graph(s) you are using. It should be configured with the correct backend and a different keyspace, table, or storage directory as appropriate for the configured backend. This graph will be used for storing usernames and passwords. HTTP Basic authentication To enable Basic authentication in JanusGraph Server include the following configuration in your gremlin-server.yaml . authentication : { authenticator : org.janusgraph.graphdb.tinkerpop.gremlin.server.auth.JanusGraphSimpleAuthenticator , authenticationHandler : org.apache.tinkerpop.gremlin.server.handler.HttpBasicAuthenticationHandler , config : { defaultUsername : user , defaultPassword : password , credentialsDb : conf/janusgraph-credentials-server.properties } } Verify that basic authentication is configured correctly. For example curl -v -XPOST http://localhost:8182 -d '{\"gremlin\": \"g.V().count()\"}' should return a 401 if the authentication is configured correctly and curl -v -XPOST http://localhost:8182 -d '{\"gremlin\": \"g.V().count()\"}' -u user:password should return a 200 and the result of 4 if authentication is configured correctly. Authentication over WebSocket Authentication over WebSocket occurs through a Simple Authentication and Security Layer (https://en.wikipedia.org/wiki/Simple_Authentication_and_Security_Layer[SASL]) mechanism. To enable SASL authentication include the following configuration in the gremlin-server.yaml authentication : { authenticator : org.janusgraph.graphdb.tinkerpop.gremlin.server.auth.JanusGraphSimpleAuthenticator , authenticationHandler : org.apache.tinkerpop.gremlin.server.handler.SaslAuthenticationHandler , config : { defaultUsername : user , defaultPassword : password , credentialsDb : conf/janusgraph-credentials-server.properties } } Important In the preceding example, credentialsDb should be different from the graph(s) you are using. It should be configured with the correct backend and a different keyspace, table, or storage directory as appropriate for the configured backend. This graph will be used for storing usernames and passwords. If you are connecting through the gremlin console, your remote yaml file should ammend the username and password properties with the appropriate values. username : user password : password Authentication over HTTP and WebSocket If you are using the combined channelizer for both HTTP and WebSocket you can use the SaslAndHMACAuthenticator to authorize through either WebSocket through SASL, HTTP through basic auth, and HTTP through hash-based messsage authentication code (https://en.wikipedia.org/wiki/Hash-based_message_authentication_code[HMAC]) Auth. HMAC is a token based authentication designed to be used over HTTP. You first acquire a token via the /session endpoint and then use that to authenticate. It is used to amortize the time spent encrypting the password using basic auth. The gremlin-server.yaml should include the following configurations authentication : { authenticator : org.janusgraph.graphdb.tinkerpop.gremlin.server.auth.SaslAndHMACAuthenticator , authenticationHandler : org.janusgraph.graphdb.tinkerpop.gremlin.server.handler.SaslAndHMACAuthenticationHandler , config : { defaultUsername : user , defaultPassword : password , hmacSecret : secret , credentialsDb : conf/janusgraph-credentials-server.properties } } Important In the preceding example, credentialsDb should be different from the graph(s) you are using. It should be configured with the correct backend and a different keyspace, table, or storage directory as appropriate for the configured backend. This graph will be used for storing usernames and passwords. Important Note the hmacSecret here. This should be the same across all running JanusGraph servers if you want to be able to use the same HMAC token on each server. For HMAC authentication over HTTP, this creates a /session endpoint that provides a token that expires after an hour by default. This timeout for the token can be configured through the tokenTimeout configuration option in the authentication.config map. This value is a Long value and in milliseconds. You can obtain the token using curl by issuing a get request to the /session endpoint. For example curl http://localhost:8182/session -XGET -u user:password { \"token\" : \"dXNlcjoxNTA5NTQ2NjI0NDUzOkhrclhYaGhRVG9KTnVSRXJ5U2VpdndhalJRcVBtWEpSMzh5WldqRTM4MW89\" } You can then use that token for authentication by using the \"Authorization: Token\" header. For example curl -v http://localhost:8182/session -XPOST -d '{\"gremlin\": \"g.V().count()\"}' -H \"Authorization: Token dXNlcjoxNTA5NTQ2NjI0NDUzOkhrclhYaGhRVG9KTnVSRXJ5U2VpdndhalJRcVBtWEpSMzh5WldqRTM4MW89\" Using TinkerPop Gremlin Server with JanusGraph Since JanusGraph Server is a TinkerPop Gremlin Server packaged with configuration files for JanusGraph, a version compatible TinkerPop Gremlin Server can be downloaded separately and used with JanusGraph. Get started by downloading the appropriate version of Gremlin Server, which needs to match a version supported by the JanusGraph version in use (3.4.4). Important Any references to file paths in this section refer to paths under a TinkerPop distribution for Gremlin Server and not a JanusGraph distribution with the JanusGraph Server, unless specifically noted. Configuring a standalone Gremlin Server to work with JanusGraph is similar to configuring the packaged JanusGraph Server. You should be familiar with graph configuration . Basically, the Gremlin Server yaml file points to graph-specific configuration files that are used to instantiate JanusGraph instances that it will then host. In order to instantiate these Graph instances, Gremlin Server requires that the appropriate libraries and dependencies for the JanusGraph be available on its classpath. For purposes of demonstration, these instructions will outline how to configure the BerkeleyDB backend for JanusGraph in Gremlin Server. As stated earlier, Gremlin Server needs JanusGraph dependencies on its classpath. Invoke the following command replacing $VERSION with the version of JanusGraph to use: bin/gremlin-server.sh -i org.janusgraph janusgraph-all $VERSION When this process completes, Gremlin Server should now have all the JanusGraph dependencies available to it and will thus be able to instantiate JanusGraph objects. Important The above command uses Groovy Grape and if it is not configured properly download errors may ensue. Please refer to this section of the TinkerPop documentation for more information around setting up ~/.groovy/grapeConfig.xml. Create a file called GREMLIN_SERVER_HOME/conf/janusgraph.properties with the following contents: gremlin.graph=org.janusgraph.core.JanusGraphFactory storage.backend=berkeleyje storage.directory=db/berkeley Configuration of other backends is similar. See Storage Backends . If using Cassandra, then use Cassandra configuration options in the janusgraph.properties file. The only important piece to leave unchanged is the gremlin.graph setting which should always use JanusGraphFactory . This setting tells Gremlin Server how to instantiate a JanusGraph instance. Next create a file called GREMLIN_SERVER_HOME/conf/gremlin-server-janusgraph.yaml that has the following contents: host : localhost port : 8182 graphs : { graph : conf/janusgraph.properties } scriptEngines : { gremlin-groovy : { plugins : { org.janusgraph.graphdb.tinkerpop.plugin.JanusGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.server.jsr223.GremlinServerGremlinPlugin : {}, org.apache.tinkerpop.gremlin.tinkergraph.jsr223.TinkerGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.jsr223.ImportGremlinPlugin : { classImports : [ java.lang.Math ], methodImports : [ java.lang.Math#* ]}, org.apache.tinkerpop.gremlin.jsr223.ScriptFileGremlinPlugin : { files : [ scripts/empty-sample.groovy ]}}}} serializers : - { className : org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 , config : { ioRegistries : [ org.janusgraph.graphdb.tinkerpop.JanusGraphIoRegistry ] }} - { className : org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 , config : { serializeResultToString : true }} - { className : org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV3d0 , config : { ioRegistries : [ org.janusgraph.graphdb.tinkerpop.JanusGraphIoRegistry ] }} metrics : { slf4jReporter : { enabled : true , interval : 180000 }} There are several important parts to this configuration file as they relate to JanusGraph. In the graphs map, there is a key called graph and its value is conf/janusgraph.properties . This tells Gremlin Server to instantiate a Graph instance called \"graph\" and use the conf/janusgraph.properties file to configure it. The \"graph\" key becomes the unique name for the Graph instance in Gremlin Server and it can be referenced as such in the scripts submitted to it. In the plugins list, there is a reference to JanusGraphGremlinPlugin , which tells Gremlin Server to initialize the \"JanusGraph Plugin\". The \"JanusGraph Plugin\" will auto-import JanusGraph specific classes for usage in scripts. Note the scripts key and the reference to scripts/janusgraph.groovy . This Groovy file is an initialization script for Gremlin Server and that particular ScriptEngine. Create scripts/janusgraph.groovy with the following contents: def globals = [:] globals << [ g : graph . traversal ()] The above script creates a Map called globals and assigns to it a key/value pair. The key is g and its value is a TraversalSource generated from graph , which was configured for Gremlin Server in its configuration file. At this point, there are now two global variables available to scripts provided to Gremlin Server - graph and g . At this point, Gremlin Server is configured and can be used to connect to a new or existing JanusGraph database. To start the server: $ bin/gremlin-server.sh conf/gremlin-server-janusgraph.yaml [ INFO ] GremlinServer - \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- [ INFO ] GremlinServer - Configuring Gremlin Server from conf/gremlin-server-janusgraph.yaml [ INFO ] MetricManager - Configured Metrics Slf4jReporter configured with interval = 180000ms and loggerName = org.apache.tinkerpop.gremlin.server.Settings $Slf4jReporterMetrics [ INFO ] GraphDatabaseConfiguration - Set default timestamp provider MICRO [ INFO ] GraphDatabaseConfiguration - Generated unique-instance-id = 7f0000016240-ubuntu1 [ INFO ] Backend - Initiated backend operations thread pool of size 8 [ INFO ] KCVSLog $MessagePuller - Loaded unidentified ReadMarker start time 2015 -10-02T12:28:24.411Z into org.janusgraph.diskstorage.log.kcvs.KCVSLog $MessagePuller @35399441 [ INFO ] GraphManager - Graph [ graph ] was successfully configured via [ conf/janusgraph.properties ] . [ INFO ] ServerGremlinExecutor - Initialized Gremlin thread pool. Threads in pool named with pattern gremlin-* [ INFO ] ScriptEngines - Loaded gremlin-groovy ScriptEngine [ INFO ] GremlinExecutor - Initialized gremlin-groovy ScriptEngine with scripts/janusgraph.groovy [ INFO ] ServerGremlinExecutor - Initialized GremlinExecutor and configured ScriptEngines. [ INFO ] ServerGremlinExecutor - A GraphTraversalSource is now bound to [ g ] with graphtraversalsource [ standardjanusgraph [ berkeleyje:db/berkeley ] , standard ] [ INFO ] AbstractChannelizer - Configured application/vnd.gremlin-v3.0+gryo with org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 [ INFO ] AbstractChannelizer - Configured application/vnd.gremlin-v3.0+gryo-stringd with org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 [ INFO ] GremlinServer $1 - Gremlin Server configured with worker thread pool of 1 , gremlin pool of 8 and boss thread pool of 1 . [ INFO ] GremlinServer $1 - Channel started at port 8182 . The following section explains how to connect to the running server. Connecting to JanusGraph via Gremlin Server Gremlin Server will be ready to listen for WebSocket connections when it is started. The easiest way to test the connection is with Gremlin Console. Follow the instructions here Connecting to Gremlin Server to verify the Gremlin Server is working. Important A difference you should understand is that when working with JanusGraph Server, the Gremlin Console is started from underneath the JanusGraph distribution and when following the test instructions here for a standalone Gremlin Server, the Gremlin Console is started from under the TinkerPop distribution. GryoMapper mapper = GryoMapper . build (). addRegistry ( JanusGraphIoRegistry . INSTANCE ). create (); Cluster cluster = Cluster . build (). serializer ( new GryoMessageSerializerV3d0 ( mapper )). create (); Client client = cluster . connect (); client . submit ( \"g.V()\" ). all (). get (); By adding the JanusGraphIoRegistry to the org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 , the driver will know how to properly deserialize custom data types returned by JanusGraph. Extending JanusGraph Server It is possible to extend Gremlin Server with other means of communication by implementing the interfaces that it provides and leverage this with JanusGraph. See more details in the appropriate TinkerPop documentation.","title":"JanusGraph Server"},{"location":"basics/server/#janusgraph-server","text":"JanusGraph uses the Gremlin Server engine as the server component to process and answer client queries. When packaged in JanusGraph, Gremlin Server is called JanusGraph Server. JanusGraph Server must be started manually in order to use it. JanusGraph Server provides a way to remotely execute Gremlin traversals against one or more JanusGraph instances hosted within it. This section will describe how to use the WebSocket configuration, as well as describe how to configure JanusGraph Server to handle HTTP endpoint interactions. For information about how to connect to a JanusGraph Server from different languages refer to Connecting to JanusGraph .","title":"JanusGraph Server"},{"location":"basics/server/#getting-started","text":"","title":"Getting Started"},{"location":"basics/server/#using-the-pre-packaged-distribution","text":"The JanusGraph release comes pre-configured to run JanusGraph Server out of the box leveraging a sample Cassandra and Elasticsearch configuration to allow users to get started quickly with JanusGraph Server. This configuration defaults to client applications that can connect to JanusGraph Server via WebSocket with a custom subprotocol. There are a number of clients developed in different languages to help support the subprotocol. The most familiar client to use the WebSocket interface is the Gremlin Console. The quick-start bundle is not intended to be representative of a production installation, but does provide a way to perform development with JanusGraph Server, run tests and see how the components are wired together. To use this default configuration: Download a copy of the current janusgraph-$VERSION.zip file from the Releases page Unzip it and enter the janusgraph-$VERSION directory Run bin/janusgraph.sh start . This step will start Gremlin Server with Cassandra/ES forked into a separate process. Note for security reasons Elasticsearch and therefore janusgraph.sh must be run under a non-root account. $ bin/janusgraph.sh start Forking Cassandra... Running ` nodetool statusthrift ` .. OK ( returned exit status 0 and printed string \"running\" ) . Forking Elasticsearch... Connecting to Elasticsearch ( 127 .0.0.1:9300 ) ... OK ( connected to 127 .0.0.1:9300 ) . Forking Gremlin-Server... Connecting to Gremlin-Server ( 127 .0.0.1:8182 ) ... OK ( connected to 127 .0.0.1:8182 ) . Run gremlin.sh to connect.","title":"Using the Pre-Packaged Distribution"},{"location":"basics/server/#connecting-to-gremlin-server","text":"After running janusgraph.sh , Gremlin Server will be ready to listen for WebSocket connections. The easiest way to test the connection is with Gremlin Console. Start Gremlin Console with bin/gremlin.sh and use the :remote and :> commands to issue Gremlin to Gremlin Server: $ bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- plugin activated: tinkerpop.server plugin activated: tinkerpop.hadoop plugin activated: tinkerpop.utilities plugin activated: janusgraph.imports plugin activated: tinkerpop.tinkergraph gremlin> :remote connect tinkerpop.server conf/remote.yaml == >Connected - localhost/127.0.0.1:8182 gremlin> :> graph.addVertex ( \"name\" , \"stephen\" ) == >v [ 256 ] gremlin> :> g.V () .values ( 'name' ) == >stephen The :remote command tells the console to configure a remote connection to Gremlin Server using the conf/remote.yaml file to connect. That file points to a Gremlin Server instance running on localhost . The :> is the \"submit\" command which sends the Gremlin on that line to the currently active remote. Instead of prefixing every single script with :> , the command :remote console can be executed once to implicitly send all subsequent scripts to the current remote connection. By default remote conenctions are sessionless, meaning that each line sent in the console is interpreted as a single request. Multiple statements can be sent on a single line using a semicolon as the delimiter. gremlin > : remote connect tinkerpop . server conf /remote.yaml ==>Configured localhost/ 127.0 . 0.1 : 8182 gremlin > : remote console ==> All scripts will now be sent to Gremlin Server - [ localhost / 127.0 . 0.1 : 8182 ] - type ':remote console' to return to local mode gremlin > graph ==> standardjanusgraph [ cql: [ 127.0 . 0.1 ]] gremlin > g ==> graphtraversalsource [ standardjanusgraph [ cql: [ 127.0 . 0.1 ]], standard ] gremlin > g . V () gremlin > user = \"Chris\" ==> Chris gremlin > graph . addVertex ( \"name\" , user ) No such property: user for class: Script21 Type ':help' or ':h' for help . Display stack trace ? [ yN ] Alternatively, you can establish a console with a session by specifying session when creating the connection. A console session allows you to reuse variables across several lines of input. gremlin > : remote connect tinkerpop . server conf /remote.yaml session ==>Configured localhost/ 127.0 . 0.1 : 8182 -[ 9 acf239e - a3ed - 4301 - b33f - 55 c911e04052 ] gremlin > : remote console ==> All scripts will now be sent to Gremlin Server - [ localhost / 127.0 . 0.1 : 8182 ]-[ 9 acf239e - a3ed - 4301 - b33f - 55 c911e04052 ] - type ':remote console' to return to local mode gremlin > g . V () gremlin > user = \"Chris\" ==> Chris gremlin > user ==> Chris gremlin > graph . addVertex ( \"name\" , user ) ==> v [ 4344 ] gremlin > g . V (). values ( 'name' ) ==> Chris","title":"Connecting to Gremlin Server"},{"location":"basics/server/#cleaning-up-after-the-pre-packaged-distribution","text":"If you want to start fresh and remove the database and logs you can use the clean command with janusgraph.sh . The server should be stopped before running the clean operation. $ cd /Path/to/janusgraph/janusgraph-0.2.0-hadoop2/ $ ./bin/janusgraph.sh stop Killing Gremlin-Server ( pid 91505 ) ... Killing Elasticsearch ( pid 91402 ) ... Killing Cassandra ( pid 91219 ) ... $ ./bin/janusgraph.sh clean Are you sure you want to delete all stored data and logs? [ y/N ] y Deleted data in /Path/to/janusgraph/janusgraph-0.2.0-hadoop2/db Deleted logs in /Path/to/janusgraph/janusgraph-0.2.0-hadoop2/log","title":"Cleaning up after the Pre-Packaged Distribution"},{"location":"basics/server/#janusgraph-server-as-a-websocket-endpoint","text":"The default configuration described in Getting Started is already a WebSocket configuration. If you want to alter the default configuration to work with your own Cassandra or HBase environment rather than use the quick start environment, follow these steps: To Configure JanusGraph Server For WebSocket Test a local connection to a JanusGraph database first. This step applies whether using the Gremlin Console to test the connection, or whether connecting from a program. Make appropriate changes in a properties file in the ./conf directory for your environment. For example, edit ./conf/janusgraph-hbase.properties and make sure the storage.backend, storage.hostname and storage.hbase.table parameters are specified correctly. For more information on configuring JanusGraph for various storage backends, see Storage Backends . Make sure the properties file contains the following line: gremlin.graph=org.janusgraph.core.JanusGraphFactory Once a local configuration is tested and you have a working properties file, copy the properties file from the ./conf directory to the ./conf/gremlin-server directory. cp conf/janusgraph-hbase.properties conf/gremlin-server/socket-janusgraph-hbase-server.properties Copy ./conf/gremlin-server/gremlin-server.yaml to a new file called socket-gremlin-server.yaml . Do this in case you need to refer to the original version of the file cp conf/gremlin-server/gremlin-server.yaml conf/gremlin-server/socket-gremlin-server.yaml Edit the socket-gremlin-server.yaml file and make the following updates: If you are planning to connect to JanusGraph Server from something other than localhost, update the IP address for host: host: 10.10.10.100 Update the graphs section to point to your new properties file so the JanusGraph Server can find and connect to your JanusGraph instance: graphs : { graph : conf/gremlin-server/socket-janusgraph-hbase-server.properties } Start the JanusGraph Server, specifying the yaml file you just configured: bin/gremlin-server.sh ./conf/gremlin-server/socket-gremlin-server.yaml The JanusGraph Server should now be running in WebSocket mode and can be tested by following the instructions in Connecting to Gremlin Server Important Do not use bin/janusgraph.sh . That starts the default configuration, which starts a separate Cassandra/Elasticsearch environment.","title":"JanusGraph Server as a WebSocket Endpoint"},{"location":"basics/server/#janusgraph-server-as-a-http-endpoint","text":"The default configuration described in Getting Started is a WebSocket configuration. If you want to alter the default configuration in order to use JanusGraph Server as an HTTP endpoint for your JanusGraph database, follow these steps: Test a local connection to a JanusGraph database first. This step applies whether using the Gremlin Console to test the connection, or whether connecting from a program. Make appropriate changes in a properties file in the ./conf directory for your environment. For example, edit ./conf/janusgraph-hbase.properties and make sure the storage.backend, storage.hostname and storage.hbase.table parameters are specified correctly. For more information on configuring JanusGraph for various storage backends, see Storage Backends . Make sure the properties file contains the following line: gremlin.graph=org.janusgraph.core.JanusGraphFactory Once a local configuration is tested and you have a working properties file, copy the properties file from the ./conf directory to the ./conf/gremlin-server directory. cp conf/janusgraph-hbase.properties conf/gremlin-server/http-janusgraph-hbase-server.properties Copy ./conf/gremlin-server/gremlin-server.yaml to a new file called http-gremlin-server.yaml . Do this in case you need to refer to the original version of the file cp conf/gremlin-server/gremlin-server.yaml conf/gremlin-server/http-gremlin-server.yaml Edit the http-gremlin-server.yaml file and make the following updates: If you are planning to connect to JanusGraph Server from something other than localhost, update the IP address for host: host: 10.10.10.100 Update the channelizer setting to specify the HttpChannelizer: channelizer : org.apache.tinkerpop.gremlin.server.channel.HttpChannelizer Update the graphs section to point to your new properties file so the JanusGraph Server can find and connect to your JanusGraph instance: graphs : { graph : conf/gremlin-server/http-janusgraph-hbase-server.properties } Start the JanusGraph Server, specifying the yaml file you just configured: bin/gremlin-server.sh ./conf/gremlin-server/http-gremlin-server.yaml The JanusGraph Server should now be running in HTTP mode and available for testing. curl can be used to verify the server is working: curl -XPOST -Hcontent-type:application/json -d * { \"gremlin\" : \"g.V().count()\" } * [ IP for JanusGraph server host ]( http:// ) :8182","title":"JanusGraph Server as a HTTP Endpoint"},{"location":"basics/server/#janusgraph-server-as-both-a-websocket-and-http-endpoint","text":"As of JanusGraph 0.2.0, you can configure your gremlin-server.yaml to accept both WebSocket and HTTP connections over the same port. This can be achieved by changing the channelizer in any of the previous examples as follows. channelizer : org.apache.tinkerpop.gremlin.server.channel.WsAndHttpChannelizer","title":"JanusGraph Server as Both a WebSocket and HTTP Endpoint"},{"location":"basics/server/#advanced-janusgraph-server-configurations","text":"","title":"Advanced JanusGraph Server Configurations"},{"location":"basics/server/#authentication-over-http","text":"Important In the following example, credentialsDb should be different from the graph(s) you are using. It should be configured with the correct backend and a different keyspace, table, or storage directory as appropriate for the configured backend. This graph will be used for storing usernames and passwords.","title":"Authentication over HTTP"},{"location":"basics/server/#http-basic-authentication","text":"To enable Basic authentication in JanusGraph Server include the following configuration in your gremlin-server.yaml . authentication : { authenticator : org.janusgraph.graphdb.tinkerpop.gremlin.server.auth.JanusGraphSimpleAuthenticator , authenticationHandler : org.apache.tinkerpop.gremlin.server.handler.HttpBasicAuthenticationHandler , config : { defaultUsername : user , defaultPassword : password , credentialsDb : conf/janusgraph-credentials-server.properties } } Verify that basic authentication is configured correctly. For example curl -v -XPOST http://localhost:8182 -d '{\"gremlin\": \"g.V().count()\"}' should return a 401 if the authentication is configured correctly and curl -v -XPOST http://localhost:8182 -d '{\"gremlin\": \"g.V().count()\"}' -u user:password should return a 200 and the result of 4 if authentication is configured correctly.","title":"HTTP Basic authentication"},{"location":"basics/server/#authentication-over-websocket","text":"Authentication over WebSocket occurs through a Simple Authentication and Security Layer (https://en.wikipedia.org/wiki/Simple_Authentication_and_Security_Layer[SASL]) mechanism. To enable SASL authentication include the following configuration in the gremlin-server.yaml authentication : { authenticator : org.janusgraph.graphdb.tinkerpop.gremlin.server.auth.JanusGraphSimpleAuthenticator , authenticationHandler : org.apache.tinkerpop.gremlin.server.handler.SaslAuthenticationHandler , config : { defaultUsername : user , defaultPassword : password , credentialsDb : conf/janusgraph-credentials-server.properties } } Important In the preceding example, credentialsDb should be different from the graph(s) you are using. It should be configured with the correct backend and a different keyspace, table, or storage directory as appropriate for the configured backend. This graph will be used for storing usernames and passwords. If you are connecting through the gremlin console, your remote yaml file should ammend the username and password properties with the appropriate values. username : user password : password","title":"Authentication over WebSocket"},{"location":"basics/server/#authentication-over-http-and-websocket","text":"If you are using the combined channelizer for both HTTP and WebSocket you can use the SaslAndHMACAuthenticator to authorize through either WebSocket through SASL, HTTP through basic auth, and HTTP through hash-based messsage authentication code (https://en.wikipedia.org/wiki/Hash-based_message_authentication_code[HMAC]) Auth. HMAC is a token based authentication designed to be used over HTTP. You first acquire a token via the /session endpoint and then use that to authenticate. It is used to amortize the time spent encrypting the password using basic auth. The gremlin-server.yaml should include the following configurations authentication : { authenticator : org.janusgraph.graphdb.tinkerpop.gremlin.server.auth.SaslAndHMACAuthenticator , authenticationHandler : org.janusgraph.graphdb.tinkerpop.gremlin.server.handler.SaslAndHMACAuthenticationHandler , config : { defaultUsername : user , defaultPassword : password , hmacSecret : secret , credentialsDb : conf/janusgraph-credentials-server.properties } } Important In the preceding example, credentialsDb should be different from the graph(s) you are using. It should be configured with the correct backend and a different keyspace, table, or storage directory as appropriate for the configured backend. This graph will be used for storing usernames and passwords. Important Note the hmacSecret here. This should be the same across all running JanusGraph servers if you want to be able to use the same HMAC token on each server. For HMAC authentication over HTTP, this creates a /session endpoint that provides a token that expires after an hour by default. This timeout for the token can be configured through the tokenTimeout configuration option in the authentication.config map. This value is a Long value and in milliseconds. You can obtain the token using curl by issuing a get request to the /session endpoint. For example curl http://localhost:8182/session -XGET -u user:password { \"token\" : \"dXNlcjoxNTA5NTQ2NjI0NDUzOkhrclhYaGhRVG9KTnVSRXJ5U2VpdndhalJRcVBtWEpSMzh5WldqRTM4MW89\" } You can then use that token for authentication by using the \"Authorization: Token\" header. For example curl -v http://localhost:8182/session -XPOST -d '{\"gremlin\": \"g.V().count()\"}' -H \"Authorization: Token dXNlcjoxNTA5NTQ2NjI0NDUzOkhrclhYaGhRVG9KTnVSRXJ5U2VpdndhalJRcVBtWEpSMzh5WldqRTM4MW89\"","title":"Authentication over HTTP and WebSocket"},{"location":"basics/server/#using-tinkerpop-gremlin-server-with-janusgraph","text":"Since JanusGraph Server is a TinkerPop Gremlin Server packaged with configuration files for JanusGraph, a version compatible TinkerPop Gremlin Server can be downloaded separately and used with JanusGraph. Get started by downloading the appropriate version of Gremlin Server, which needs to match a version supported by the JanusGraph version in use (3.4.4). Important Any references to file paths in this section refer to paths under a TinkerPop distribution for Gremlin Server and not a JanusGraph distribution with the JanusGraph Server, unless specifically noted. Configuring a standalone Gremlin Server to work with JanusGraph is similar to configuring the packaged JanusGraph Server. You should be familiar with graph configuration . Basically, the Gremlin Server yaml file points to graph-specific configuration files that are used to instantiate JanusGraph instances that it will then host. In order to instantiate these Graph instances, Gremlin Server requires that the appropriate libraries and dependencies for the JanusGraph be available on its classpath. For purposes of demonstration, these instructions will outline how to configure the BerkeleyDB backend for JanusGraph in Gremlin Server. As stated earlier, Gremlin Server needs JanusGraph dependencies on its classpath. Invoke the following command replacing $VERSION with the version of JanusGraph to use: bin/gremlin-server.sh -i org.janusgraph janusgraph-all $VERSION When this process completes, Gremlin Server should now have all the JanusGraph dependencies available to it and will thus be able to instantiate JanusGraph objects. Important The above command uses Groovy Grape and if it is not configured properly download errors may ensue. Please refer to this section of the TinkerPop documentation for more information around setting up ~/.groovy/grapeConfig.xml. Create a file called GREMLIN_SERVER_HOME/conf/janusgraph.properties with the following contents: gremlin.graph=org.janusgraph.core.JanusGraphFactory storage.backend=berkeleyje storage.directory=db/berkeley Configuration of other backends is similar. See Storage Backends . If using Cassandra, then use Cassandra configuration options in the janusgraph.properties file. The only important piece to leave unchanged is the gremlin.graph setting which should always use JanusGraphFactory . This setting tells Gremlin Server how to instantiate a JanusGraph instance. Next create a file called GREMLIN_SERVER_HOME/conf/gremlin-server-janusgraph.yaml that has the following contents: host : localhost port : 8182 graphs : { graph : conf/janusgraph.properties } scriptEngines : { gremlin-groovy : { plugins : { org.janusgraph.graphdb.tinkerpop.plugin.JanusGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.server.jsr223.GremlinServerGremlinPlugin : {}, org.apache.tinkerpop.gremlin.tinkergraph.jsr223.TinkerGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.jsr223.ImportGremlinPlugin : { classImports : [ java.lang.Math ], methodImports : [ java.lang.Math#* ]}, org.apache.tinkerpop.gremlin.jsr223.ScriptFileGremlinPlugin : { files : [ scripts/empty-sample.groovy ]}}}} serializers : - { className : org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 , config : { ioRegistries : [ org.janusgraph.graphdb.tinkerpop.JanusGraphIoRegistry ] }} - { className : org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 , config : { serializeResultToString : true }} - { className : org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV3d0 , config : { ioRegistries : [ org.janusgraph.graphdb.tinkerpop.JanusGraphIoRegistry ] }} metrics : { slf4jReporter : { enabled : true , interval : 180000 }} There are several important parts to this configuration file as they relate to JanusGraph. In the graphs map, there is a key called graph and its value is conf/janusgraph.properties . This tells Gremlin Server to instantiate a Graph instance called \"graph\" and use the conf/janusgraph.properties file to configure it. The \"graph\" key becomes the unique name for the Graph instance in Gremlin Server and it can be referenced as such in the scripts submitted to it. In the plugins list, there is a reference to JanusGraphGremlinPlugin , which tells Gremlin Server to initialize the \"JanusGraph Plugin\". The \"JanusGraph Plugin\" will auto-import JanusGraph specific classes for usage in scripts. Note the scripts key and the reference to scripts/janusgraph.groovy . This Groovy file is an initialization script for Gremlin Server and that particular ScriptEngine. Create scripts/janusgraph.groovy with the following contents: def globals = [:] globals << [ g : graph . traversal ()] The above script creates a Map called globals and assigns to it a key/value pair. The key is g and its value is a TraversalSource generated from graph , which was configured for Gremlin Server in its configuration file. At this point, there are now two global variables available to scripts provided to Gremlin Server - graph and g . At this point, Gremlin Server is configured and can be used to connect to a new or existing JanusGraph database. To start the server: $ bin/gremlin-server.sh conf/gremlin-server-janusgraph.yaml [ INFO ] GremlinServer - \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- [ INFO ] GremlinServer - Configuring Gremlin Server from conf/gremlin-server-janusgraph.yaml [ INFO ] MetricManager - Configured Metrics Slf4jReporter configured with interval = 180000ms and loggerName = org.apache.tinkerpop.gremlin.server.Settings $Slf4jReporterMetrics [ INFO ] GraphDatabaseConfiguration - Set default timestamp provider MICRO [ INFO ] GraphDatabaseConfiguration - Generated unique-instance-id = 7f0000016240-ubuntu1 [ INFO ] Backend - Initiated backend operations thread pool of size 8 [ INFO ] KCVSLog $MessagePuller - Loaded unidentified ReadMarker start time 2015 -10-02T12:28:24.411Z into org.janusgraph.diskstorage.log.kcvs.KCVSLog $MessagePuller @35399441 [ INFO ] GraphManager - Graph [ graph ] was successfully configured via [ conf/janusgraph.properties ] . [ INFO ] ServerGremlinExecutor - Initialized Gremlin thread pool. Threads in pool named with pattern gremlin-* [ INFO ] ScriptEngines - Loaded gremlin-groovy ScriptEngine [ INFO ] GremlinExecutor - Initialized gremlin-groovy ScriptEngine with scripts/janusgraph.groovy [ INFO ] ServerGremlinExecutor - Initialized GremlinExecutor and configured ScriptEngines. [ INFO ] ServerGremlinExecutor - A GraphTraversalSource is now bound to [ g ] with graphtraversalsource [ standardjanusgraph [ berkeleyje:db/berkeley ] , standard ] [ INFO ] AbstractChannelizer - Configured application/vnd.gremlin-v3.0+gryo with org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 [ INFO ] AbstractChannelizer - Configured application/vnd.gremlin-v3.0+gryo-stringd with org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 [ INFO ] GremlinServer $1 - Gremlin Server configured with worker thread pool of 1 , gremlin pool of 8 and boss thread pool of 1 . [ INFO ] GremlinServer $1 - Channel started at port 8182 . The following section explains how to connect to the running server.","title":"Using TinkerPop Gremlin Server with JanusGraph"},{"location":"basics/server/#connecting-to-janusgraph-via-gremlin-server","text":"Gremlin Server will be ready to listen for WebSocket connections when it is started. The easiest way to test the connection is with Gremlin Console. Follow the instructions here Connecting to Gremlin Server to verify the Gremlin Server is working. Important A difference you should understand is that when working with JanusGraph Server, the Gremlin Console is started from underneath the JanusGraph distribution and when following the test instructions here for a standalone Gremlin Server, the Gremlin Console is started from under the TinkerPop distribution. GryoMapper mapper = GryoMapper . build (). addRegistry ( JanusGraphIoRegistry . INSTANCE ). create (); Cluster cluster = Cluster . build (). serializer ( new GryoMessageSerializerV3d0 ( mapper )). create (); Client client = cluster . connect (); client . submit ( \"g.V()\" ). all (). get (); By adding the JanusGraphIoRegistry to the org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV3d0 , the driver will know how to properly deserialize custom data types returned by JanusGraph.","title":"Connecting to JanusGraph via Gremlin Server"},{"location":"basics/server/#extending-janusgraph-server","text":"It is possible to extend Gremlin Server with other means of communication by implementing the interfaces that it provides and leverage this with JanusGraph. See more details in the appropriate TinkerPop documentation.","title":"Extending JanusGraph Server"},{"location":"basics/technical-limitations/","text":"Technical Limitations There are various limitations and \"gotchas\" that one should be aware of when using JanusGraph. Some of these limitations are necessary design choices and others are issues that will be rectified as JanusGraph development continues. Finally, the last section provides solutions to common issues. Design Limitations These limitations reflect long-term tradeoffs design tradeoffs which are either difficult or impractical to change. These limitations are unlikely to be removed in the near future. Size Limitation JanusGraph can store up to a quintillion edges (2^60) and half as many vertices. That limitation is imposed by JanusGraph\u2019s id scheme. DataType Definitions When declaring the data type of a property key using dataType(Class) JanusGraph will enforce that all properties for that key have the declared type, unless that type is Object.class . This is an equality type check, meaning that sub-classes will not be allowed. For instance, one cannot declare the data type to be Number.class and use Integer or Long . For efficiency reasons, the type needs to match exactly. Hence, use Object.class as the data type for type flexibility. In all other cases, declare the actual data type to benefit from increased performance and type safety. Edge Retrievals are O(log(k)) Retrieving an edge by id, e.g tx.getEdge(edge.getId()) , is not a constant time operation because it requires an index call on one of its adjacent vertices. Hence, the cost of retrieving an individual edge by its id is O(log(k)) where k is the number of incident edges on the adjacent vertex. JanusGraph will attempt to pick the adjacent vertex with the smaller degree. This also applies to index retrievals for edges via a standard or external index. Type Definitions cannot be changed The definition of an edge label, property key, or vertex label cannot be changed once it has been committed to the graph. However, a type can be renamed and new types can be created at runtime to accommodate an evolving schema. Reserved Keywords There are certain keywords that JanusGraph uses internally for types that cannot be used otherwise. These types include vertex labels, edge labels, and property keys. The following are keywords that cannot be used: vertex element edge property label key For example, if you attempt to create a vertex with the label of property , you will receive an exception regarding protected system types. Temporary Limitations These are limitations in JanusGraph\u2019s current implementation. These limitations could reasonably be removed in upcoming versions of JanusGraph. Limited Mixed Index Support Mixed indexes only support a subset of the data types that JanusGraph supports. See Mixed Index Data Types for a current listing. Also, mixed indexes do not currently support property keys with SET or LIST cardinality. Batch Loading Speed JanusGraph provides a batch loading mode that can be enabled through the graph configuration . However, this batch mode only facilitates faster loading into the storage backend, it does not use storage backend specific batch loading techniques that prepare the data in memory for disk storage. As such, batch loading in JanusGraph is currently slower than batch loading modes provided by single machine databases. Bulk Loading contains information on speeding up batch loading in JanusGraph. Another limitation related to batch loading is the failure to load millions of edges into a single vertex at once or in a short time of period. Such supernode loading can fail for some storage backends. This limitation also applies to dense index entries.","title":"Technical Limitations"},{"location":"basics/technical-limitations/#technical-limitations","text":"There are various limitations and \"gotchas\" that one should be aware of when using JanusGraph. Some of these limitations are necessary design choices and others are issues that will be rectified as JanusGraph development continues. Finally, the last section provides solutions to common issues.","title":"Technical Limitations"},{"location":"basics/technical-limitations/#design-limitations","text":"These limitations reflect long-term tradeoffs design tradeoffs which are either difficult or impractical to change. These limitations are unlikely to be removed in the near future.","title":"Design Limitations"},{"location":"basics/technical-limitations/#size-limitation","text":"JanusGraph can store up to a quintillion edges (2^60) and half as many vertices. That limitation is imposed by JanusGraph\u2019s id scheme.","title":"Size Limitation"},{"location":"basics/technical-limitations/#datatype-definitions","text":"When declaring the data type of a property key using dataType(Class) JanusGraph will enforce that all properties for that key have the declared type, unless that type is Object.class . This is an equality type check, meaning that sub-classes will not be allowed. For instance, one cannot declare the data type to be Number.class and use Integer or Long . For efficiency reasons, the type needs to match exactly. Hence, use Object.class as the data type for type flexibility. In all other cases, declare the actual data type to benefit from increased performance and type safety.","title":"DataType Definitions"},{"location":"basics/technical-limitations/#edge-retrievals-are-ologk","text":"Retrieving an edge by id, e.g tx.getEdge(edge.getId()) , is not a constant time operation because it requires an index call on one of its adjacent vertices. Hence, the cost of retrieving an individual edge by its id is O(log(k)) where k is the number of incident edges on the adjacent vertex. JanusGraph will attempt to pick the adjacent vertex with the smaller degree. This also applies to index retrievals for edges via a standard or external index.","title":"Edge Retrievals are O(log(k))"},{"location":"basics/technical-limitations/#type-definitions-cannot-be-changed","text":"The definition of an edge label, property key, or vertex label cannot be changed once it has been committed to the graph. However, a type can be renamed and new types can be created at runtime to accommodate an evolving schema.","title":"Type Definitions cannot be changed"},{"location":"basics/technical-limitations/#reserved-keywords","text":"There are certain keywords that JanusGraph uses internally for types that cannot be used otherwise. These types include vertex labels, edge labels, and property keys. The following are keywords that cannot be used: vertex element edge property label key For example, if you attempt to create a vertex with the label of property , you will receive an exception regarding protected system types.","title":"Reserved Keywords"},{"location":"basics/technical-limitations/#temporary-limitations","text":"These are limitations in JanusGraph\u2019s current implementation. These limitations could reasonably be removed in upcoming versions of JanusGraph.","title":"Temporary Limitations"},{"location":"basics/technical-limitations/#limited-mixed-index-support","text":"Mixed indexes only support a subset of the data types that JanusGraph supports. See Mixed Index Data Types for a current listing. Also, mixed indexes do not currently support property keys with SET or LIST cardinality.","title":"Limited Mixed Index Support"},{"location":"basics/technical-limitations/#batch-loading-speed","text":"JanusGraph provides a batch loading mode that can be enabled through the graph configuration . However, this batch mode only facilitates faster loading into the storage backend, it does not use storage backend specific batch loading techniques that prepare the data in memory for disk storage. As such, batch loading in JanusGraph is currently slower than batch loading modes provided by single machine databases. Bulk Loading contains information on speeding up batch loading in JanusGraph. Another limitation related to batch loading is the failure to load millions of edges into a single vertex at once or in a short time of period. Such supernode loading can fail for some storage backends. This limitation also applies to dense index entries.","title":"Batch Loading Speed"},{"location":"basics/transaction-log/","text":"Transaction Log JanusGraph can automatically log transactional changes for additional processing or as a record of change. To enable logging for a particular transaction, specify the name of the target log during the start of the transaction. tx = graph . buildTransaction (). logIdentifier ( 'addedPerson' ). start () u = tx . addVertex ( label , 'human' ) u . property ( 'name' , 'proteros' ) u . property ( 'age' , 36 ) tx . commit () Upon commit, any changes made during the transaction are logged to the user logging system into a log named addedPerson . The user logging system is a configurable logging backend with a JanusGraph compatible log interface. By default, the log is written to a separate store in the primary storage backend which can be configured as described below. The log identifier specified during the start of the transaction identifies the log in which the changes are recorded thereby allowing different types of changes to be recorded in separate logs for individual processing. tx = graph . buildTransaction (). logIdentifier ( 'battle' ). start () h = tx . traversal (). V (). has ( 'name' , 'hercules' ). next () m = tx . addVertex ( label , 'monster' ) m . property ( 'name' , 'phylatax' ) h . addEdge ( 'battled' , m , 'time' , 22 ) tx . commit () JanusGraph provides a user transaction log processor framework to process the recorded transactional changes. The transaction log processor is opened via JanusGraphFactory.openTransactionLog(JanusGraph) against a previously opened JanusGraph graph instance. One can then add processors for a particular log which holds transactional changes. import java.util.concurrent.atomic.* ; import org.janusgraph.core.log.* ; import java.util.concurrent.* ; logProcessor = JanusGraphFactory . openTransactionLog ( g ); totalHumansAdded = new AtomicInteger ( 0 ); totalGodsAdded = new AtomicInteger ( 0 ); logProcessor . addLogProcessor ( \"addedPerson\" ). setProcessorIdentifier ( \"addedPersonCounter\" ). setStartTimeNow (). addProcessor ( new ChangeProcessor () { @Override public void process ( JanusGraphTransaction tx , TransactionId txId , ChangeState changeState ) { for ( v in changeState . getVertices ( Change . ADDED )) { if ( v . label (). equals ( \"human\" )) totalHumansAdded . incrementAndGet (); } } }). addProcessor ( new ChangeProcessor () { @Override public void process ( JanusGraphTransaction tx , TransactionId txId , ChangeState changeState ) { for ( v in changeState . getVertices ( Change . ADDED )) { if ( v . label (). equals ( \"god\" )) totalGodsAdded . incrementAndGet (); } } }). build (); In this example, a log processor is built for the user transaction log named addedPerson to process the changes made in transactions which used the addedPerson log identifier. Two change processors are added to this log processor. The first processor counts the number of humans added and the second counts the number of gods added to the graph. When a log processor is built against a particular log, such as the addedPerson log in the example above, it will start reading transactional change records from the log immediately upon successful construction and initialization up to the head of the log. The start time specified in the builder marks the time point in the log where the log processor will start reading records. Optionally, one can specify an identifier for the log processor in the builder. The log processor will use the identifier to regularly persist its state of processing, i.e. it will maintain a marker on the last read log record. If the log processor is later restarted with the same identifier, it will continue reading from the last read record. This is particularly useful when the log processor is supposed to run for long periods of time and is therefore likely to fail. In such failure situations, the log processor can simply be restarted with the same identifier. It must be ensured that log processor identifiers are unique in a JanusGraph cluster in order to avoid conflicts on the persisted read markers. A change processor must implement the ChangeProcessor interface. It\u2019s process() method is invoked for each change record read from the log with a JanusGraphTransaction handle, the id of the transaction that caused the change, and a ChangeState container which holds the transactional changes. The change state container can be queried to retrieve individual elements that were part of the change state. In the example, all added vertices are retrieved. Refer to the API documentation for a description of all the query methods on ChangeState . The provided transaction id can be used to investigate the origin of the transaction which is uniquely identified by the combination of the id of the JanusGraph instance that executed the transaction ( txId.getInstanceId() ) and the instance specific transaction id ( txId.getTransactionId() ). In addition, the time of the transaction is available through txId.getTransactionTime() . Change processors are executed individually and in multiple threads. If a change processor accesses global state it must be ensured that such state allows concurrent access. While the log processor reads log records sequentially, the changes are processed in multiple threads so it cannot be guaranteed that the log order is preserved in the change processors. Note, that log processors run each registered change processor at least once for each record in the log which means that a single transactional change record may be processed multiple times under certain failure conditions. One cannot add or remove change processor from a running log processor. In other words, a log processor is immutable after it is built. To change log processing, start a new log processor and shut down an existing one. logProcessor . addLogProcessor ( \"battle\" ). setProcessorIdentifier ( \"battleTimer\" ). setStartTimeNow (). addProcessor ( new ChangeProcessor () { @Override public void process ( JanusGraphTransaction tx , TransactionId txId , ChangeState changeState ) { h = tx . V (). has ( \"name\" , \"hercules\" ). toList (). iterator (). next (); for ( edge in changeState . getEdges ( h , Change . ADDED , Direction . OUT , \"battled\" )) { if ( edge .< Integer > value ( \"time\" )> 1000 ) h . property ( \"oldFighter\" , true ); } } }). build (); The log processor above processes transactions for the battle log identifier with a single change processor which evaluates battled edges that were added to Hercules. This example demonstrates that the transaction handle passed into the change processor is a normal JanusGraphTransaction which query the JanusGraph graph and make changes to it. Transaction Log Use Cases Record of Change The user transaction log can be used to keep a record of all changes made against the graph. By using separate log identifiers, changes can be recorded in different logs to distinguish separate transaction types. At any time, a log processor can be built which can processes all recorded changes starting from the desired start time. This can be used for forensic analysis, to replay changes against a different graph, or to compute an aggregate. Downstream Updates It is often the case that a JanusGraph graph cluster is part of a larger architecture. The user transaction log and the log processor framework provide the tools needed to broadcast changes to other components of the overall system without slowing down the original transactions causing the change. This is particularly useful when transaction latencies need to be low and/or there are a number of other systems that need to be alerted to a change in the graph. Triggers The user transaction log provides the basic infrastructure to implement triggers that can scale to a large number of concurrent transactions and very large graphs. A trigger is registered with a particular change of data and either triggers an event in an external system or additional changes to the graph. At scale, it is not advisable to implement triggers in the original transaction but rather process triggers with a slight delay through the log processor framework. The second example shows how changes to the graph can be evaluated and trigger additional modifications. Log Configuration There are a number of configuration options to fine tune how the log processor reads from the log. Refer to the complete list of configuration options Configuration Reference for the options under the log namespace. To configure the user transaction log, use the log.user namespace. The options listed there allow the configuration of the number of threads to be used, the number of log records read in each batch, the read interval, and whether the transaction change records should automatically expire and be removed from the log after a configurable amount of time (TTL).","title":"Transaction Log"},{"location":"basics/transaction-log/#transaction-log","text":"JanusGraph can automatically log transactional changes for additional processing or as a record of change. To enable logging for a particular transaction, specify the name of the target log during the start of the transaction. tx = graph . buildTransaction (). logIdentifier ( 'addedPerson' ). start () u = tx . addVertex ( label , 'human' ) u . property ( 'name' , 'proteros' ) u . property ( 'age' , 36 ) tx . commit () Upon commit, any changes made during the transaction are logged to the user logging system into a log named addedPerson . The user logging system is a configurable logging backend with a JanusGraph compatible log interface. By default, the log is written to a separate store in the primary storage backend which can be configured as described below. The log identifier specified during the start of the transaction identifies the log in which the changes are recorded thereby allowing different types of changes to be recorded in separate logs for individual processing. tx = graph . buildTransaction (). logIdentifier ( 'battle' ). start () h = tx . traversal (). V (). has ( 'name' , 'hercules' ). next () m = tx . addVertex ( label , 'monster' ) m . property ( 'name' , 'phylatax' ) h . addEdge ( 'battled' , m , 'time' , 22 ) tx . commit () JanusGraph provides a user transaction log processor framework to process the recorded transactional changes. The transaction log processor is opened via JanusGraphFactory.openTransactionLog(JanusGraph) against a previously opened JanusGraph graph instance. One can then add processors for a particular log which holds transactional changes. import java.util.concurrent.atomic.* ; import org.janusgraph.core.log.* ; import java.util.concurrent.* ; logProcessor = JanusGraphFactory . openTransactionLog ( g ); totalHumansAdded = new AtomicInteger ( 0 ); totalGodsAdded = new AtomicInteger ( 0 ); logProcessor . addLogProcessor ( \"addedPerson\" ). setProcessorIdentifier ( \"addedPersonCounter\" ). setStartTimeNow (). addProcessor ( new ChangeProcessor () { @Override public void process ( JanusGraphTransaction tx , TransactionId txId , ChangeState changeState ) { for ( v in changeState . getVertices ( Change . ADDED )) { if ( v . label (). equals ( \"human\" )) totalHumansAdded . incrementAndGet (); } } }). addProcessor ( new ChangeProcessor () { @Override public void process ( JanusGraphTransaction tx , TransactionId txId , ChangeState changeState ) { for ( v in changeState . getVertices ( Change . ADDED )) { if ( v . label (). equals ( \"god\" )) totalGodsAdded . incrementAndGet (); } } }). build (); In this example, a log processor is built for the user transaction log named addedPerson to process the changes made in transactions which used the addedPerson log identifier. Two change processors are added to this log processor. The first processor counts the number of humans added and the second counts the number of gods added to the graph. When a log processor is built against a particular log, such as the addedPerson log in the example above, it will start reading transactional change records from the log immediately upon successful construction and initialization up to the head of the log. The start time specified in the builder marks the time point in the log where the log processor will start reading records. Optionally, one can specify an identifier for the log processor in the builder. The log processor will use the identifier to regularly persist its state of processing, i.e. it will maintain a marker on the last read log record. If the log processor is later restarted with the same identifier, it will continue reading from the last read record. This is particularly useful when the log processor is supposed to run for long periods of time and is therefore likely to fail. In such failure situations, the log processor can simply be restarted with the same identifier. It must be ensured that log processor identifiers are unique in a JanusGraph cluster in order to avoid conflicts on the persisted read markers. A change processor must implement the ChangeProcessor interface. It\u2019s process() method is invoked for each change record read from the log with a JanusGraphTransaction handle, the id of the transaction that caused the change, and a ChangeState container which holds the transactional changes. The change state container can be queried to retrieve individual elements that were part of the change state. In the example, all added vertices are retrieved. Refer to the API documentation for a description of all the query methods on ChangeState . The provided transaction id can be used to investigate the origin of the transaction which is uniquely identified by the combination of the id of the JanusGraph instance that executed the transaction ( txId.getInstanceId() ) and the instance specific transaction id ( txId.getTransactionId() ). In addition, the time of the transaction is available through txId.getTransactionTime() . Change processors are executed individually and in multiple threads. If a change processor accesses global state it must be ensured that such state allows concurrent access. While the log processor reads log records sequentially, the changes are processed in multiple threads so it cannot be guaranteed that the log order is preserved in the change processors. Note, that log processors run each registered change processor at least once for each record in the log which means that a single transactional change record may be processed multiple times under certain failure conditions. One cannot add or remove change processor from a running log processor. In other words, a log processor is immutable after it is built. To change log processing, start a new log processor and shut down an existing one. logProcessor . addLogProcessor ( \"battle\" ). setProcessorIdentifier ( \"battleTimer\" ). setStartTimeNow (). addProcessor ( new ChangeProcessor () { @Override public void process ( JanusGraphTransaction tx , TransactionId txId , ChangeState changeState ) { h = tx . V (). has ( \"name\" , \"hercules\" ). toList (). iterator (). next (); for ( edge in changeState . getEdges ( h , Change . ADDED , Direction . OUT , \"battled\" )) { if ( edge .< Integer > value ( \"time\" )> 1000 ) h . property ( \"oldFighter\" , true ); } } }). build (); The log processor above processes transactions for the battle log identifier with a single change processor which evaluates battled edges that were added to Hercules. This example demonstrates that the transaction handle passed into the change processor is a normal JanusGraphTransaction which query the JanusGraph graph and make changes to it.","title":"Transaction Log"},{"location":"basics/transaction-log/#transaction-log-use-cases","text":"","title":"Transaction Log Use Cases"},{"location":"basics/transaction-log/#record-of-change","text":"The user transaction log can be used to keep a record of all changes made against the graph. By using separate log identifiers, changes can be recorded in different logs to distinguish separate transaction types. At any time, a log processor can be built which can processes all recorded changes starting from the desired start time. This can be used for forensic analysis, to replay changes against a different graph, or to compute an aggregate.","title":"Record of Change"},{"location":"basics/transaction-log/#downstream-updates","text":"It is often the case that a JanusGraph graph cluster is part of a larger architecture. The user transaction log and the log processor framework provide the tools needed to broadcast changes to other components of the overall system without slowing down the original transactions causing the change. This is particularly useful when transaction latencies need to be low and/or there are a number of other systems that need to be alerted to a change in the graph.","title":"Downstream Updates"},{"location":"basics/transaction-log/#triggers","text":"The user transaction log provides the basic infrastructure to implement triggers that can scale to a large number of concurrent transactions and very large graphs. A trigger is registered with a particular change of data and either triggers an event in an external system or additional changes to the graph. At scale, it is not advisable to implement triggers in the original transaction but rather process triggers with a slight delay through the log processor framework. The second example shows how changes to the graph can be evaluated and trigger additional modifications.","title":"Triggers"},{"location":"basics/transaction-log/#log-configuration","text":"There are a number of configuration options to fine tune how the log processor reads from the log. Refer to the complete list of configuration options Configuration Reference for the options under the log namespace. To configure the user transaction log, use the log.user namespace. The options listed there allow the configuration of the number of threads to be used, the number of log records read in each batch, the read interval, and whether the transaction change records should automatically expire and be removed from the log after a configurable amount of time (TTL).","title":"Log Configuration"},{"location":"basics/transactions/","text":"Transactions Almost all interaction with JanusGraph is associated with a transaction. JanusGraph transactions are safe for concurrent use by multiple threads. Methods on a JanusGraph instance like graph.V(...) and graph.tx().commit() perform a ThreadLocal lookup to retrieve or create a transaction associated with the calling thread. Callers can alternatively forego ThreadLocal transaction management in favor of calling graph.tx().createThreadedTx() , which returns a reference to a transaction object with methods to read/write graph data and commit or rollback. JanusGraph transactions are not necessarily ACID. They can be so configured on BerkeleyDB, but they are not generally so on Cassandra or HBase, where the underlying storage system does not provide serializable isolation or multi-row atomic writes and the cost of simulating those properties would be substantial. This section describes JanusGraph\u2019s transactional semantics and API. Transaction Handling Every graph operation in JanusGraph occurs within the context of a transaction. According to the TinkerPop\u2019s transactional specification, each thread opens its own transaction against the graph database with the first operation (i.e. retrieval or mutation) on the graph: graph = JanusGraphFactory . open ( \"berkeleyje:/tmp/janusgraph\" ) juno = graph . addVertex () //Automatically opens a new transaction juno . property ( \"name\" , \"juno\" ) graph . tx (). commit () //Commits transaction In this example, a local JanusGraph graph database is opened. Adding the vertex \"juno\" is the first operation (in this thread) which automatically opens a new transaction. All subsequent operations occur in the context of that same transaction until the transaction is explicitly stopped or the graph database is closed. If transactions are still open when close() is called, then the behavior of the outstanding transactions is technically undefined. In practice, any non-thread-bound transactions will usually be effectively rolled back, but the thread-bound transaction belonging to the thread that invoked shutdown will first be committed. Note, that both read and write operations occur within the context of a transaction. Transactional Scope All graph elements (vertices, edges, and types) are associated with the transactional scope in which they were retrieved or created. Under TinkerPop\u2019s default transactional semantics, transactions are automatically created with the first operation on the graph and closed explicitly using commit() or rollback() . Once the transaction is closed, all graph elements associated with that transaction become stale and unavailable. However, JanusGraph will automatically transition vertices and types into the new transactional scope as shown in this example: graph = JanusGraphFactory . open ( \"berkeleyje:/tmp/janusgraph\" ) juno = graph . addVertex () //Automatically opens a new transaction graph . tx (). commit () //Ends transaction juno . property ( \"name\" , \"juno\" ) //Vertex is automatically transitioned Edges, on the other hand, are not automatically transitioned and cannot be accessed outside their original transaction. They must be explicitly transitioned: e = juno . addEdge ( \"knows\" , graph . addVertex ()) graph . tx (). commit () //Ends transaction e = g . E ( e ). next () //Need to refresh edge e . property ( \"time\" , 99 ) Transaction Failures When committing a transaction, JanusGraph will attempt to persist all changes to the storage backend. This might not always be successful due to IO exceptions, network errors, machine crashes or resource unavailability. Hence, transactions can fail. In fact, transactions will eventually fail in sufficiently large systems. Therefore, we highly recommend that your code expects and accommodates such failures: try { if ( g . V (). has ( \"name\" , name ). iterator (). hasNext ()) throw new IllegalArgumentException ( \"Username already taken: \" + name ) user = graph . addVertex () user . property ( \"name\" , name ) graph . tx (). commit () } catch ( Exception e ) { //Recover, retry, or return error message println ( e . getMessage ()) } The example above demonstrates a simplified user signup implementation where name is the name of the user who wishes to register. First, it is checked whether a user with that name already exists. If not, a new user vertex is created and the name assigned. Finally, the transaction is committed. If the transaction fails, a JanusGraphException is thrown. There are a variety of reasons why a transaction may fail. JanusGraph differentiates between potentially temporary and permanent failures. Potentially temporary failures are those related to resource unavailability and IO hiccups (e.g. network timeouts). JanusGraph automatically tries to recover from temporary failures by retrying to persist the transactional state after some delay. The number of retry attempts and the retry delay are configurable (see Configuration Reference ). Permanent failures can be caused by complete connection loss, hardware failure or lock contention. To understand the cause of lock contention, consider the signup example above and suppose a user tries to signup with username \"juno\". That username may still be available at the beginning of the transaction but by the time the transaction is committed, another user might have concurrently registered with \"juno\" as well and that transaction holds the lock on the username therefore causing the other transaction to fail. Depending on the transaction semantics one can recover from a lock contention failure by re-running the entire transaction. Permanent exceptions that can fail a transaction include: PermanentLockingException( Local lock contention ): Another local thread has already been granted a conflicting lock. PermanentLockingException( Expected value mismatch for X: expected=Y vs actual=Z ): The verification that the value read in this transaction is the same as the one in the datastore after applying for the lock failed. In other words, another transaction modified the value after it had been read and modified. Multi-Threaded Transactions JanusGraph supports multi-threaded transactions through TinkerPop\u2019s threaded transactions. Hence, to speed up transaction processing and utilize multi-core architectures multiple threads can run concurrently in a single transaction. With TinkerPop\u2019s default transaction handling, each thread automatically opens its own transaction against the graph database. To open a thread-independent transaction, use the createThreadedTx() method. threadedGraph = graph . tx (). createThreadedTx (); threads = new Thread [ 10 ]; for ( int i = 0 ; i < threads . length ; i ++) { threads [ i ]= new Thread ({ println ( \"Do something with 'threadedGraph''\" ); }); threads [ i ]. start (); } for ( int i = 0 ; i < threads . length ; i ++) threads [ i ]. join (); threadedGraph . tx (). commit (); The createThreadedTx() method returns a new Graph object that represents this newly opened transaction. The graph object tx supports all of the methods that the original graph did, but does so without opening new transactions for each thread. This allows us to start multiple threads which all work concurrently in the same transaction and one of which finally commits the transaction when all threads have completed their work. JanusGraph relies on optimized concurrent data structures to support hundreds of concurrent threads running efficiently in a single transaction. Concurrent Algorithms Thread independent transactions started through createThreadedTx() are particularly useful when implementing concurrent graph algorithms. Most traversal or message-passing (ego-centric) like graph algorithms are embarrassingly parallel which means they can be parallelized and executed through multiple threads with little effort. Each of these threads can operate on a single Graph object returned by createThreadedTx() without blocking each other. Nested Transactions Another use case for thread independent transactions is nested transactions that ought to be independent from the surrounding transaction. For instance, assume a long running transactional job that has to create a new vertex with a unique name. Since enforcing unique names requires the acquisition of a lock (see Eventually-Consistent Storage Backends for more detail) and since the transaction is running for a long time, lock congestion and expensive transactional failures are likely. v1 = graph . addVertex () //Do many other things v2 = graph . addVertex () v2 . property ( \"uniqueName\" , \"foo\" ) v1 . addEdge ( \"related\" , v2 ) //Do many other things graph . tx (). commit () // This long-running tx might fail due to contention on its uniqueName lock One way around this is to create the vertex in a short, nested thread-independent transaction as demonstrated by the following pseudo code v1 = graph . addVertex () //Do many other things tx = graph . tx (). createThreadedTx () v2 = tx . addVertex () v2 . property ( \"uniqueName\" , \"foo\" ) tx . commit () // Any lock contention will be detected here v1 . addEdge ( \"related\" , g . V ( v2 ). next ()) // Need to load v2 into outer transaction //Do many other things graph . tx (). commit () // Can't fail due to uniqueName write lock contention involving v2 Common Transaction Handling Problems Transactions are started automatically with the first operation executed against the graph. One does NOT have to start a transaction manually. The method newTransaction is used to start multi-threaded transactions only. Transactions are automatically started under the TinkerPop semantics but not automatically terminated. Transactions must be terminated manually with commit() or rollback() . If a commit() transactions fails, it should be terminated manually with rollback() after catching the failure. Manual termination of transactions is necessary because only the user knows the transactional boundary. A transaction will attempt to maintain its state from the beginning of the transaction. This might lead to unexpected behavior in multi-threaded applications as illustrated in the following artificial example v = g . V ( 4 ). next () // Retrieve vertex, first action automatically starts transaction g . V ( v ). bothE () >> returns nothing , v has no edges //thread is idle for a few seconds, another thread adds edges to v g . V ( v ). bothE () >> still returns nothing because the transactional state from the beginning is maintained Such unexpected behavior is likely to occur in client-server applications where the server maintains multiple threads to answer client requests. It is therefore important to terminate the transaction after a unit of work (e.g. code snippet, query, etc). So, the example above should be: v = g . V ( 4 ). next () // Retrieve vertex, first action automatically starts transaction g . V ( v ). bothE () graph . tx (). commit () //thread is idle for a few seconds, another thread adds edges to v g . V ( v ). bothE () >> returns the newly added edge graph . tx (). commit () When using multi-threaded transactions via newTransaction all vertices and edges retrieved or created in the scope of that transaction are not available outside the scope of that transaction. Accessing such elements after the transaction has been closed will result in an exception. As demonstrated in the example above, such elements have to be explicitly refreshed in the new transaction using g.V(existingVertex) or g.E(existingEdge) . Transaction Configuration JanusGraph\u2019s JanusGraph.buildTransaction() method gives the user the ability to configure and start a new multi-threaded transaction against a JanusGraph . Hence, it is identical to JanusGraph.newTransaction() with additional configuration options. buildTransaction() returns a TransactionBuilder which allows the following aspects of a transaction to be configured: readOnly() - makes the transaction read-only and any attempt to modify the graph will result in an exception. enableBatchLoading() - enables batch-loading for an individual transaction. This setting results in similar efficiencies as the graph-wide setting storage.batch-loading due to the disabling of consistency checks and other optimizations. Unlike storage.batch-loading this option will not change the behavior of the storage backend. setTimestamp(long) - Sets the timestamp for this transaction as communicated to the storage backend for persistence. Depending on the storage backend, this setting may be ignored. For eventually consistent backends, this is the timestamp used to resolve write conflicts. If this setting is not explicitly specified, JanusGraph uses the current time. setVertexCacheSize(long size) - The number of vertices this transaction caches in memory. The larger this number, the more memory a transaction can potentially consume. If this number is too small, a transaction might have to re-fetch data which causes delays in particular for long running transactions. checkExternalVertexExistence(boolean) - Whether this transaction should verify the existence of vertices for user provided vertex ids. Such checks requires access to the database which takes time. The existence check should only be disabled if the user is absolutely sure that the vertex must exist - otherwise data corruption can ensue. checkInternalVertexExistence(boolean) - Whether this transaction should double-check the existence of vertices during query execution. This can be useful to avoid phantom vertices on eventually consistent storage backends. Disabled by default. Enabling this setting can slow down query processing. consistencyChecks(boolean) - Whether JanusGraph should enforce schema level consistency constraints (e.g. multiplicity constraints). Disabling consistency checks leads to better performance but requires that the user ensures consistency confirmation at the application level to avoid inconsistencies. USE WITH GREAT CARE! Once, the desired configuration options have been specified, the new transaction is started via start() which returns a JanusGraphTransaction .","title":"Transactions"},{"location":"basics/transactions/#transactions","text":"Almost all interaction with JanusGraph is associated with a transaction. JanusGraph transactions are safe for concurrent use by multiple threads. Methods on a JanusGraph instance like graph.V(...) and graph.tx().commit() perform a ThreadLocal lookup to retrieve or create a transaction associated with the calling thread. Callers can alternatively forego ThreadLocal transaction management in favor of calling graph.tx().createThreadedTx() , which returns a reference to a transaction object with methods to read/write graph data and commit or rollback. JanusGraph transactions are not necessarily ACID. They can be so configured on BerkeleyDB, but they are not generally so on Cassandra or HBase, where the underlying storage system does not provide serializable isolation or multi-row atomic writes and the cost of simulating those properties would be substantial. This section describes JanusGraph\u2019s transactional semantics and API.","title":"Transactions"},{"location":"basics/transactions/#transaction-handling","text":"Every graph operation in JanusGraph occurs within the context of a transaction. According to the TinkerPop\u2019s transactional specification, each thread opens its own transaction against the graph database with the first operation (i.e. retrieval or mutation) on the graph: graph = JanusGraphFactory . open ( \"berkeleyje:/tmp/janusgraph\" ) juno = graph . addVertex () //Automatically opens a new transaction juno . property ( \"name\" , \"juno\" ) graph . tx (). commit () //Commits transaction In this example, a local JanusGraph graph database is opened. Adding the vertex \"juno\" is the first operation (in this thread) which automatically opens a new transaction. All subsequent operations occur in the context of that same transaction until the transaction is explicitly stopped or the graph database is closed. If transactions are still open when close() is called, then the behavior of the outstanding transactions is technically undefined. In practice, any non-thread-bound transactions will usually be effectively rolled back, but the thread-bound transaction belonging to the thread that invoked shutdown will first be committed. Note, that both read and write operations occur within the context of a transaction.","title":"Transaction Handling"},{"location":"basics/transactions/#transactional-scope","text":"All graph elements (vertices, edges, and types) are associated with the transactional scope in which they were retrieved or created. Under TinkerPop\u2019s default transactional semantics, transactions are automatically created with the first operation on the graph and closed explicitly using commit() or rollback() . Once the transaction is closed, all graph elements associated with that transaction become stale and unavailable. However, JanusGraph will automatically transition vertices and types into the new transactional scope as shown in this example: graph = JanusGraphFactory . open ( \"berkeleyje:/tmp/janusgraph\" ) juno = graph . addVertex () //Automatically opens a new transaction graph . tx (). commit () //Ends transaction juno . property ( \"name\" , \"juno\" ) //Vertex is automatically transitioned Edges, on the other hand, are not automatically transitioned and cannot be accessed outside their original transaction. They must be explicitly transitioned: e = juno . addEdge ( \"knows\" , graph . addVertex ()) graph . tx (). commit () //Ends transaction e = g . E ( e ). next () //Need to refresh edge e . property ( \"time\" , 99 )","title":"Transactional Scope"},{"location":"basics/transactions/#transaction-failures","text":"When committing a transaction, JanusGraph will attempt to persist all changes to the storage backend. This might not always be successful due to IO exceptions, network errors, machine crashes or resource unavailability. Hence, transactions can fail. In fact, transactions will eventually fail in sufficiently large systems. Therefore, we highly recommend that your code expects and accommodates such failures: try { if ( g . V (). has ( \"name\" , name ). iterator (). hasNext ()) throw new IllegalArgumentException ( \"Username already taken: \" + name ) user = graph . addVertex () user . property ( \"name\" , name ) graph . tx (). commit () } catch ( Exception e ) { //Recover, retry, or return error message println ( e . getMessage ()) } The example above demonstrates a simplified user signup implementation where name is the name of the user who wishes to register. First, it is checked whether a user with that name already exists. If not, a new user vertex is created and the name assigned. Finally, the transaction is committed. If the transaction fails, a JanusGraphException is thrown. There are a variety of reasons why a transaction may fail. JanusGraph differentiates between potentially temporary and permanent failures. Potentially temporary failures are those related to resource unavailability and IO hiccups (e.g. network timeouts). JanusGraph automatically tries to recover from temporary failures by retrying to persist the transactional state after some delay. The number of retry attempts and the retry delay are configurable (see Configuration Reference ). Permanent failures can be caused by complete connection loss, hardware failure or lock contention. To understand the cause of lock contention, consider the signup example above and suppose a user tries to signup with username \"juno\". That username may still be available at the beginning of the transaction but by the time the transaction is committed, another user might have concurrently registered with \"juno\" as well and that transaction holds the lock on the username therefore causing the other transaction to fail. Depending on the transaction semantics one can recover from a lock contention failure by re-running the entire transaction. Permanent exceptions that can fail a transaction include: PermanentLockingException( Local lock contention ): Another local thread has already been granted a conflicting lock. PermanentLockingException( Expected value mismatch for X: expected=Y vs actual=Z ): The verification that the value read in this transaction is the same as the one in the datastore after applying for the lock failed. In other words, another transaction modified the value after it had been read and modified.","title":"Transaction Failures"},{"location":"basics/transactions/#multi-threaded-transactions","text":"JanusGraph supports multi-threaded transactions through TinkerPop\u2019s threaded transactions. Hence, to speed up transaction processing and utilize multi-core architectures multiple threads can run concurrently in a single transaction. With TinkerPop\u2019s default transaction handling, each thread automatically opens its own transaction against the graph database. To open a thread-independent transaction, use the createThreadedTx() method. threadedGraph = graph . tx (). createThreadedTx (); threads = new Thread [ 10 ]; for ( int i = 0 ; i < threads . length ; i ++) { threads [ i ]= new Thread ({ println ( \"Do something with 'threadedGraph''\" ); }); threads [ i ]. start (); } for ( int i = 0 ; i < threads . length ; i ++) threads [ i ]. join (); threadedGraph . tx (). commit (); The createThreadedTx() method returns a new Graph object that represents this newly opened transaction. The graph object tx supports all of the methods that the original graph did, but does so without opening new transactions for each thread. This allows us to start multiple threads which all work concurrently in the same transaction and one of which finally commits the transaction when all threads have completed their work. JanusGraph relies on optimized concurrent data structures to support hundreds of concurrent threads running efficiently in a single transaction.","title":"Multi-Threaded Transactions"},{"location":"basics/transactions/#concurrent-algorithms","text":"Thread independent transactions started through createThreadedTx() are particularly useful when implementing concurrent graph algorithms. Most traversal or message-passing (ego-centric) like graph algorithms are embarrassingly parallel which means they can be parallelized and executed through multiple threads with little effort. Each of these threads can operate on a single Graph object returned by createThreadedTx() without blocking each other.","title":"Concurrent Algorithms"},{"location":"basics/transactions/#nested-transactions","text":"Another use case for thread independent transactions is nested transactions that ought to be independent from the surrounding transaction. For instance, assume a long running transactional job that has to create a new vertex with a unique name. Since enforcing unique names requires the acquisition of a lock (see Eventually-Consistent Storage Backends for more detail) and since the transaction is running for a long time, lock congestion and expensive transactional failures are likely. v1 = graph . addVertex () //Do many other things v2 = graph . addVertex () v2 . property ( \"uniqueName\" , \"foo\" ) v1 . addEdge ( \"related\" , v2 ) //Do many other things graph . tx (). commit () // This long-running tx might fail due to contention on its uniqueName lock One way around this is to create the vertex in a short, nested thread-independent transaction as demonstrated by the following pseudo code v1 = graph . addVertex () //Do many other things tx = graph . tx (). createThreadedTx () v2 = tx . addVertex () v2 . property ( \"uniqueName\" , \"foo\" ) tx . commit () // Any lock contention will be detected here v1 . addEdge ( \"related\" , g . V ( v2 ). next ()) // Need to load v2 into outer transaction //Do many other things graph . tx (). commit () // Can't fail due to uniqueName write lock contention involving v2","title":"Nested Transactions"},{"location":"basics/transactions/#common-transaction-handling-problems","text":"Transactions are started automatically with the first operation executed against the graph. One does NOT have to start a transaction manually. The method newTransaction is used to start multi-threaded transactions only. Transactions are automatically started under the TinkerPop semantics but not automatically terminated. Transactions must be terminated manually with commit() or rollback() . If a commit() transactions fails, it should be terminated manually with rollback() after catching the failure. Manual termination of transactions is necessary because only the user knows the transactional boundary. A transaction will attempt to maintain its state from the beginning of the transaction. This might lead to unexpected behavior in multi-threaded applications as illustrated in the following artificial example v = g . V ( 4 ). next () // Retrieve vertex, first action automatically starts transaction g . V ( v ). bothE () >> returns nothing , v has no edges //thread is idle for a few seconds, another thread adds edges to v g . V ( v ). bothE () >> still returns nothing because the transactional state from the beginning is maintained Such unexpected behavior is likely to occur in client-server applications where the server maintains multiple threads to answer client requests. It is therefore important to terminate the transaction after a unit of work (e.g. code snippet, query, etc). So, the example above should be: v = g . V ( 4 ). next () // Retrieve vertex, first action automatically starts transaction g . V ( v ). bothE () graph . tx (). commit () //thread is idle for a few seconds, another thread adds edges to v g . V ( v ). bothE () >> returns the newly added edge graph . tx (). commit () When using multi-threaded transactions via newTransaction all vertices and edges retrieved or created in the scope of that transaction are not available outside the scope of that transaction. Accessing such elements after the transaction has been closed will result in an exception. As demonstrated in the example above, such elements have to be explicitly refreshed in the new transaction using g.V(existingVertex) or g.E(existingEdge) .","title":"Common Transaction Handling Problems"},{"location":"basics/transactions/#transaction-configuration","text":"JanusGraph\u2019s JanusGraph.buildTransaction() method gives the user the ability to configure and start a new multi-threaded transaction against a JanusGraph . Hence, it is identical to JanusGraph.newTransaction() with additional configuration options. buildTransaction() returns a TransactionBuilder which allows the following aspects of a transaction to be configured: readOnly() - makes the transaction read-only and any attempt to modify the graph will result in an exception. enableBatchLoading() - enables batch-loading for an individual transaction. This setting results in similar efficiencies as the graph-wide setting storage.batch-loading due to the disabling of consistency checks and other optimizations. Unlike storage.batch-loading this option will not change the behavior of the storage backend. setTimestamp(long) - Sets the timestamp for this transaction as communicated to the storage backend for persistence. Depending on the storage backend, this setting may be ignored. For eventually consistent backends, this is the timestamp used to resolve write conflicts. If this setting is not explicitly specified, JanusGraph uses the current time. setVertexCacheSize(long size) - The number of vertices this transaction caches in memory. The larger this number, the more memory a transaction can potentially consume. If this number is too small, a transaction might have to re-fetch data which causes delays in particular for long running transactions. checkExternalVertexExistence(boolean) - Whether this transaction should verify the existence of vertices for user provided vertex ids. Such checks requires access to the database which takes time. The existence check should only be disabled if the user is absolutely sure that the vertex must exist - otherwise data corruption can ensue. checkInternalVertexExistence(boolean) - Whether this transaction should double-check the existence of vertices during query execution. This can be useful to avoid phantom vertices on eventually consistent storage backends. Disabled by default. Enabling this setting can slow down query processing. consistencyChecks(boolean) - Whether JanusGraph should enforce schema level consistency constraints (e.g. multiplicity constraints). Disabling consistency checks leads to better performance but requires that the user ensures consistency confirmation at the application level to avoid inconsistencies. USE WITH GREAT CARE! Once, the desired configuration options have been specified, the new transaction is started via start() which returns a JanusGraphTransaction .","title":"Transaction Configuration"},{"location":"connecting/","text":"JanusGraph can be queried from all languages for which a TinkerPop driver exists. Drivers allow sending of Gremlin traversals to a Gremlin Server like the JanusGraph Server . A list of TinkerPop drivers is available on TinkerPop\u2019s homepage . In addition to drivers, there exist query languages for TinkerPop that make it easier to use Gremlin in different programming languages like Java, Python, or C#. Some of these languages even construct Gremlin traversals from completely different query languages like Cypher or SPARQL. Since JanusGraph implements TinkerPop, all of these languages can be used together with JanusGraph.","title":"Introduction"},{"location":"connecting/dotnet/","text":"Connecting from .NET Gremlin traversals can be constructed with Gremlin.Net just like in Gremlin-Java or Gremiln-Groovy. Refer to Gremlin Query Language for an introduction to Gremlin and pointers to further resources. The main syntactical difference for Gremlin.Net is that it follows .NET naming conventions, e.g., method names use PascalCase instead of camelCase. Getting Started with JanusGraph and Gremlin.Net To get started with Gremlin.Net: Create a console application: dotnet new console -o GremlinExample Add Gremlin.Net: dotnet add package Gremlin.Net -v 3 .4.4 Create a GraphTraversalSource which is the basis for all Gremlin traversals: var graph = new Graph (); var client = new GremlinClient ( new GremlinServer ( \"localhost\" , 8182 )); // The client should be disposed on shut down to release resources // and to close open connections with client.Dispose() var g = graph . Traversal (). WithRemote ( new DriverRemoteConnection ( client )); // Reuse 'g' across the application Execute a simple traversal: var herculesAge = g . V (). Has ( \"name\" , \"hercules\" ). Values < int >( \"age\" ). Next (); Console . WriteLine ( $ \"Hercules is {herculesAge} years old.\" ); The traversal can also be executed asynchronously by using Promise() which is the recommended way as the underlying driver in Gremlin.Net also works asynchronously: var herculesAge = await g . V (). Has ( \"name\" , \"hercules\" ). Values < int >( \"age\" ). Promise ( t => t . Next ()); JanusGraph Specific Types and Predicates JanusGraph contains some types and predicates that are not part of Apache TinkerPop and are therefore also not supported by Gremlin.Net.","title":"Using .Net"},{"location":"connecting/dotnet/#connecting-from-net","text":"Gremlin traversals can be constructed with Gremlin.Net just like in Gremlin-Java or Gremiln-Groovy. Refer to Gremlin Query Language for an introduction to Gremlin and pointers to further resources. The main syntactical difference for Gremlin.Net is that it follows .NET naming conventions, e.g., method names use PascalCase instead of camelCase.","title":"Connecting from .NET"},{"location":"connecting/dotnet/#getting-started-with-janusgraph-and-gremlinnet","text":"To get started with Gremlin.Net: Create a console application: dotnet new console -o GremlinExample Add Gremlin.Net: dotnet add package Gremlin.Net -v 3 .4.4 Create a GraphTraversalSource which is the basis for all Gremlin traversals: var graph = new Graph (); var client = new GremlinClient ( new GremlinServer ( \"localhost\" , 8182 )); // The client should be disposed on shut down to release resources // and to close open connections with client.Dispose() var g = graph . Traversal (). WithRemote ( new DriverRemoteConnection ( client )); // Reuse 'g' across the application Execute a simple traversal: var herculesAge = g . V (). Has ( \"name\" , \"hercules\" ). Values < int >( \"age\" ). Next (); Console . WriteLine ( $ \"Hercules is {herculesAge} years old.\" ); The traversal can also be executed asynchronously by using Promise() which is the recommended way as the underlying driver in Gremlin.Net also works asynchronously: var herculesAge = await g . V (). Has ( \"name\" , \"hercules\" ). Values < int >( \"age\" ). Promise ( t => t . Next ());","title":"Getting Started with JanusGraph and Gremlin.Net"},{"location":"connecting/dotnet/#janusgraph-specific-types-and-predicates","text":"JanusGraph contains some types and predicates that are not part of Apache TinkerPop and are therefore also not supported by Gremlin.Net.","title":"JanusGraph Specific Types and Predicates"},{"location":"connecting/java/","text":"Connecting from Java While it is possible to embed JanusGraph as a library inside a Java application and then directly connect to the backend, this section assumes that the application connects to JanusGraph Server. For information on how to embed JanusGraph, see the JanusGraph Examples projects . This section only covers how applications can connect to JanusGraph Server. Refer to Gremlin Query Language for an introduction to Gremlin and pointers to further resources. Getting Started with JanusGraph and Gremlin-Java To get started with JanusGraph in Java: Create an application with Maven: mvn archetype:generate -DgroupId = com.mycompany.project -DartifactId = gremlin-example -DarchetypeArtifactId = maven-archetype-quickstart -DinteractiveMode = false Add dependencies on janusgraph-core and gremlin-driver to the dependency manager: Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.4.1 </version> </dependency> <dependency> <groupId> org.apache.tinkerpop </groupId> <artifactId> gremlin-driver </artifactId> <version> 3.4.4 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.4.1\" compile \"org.apache.tinkerpop:gremlin-driver:3.4.4\" Add two configuration files, conf/remote-graph.properties and conf/remote-objects.yaml : conf/remote-graph.properties gremlin.remote.remoteConnectionClass=org.apache.tinkerpop.gremlin.driver.remote.DriverRemoteConnection gremlin.remote.driver.clusterFile=conf/remote-objects.yaml gremlin.remote.driver.sourceName=g conf/remote-objects.yaml hosts : [ localhost ] port : 8182 serializer : { className : org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV1d0 , config : { ioRegistries : [ org.janusgraph.graphdb.tinkerpop.JanusGraphIoRegistry ] }} Create a GraphTraversalSource which is the basis for all Gremlin traversals: Graph graph = EmptyGraph . instance (); GraphTraversalSource g = graph . traversal (). withRemote ( \"conf/remote-graph.properties\" ); // Reuse 'g' across the application // and close it on shut-down to close open connections with g.close() Execute a simple traversal: Object herculesAge = g . V (). has ( \"name\" , \"hercules\" ). values ( \"age\" ). next (); System . out . println ( \"Hercules is \" + herculesAge + \" years old.\" ); next() is a terminal step that submits the traversal to the Gremlin Server and returns a single result. JanusGraph Specific Types and Predicates JanusGraph specific types and predicates can be used directly from a Java application through the dependency janusgraph-core .","title":"Using Java"},{"location":"connecting/java/#connecting-from-java","text":"While it is possible to embed JanusGraph as a library inside a Java application and then directly connect to the backend, this section assumes that the application connects to JanusGraph Server. For information on how to embed JanusGraph, see the JanusGraph Examples projects . This section only covers how applications can connect to JanusGraph Server. Refer to Gremlin Query Language for an introduction to Gremlin and pointers to further resources.","title":"Connecting from Java"},{"location":"connecting/java/#getting-started-with-janusgraph-and-gremlin-java","text":"To get started with JanusGraph in Java: Create an application with Maven: mvn archetype:generate -DgroupId = com.mycompany.project -DartifactId = gremlin-example -DarchetypeArtifactId = maven-archetype-quickstart -DinteractiveMode = false Add dependencies on janusgraph-core and gremlin-driver to the dependency manager: Maven <dependency> <groupId> org.janusgraph </groupId> <artifactId> janusgraph-core </artifactId> <version> 0.4.1 </version> </dependency> <dependency> <groupId> org.apache.tinkerpop </groupId> <artifactId> gremlin-driver </artifactId> <version> 3.4.4 </version> </dependency> Gradle compile \"org.janusgraph:janusgraph-core:0.4.1\" compile \"org.apache.tinkerpop:gremlin-driver:3.4.4\" Add two configuration files, conf/remote-graph.properties and conf/remote-objects.yaml : conf/remote-graph.properties gremlin.remote.remoteConnectionClass=org.apache.tinkerpop.gremlin.driver.remote.DriverRemoteConnection gremlin.remote.driver.clusterFile=conf/remote-objects.yaml gremlin.remote.driver.sourceName=g conf/remote-objects.yaml hosts : [ localhost ] port : 8182 serializer : { className : org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV1d0 , config : { ioRegistries : [ org.janusgraph.graphdb.tinkerpop.JanusGraphIoRegistry ] }} Create a GraphTraversalSource which is the basis for all Gremlin traversals: Graph graph = EmptyGraph . instance (); GraphTraversalSource g = graph . traversal (). withRemote ( \"conf/remote-graph.properties\" ); // Reuse 'g' across the application // and close it on shut-down to close open connections with g.close() Execute a simple traversal: Object herculesAge = g . V (). has ( \"name\" , \"hercules\" ). values ( \"age\" ). next (); System . out . println ( \"Hercules is \" + herculesAge + \" years old.\" ); next() is a terminal step that submits the traversal to the Gremlin Server and returns a single result.","title":"Getting Started with JanusGraph and Gremlin-Java"},{"location":"connecting/java/#janusgraph-specific-types-and-predicates","text":"JanusGraph specific types and predicates can be used directly from a Java application through the dependency janusgraph-core .","title":"JanusGraph Specific Types and Predicates"},{"location":"connecting/python/","text":"Connecting from Python Gremlin traversals can be constructed with Gremlin-Python just like in Gremlin-Java or Gremiln-Groovy. Refer to Gremlin Query Language for an introduction to Gremlin and pointers to further resources. Important Some Gremlin step and predicate names are reserved words in Python. Those names are simply postfixed with _ in Gremlin-Python, e.g., in() becomes in_() , not() becomes not_() , and so on. The other names affected by this are: all , and , as , from , global , is , list , or , and set . Getting Started with JanusGraph and Gremlin-Python To get started with Gremlin-Python: Install Gremlin-Python: pip install gremlinpython == 3 .4.4 Create a text file gremlinexample.py and add the following imports to it: from gremlin_python import statics from gremlin_python.structure.graph import Graph from gremlin_python.process.graph_traversal import __ from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection Create a GraphTraversalSource which is the basis for all Gremlin traversals: graph = Graph () connection = DriverRemoteConnection ( 'ws://localhost:8182/gremlin' , 'g' ) # The connection should be closed on shut down to close open connections with connection.close() g = graph . traversal () . withRemote ( connection ) # Reuse 'g' across the application Execute a simple traversal: herculesAge = g . V () . has ( 'name' , 'hercules' ) . values ( 'age' ) . next () print ( 'Hercules is {} years old.' . format ( herculesAge )) next() is a terminal step that submits the traversal to the Gremlin Server and returns a single result. JanusGraph Specific Types and Predicates JanusGraph contains some types and predicates that are not part of Apache TinkerPop and are therefore also not supported by Gremlin-Python.","title":"Using Python"},{"location":"connecting/python/#connecting-from-python","text":"Gremlin traversals can be constructed with Gremlin-Python just like in Gremlin-Java or Gremiln-Groovy. Refer to Gremlin Query Language for an introduction to Gremlin and pointers to further resources. Important Some Gremlin step and predicate names are reserved words in Python. Those names are simply postfixed with _ in Gremlin-Python, e.g., in() becomes in_() , not() becomes not_() , and so on. The other names affected by this are: all , and , as , from , global , is , list , or , and set .","title":"Connecting from Python"},{"location":"connecting/python/#getting-started-with-janusgraph-and-gremlin-python","text":"To get started with Gremlin-Python: Install Gremlin-Python: pip install gremlinpython == 3 .4.4 Create a text file gremlinexample.py and add the following imports to it: from gremlin_python import statics from gremlin_python.structure.graph import Graph from gremlin_python.process.graph_traversal import __ from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection Create a GraphTraversalSource which is the basis for all Gremlin traversals: graph = Graph () connection = DriverRemoteConnection ( 'ws://localhost:8182/gremlin' , 'g' ) # The connection should be closed on shut down to close open connections with connection.close() g = graph . traversal () . withRemote ( connection ) # Reuse 'g' across the application Execute a simple traversal: herculesAge = g . V () . has ( 'name' , 'hercules' ) . values ( 'age' ) . next () print ( 'Hercules is {} years old.' . format ( herculesAge )) next() is a terminal step that submits the traversal to the Gremlin Server and returns a single result.","title":"Getting Started with JanusGraph and Gremlin-Python"},{"location":"connecting/python/#janusgraph-specific-types-and-predicates","text":"JanusGraph contains some types and predicates that are not part of Apache TinkerPop and are therefore also not supported by Gremlin-Python.","title":"JanusGraph Specific Types and Predicates"},{"location":"getting-started/architecture/","text":"JanusGraph is a graph database engine. JanusGraph itself is focused on compact graph serialization, rich graph data modeling, and efficient query execution. In addition, JanusGraph utilizes Hadoop for graph analytics and batch graph processing. JanusGraph implements robust, modular interfaces for data persistence, data indexing, and client access. JanusGraph\u2019s modular architecture allows it to interoperate with a wide range of storage, index, and client technologies; it also eases the process of extending JanusGraph to support new ones. Between JanusGraph and the disks sits one or more storage and indexing adapters. JanusGraph comes standard with the following adapters, but JanusGraph\u2019s modular architecture supports third-party adapters. Data storage: Apache Cassandra Apache HBase Oracle Berkeley DB Java Edition Indices, which speed up and enable more complex queries: Elasticsearch Apache Solr Apache Lucene Broadly speaking, applications can interact with JanusGraph in two ways: Embed JanusGraph inside the application executing Gremlin queries directly against the graph within the same JVM. Query execution, JanusGraph\u2019s caches, and transaction handling all happen in the same JVM as the application while data retrieval from the storage backend may be local or remote. Interact with a local or remote JanusGraph instance by submitting Gremlin queries to the server. JanusGraph natively supports the Gremlin Server component of the Apache TinkerPop stack.","title":"Architectural Overview"},{"location":"getting-started/basic-usage/","text":"Basic Usage This section offers a very short introduction to Gremlin's feature set. For a closer look at the topic, refer to Gremlin Query Language . The examples in this section make extensive use of a toy graph distributed with JanusGraph called The Graph of the Gods . This graph is diagrammed below. The abstract data model is known as a Property Graph Model and this particular instance describes the relationships between the beings and places of the Roman pantheon. Moreover, special text and symbol modifiers in the diagram (e.g. bold, underline, etc.) denote different schematics/typings in the graph. visual symbol meaning bold key a graph indexed key bold key with star a graph indexed key that must have a unique value underlined key a vertex-centric indexed key hollow-head edge a functional/unique edge (no duplicates) tail-crossed edge a unidirectional edge (can only traverse in one direction) Loading the Graph of the Gods Into JanusGraph The example below will open a JanusGraph graph instance and load The Graph of the Gods dataset diagrammed above. JanusGraphFactory provides a set of static open methods, each of which takes a configuration as its argument and returns a graph instance. This tutorial calls one of these open methods on a configuration that uses the BerkeleyDB storage backend and the Elasticsearch index backend, then loads The Graph of the Gods using the helper class GraphOfTheGodsFactory . This section skips over the configuration details, but additional information about storage backends, index backends, and their configuration are available in Storage Backends , Index Backends , and Configuration Reference . gremlin > graph = JanusGraphFactory . open ( 'conf/janusgraph-berkeleyje-es.properties' ) ==> standardjanusgraph [ berkeleyje: .. /db/ berkeley ] gremlin > GraphOfTheGodsFactory . load ( graph ) ==> null gremlin > g = graph . traversal () ==> graphtraversalsource [ standardjanusgraph [ berkeleyje: .. /db/ berkeley ], standard ] The JanusGraphFactory.open() and GraphOfTheGodsFactory.load() methods do the following to the newly constructed graph prior to returning it: Creates a collection of global and vertex-centric indices on the graph. Adds all the vertices to the graph along with their properties. Adds all the edges to the graph along with their properties. Please see the GraphOfTheGodsFactory source code for details. For those using JanusGraph/Cassandra (or JanusGraph/HBase), be sure to make use of conf/janusgraph-cql-es.properties (or conf/janusgraph-hbase-es.properties ) and GraphOfTheGodsFactory.load() . gremlin > graph = JanusGraphFactory . open ( 'conf/janusgraph-cql-es.properties' ) ==> standardjanusgraph [ cql: [ 127.0 . 0.1 ]] gremlin > GraphOfTheGodsFactory . load ( graph ) ==> null gremlin > g = graph . traversal () ==> graphtraversalsource [ standardjanusgraph [ cql: [ 127.0 . 0.1 ]], standard ] You may also use the conf/janusgraph-cql.properties , conf/janusgraph-berkeleyje.properties , or conf/janusgraph-hbase.properties configuration files to open a graph without an indexing backend configured. In such cases, you will need to use the GraphOfTheGodsFactory.loadWithoutMixedIndex() method to load the Graph of the Gods so that it doesn\u2019t attempt to make use of an indexing backend. gremlin > graph = JanusGraphFactory . open ( 'conf/janusgraph-cql.properties' ) ==> standardjanusgraph [ cql: [ 127.0 . 0.1 ]] gremlin > GraphOfTheGodsFactory . loadWithoutMixedIndex ( graph , true ) ==> null gremlin > g = graph . traversal () ==> graphtraversalsource [ standardjanusgraph [ cql: [ 127.0 . 0.1 ]], standard ] Global Graph Indices The typical pattern for accessing data in a graph database is to first locate the entry point into the graph using a graph index. That entry point is an element (or set of elements)\u2009\u2014\u2009i.e. a vertex or edge. From the entry elements, a Gremlin path description describes how to traverse to other elements in the graph via the explicit graph structure. Given that there is a unique index on name property, the Saturn vertex can be retrieved. The property map (i.e. the key/value pairs of Saturn) can then be examined. As demonstrated, the Saturn vertex has a name of \"saturn, \" an age of 10000, and a type of \"titan.\" The grandchild of Saturn can be retrieved with a traversal that expresses: \"Who is Saturn\u2019s grandchild?\" (the inverse of \"father\" is \"child\"). The result is Hercules. gremlin > saturn = g . V (). has ( 'name' , 'saturn' ). next () ==> v [ 256 ] gremlin > g . V ( saturn ). valueMap () ==>[ name: [ saturn ], age: [ 10000 ]] gremlin > g . V ( saturn ). in ( 'father' ). in ( 'father' ). values ( 'name' ) ==> hercules The property place is also in a graph index. The property place is an edge property. Therefore, JanusGraph can index edges in a graph index. It is possible to query The Graph of the Gods for all events that have happened within 50 kilometers of Athens (latitude:37.97 and long:23.72). Then, given that information, which vertices were involved in those events. gremlin > g . E (). has ( 'place' , geoWithin ( Geoshape . circle ( 37.97 , 23.72 , 50 ))) ==> e [ a9x - co8 - 9 hx - 39 s ][ 16424 - battled -> 4240 ] ==> e [ 9 vp - co8 - 9 hx - 9 ns ][ 16424 - battled -> 12520 ] gremlin > g . E (). has ( 'place' , geoWithin ( Geoshape . circle ( 37.97 , 23.72 , 50 ))). as ( 'source' ). inV (). as ( 'god2' ). select ( 'source' ). outV (). as ( 'god1' ). select ( 'god1' , 'god2' ). by ( 'name' ) ==>[ god1: hercules , god2: hydra ] ==>[ god1: hercules , god2: nemean ] Graph indices are one type of index structure in JanusGraph. Graph indices are automatically chosen by JanusGraph to answer which ask for all vertices ( g.V ) or all edges ( g.E ) that satisfy one or multiple constraints (e.g. has or interval ). The second aspect of indexing in JanusGraph is known as vertex-centric indices. Vertex-centric indices are utilized to speed up traversals inside the graph. Vertex-centric indices are described later. Graph Traversal Examples Hercules , son of Jupiter and Alcmene , bore super human strength. Hercules was a Demigod because his father was a god and his mother was a human. Juno , wife of Jupiter, was furious with Jupiter\u2019s infidelity. In revenge, she blinded Hercules with temporary insanity and caused him to kill his wife and children. To atone for the slaying, Hercules was ordered by the Oracle of Delphi to serve Eurystheus . Eurystheus appointed Hercules to 12 labors. In the previous section, it was demonstrated that Saturn\u2019s grandchild was Hercules. This can be expressed using a loop . In essence, Hercules is the vertex that is 2-steps away from Saturn along the in('father') path. gremlin > hercules = g . V ( saturn ). repeat ( __ . in ( 'father' )). times ( 2 ). next () ==> v [ 1536 ] Hercules is a demigod. To prove that Hercules is half human and half god, his parent\u2019s origins must be examined. It is possible to traverse from the Hercules vertex to his mother and father. Finally, it is possible to determine the type of each of them\u2009\u2014\u2009yielding \"god\" and \"human.\" gremlin > g . V ( hercules ). out ( 'father' , 'mother' ) ==> v [ 1024 ] ==> v [ 1792 ] gremlin > g . V ( hercules ). out ( 'father' , 'mother' ). values ( 'name' ) ==> jupiter ==> alcmene gremlin > g . V ( hercules ). out ( 'father' , 'mother' ). label () ==> god ==> human gremlin > hercules . label () ==> demigod The examples thus far have been with respect to the genetic lines of the various actors in the Roman pantheon. The Property Graph Model is expressive enough to represent multiple types of things and relationships. In this way, The Graph of the Gods also identifies Hercules' various heroic exploits --- his famous 12 labors. In the previous section, it was discovered that Hercules was involved in two battles near Athens. It is possible to explore these events by traversing battled edges out of the Hercules vertex. gremlin > g . V ( hercules ). out ( 'battled' ) ==> v [ 2304 ] ==> v [ 2560 ] ==> v [ 2816 ] gremlin > g . V ( hercules ). out ( 'battled' ). valueMap () ==>[ name: [ nemean ]] ==>[ name: [ hydra ]] ==>[ name: [ cerberus ]] gremlin > g . V ( hercules ). outE ( 'battled' ). has ( 'time' , gt ( 1 )). inV (). values ( 'name' ) ==> cerberus ==> hydra The edge property time on battled edges is indexed by the vertex-centric indices of a vertex. Retrieving battled edges incident to Hercules according to a constraint/filter on time is faster than doing a linear scan of all edges and filtering (typically O(log n) , where n is the number incident edges). JanusGraph is intelligent enough to use vertex-centric indices when available. A toString() of a Gremlin expression shows a decomposition into individual steps. gremlin > g . V ( hercules ). outE ( 'battled' ). has ( 'time' , gt ( 1 )). inV (). values ( 'name' ). toString () ==>[ GraphStep ([ v [ 24744 ]], vertex ), VertexStep ( OUT ,[ battled ], edge ), HasStep ([ time . gt ( 1 )]), EdgeVertexStep ( IN ), PropertiesStep ([ name ], value )] More Complex Graph Traversal Examples In the depths of Tartarus lives Pluto. His relationship with Hercules was strained by the fact that Hercules battled his pet, Cerberus. However, Hercules is his nephew\u2009\u2014\u2009how should he make Hercules pay for his insolence? The Gremlin traversals below provide more examples over The Graph of the Gods . The explanation of each traversal is provided in the prior line as a // comment. Cohabitors of Tartarus gremlin > pluto = g . V (). has ( 'name' , 'pluto' ). next () ==> v [ 2048 ] gremlin > // who are pluto's cohabitants? gremlin > g . V ( pluto ). out ( 'lives' ). in ( 'lives' ). values ( 'name' ) ==> pluto ==> cerberus gremlin > // pluto can't be his own cohabitant gremlin > g . V ( pluto ). out ( 'lives' ). in ( 'lives' ). where ( is ( neq ( pluto ))). values ( 'name' ) ==> cerberus gremlin > g . V ( pluto ). as ( 'x' ). out ( 'lives' ). in ( 'lives' ). where ( neq ( 'x' )). values ( 'name' ) ==> cerberus Pluto\u2019s Brothers gremlin > // where do pluto's brothers live? gremlin > g . V ( pluto ). out ( 'brother' ). out ( 'lives' ). values ( 'name' ) ==> sky ==> sea gremlin > // which brother lives in which place? gremlin > g . V ( pluto ). out ( 'brother' ). as ( 'god' ). out ( 'lives' ). as ( 'place' ). select ( 'god' , 'place' ) ==>[ god: v [ 1024 ], place: v [ 512 ]] ==>[ god: v [ 1280 ], place: v [ 768 ]] gremlin > // what is the name of the brother and the name of the place? gremlin > g . V ( pluto ). out ( 'brother' ). as ( 'god' ). out ( 'lives' ). as ( 'place' ). select ( 'god' , 'place' ). by ( 'name' ) ==>[ god: jupiter , place: sky ] ==>[ god: neptune , place: sea ] Finally, Pluto lives in Tartarus because he shows no concern for death. His brothers, on the other hand, chose their locations based upon their love for certain qualities of those locations.! gremlin > g . V ( pluto ). outE ( 'lives' ). values ( 'reason' ) ==> no fear of death gremlin > g . E (). has ( 'reason' , textContains ( 'loves' )) ==> e [ 6 xs - sg - m51 - e8 ][ 1024 - lives -> 512 ] ==> e [ 70 g - zk - m51 - lc ][ 1280 - lives -> 768 ] gremlin > g . E (). has ( 'reason' , textContains ( 'loves' )). as ( 'source' ). values ( 'reason' ). as ( 'reason' ). select ( 'source' ). outV (). values ( 'name' ). as ( 'god' ). select ( 'source' ). inV (). values ( 'name' ). as ( 'thing' ). select ( 'god' , 'reason' , 'thing' ) ==>[ god: neptune , reason: loves waves , thing: sea ] ==>[ god: jupiter , reason: loves fresh breezes , thing: sky ]","title":"Basic Usage"},{"location":"getting-started/basic-usage/#basic-usage","text":"This section offers a very short introduction to Gremlin's feature set. For a closer look at the topic, refer to Gremlin Query Language . The examples in this section make extensive use of a toy graph distributed with JanusGraph called The Graph of the Gods . This graph is diagrammed below. The abstract data model is known as a Property Graph Model and this particular instance describes the relationships between the beings and places of the Roman pantheon. Moreover, special text and symbol modifiers in the diagram (e.g. bold, underline, etc.) denote different schematics/typings in the graph. visual symbol meaning bold key a graph indexed key bold key with star a graph indexed key that must have a unique value underlined key a vertex-centric indexed key hollow-head edge a functional/unique edge (no duplicates) tail-crossed edge a unidirectional edge (can only traverse in one direction)","title":"Basic Usage"},{"location":"getting-started/basic-usage/#loading-the-graph-of-the-gods-into-janusgraph","text":"The example below will open a JanusGraph graph instance and load The Graph of the Gods dataset diagrammed above. JanusGraphFactory provides a set of static open methods, each of which takes a configuration as its argument and returns a graph instance. This tutorial calls one of these open methods on a configuration that uses the BerkeleyDB storage backend and the Elasticsearch index backend, then loads The Graph of the Gods using the helper class GraphOfTheGodsFactory . This section skips over the configuration details, but additional information about storage backends, index backends, and their configuration are available in Storage Backends , Index Backends , and Configuration Reference . gremlin > graph = JanusGraphFactory . open ( 'conf/janusgraph-berkeleyje-es.properties' ) ==> standardjanusgraph [ berkeleyje: .. /db/ berkeley ] gremlin > GraphOfTheGodsFactory . load ( graph ) ==> null gremlin > g = graph . traversal () ==> graphtraversalsource [ standardjanusgraph [ berkeleyje: .. /db/ berkeley ], standard ] The JanusGraphFactory.open() and GraphOfTheGodsFactory.load() methods do the following to the newly constructed graph prior to returning it: Creates a collection of global and vertex-centric indices on the graph. Adds all the vertices to the graph along with their properties. Adds all the edges to the graph along with their properties. Please see the GraphOfTheGodsFactory source code for details. For those using JanusGraph/Cassandra (or JanusGraph/HBase), be sure to make use of conf/janusgraph-cql-es.properties (or conf/janusgraph-hbase-es.properties ) and GraphOfTheGodsFactory.load() . gremlin > graph = JanusGraphFactory . open ( 'conf/janusgraph-cql-es.properties' ) ==> standardjanusgraph [ cql: [ 127.0 . 0.1 ]] gremlin > GraphOfTheGodsFactory . load ( graph ) ==> null gremlin > g = graph . traversal () ==> graphtraversalsource [ standardjanusgraph [ cql: [ 127.0 . 0.1 ]], standard ] You may also use the conf/janusgraph-cql.properties , conf/janusgraph-berkeleyje.properties , or conf/janusgraph-hbase.properties configuration files to open a graph without an indexing backend configured. In such cases, you will need to use the GraphOfTheGodsFactory.loadWithoutMixedIndex() method to load the Graph of the Gods so that it doesn\u2019t attempt to make use of an indexing backend. gremlin > graph = JanusGraphFactory . open ( 'conf/janusgraph-cql.properties' ) ==> standardjanusgraph [ cql: [ 127.0 . 0.1 ]] gremlin > GraphOfTheGodsFactory . loadWithoutMixedIndex ( graph , true ) ==> null gremlin > g = graph . traversal () ==> graphtraversalsource [ standardjanusgraph [ cql: [ 127.0 . 0.1 ]], standard ]","title":"Loading the Graph of the Gods Into JanusGraph"},{"location":"getting-started/basic-usage/#global-graph-indices","text":"The typical pattern for accessing data in a graph database is to first locate the entry point into the graph using a graph index. That entry point is an element (or set of elements)\u2009\u2014\u2009i.e. a vertex or edge. From the entry elements, a Gremlin path description describes how to traverse to other elements in the graph via the explicit graph structure. Given that there is a unique index on name property, the Saturn vertex can be retrieved. The property map (i.e. the key/value pairs of Saturn) can then be examined. As demonstrated, the Saturn vertex has a name of \"saturn, \" an age of 10000, and a type of \"titan.\" The grandchild of Saturn can be retrieved with a traversal that expresses: \"Who is Saturn\u2019s grandchild?\" (the inverse of \"father\" is \"child\"). The result is Hercules. gremlin > saturn = g . V (). has ( 'name' , 'saturn' ). next () ==> v [ 256 ] gremlin > g . V ( saturn ). valueMap () ==>[ name: [ saturn ], age: [ 10000 ]] gremlin > g . V ( saturn ). in ( 'father' ). in ( 'father' ). values ( 'name' ) ==> hercules The property place is also in a graph index. The property place is an edge property. Therefore, JanusGraph can index edges in a graph index. It is possible to query The Graph of the Gods for all events that have happened within 50 kilometers of Athens (latitude:37.97 and long:23.72). Then, given that information, which vertices were involved in those events. gremlin > g . E (). has ( 'place' , geoWithin ( Geoshape . circle ( 37.97 , 23.72 , 50 ))) ==> e [ a9x - co8 - 9 hx - 39 s ][ 16424 - battled -> 4240 ] ==> e [ 9 vp - co8 - 9 hx - 9 ns ][ 16424 - battled -> 12520 ] gremlin > g . E (). has ( 'place' , geoWithin ( Geoshape . circle ( 37.97 , 23.72 , 50 ))). as ( 'source' ). inV (). as ( 'god2' ). select ( 'source' ). outV (). as ( 'god1' ). select ( 'god1' , 'god2' ). by ( 'name' ) ==>[ god1: hercules , god2: hydra ] ==>[ god1: hercules , god2: nemean ] Graph indices are one type of index structure in JanusGraph. Graph indices are automatically chosen by JanusGraph to answer which ask for all vertices ( g.V ) or all edges ( g.E ) that satisfy one or multiple constraints (e.g. has or interval ). The second aspect of indexing in JanusGraph is known as vertex-centric indices. Vertex-centric indices are utilized to speed up traversals inside the graph. Vertex-centric indices are described later.","title":"Global Graph Indices"},{"location":"getting-started/basic-usage/#graph-traversal-examples","text":"Hercules , son of Jupiter and Alcmene , bore super human strength. Hercules was a Demigod because his father was a god and his mother was a human. Juno , wife of Jupiter, was furious with Jupiter\u2019s infidelity. In revenge, she blinded Hercules with temporary insanity and caused him to kill his wife and children. To atone for the slaying, Hercules was ordered by the Oracle of Delphi to serve Eurystheus . Eurystheus appointed Hercules to 12 labors. In the previous section, it was demonstrated that Saturn\u2019s grandchild was Hercules. This can be expressed using a loop . In essence, Hercules is the vertex that is 2-steps away from Saturn along the in('father') path. gremlin > hercules = g . V ( saturn ). repeat ( __ . in ( 'father' )). times ( 2 ). next () ==> v [ 1536 ] Hercules is a demigod. To prove that Hercules is half human and half god, his parent\u2019s origins must be examined. It is possible to traverse from the Hercules vertex to his mother and father. Finally, it is possible to determine the type of each of them\u2009\u2014\u2009yielding \"god\" and \"human.\" gremlin > g . V ( hercules ). out ( 'father' , 'mother' ) ==> v [ 1024 ] ==> v [ 1792 ] gremlin > g . V ( hercules ). out ( 'father' , 'mother' ). values ( 'name' ) ==> jupiter ==> alcmene gremlin > g . V ( hercules ). out ( 'father' , 'mother' ). label () ==> god ==> human gremlin > hercules . label () ==> demigod The examples thus far have been with respect to the genetic lines of the various actors in the Roman pantheon. The Property Graph Model is expressive enough to represent multiple types of things and relationships. In this way, The Graph of the Gods also identifies Hercules' various heroic exploits --- his famous 12 labors. In the previous section, it was discovered that Hercules was involved in two battles near Athens. It is possible to explore these events by traversing battled edges out of the Hercules vertex. gremlin > g . V ( hercules ). out ( 'battled' ) ==> v [ 2304 ] ==> v [ 2560 ] ==> v [ 2816 ] gremlin > g . V ( hercules ). out ( 'battled' ). valueMap () ==>[ name: [ nemean ]] ==>[ name: [ hydra ]] ==>[ name: [ cerberus ]] gremlin > g . V ( hercules ). outE ( 'battled' ). has ( 'time' , gt ( 1 )). inV (). values ( 'name' ) ==> cerberus ==> hydra The edge property time on battled edges is indexed by the vertex-centric indices of a vertex. Retrieving battled edges incident to Hercules according to a constraint/filter on time is faster than doing a linear scan of all edges and filtering (typically O(log n) , where n is the number incident edges). JanusGraph is intelligent enough to use vertex-centric indices when available. A toString() of a Gremlin expression shows a decomposition into individual steps. gremlin > g . V ( hercules ). outE ( 'battled' ). has ( 'time' , gt ( 1 )). inV (). values ( 'name' ). toString () ==>[ GraphStep ([ v [ 24744 ]], vertex ), VertexStep ( OUT ,[ battled ], edge ), HasStep ([ time . gt ( 1 )]), EdgeVertexStep ( IN ), PropertiesStep ([ name ], value )]","title":"Graph Traversal Examples"},{"location":"getting-started/basic-usage/#more-complex-graph-traversal-examples","text":"In the depths of Tartarus lives Pluto. His relationship with Hercules was strained by the fact that Hercules battled his pet, Cerberus. However, Hercules is his nephew\u2009\u2014\u2009how should he make Hercules pay for his insolence? The Gremlin traversals below provide more examples over The Graph of the Gods . The explanation of each traversal is provided in the prior line as a // comment.","title":"More Complex Graph Traversal Examples"},{"location":"getting-started/basic-usage/#cohabitors-of-tartarus","text":"gremlin > pluto = g . V (). has ( 'name' , 'pluto' ). next () ==> v [ 2048 ] gremlin > // who are pluto's cohabitants? gremlin > g . V ( pluto ). out ( 'lives' ). in ( 'lives' ). values ( 'name' ) ==> pluto ==> cerberus gremlin > // pluto can't be his own cohabitant gremlin > g . V ( pluto ). out ( 'lives' ). in ( 'lives' ). where ( is ( neq ( pluto ))). values ( 'name' ) ==> cerberus gremlin > g . V ( pluto ). as ( 'x' ). out ( 'lives' ). in ( 'lives' ). where ( neq ( 'x' )). values ( 'name' ) ==> cerberus","title":"Cohabitors of Tartarus"},{"location":"getting-started/basic-usage/#plutos-brothers","text":"gremlin > // where do pluto's brothers live? gremlin > g . V ( pluto ). out ( 'brother' ). out ( 'lives' ). values ( 'name' ) ==> sky ==> sea gremlin > // which brother lives in which place? gremlin > g . V ( pluto ). out ( 'brother' ). as ( 'god' ). out ( 'lives' ). as ( 'place' ). select ( 'god' , 'place' ) ==>[ god: v [ 1024 ], place: v [ 512 ]] ==>[ god: v [ 1280 ], place: v [ 768 ]] gremlin > // what is the name of the brother and the name of the place? gremlin > g . V ( pluto ). out ( 'brother' ). as ( 'god' ). out ( 'lives' ). as ( 'place' ). select ( 'god' , 'place' ). by ( 'name' ) ==>[ god: jupiter , place: sky ] ==>[ god: neptune , place: sea ] Finally, Pluto lives in Tartarus because he shows no concern for death. His brothers, on the other hand, chose their locations based upon their love for certain qualities of those locations.! gremlin > g . V ( pluto ). outE ( 'lives' ). values ( 'reason' ) ==> no fear of death gremlin > g . E (). has ( 'reason' , textContains ( 'loves' )) ==> e [ 6 xs - sg - m51 - e8 ][ 1024 - lives -> 512 ] ==> e [ 70 g - zk - m51 - lc ][ 1280 - lives -> 768 ] gremlin > g . E (). has ( 'reason' , textContains ( 'loves' )). as ( 'source' ). values ( 'reason' ). as ( 'reason' ). select ( 'source' ). outV (). values ( 'name' ). as ( 'god' ). select ( 'source' ). inV (). values ( 'name' ). as ( 'thing' ). select ( 'god' , 'reason' , 'thing' ) ==>[ god: neptune , reason: loves waves , thing: sea ] ==>[ god: jupiter , reason: loves fresh breezes , thing: sky ]","title":"Pluto\u2019s Brothers"},{"location":"getting-started/installation/","text":"Installation Running JanusGraph inside a Docker container For virtualization and easy access, JanusGraph provides a Docker image . Docker makes it easier to run servers and clients on a single machine without dealing with multiple installations. For instructions on installing and using Docker, please refer to the docker guide . Let's try running a simple JanusGraph instance in Docker: $ docker run -it -p 8182 :8182 janusgraph/janusgraph We run the image interactively and request Docker to make the container's port 8182 available for us to see. The server may need a few seconds to start up so be patient and wait for the corresponding log messages to appear. Example log SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/opt/janusgraph/lib/slf4j-log4j12-1.7.12.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/opt/janusgraph/lib/logback-classic-1.1.3.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] 0 [main] INFO com.jcabi.manifests.Manifests - 110 attributes loaded from 283 stream(s) in 130ms, 110 saved, 3770 ignored: [\"Agent-Class\", \"Ant-Version\", \"Archiver-Version\", \"Automatic-Module-Name\", \"Bnd-LastModified\", \"Boot-Class-Path\", \"Branch\", \"Build-Date\", \"Build-Host\", \"Build-Id\", \"Build-Java-Version\", \"Build-Jdk\", \"Build-Job\", \"Build-Number\", \"Build-Timestamp\", \"Build-Version\", \"Built-At\", \"Built-By\", \"Built-Date\", \"Built-OS\", \"Built-On\", \"Built-Status\", \"Bundle-ActivationPolicy\", \"Bundle-Activator\", \"Bundle-BuddyPolicy\", \"Bundle-Category\", \"Bundle-ClassPath\", \"Bundle-ContactAddress\", \"Bundle-Description\", \"Bundle-DocURL\", \"Bundle-License\", \"Bundle-ManifestVersion\", \"Bundle-Name\", \"Bundle-NativeCode\", \"Bundle-RequiredExecutionEnvironment\", \"Bundle-SymbolicName\", \"Bundle-Vendor\", \"Bundle-Version\", \"Can-Redefine-Classes\", \"Change\", \"Class-Path\", \"Created-By\", \"DSTAMP\", \"DynamicImport-Package\", \"Eclipse-BuddyPolicy\", \"Eclipse-ExtensibleAPI\", \"Embed-Dependency\", \"Embed-Transitive\", \"Export-Package\", \"Extension-Name\", \"Extension-name\", \"Fragment-Host\", \"Gradle-Version\", \"Gremlin-Lib-Paths\", \"Gremlin-Plugin-Dependencies\", \"Gremlin-Plugin-Paths\", \"Ignore-Package\", \"Implementation-Build\", \"Implementation-Build-Date\", \"Implementation-Title\", \"Implementation-URL\", \"Implementation-Vendor\", \"Implementation-Vendor-Id\", \"Implementation-Version\", \"Import-Package\", \"Include-Resource\", \"JCabi-Build\", \"JCabi-Date\", \"JCabi-Version\", \"Java-Vendor\", \"Java-Version\", \"Main-Class\", \"Manifest-Version\", \"Maven-Version\", \"Module-Email\", \"Module-Origin\", \"Module-Owner\", \"Module-Source\", \"Originally-Created-By\", \"Os-Arch\", \"Os-Name\", \"Os-Version\", \"Package\", \"Premain-Class\", \"Private-Package\", \"Provide-Capability\", \"Require-Bundle\", \"Require-Capability\", \"Scm-Connection\", \"Scm-Revision\", \"Scm-Url\", \"Specification-Title\", \"Specification-Vendor\", \"Specification-Version\", \"TODAY\", \"TSTAMP\", \"Time-Zone-Database-Version\", \"Tool\", \"X-Compile-Elasticsearch-Snapshot\", \"X-Compile-Elasticsearch-Version\", \"X-Compile-Lucene-Version\", \"X-Compile-Source-JDK\", \"X-Compile-Target-JDK\", \"hash\", \"implementation-version\", \"mode\", \"package\", \"service\", \"url\", \"version\"] 1 [main] INFO org.apache.tinkerpop.gremlin.server.GremlinServer - 3.4.1 \\,,,/ (o o) -----oOOo-(3)-oOOo----- 100 [main] INFO org.apache.tinkerpop.gremlin.server.GremlinServer - Configuring Gremlin Server from /etc/opt/janusgraph/gremlin-server.yaml ... ... 3965 [gremlin-server-boss-1] INFO org.apache.tinkerpop.gremlin.server.GremlinServer - Gremlin Server configured with worker thread pool of 1, gremlin pool of 8 and boss thread pool of 1. 3965 [gremlin-server-boss-1] INFO org.apache.tinkerpop.gremlin.server.GremlinServer - Channel started at port 8182. We can now start a Gremlin Console on our local device and try to connect to the new server: $ bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- gremlin> :remote connect tinkerpop.server conf/remote.yaml == >Configured localhost/127.0.0.1:8182 Notice that the client side of this works exactly the same as before when running both the client and server locally without Docker. Conveniently, it's also possible to run both the server and the client within separate Docker containers. We therefore instantiate a container for the server: $ docker run --name janusgraph-default janusgraph/janusgraph:latest We can now instruct Docker to start a second container for the client and link it to the already running server. $ docker run --rm --link janusgraph-default:janusgraph -e GREMLIN_REMOTE_HOSTS = janusgraph \\ -it janusgraph/janusgraph:latest ./bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- gremlin> :remote connect tinkerpop.server conf/remote.yaml == >Configured janusgraph/172.17.0.2:8182 Notice how it's not necessary to bind any ports in order to make this example work. For further reading, see the JanusGraph Server section as well as the JanusGraph Docker documentation . Local Installation In order to run JanusGraph, Java 8 SE is required. Make sure the $JAVA_HOME environment variable points to the correct location where either JRE or JDK is installed. JanusGraph can be downloaded as a .zip archive from the Releases section of the project repository. $ unzip janusgraph-0.4.1-hadoop2.zip Archive: janusgraph-0.4.1-hadoop2.zip creating: janusgraph-0.4.1-hadoop2/ ... Once you have unzipped the downloaded archive, you are ready to go. Running the Gremlin Console The Gremlin Console is an interactive shell that gives you access to the data managed by JanusGraph. You can reach it by running the gremlin.sh script which is located in the project's bin directory. $ cd janusgraph-0.4.1-hadoop2 $ bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- 09 :12:24 INFO org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph - HADOOP_GREMLIN_LIBS is set to: /usr/local/janusgraph/lib plugin activated: tinkerpop.hadoop plugin activated: janusgraph.imports gremlin> The Gremlin Console interprets commands using Apache Groovy , which is a superset of Java. Gremlin-Groovy extends Groovy by providing a set of methods for basic and advanced graph traversal funcionality. For a deeper dive into Gremlin language's features, please refer to our introduction to Gremlin . Running the Gremlin Server In most real-world use cases, queries to a database will not be run from the exact same server the data is stored on. Instead, there will be some sort of client-server hierarchy in which the server runs the database and handles requests while multiple clients create these requests and thereby read and write entries within the database independently of one another. This behavior can also be achieved with JanusGraph. In order to start a server on your local machine, simply run the gremlin-server.sh script instead of the gremlin.sh script. You can optionally pass a configuration file as a parameter. The default configuration is located at conf/gremlin-server/gremlin-server.yaml . $ ./bin/gremlin-server.sh start or $ ./bin/gremlin-server.sh /conf/gremlin-server/ [ ... ] .yaml Info By default, JanusGraph will try to use a CQL-compatible storage backend. To use another backend, the following line within the earlier mentioned default configuration must be altered: graphs : { graph : conf/gremlin-server/janusgraph-cql-es-server.properties } To get started, the non-persistent inmemory backend provided by conf/janusgraph-inmemory.properties is the easiest option to use. For further information about storage backends, visit the corresponding section of the documentation. You are also encouraged to look into janusgraph.sh , which by defaults starts a more sophisticated server than gremlin-server.sh . Further documentation on server configuration can be found in the JanusGraph Server section. A Gremlin server is now running on your local machine and waiting for clients to connect on the default port 8182 . To instantiate a client -- as done before -- run the gremlin.sh script. Again, a local Gremlin Console will show up. This time, instead of using it locally, we will connect the Gremlin Console to a remote server and redirect all of it's queries to this server. This is done by using the :remote command: gremlin> :remote connect tinkerpop.server conf/remote.yaml == >Configured localhost/127.0.0.1:8182 As you can probably tell from the log, the client and server are running on the same machine in this case. When using a different setup, all you have to do is modify the parameters in the conf/remote.yaml file. Warning The above command only establishes the connection to the server. It does not forward the following commands to the server by default! As a result, further commands will still be executed locally unless preceeded by :> . To forward every command to the remote server, use the :remote console command. Further documentation can be found in the TinkerPop reference docs","title":"Installation"},{"location":"getting-started/installation/#installation","text":"","title":"Installation"},{"location":"getting-started/installation/#running-janusgraph-inside-a-docker-container","text":"For virtualization and easy access, JanusGraph provides a Docker image . Docker makes it easier to run servers and clients on a single machine without dealing with multiple installations. For instructions on installing and using Docker, please refer to the docker guide . Let's try running a simple JanusGraph instance in Docker: $ docker run -it -p 8182 :8182 janusgraph/janusgraph We run the image interactively and request Docker to make the container's port 8182 available for us to see. The server may need a few seconds to start up so be patient and wait for the corresponding log messages to appear. Example log SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/opt/janusgraph/lib/slf4j-log4j12-1.7.12.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/opt/janusgraph/lib/logback-classic-1.1.3.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory] 0 [main] INFO com.jcabi.manifests.Manifests - 110 attributes loaded from 283 stream(s) in 130ms, 110 saved, 3770 ignored: [\"Agent-Class\", \"Ant-Version\", \"Archiver-Version\", \"Automatic-Module-Name\", \"Bnd-LastModified\", \"Boot-Class-Path\", \"Branch\", \"Build-Date\", \"Build-Host\", \"Build-Id\", \"Build-Java-Version\", \"Build-Jdk\", \"Build-Job\", \"Build-Number\", \"Build-Timestamp\", \"Build-Version\", \"Built-At\", \"Built-By\", \"Built-Date\", \"Built-OS\", \"Built-On\", \"Built-Status\", \"Bundle-ActivationPolicy\", \"Bundle-Activator\", \"Bundle-BuddyPolicy\", \"Bundle-Category\", \"Bundle-ClassPath\", \"Bundle-ContactAddress\", \"Bundle-Description\", \"Bundle-DocURL\", \"Bundle-License\", \"Bundle-ManifestVersion\", \"Bundle-Name\", \"Bundle-NativeCode\", \"Bundle-RequiredExecutionEnvironment\", \"Bundle-SymbolicName\", \"Bundle-Vendor\", \"Bundle-Version\", \"Can-Redefine-Classes\", \"Change\", \"Class-Path\", \"Created-By\", \"DSTAMP\", \"DynamicImport-Package\", \"Eclipse-BuddyPolicy\", \"Eclipse-ExtensibleAPI\", \"Embed-Dependency\", \"Embed-Transitive\", \"Export-Package\", \"Extension-Name\", \"Extension-name\", \"Fragment-Host\", \"Gradle-Version\", \"Gremlin-Lib-Paths\", \"Gremlin-Plugin-Dependencies\", \"Gremlin-Plugin-Paths\", \"Ignore-Package\", \"Implementation-Build\", \"Implementation-Build-Date\", \"Implementation-Title\", \"Implementation-URL\", \"Implementation-Vendor\", \"Implementation-Vendor-Id\", \"Implementation-Version\", \"Import-Package\", \"Include-Resource\", \"JCabi-Build\", \"JCabi-Date\", \"JCabi-Version\", \"Java-Vendor\", \"Java-Version\", \"Main-Class\", \"Manifest-Version\", \"Maven-Version\", \"Module-Email\", \"Module-Origin\", \"Module-Owner\", \"Module-Source\", \"Originally-Created-By\", \"Os-Arch\", \"Os-Name\", \"Os-Version\", \"Package\", \"Premain-Class\", \"Private-Package\", \"Provide-Capability\", \"Require-Bundle\", \"Require-Capability\", \"Scm-Connection\", \"Scm-Revision\", \"Scm-Url\", \"Specification-Title\", \"Specification-Vendor\", \"Specification-Version\", \"TODAY\", \"TSTAMP\", \"Time-Zone-Database-Version\", \"Tool\", \"X-Compile-Elasticsearch-Snapshot\", \"X-Compile-Elasticsearch-Version\", \"X-Compile-Lucene-Version\", \"X-Compile-Source-JDK\", \"X-Compile-Target-JDK\", \"hash\", \"implementation-version\", \"mode\", \"package\", \"service\", \"url\", \"version\"] 1 [main] INFO org.apache.tinkerpop.gremlin.server.GremlinServer - 3.4.1 \\,,,/ (o o) -----oOOo-(3)-oOOo----- 100 [main] INFO org.apache.tinkerpop.gremlin.server.GremlinServer - Configuring Gremlin Server from /etc/opt/janusgraph/gremlin-server.yaml ... ... 3965 [gremlin-server-boss-1] INFO org.apache.tinkerpop.gremlin.server.GremlinServer - Gremlin Server configured with worker thread pool of 1, gremlin pool of 8 and boss thread pool of 1. 3965 [gremlin-server-boss-1] INFO org.apache.tinkerpop.gremlin.server.GremlinServer - Channel started at port 8182. We can now start a Gremlin Console on our local device and try to connect to the new server: $ bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- gremlin> :remote connect tinkerpop.server conf/remote.yaml == >Configured localhost/127.0.0.1:8182 Notice that the client side of this works exactly the same as before when running both the client and server locally without Docker. Conveniently, it's also possible to run both the server and the client within separate Docker containers. We therefore instantiate a container for the server: $ docker run --name janusgraph-default janusgraph/janusgraph:latest We can now instruct Docker to start a second container for the client and link it to the already running server. $ docker run --rm --link janusgraph-default:janusgraph -e GREMLIN_REMOTE_HOSTS = janusgraph \\ -it janusgraph/janusgraph:latest ./bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- gremlin> :remote connect tinkerpop.server conf/remote.yaml == >Configured janusgraph/172.17.0.2:8182 Notice how it's not necessary to bind any ports in order to make this example work. For further reading, see the JanusGraph Server section as well as the JanusGraph Docker documentation .","title":"Running JanusGraph inside a Docker container"},{"location":"getting-started/installation/#local-installation","text":"In order to run JanusGraph, Java 8 SE is required. Make sure the $JAVA_HOME environment variable points to the correct location where either JRE or JDK is installed. JanusGraph can be downloaded as a .zip archive from the Releases section of the project repository. $ unzip janusgraph-0.4.1-hadoop2.zip Archive: janusgraph-0.4.1-hadoop2.zip creating: janusgraph-0.4.1-hadoop2/ ... Once you have unzipped the downloaded archive, you are ready to go.","title":"Local Installation"},{"location":"getting-started/installation/#running-the-gremlin-console","text":"The Gremlin Console is an interactive shell that gives you access to the data managed by JanusGraph. You can reach it by running the gremlin.sh script which is located in the project's bin directory. $ cd janusgraph-0.4.1-hadoop2 $ bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- 09 :12:24 INFO org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph - HADOOP_GREMLIN_LIBS is set to: /usr/local/janusgraph/lib plugin activated: tinkerpop.hadoop plugin activated: janusgraph.imports gremlin> The Gremlin Console interprets commands using Apache Groovy , which is a superset of Java. Gremlin-Groovy extends Groovy by providing a set of methods for basic and advanced graph traversal funcionality. For a deeper dive into Gremlin language's features, please refer to our introduction to Gremlin .","title":"Running the Gremlin Console"},{"location":"getting-started/installation/#running-the-gremlin-server","text":"In most real-world use cases, queries to a database will not be run from the exact same server the data is stored on. Instead, there will be some sort of client-server hierarchy in which the server runs the database and handles requests while multiple clients create these requests and thereby read and write entries within the database independently of one another. This behavior can also be achieved with JanusGraph. In order to start a server on your local machine, simply run the gremlin-server.sh script instead of the gremlin.sh script. You can optionally pass a configuration file as a parameter. The default configuration is located at conf/gremlin-server/gremlin-server.yaml . $ ./bin/gremlin-server.sh start or $ ./bin/gremlin-server.sh /conf/gremlin-server/ [ ... ] .yaml Info By default, JanusGraph will try to use a CQL-compatible storage backend. To use another backend, the following line within the earlier mentioned default configuration must be altered: graphs : { graph : conf/gremlin-server/janusgraph-cql-es-server.properties } To get started, the non-persistent inmemory backend provided by conf/janusgraph-inmemory.properties is the easiest option to use. For further information about storage backends, visit the corresponding section of the documentation. You are also encouraged to look into janusgraph.sh , which by defaults starts a more sophisticated server than gremlin-server.sh . Further documentation on server configuration can be found in the JanusGraph Server section. A Gremlin server is now running on your local machine and waiting for clients to connect on the default port 8182 . To instantiate a client -- as done before -- run the gremlin.sh script. Again, a local Gremlin Console will show up. This time, instead of using it locally, we will connect the Gremlin Console to a remote server and redirect all of it's queries to this server. This is done by using the :remote command: gremlin> :remote connect tinkerpop.server conf/remote.yaml == >Configured localhost/127.0.0.1:8182 As you can probably tell from the log, the client and server are running on the same machine in this case. When using a different setup, all you have to do is modify the parameters in the conf/remote.yaml file. Warning The above command only establishes the connection to the server. It does not forward the following commands to the server by default! As a result, further commands will still be executed locally unless preceeded by :> . To forward every command to the remote server, use the :remote console command. Further documentation can be found in the TinkerPop reference docs","title":"Running the Gremlin Server"},{"location":"index-backend/","text":"While JanusGraph's composite graph indexes are natively supported through the primary storage backend, mixed graph indexes require that an indexing backend is configured. Mixed indexes provide support for geo, numeric range, and full-text search. The choice of index backend determines which search features are supported, as well as the performance and scalability of the index. JanusGraph currently supports three index backends: Elasticsearch , Apache Solr and Apache Lucene . Use Elasticsearch or Apache Solr when there is an expectation that JanusGraph will be distributed across multiple machines. Apache Lucene performs better in small scale, single machine applications. It performs better in unit tests, for instance.","title":"Introduction"},{"location":"index-backend/direct-index-query/","text":"Direct Index Query JanusGraph\u2019s standard global graph querying mechanism supports boolean queries for vertices or edges. In other words, an element either matches the query or it does not. There are no partial matches or result scoring. Some indexing backends additionally support fuzzy search queries. For those queries, a score is computed for each match to indicate the \"goodness\" of the match and results are returned in the order of their score. Fuzzy search is particularly useful when dealing with full-text search queries where matching more words is considered to be better. Since fuzzy search implementations and scoring algorithms differ significantly between indexing backends, JanusGraph does not support fuzzy search natively. However, JanusGraph provides a direct index query mechanism that allows search queries to be directly send to the indexing backend for evaluation (for those backends that support it). Use Graph.indexQuery() to compose a query that is executed directly against an indexing backend. This query builder expects two parameters: The name of the indexing backend to query. This must be the name configured in JanusGraph\u2019s configuration and used in the property key indexing definitions The query string The builder allows configuration of the maximum number of elements to be returned via its limit(int) method. The builder\u2019s offset(int) controls number of initial matches in the result set to skip. To retrieve all vertex or edges matching the given query in the specified indexing backend, invoke vertices() or edges() , respectively. It is not possible to query for both vertices and edges at the same time. These methods return an Iterable over Result objects. A result object contains the matched handle, retrievable via getElement() , and the associated score - getScore() . Consider the following example: ManagementSystem mgmt = graph . openManagement (); PropertyKey text = mgmt . makePropertyKey ( \"text\" ). dataType ( String . class ). make (); mgmt . buildIndex ( \"vertexByText\" , Vertex . class ). addKey ( text ). buildMixedIndex ( \"search\" ); mgmt . commit (); // ... Load vertices ... for ( Result < Vertex > result : graph . indexQuery ( \"vertexByText\" , \"v.text:(farm uncle berry)\" ). vertices ()) { System . out . println ( result . getElement () + \": \" + result . getScore ()); } Query String The query string is handed directly to the indexing backend for processing and hence the query string syntax depends on what is supported by the indexing backend. For vertex queries, JanusGraph will analyze the query string for property key references starting with \"v.\" and replace those by a handle to the indexing field that corresponds to the property key. Likewise, for edge queries, JanusGraph will replace property key references starting with \"e.\". Hence, to refer to a property of a vertex, use \"v.[KEY_NAME]\" in the query string. Likewise, for edges write \"e.[KEY_NAME]\". Elasticsearch and Lucene support the Lucene query syntax . Refer to the Lucene documentation or the Elasticsearch documentation for more information. The query used in the example above follows the Lucene query syntax. 1 graph.indexQuery(\"vertexByText\", \"v.text:(farm uncle berry)\").vertices() This query matches all vertices where the text contains any of the three words (grouped by parentheses) and score matches higher the more words are matched in the text. In addition Elasticsearch supports wildcard queries, use \"v.*\" or \"e.*\" in the query string to query if any of the properties on the element match. Query Totals It is sometimes useful to know how many total results were returned from a query without having to retrieve all results. Fortunately, Elasticsearch and Solr provide a shortcut that does not involve retrieving and ranking all documents. This shortcut is exposed through the \".vertexTotals()\", \".edgeTotals()\", and \".propertyTotals()\" methods. The totals can be retrieved using the same query syntax as the indexQuery builder, but size is overwritten to be 0. graph . indexQuery ( \"vertexByText\" , \"v.text:(farm uncle berry)\" ). vertexTotals () Gotchas Property Key Names Names of property keys that contain non-alphanumeric characters must be placed in quotation marks to ensure that the query is parsed correctly. graph . indexQuery ( \"vertexByText\" , \"v.\\\"first_name\\\":john\" ). vertices () Some property key names may be transformed by the JanusGraph indexing backend implementation. For instance, an indexing backend that does not permit spaces in field names may transform \"My Field Name\" to \"My\u2022Field\u2022Name\", or an indexing backend like Solr may append type information to the name, transforming \"myBooleanField\" to \"myBooleanField_b\". These transformations happen in the index backend\u2019s implementation of IndexProvider, in the \"mapKey2Field\" method. Indexing backends may reserve special characters (such as \u2022 ) and prohibit indexing of fields that contain them. For this reason it is recommended to avoid spaces and special characters in property names. In general, making direct index queries depends on implementation details of JanusGraph indexing backends that are normally hidden from users, so it\u2019s best to verify a query empirically against the indexing backend in use. Element Identifier Collision The strings \"v.\", \"e.\", and \"p.\" are used to identify a vertex, edge or property element respectively in a query. If the field name or the query value contains the same sequence of characters, this can cause a collision in the query string and parsing errors as in the following example: graph . indexQuery ( \"vertexByText\" , \"v.name:v.john\" ). vertices () //DOES NOT WORK! To avoid such identifier collisions, use the setElementIdentifier method to define a unique element identifier string that does not occur in any other parts of the query: graph . indexQuery ( \"vertexByText\" , \"$v$name:v.john\" ). setElementIdentifier ( \"$v$\" ). vertices () Mixed Index Availability Delay When a query traverses a mixed index immediately after data is inserted the changes may not be visible. In Elasticsearch the configuration option that determines this delay is index refresh interval . In Solr the primary configuration option is max time .","title":"Direct Index Query"},{"location":"index-backend/direct-index-query/#direct-index-query","text":"JanusGraph\u2019s standard global graph querying mechanism supports boolean queries for vertices or edges. In other words, an element either matches the query or it does not. There are no partial matches or result scoring. Some indexing backends additionally support fuzzy search queries. For those queries, a score is computed for each match to indicate the \"goodness\" of the match and results are returned in the order of their score. Fuzzy search is particularly useful when dealing with full-text search queries where matching more words is considered to be better. Since fuzzy search implementations and scoring algorithms differ significantly between indexing backends, JanusGraph does not support fuzzy search natively. However, JanusGraph provides a direct index query mechanism that allows search queries to be directly send to the indexing backend for evaluation (for those backends that support it). Use Graph.indexQuery() to compose a query that is executed directly against an indexing backend. This query builder expects two parameters: The name of the indexing backend to query. This must be the name configured in JanusGraph\u2019s configuration and used in the property key indexing definitions The query string The builder allows configuration of the maximum number of elements to be returned via its limit(int) method. The builder\u2019s offset(int) controls number of initial matches in the result set to skip. To retrieve all vertex or edges matching the given query in the specified indexing backend, invoke vertices() or edges() , respectively. It is not possible to query for both vertices and edges at the same time. These methods return an Iterable over Result objects. A result object contains the matched handle, retrievable via getElement() , and the associated score - getScore() . Consider the following example: ManagementSystem mgmt = graph . openManagement (); PropertyKey text = mgmt . makePropertyKey ( \"text\" ). dataType ( String . class ). make (); mgmt . buildIndex ( \"vertexByText\" , Vertex . class ). addKey ( text ). buildMixedIndex ( \"search\" ); mgmt . commit (); // ... Load vertices ... for ( Result < Vertex > result : graph . indexQuery ( \"vertexByText\" , \"v.text:(farm uncle berry)\" ). vertices ()) { System . out . println ( result . getElement () + \": \" + result . getScore ()); }","title":"Direct Index Query"},{"location":"index-backend/direct-index-query/#query-string","text":"The query string is handed directly to the indexing backend for processing and hence the query string syntax depends on what is supported by the indexing backend. For vertex queries, JanusGraph will analyze the query string for property key references starting with \"v.\" and replace those by a handle to the indexing field that corresponds to the property key. Likewise, for edge queries, JanusGraph will replace property key references starting with \"e.\". Hence, to refer to a property of a vertex, use \"v.[KEY_NAME]\" in the query string. Likewise, for edges write \"e.[KEY_NAME]\". Elasticsearch and Lucene support the Lucene query syntax . Refer to the Lucene documentation or the Elasticsearch documentation for more information. The query used in the example above follows the Lucene query syntax. 1 graph.indexQuery(\"vertexByText\", \"v.text:(farm uncle berry)\").vertices() This query matches all vertices where the text contains any of the three words (grouped by parentheses) and score matches higher the more words are matched in the text. In addition Elasticsearch supports wildcard queries, use \"v.*\" or \"e.*\" in the query string to query if any of the properties on the element match.","title":"Query String"},{"location":"index-backend/direct-index-query/#query-totals","text":"It is sometimes useful to know how many total results were returned from a query without having to retrieve all results. Fortunately, Elasticsearch and Solr provide a shortcut that does not involve retrieving and ranking all documents. This shortcut is exposed through the \".vertexTotals()\", \".edgeTotals()\", and \".propertyTotals()\" methods. The totals can be retrieved using the same query syntax as the indexQuery builder, but size is overwritten to be 0. graph . indexQuery ( \"vertexByText\" , \"v.text:(farm uncle berry)\" ). vertexTotals ()","title":"Query Totals"},{"location":"index-backend/direct-index-query/#gotchas","text":"","title":"Gotchas"},{"location":"index-backend/direct-index-query/#property-key-names","text":"Names of property keys that contain non-alphanumeric characters must be placed in quotation marks to ensure that the query is parsed correctly. graph . indexQuery ( \"vertexByText\" , \"v.\\\"first_name\\\":john\" ). vertices () Some property key names may be transformed by the JanusGraph indexing backend implementation. For instance, an indexing backend that does not permit spaces in field names may transform \"My Field Name\" to \"My\u2022Field\u2022Name\", or an indexing backend like Solr may append type information to the name, transforming \"myBooleanField\" to \"myBooleanField_b\". These transformations happen in the index backend\u2019s implementation of IndexProvider, in the \"mapKey2Field\" method. Indexing backends may reserve special characters (such as \u2022 ) and prohibit indexing of fields that contain them. For this reason it is recommended to avoid spaces and special characters in property names. In general, making direct index queries depends on implementation details of JanusGraph indexing backends that are normally hidden from users, so it\u2019s best to verify a query empirically against the indexing backend in use.","title":"Property Key Names"},{"location":"index-backend/direct-index-query/#element-identifier-collision","text":"The strings \"v.\", \"e.\", and \"p.\" are used to identify a vertex, edge or property element respectively in a query. If the field name or the query value contains the same sequence of characters, this can cause a collision in the query string and parsing errors as in the following example: graph . indexQuery ( \"vertexByText\" , \"v.name:v.john\" ). vertices () //DOES NOT WORK! To avoid such identifier collisions, use the setElementIdentifier method to define a unique element identifier string that does not occur in any other parts of the query: graph . indexQuery ( \"vertexByText\" , \"$v$name:v.john\" ). setElementIdentifier ( \"$v$\" ). vertices ()","title":"Element Identifier Collision"},{"location":"index-backend/direct-index-query/#mixed-index-availability-delay","text":"When a query traverses a mixed index immediately after data is inserted the changes may not be visible. In Elasticsearch the configuration option that determines this delay is index refresh interval . In Solr the primary configuration option is max time .","title":"Mixed Index Availability Delay"},{"location":"index-backend/elasticsearch/","text":"Elasticsearch Elasticsearch is a distributed, RESTful search and analytics engine capable of solving a growing number of use cases. As the heart of the Elastic Stack, it centrally stores your data so you can discover the expected and uncover the unexpected. \u2014 Elasticsearch Overview JanusGraph supports Elasticsearch as an index backend. Here are some of the Elasticsearch features supported by JanusGraph: Full-Text : Supports all Text predicates to search for text properties that matches a given word, prefix or regular expression. Geo : Supports all Geo predicates to search for geo properties that are intersecting, within, disjoint to or contained in a given query geometry. Supports points, circles, boxes, lines and polygons for indexing. Supports circles, boxes and polygons for querying point properties and all shapes for querying non-point properties. Numeric Range : Supports all numeric comparisons in Compare . Flexible Configuration : Supports remote operation and open-ended settings customization. Collections : Supports indexing SET and LIST cardinality properties. Temporal : Nanosecond granularity temporal indexing. Custom Analyzer : Choose to use a custom analyzer Please see Version Compatibility for details on what versions of Elasticsearch will work with JanusGraph. Important Beginning with Elasticsearch 5.0 JanusGraph uses sandboxed Painless scripts for inline updates, which are enabled by default in Elasticsearch 5.x. Using JanusGraph with Elasticsearch 2.x requires enabling Groovy inline scripting by setting script.engine.groovy.inline.update to true on the Elasticsearch cluster (see dynamic scripting documentation for more information). Running Elasticsearch JanusGraph supports connections to a running Elasticsearch cluster. JanusGraph provides two options for running local Elasticsearch instances for getting started quickly. JanusGraph server (see Getting started ) automatically starts a local Elasticsearch instance. Alternatively JanusGraph releases include a full Elasticsearch distribution to allow users to manually start a local Elasticsearch instance (see this page for more information). $ elasticsearch/bin/elasticsearch Note For security reasons Elasticsearch must be run under a non-root account Elasticsearch Configuration Overview JanusGraph supports HTTP(S) client connections to a running Elasticsearch cluster. Please see Version Compatibility for details on what versions of Elasticsearch will work with the different client types in JanusGraph. Note JanusGraph\u2019s index options start with the string \" index.[X]. \" where \" [X] \" is a user-defined name for the backend. This user-defined name must be passed to JanusGraph\u2019s ManagementSystem interface when building a mixed index, as described in Mixed Index , so that JanusGraph knows which of potentially multiple configured index backends to use. Configuration snippets in this chapter use the name search , whereas prose discussion of options typically write [X] in the same position. The exact index name is not significant as long as it is used consistently in JanusGraph\u2019s configuration and when administering indices. Tip It\u2019s recommended that index names contain only alphanumeric lowercase characters and hyphens, and that they start with a lowercase letter. Connecting to Elasticsearch The Elasticsearch client is specified as follows: index.search.backend=elasticsearch When connecting to Elasticsearch a single or list of hostnames for the Elasticsearch instances must be provided. These are supplied via JanusGraph\u2019s index.[X].hostname key. index.search.backend=elasticsearch index.search.hostname=10.0.0.10:9200 Each host or host:port pair specified here will be added to the HTTP client\u2019s round-robin list of request targets. Here\u2019s a minimal configuration that will round-robin over 10.0.0.10 on the default Elasticsearch HTTP port (9200) and 10.0.0.20 on port 7777: index.search.backend=elasticsearch index.search.hostname=10.0.0.10, 10.0.0.20:7777 JanusGraph index.[X] and index.[X].elasticsearch options JanusGraph only uses default values for index-name and health-request-timeout . See Configuration Reference for descriptions of these options and their accepted values. index.[X].elasticsearch.index-name index.[X].elasticsearch.health-request-timeout REST Client Options The REST client accepts the index.[X].bulk-refresh option. This option controls when changes are made visible to search. See ?refresh documentation for more information. REST Client HTTPS Configuration SSL support for HTTP can be enabled by setting the index.[X].elasticsearch.ssl.enabled configuration option to true . Note that depending on your configuration you may need to change the value of index.[X].port if your HTTPS port number is different from the default one for the REST API (9200). When SSL is enabled you may also configure the location and password of the truststore. This can be done as follows: index.search.elasticsearch.ssl.truststore.location = /path/to/your/truststore.jks index.search.elasticsearch.ssl.truststore.password = truststorepwd Note that these settings apply only to Elasticsearch REST client and do not affect any other SSL connections in JanusGraph. Configuration of the client keystore is also supported: index.search.elasticsearch.ssl.keystore.location = /path/to/your/keystore.jks index.search.elasticsearch.ssl.keystore.storepassword = keystorepwd index.search.elasticsearch.ssl.keystore.keypassword = keypwd Any of the passwords can be empty. If needed, the SSL hostname verification can be disabled by setting the index.[X].elasticsearch.ssl.disable-hostname-verification property value to true and the support for self-signed SSL certificates can be enabled by setting index.[X].elasticsearch.ssl.allow-self-signed-certificates property value to true . Tip It is not recommended to rely on the self-signed SSL certificates or to disable the hostname verification for a production system as it significantly limits the client's ability to provide the secure communication channel with the Elasticsearch server(s). This may result in leaking the confidential data which may be a part of your JanusGraph index. REST Client HTTP Authentication REST client supports the following authentication options: Basic HTTP Authentication (username/password) and custom authentication based on the user-provided implementation. These authentication methods are independent from SSL client authentication described above. REST Client Basic HTTP Authentication Basic HTTP Authentication is available regardless of the state of SSL support. Optionally, an authentication realm can be specified via index.[X].elasticsearch.http.auth.basic.realm property. index.search.elasticsearch.http.auth.type = basic index.search.elasticsearch.http.auth.basic.username = httpuser index.search.elasticsearch.http.auth.basic.password = httppassword Tip It is highly recommended to use SSL (e.g. setting index.[X].elasticsearch.ssl.enabled to true ) when using this option as the credentials can be intercepted when sent over an unencrypted connection! REST Client Custom HTTP Authentication Additional authentication methods can be implemented by providing your own implementation. The custom authenticator is configured as follows: index.search.elasticsearch.http.auth.custom.authenticator-class = fully.qualified.class.Name index.search.elasticsearch.elasticsearch.http.auth.custom.authenticator-args = arg1,arg2,... Argument list is optional and can be empty. The class specified there has to implement the org.janusgraph.diskstorage.es.rest.util.RestClientAuthenticator interface or extend org.janusgraph.diskstorage.es.rest.util.RestClientAuthenticatorBase convenience class. The implementation gets access to HTTP client configuration and can customize the client as needed. Refer to < > for more information. For example, the following code snippet implements an authenticator allowing the Elasticsearch REST client to authenticate and get authorized against AWS IAM: import java.io.IOException ; import java.time.LocalDateTime ; import java.time.ZoneOffset ; import org.apache.http.HttpRequestInterceptor ; import org.apache.http.impl.nio.client.HttpAsyncClientBuilder ; import org.janusgraph.diskstorage.es.rest.util.RestClientAuthenticatorBase ; import com.amazonaws.auth.DefaultAWSCredentialsProviderChain ; import com.amazonaws.regions.DefaultAwsRegionProviderChain ; import com.google.common.base.Supplier ; import vc.inreach.aws.request.AWSSigner ; import vc.inreach.aws.request.AWSSigningRequestInterceptor ; /** * <p> * Elasticsearch REST HTTP(S) client callback implementing AWS request signing. * </p> * <p> * The signer is based on AWS SDK default provider chain, allowing multiple options for providing * the caller credentials. See {@link DefaultAWSCredentialsProviderChain} documentation for the details. * </p> */ public class AWSV4AuthHttpClientConfigCallback extends RestClientAuthenticatorBase { private static final String AWS_SERVICE_NAME = \"es\" ; private HttpRequestInterceptor awsSigningInterceptor ; public AWSV4AuthHttpClientConfigCallback ( final String [] args ) { // does not require any configuration } @Override public void init () throws IOException { DefaultAWSCredentialsProviderChain awsCredentialsProvider = new DefaultAWSCredentialsProviderChain (); final Supplier < LocalDateTime > clock = () -> LocalDateTime . now ( ZoneOffset . UTC ); // using default region provider chain // (https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/java-dg-region-selection.html) DefaultAwsRegionProviderChain regionProviderChain = new DefaultAwsRegionProviderChain (); final String awsRegion = regionProviderChain . getRegion (); final AWSSigner awsSigner = new AWSSigner ( awsCredentialsProvider , awsRegion , AWS_SERVICE_NAME , clock ); this . awsSigningInterceptor = new AWSSigningRequestInterceptor ( awsSigner ); } @Override public HttpAsyncClientBuilder customizeHttpClient ( HttpAsyncClientBuilder httpClientBuilder ) { return httpClientBuilder . addInterceptorLast ( awsSigningInterceptor ); / } } This custom authenticator does not use any constructor arguments. Ingest Pipelines If using Elasticsearch 5.0 or higher, a different ingest pipelines can be set for each mixed index. Ingest pipeline can be use to pre-process documents before indexing. A pipeline is composed by a series of processors. Each processor transforms the document in some way. For example date processor can extract a date from a text to a date field. So you can query this date with JanusGraph without it being physically in the primary storage. index.[X].elasticsearch.ingest-pipeline.[mixedIndexName] = pipeline_id See ingest documentation for more information about ingest pipelines and processors documentation for more information about ingest processors. Secure Elasticsearch Elasticsearch does not perform authentication or authorization. A client that can connect to Elasticsearch is trusted by Elasticsearch. When Elasticsearch runs on an unsecured or public network, particularly the Internet, it should be deployed with some type of external security. This is generally done with a combination of firewalling, tunneling of Elasticsearch\u2019s ports or by using Elasticsearch extensions such as X-Pack . Elasticsearch has two client-facing ports to consider: The HTTP REST API, usually on port 9200 The native \"transport\" protocol, usually on port 9300 A client uses either one protocol/port or the other, but not both simultaneously. Securing the HTTP protocol port is generally done with a combination of firewalling and a reverse proxy with SSL encryption and HTTP authentication. There are a couple of ways to approach security on the native \"transport\" protocol port: In addition to that, some hosted Elasticsearch services offer other methods of authentication and authorization. For example, AWS Elasticsearch Service requires the use of HTTPS and offers an option for using IAM-based access control. For that the requests sent to this service must be signed. This can be achieved by using a custom authenticator (see above). Tunnel Elasticsearch's native \"transport\" protocol:: This approach can be implemented with SSL/TLS tunneling (for instance via stunnel ), a VPN, or SSH port forwarding. SSL/TLS tunnels require non-trivial setup and monitoring: one or both ends of the tunnel need a certificate, and the stunnel processes need to be configured and running continuously. The setup for most secure VPNs is likewise non-trivial. Some Elasticsearch service providers handle server-side tunnel management and provide a custom Elasticsearch transport.type to simplify the client setup. Add a firewall rule that allows only trusted clients to connect on Elasticsearch\u2019s native protocol port This is typically done at the host firewall level. Easy to configure, but very weak security by itself. Index Creation Options JanusGraph supports customization of the index settings it uses when creating its Elasticsearch index. It allows setting arbitrary key-value pairs on the settings object in the Elasticsearch create index request issued by JanusGraph. Here is a non-exhaustive sample of Elasticsearch index settings that can be customized using this mechanism: index.number_of_replicas index.number_of_shards index.refresh_interval Settings customized through this mechanism are only applied when JanusGraph attempts to create its index in Elasticsearch. If JanusGraph finds that its index already exists, then it does not attempt to recreate it, and these settings have no effect. Embedding Elasticsearch index creation settings with create.ext JanusGraph iterates over all properties prefixed with index.[X].elasticsearch.create.ext. , where [X] is an index name such as search . It strips the prefix from each property key. The remainder of the stripped key will be interpreted as an Elasticsearch index creation setting. The value associated with the key is not modified. The stripped key and unmodified value are passed as part of the settings object in the Elasticsearch create index request that JanusGraph issues when bootstrapping on Elasticsearch. This allows embedding arbitrary index creation settings settings in JanusGraph\u2019s properties. Here\u2019s an example configuration fragment that customizes three Elasticsearch index settings using the create.ext config mechanism: index.search.backend = elasticsearch index.search.elasticsearch.create.ext.number_of_shards = 15 index.search.elasticsearch.create.ext.number_of_replicas = 3 index.search.elasticsearch.create.ext.shard.check_on_startup = true The configuration fragment listed above takes advantage of Elasticsearch\u2019s assumption, implemented server-side, that unqualified create index setting keys have an index. prefix. It\u2019s also possible to spell out the index prefix explicitly. Here\u2019s a JanusGraph config file functionally equivalent to the one listed above, except that the index. prefix before the index creation settings is explicit: index.search.backend=elasticsearch index.search.elasticsearch.create.ext.index.number_of_shards=15 index.search.elasticsearch.create.ext.index.number_of_replicas=3 index.search.elasticsearch.create.ext.index.shard.check_on_startup=false Tip The create.ext mechanism for specifying index creation settings is compatible with JanusGraph\u2019s Elasticsearch configuration. Troubleshooting Connection Issues to remote Elasticsearch cluster Check that the Elasticsearch cluster nodes are reachable on the HTTP protocol port from the JanusGraph nodes. Check the node listen port by examining the Elasticsearch node configuration logs or using a general diagnostic utility like netstat . Check the JanusGraph configuration. Optimizing Elasticsearch Write Optimization For bulk loading or other write-intense applications, consider increasing Elasticsearch\u2019s refresh interval. Refer to this discussion on how to increase the refresh interval and its impact on write performance. Note, that a higher refresh interval means that it takes a longer time for graph mutations to be available in the index. For additional suggestions on how to increase write performance in Elasticsearch with detailed instructions, please read this blog post . Further Reading Please refer to the Elasticsearch homepage and available documentation for more information on Elasticsearch and how to setup an Elasticsearch cluster.","title":"Elasticsearch"},{"location":"index-backend/elasticsearch/#elasticsearch","text":"Elasticsearch is a distributed, RESTful search and analytics engine capable of solving a growing number of use cases. As the heart of the Elastic Stack, it centrally stores your data so you can discover the expected and uncover the unexpected. \u2014 Elasticsearch Overview JanusGraph supports Elasticsearch as an index backend. Here are some of the Elasticsearch features supported by JanusGraph: Full-Text : Supports all Text predicates to search for text properties that matches a given word, prefix or regular expression. Geo : Supports all Geo predicates to search for geo properties that are intersecting, within, disjoint to or contained in a given query geometry. Supports points, circles, boxes, lines and polygons for indexing. Supports circles, boxes and polygons for querying point properties and all shapes for querying non-point properties. Numeric Range : Supports all numeric comparisons in Compare . Flexible Configuration : Supports remote operation and open-ended settings customization. Collections : Supports indexing SET and LIST cardinality properties. Temporal : Nanosecond granularity temporal indexing. Custom Analyzer : Choose to use a custom analyzer Please see Version Compatibility for details on what versions of Elasticsearch will work with JanusGraph. Important Beginning with Elasticsearch 5.0 JanusGraph uses sandboxed Painless scripts for inline updates, which are enabled by default in Elasticsearch 5.x. Using JanusGraph with Elasticsearch 2.x requires enabling Groovy inline scripting by setting script.engine.groovy.inline.update to true on the Elasticsearch cluster (see dynamic scripting documentation for more information).","title":"Elasticsearch"},{"location":"index-backend/elasticsearch/#running-elasticsearch","text":"JanusGraph supports connections to a running Elasticsearch cluster. JanusGraph provides two options for running local Elasticsearch instances for getting started quickly. JanusGraph server (see Getting started ) automatically starts a local Elasticsearch instance. Alternatively JanusGraph releases include a full Elasticsearch distribution to allow users to manually start a local Elasticsearch instance (see this page for more information). $ elasticsearch/bin/elasticsearch Note For security reasons Elasticsearch must be run under a non-root account","title":"Running Elasticsearch"},{"location":"index-backend/elasticsearch/#elasticsearch-configuration-overview","text":"JanusGraph supports HTTP(S) client connections to a running Elasticsearch cluster. Please see Version Compatibility for details on what versions of Elasticsearch will work with the different client types in JanusGraph. Note JanusGraph\u2019s index options start with the string \" index.[X]. \" where \" [X] \" is a user-defined name for the backend. This user-defined name must be passed to JanusGraph\u2019s ManagementSystem interface when building a mixed index, as described in Mixed Index , so that JanusGraph knows which of potentially multiple configured index backends to use. Configuration snippets in this chapter use the name search , whereas prose discussion of options typically write [X] in the same position. The exact index name is not significant as long as it is used consistently in JanusGraph\u2019s configuration and when administering indices. Tip It\u2019s recommended that index names contain only alphanumeric lowercase characters and hyphens, and that they start with a lowercase letter.","title":"Elasticsearch Configuration Overview"},{"location":"index-backend/elasticsearch/#connecting-to-elasticsearch","text":"The Elasticsearch client is specified as follows: index.search.backend=elasticsearch When connecting to Elasticsearch a single or list of hostnames for the Elasticsearch instances must be provided. These are supplied via JanusGraph\u2019s index.[X].hostname key. index.search.backend=elasticsearch index.search.hostname=10.0.0.10:9200 Each host or host:port pair specified here will be added to the HTTP client\u2019s round-robin list of request targets. Here\u2019s a minimal configuration that will round-robin over 10.0.0.10 on the default Elasticsearch HTTP port (9200) and 10.0.0.20 on port 7777: index.search.backend=elasticsearch index.search.hostname=10.0.0.10, 10.0.0.20:7777","title":"Connecting to Elasticsearch"},{"location":"index-backend/elasticsearch/#janusgraph-indexx-and-indexxelasticsearch-options","text":"JanusGraph only uses default values for index-name and health-request-timeout . See Configuration Reference for descriptions of these options and their accepted values. index.[X].elasticsearch.index-name index.[X].elasticsearch.health-request-timeout","title":"JanusGraph index.[X] and index.[X].elasticsearch options"},{"location":"index-backend/elasticsearch/#rest-client-options","text":"The REST client accepts the index.[X].bulk-refresh option. This option controls when changes are made visible to search. See ?refresh documentation for more information.","title":"REST Client Options"},{"location":"index-backend/elasticsearch/#rest-client-https-configuration","text":"SSL support for HTTP can be enabled by setting the index.[X].elasticsearch.ssl.enabled configuration option to true . Note that depending on your configuration you may need to change the value of index.[X].port if your HTTPS port number is different from the default one for the REST API (9200). When SSL is enabled you may also configure the location and password of the truststore. This can be done as follows: index.search.elasticsearch.ssl.truststore.location = /path/to/your/truststore.jks index.search.elasticsearch.ssl.truststore.password = truststorepwd Note that these settings apply only to Elasticsearch REST client and do not affect any other SSL connections in JanusGraph. Configuration of the client keystore is also supported: index.search.elasticsearch.ssl.keystore.location = /path/to/your/keystore.jks index.search.elasticsearch.ssl.keystore.storepassword = keystorepwd index.search.elasticsearch.ssl.keystore.keypassword = keypwd Any of the passwords can be empty. If needed, the SSL hostname verification can be disabled by setting the index.[X].elasticsearch.ssl.disable-hostname-verification property value to true and the support for self-signed SSL certificates can be enabled by setting index.[X].elasticsearch.ssl.allow-self-signed-certificates property value to true . Tip It is not recommended to rely on the self-signed SSL certificates or to disable the hostname verification for a production system as it significantly limits the client's ability to provide the secure communication channel with the Elasticsearch server(s). This may result in leaking the confidential data which may be a part of your JanusGraph index.","title":"REST Client HTTPS Configuration"},{"location":"index-backend/elasticsearch/#rest-client-http-authentication","text":"REST client supports the following authentication options: Basic HTTP Authentication (username/password) and custom authentication based on the user-provided implementation. These authentication methods are independent from SSL client authentication described above.","title":"REST Client HTTP Authentication"},{"location":"index-backend/elasticsearch/#rest-client-basic-http-authentication","text":"Basic HTTP Authentication is available regardless of the state of SSL support. Optionally, an authentication realm can be specified via index.[X].elasticsearch.http.auth.basic.realm property. index.search.elasticsearch.http.auth.type = basic index.search.elasticsearch.http.auth.basic.username = httpuser index.search.elasticsearch.http.auth.basic.password = httppassword Tip It is highly recommended to use SSL (e.g. setting index.[X].elasticsearch.ssl.enabled to true ) when using this option as the credentials can be intercepted when sent over an unencrypted connection!","title":"REST Client Basic HTTP Authentication"},{"location":"index-backend/elasticsearch/#rest-client-custom-http-authentication","text":"Additional authentication methods can be implemented by providing your own implementation. The custom authenticator is configured as follows: index.search.elasticsearch.http.auth.custom.authenticator-class = fully.qualified.class.Name index.search.elasticsearch.elasticsearch.http.auth.custom.authenticator-args = arg1,arg2,... Argument list is optional and can be empty. The class specified there has to implement the org.janusgraph.diskstorage.es.rest.util.RestClientAuthenticator interface or extend org.janusgraph.diskstorage.es.rest.util.RestClientAuthenticatorBase convenience class. The implementation gets access to HTTP client configuration and can customize the client as needed. Refer to < > for more information. For example, the following code snippet implements an authenticator allowing the Elasticsearch REST client to authenticate and get authorized against AWS IAM: import java.io.IOException ; import java.time.LocalDateTime ; import java.time.ZoneOffset ; import org.apache.http.HttpRequestInterceptor ; import org.apache.http.impl.nio.client.HttpAsyncClientBuilder ; import org.janusgraph.diskstorage.es.rest.util.RestClientAuthenticatorBase ; import com.amazonaws.auth.DefaultAWSCredentialsProviderChain ; import com.amazonaws.regions.DefaultAwsRegionProviderChain ; import com.google.common.base.Supplier ; import vc.inreach.aws.request.AWSSigner ; import vc.inreach.aws.request.AWSSigningRequestInterceptor ; /** * <p> * Elasticsearch REST HTTP(S) client callback implementing AWS request signing. * </p> * <p> * The signer is based on AWS SDK default provider chain, allowing multiple options for providing * the caller credentials. See {@link DefaultAWSCredentialsProviderChain} documentation for the details. * </p> */ public class AWSV4AuthHttpClientConfigCallback extends RestClientAuthenticatorBase { private static final String AWS_SERVICE_NAME = \"es\" ; private HttpRequestInterceptor awsSigningInterceptor ; public AWSV4AuthHttpClientConfigCallback ( final String [] args ) { // does not require any configuration } @Override public void init () throws IOException { DefaultAWSCredentialsProviderChain awsCredentialsProvider = new DefaultAWSCredentialsProviderChain (); final Supplier < LocalDateTime > clock = () -> LocalDateTime . now ( ZoneOffset . UTC ); // using default region provider chain // (https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/java-dg-region-selection.html) DefaultAwsRegionProviderChain regionProviderChain = new DefaultAwsRegionProviderChain (); final String awsRegion = regionProviderChain . getRegion (); final AWSSigner awsSigner = new AWSSigner ( awsCredentialsProvider , awsRegion , AWS_SERVICE_NAME , clock ); this . awsSigningInterceptor = new AWSSigningRequestInterceptor ( awsSigner ); } @Override public HttpAsyncClientBuilder customizeHttpClient ( HttpAsyncClientBuilder httpClientBuilder ) { return httpClientBuilder . addInterceptorLast ( awsSigningInterceptor ); / } } This custom authenticator does not use any constructor arguments.","title":"REST Client Custom HTTP Authentication"},{"location":"index-backend/elasticsearch/#ingest-pipelines","text":"If using Elasticsearch 5.0 or higher, a different ingest pipelines can be set for each mixed index. Ingest pipeline can be use to pre-process documents before indexing. A pipeline is composed by a series of processors. Each processor transforms the document in some way. For example date processor can extract a date from a text to a date field. So you can query this date with JanusGraph without it being physically in the primary storage. index.[X].elasticsearch.ingest-pipeline.[mixedIndexName] = pipeline_id See ingest documentation for more information about ingest pipelines and processors documentation for more information about ingest processors.","title":"Ingest Pipelines"},{"location":"index-backend/elasticsearch/#secure-elasticsearch","text":"Elasticsearch does not perform authentication or authorization. A client that can connect to Elasticsearch is trusted by Elasticsearch. When Elasticsearch runs on an unsecured or public network, particularly the Internet, it should be deployed with some type of external security. This is generally done with a combination of firewalling, tunneling of Elasticsearch\u2019s ports or by using Elasticsearch extensions such as X-Pack . Elasticsearch has two client-facing ports to consider: The HTTP REST API, usually on port 9200 The native \"transport\" protocol, usually on port 9300 A client uses either one protocol/port or the other, but not both simultaneously. Securing the HTTP protocol port is generally done with a combination of firewalling and a reverse proxy with SSL encryption and HTTP authentication. There are a couple of ways to approach security on the native \"transport\" protocol port: In addition to that, some hosted Elasticsearch services offer other methods of authentication and authorization. For example, AWS Elasticsearch Service requires the use of HTTPS and offers an option for using IAM-based access control. For that the requests sent to this service must be signed. This can be achieved by using a custom authenticator (see above). Tunnel Elasticsearch's native \"transport\" protocol:: This approach can be implemented with SSL/TLS tunneling (for instance via stunnel ), a VPN, or SSH port forwarding. SSL/TLS tunnels require non-trivial setup and monitoring: one or both ends of the tunnel need a certificate, and the stunnel processes need to be configured and running continuously. The setup for most secure VPNs is likewise non-trivial. Some Elasticsearch service providers handle server-side tunnel management and provide a custom Elasticsearch transport.type to simplify the client setup. Add a firewall rule that allows only trusted clients to connect on Elasticsearch\u2019s native protocol port This is typically done at the host firewall level. Easy to configure, but very weak security by itself.","title":"Secure Elasticsearch"},{"location":"index-backend/elasticsearch/#index-creation-options","text":"JanusGraph supports customization of the index settings it uses when creating its Elasticsearch index. It allows setting arbitrary key-value pairs on the settings object in the Elasticsearch create index request issued by JanusGraph. Here is a non-exhaustive sample of Elasticsearch index settings that can be customized using this mechanism: index.number_of_replicas index.number_of_shards index.refresh_interval Settings customized through this mechanism are only applied when JanusGraph attempts to create its index in Elasticsearch. If JanusGraph finds that its index already exists, then it does not attempt to recreate it, and these settings have no effect.","title":"Index Creation Options"},{"location":"index-backend/elasticsearch/#embedding-elasticsearch-index-creation-settings-with-createext","text":"JanusGraph iterates over all properties prefixed with index.[X].elasticsearch.create.ext. , where [X] is an index name such as search . It strips the prefix from each property key. The remainder of the stripped key will be interpreted as an Elasticsearch index creation setting. The value associated with the key is not modified. The stripped key and unmodified value are passed as part of the settings object in the Elasticsearch create index request that JanusGraph issues when bootstrapping on Elasticsearch. This allows embedding arbitrary index creation settings settings in JanusGraph\u2019s properties. Here\u2019s an example configuration fragment that customizes three Elasticsearch index settings using the create.ext config mechanism: index.search.backend = elasticsearch index.search.elasticsearch.create.ext.number_of_shards = 15 index.search.elasticsearch.create.ext.number_of_replicas = 3 index.search.elasticsearch.create.ext.shard.check_on_startup = true The configuration fragment listed above takes advantage of Elasticsearch\u2019s assumption, implemented server-side, that unqualified create index setting keys have an index. prefix. It\u2019s also possible to spell out the index prefix explicitly. Here\u2019s a JanusGraph config file functionally equivalent to the one listed above, except that the index. prefix before the index creation settings is explicit: index.search.backend=elasticsearch index.search.elasticsearch.create.ext.index.number_of_shards=15 index.search.elasticsearch.create.ext.index.number_of_replicas=3 index.search.elasticsearch.create.ext.index.shard.check_on_startup=false Tip The create.ext mechanism for specifying index creation settings is compatible with JanusGraph\u2019s Elasticsearch configuration.","title":"Embedding Elasticsearch index creation settings with create.ext"},{"location":"index-backend/elasticsearch/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"index-backend/elasticsearch/#connection-issues-to-remote-elasticsearch-cluster","text":"Check that the Elasticsearch cluster nodes are reachable on the HTTP protocol port from the JanusGraph nodes. Check the node listen port by examining the Elasticsearch node configuration logs or using a general diagnostic utility like netstat . Check the JanusGraph configuration.","title":"Connection Issues to remote Elasticsearch cluster"},{"location":"index-backend/elasticsearch/#optimizing-elasticsearch","text":"","title":"Optimizing Elasticsearch"},{"location":"index-backend/elasticsearch/#write-optimization","text":"For bulk loading or other write-intense applications, consider increasing Elasticsearch\u2019s refresh interval. Refer to this discussion on how to increase the refresh interval and its impact on write performance. Note, that a higher refresh interval means that it takes a longer time for graph mutations to be available in the index. For additional suggestions on how to increase write performance in Elasticsearch with detailed instructions, please read this blog post .","title":"Write Optimization"},{"location":"index-backend/elasticsearch/#further-reading","text":"Please refer to the Elasticsearch homepage and available documentation for more information on Elasticsearch and how to setup an Elasticsearch cluster.","title":"Further Reading"},{"location":"index-backend/field-mapping/","text":"Field Mapping Individual Field Mapping By default, JanusGraph will encode property keys to generate a unique field name for the property key in the mixed index. If one wants to query the mixed index directly in the external index backend can be difficult to deal with and are illegible. For this use case, the field name can be explicitly specified through a parameter. mgmt = graph . openManagement () name = mgmt . makePropertyKey ( 'bookname' ). dataType ( String . class ). make () mgmt . buildIndex ( 'booksBySummary' , Vertex . class ). addKey ( name , Parameter . of ( 'mapped-name' , 'bookname' )). buildMixedIndex ( \"search\" ) mgmt . commit () With this field mapping defined as a parameter, JanusGraph will use the same name for the field in the booksBySummary index created in the external index system as for the property key. Note, that it must be ensured that the given field name is unique in the index. Global Field Mapping Instead of individually adjusting the field mapping for every key added to a mixed index, one can instruct JanusGraph to always set the field name in the external index to be identical to the property key name. This is accomplished by enabling the configuration option map-name which is configured per indexing backend. If this option is enabled for a particular indexing backend, then all mixed indexes defined against said backend will use field names identical to the property key names. However, this approach has two limitations: 1) The user has to ensure that the property key names are valid field names for the indexing backend and 2) renaming the property key will NOT rename the field name in the index which can lead to naming collisions that the user has to be aware of and avoid. Note, that individual field mappings as described above can be used to overwrite the default name for a particular key. Custom Analyzer By default, JanusGraph will use the default analyzer from the indexing backend for properties with Mapping.TEXT, and no analyzer for properties with Mapping.STRING. If one wants to use another analyzer, it can be explicitly specified through a parameter : ParameterType.TEXT_ANALYZER for Mapping.TEXT and ParameterType.STRING_ANALYZER for Mapping.STRING. For Elasticsearch The name of the analyzer must be set as parameter value. mgmt = graph . openManagement () string = mgmt . makePropertyKey ( 'string' ). dataType ( String . class ). make () text = mgmt . makePropertyKey ( 'text' ). dataType ( String . class ). make () textString = mgmt . makePropertyKey ( 'textString' ). dataType ( String . class ). make () mgmt . buildIndex ( 'string' , Vertex . class ). addKey ( string , Mapping . STRING . asParameter (), Parameter . of ( ParameterType . STRING_ANALYZER . getName (), 'standard' )). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( 'text' , Vertex . class ). addKey ( text , Mapping . TEXT . asParameter (), Parameter . of ( ParameterType . TEXT_ANALYZER . getName (), 'english' )). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( 'textString' , Vertex . class ). addKey ( text , Mapping . TEXTSTRING . asParameter (), Parameter . of ( ParameterType . STRING_ANALYZER . getName (), 'standard' ), Parameter . of ( ParameterType . TEXT_ANALYZER . getName (), 'english' )). buildMixedIndex ( \"search\" ) mgmt . commit () With these settings, JanusGraph will use the standard analyzer for property key string and the english analyzer for property key text . For Solr The class of the tokenizer must be set as parameter value. mgmt = graph . openManagement () string = mgmt . makePropertyKey ( ' string ' ). dataType ( String . class ). make () text = mgmt . makePropertyKey ( ' text ' ). dataType ( String . class ). make () mgmt . buildIndex ( ' string ' , Vertex . class ). addKey ( string , Mapping . STRING . asParameter (), Parameter . of ( ParameterType . STRING_ANALYZER . getName (), ' org . apache . lucene . analysis . standard . StandardTokenizer ' )). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( ' text ' , Vertex . class ). addKey ( text , Mapping . TEXT . asParameter (), Parameter . of ( ParameterType . TEXT_ANALYZER . getName (), ' org . apache . lucene . analysis . core . WhitespaceTokenizer ' )). buildMixedIndex ( \"search\" ) mgmt . commit () With these settings, JanusGraph will use the standard tokenizer for property key string and the whitespace tokenizer for property key text . For Lucene The name of the analyzer must be set as parameter value or it defaults to KeywordAnalyzer for Mapping.STRING and to StandardAnalyzer for Mapping.TEXT . mgmt = graph . openManagement () string = mgmt . makePropertyKey ( ' string ' ). dataType ( String . class ). make () text = mgmt . makePropertyKey ( ' text ' ). dataType ( String . class ). make () name = mgmt . makePropertyKey ( ' name ' ). dataType ( String . class ). make () document = mgmt . makePropertyKey ( ' document ' ). dataType ( String . class ). make () mgmt . buildIndex ( ' string ' , Vertex . class ). addKey ( string , Mapping . STRING . asParameter (), Parameter . of ( ParameterType . STRING_ANALYZER . getName (), org . apache . lucene . analysis . core . SimpleAnalyzer . class . getName ())). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( ' text ' , Vertex . class ). addKey ( text , Mapping . TEXT . asParameter (), Parameter . of ( ParameterType . TEXT_ANALYZER . getName (), org . apache . lucene . analysis . en . EnglishAnalyzer . class . getName ())). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( ' name ' , Vertex . class ). addKey ( string , Mapping . STRING . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( ' document ' , Vertex . class ). addKey ( text , Mapping . TEXT . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () With these settings, JanusGraph will use a SimpleAnalyzer analyzer for property key string , an EnglishAnalyzer analyzer for property key text , a KeywordAnalyzer analyzer for property name and a StandardAnalyzer analyzer for property 'document'. Custom parameters Sometimes it is required to set additional parameters on mappings (other than mapping type, mapping name and analyzer). For example, when we would like to use a different similarity algorithm (to modify the scoring algorithm of full text search) or if we want to use a custom boosting on some fields in Elasticsearch we can set custom parameters (right now only Elasticsearch supports custom parameters). The name of the custom parameter must be set through ParameterType.customParameterName(\"yourProperty\") . For Elasticsearch mgmt = graph . openManagement () myProperty = mgmt . makePropertyKey ( ' my_property ' ). dataType ( String . class ). make () mgmt . buildIndex ( ' custom_property_test ' , Vertex . class ). addKey ( myProperty , Mapping . TEXT . asParameter (), Parameter . of ( ParameterType . customParameterName ( \"boost\" ), 5 ), Parameter . of ( ParameterType . customParameterName ( \"similarity\" ), \"boolean\" )). buildMixedIndex ( \"search\" ) mgmt . commit () With these settings, JanusGraph will use the boost 5 and boolean similarity algorithm for property key my_property . Possible mapping parameters depend on Elasticsearch version. See mapping parameters for current Elasticsearch version.","title":"Field Mapping"},{"location":"index-backend/field-mapping/#field-mapping","text":"","title":"Field Mapping"},{"location":"index-backend/field-mapping/#individual-field-mapping","text":"By default, JanusGraph will encode property keys to generate a unique field name for the property key in the mixed index. If one wants to query the mixed index directly in the external index backend can be difficult to deal with and are illegible. For this use case, the field name can be explicitly specified through a parameter. mgmt = graph . openManagement () name = mgmt . makePropertyKey ( 'bookname' ). dataType ( String . class ). make () mgmt . buildIndex ( 'booksBySummary' , Vertex . class ). addKey ( name , Parameter . of ( 'mapped-name' , 'bookname' )). buildMixedIndex ( \"search\" ) mgmt . commit () With this field mapping defined as a parameter, JanusGraph will use the same name for the field in the booksBySummary index created in the external index system as for the property key. Note, that it must be ensured that the given field name is unique in the index.","title":"Individual Field Mapping"},{"location":"index-backend/field-mapping/#global-field-mapping","text":"Instead of individually adjusting the field mapping for every key added to a mixed index, one can instruct JanusGraph to always set the field name in the external index to be identical to the property key name. This is accomplished by enabling the configuration option map-name which is configured per indexing backend. If this option is enabled for a particular indexing backend, then all mixed indexes defined against said backend will use field names identical to the property key names. However, this approach has two limitations: 1) The user has to ensure that the property key names are valid field names for the indexing backend and 2) renaming the property key will NOT rename the field name in the index which can lead to naming collisions that the user has to be aware of and avoid. Note, that individual field mappings as described above can be used to overwrite the default name for a particular key.","title":"Global Field Mapping"},{"location":"index-backend/field-mapping/#custom-analyzer","text":"By default, JanusGraph will use the default analyzer from the indexing backend for properties with Mapping.TEXT, and no analyzer for properties with Mapping.STRING. If one wants to use another analyzer, it can be explicitly specified through a parameter : ParameterType.TEXT_ANALYZER for Mapping.TEXT and ParameterType.STRING_ANALYZER for Mapping.STRING.","title":"Custom Analyzer"},{"location":"index-backend/field-mapping/#for-elasticsearch","text":"The name of the analyzer must be set as parameter value. mgmt = graph . openManagement () string = mgmt . makePropertyKey ( 'string' ). dataType ( String . class ). make () text = mgmt . makePropertyKey ( 'text' ). dataType ( String . class ). make () textString = mgmt . makePropertyKey ( 'textString' ). dataType ( String . class ). make () mgmt . buildIndex ( 'string' , Vertex . class ). addKey ( string , Mapping . STRING . asParameter (), Parameter . of ( ParameterType . STRING_ANALYZER . getName (), 'standard' )). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( 'text' , Vertex . class ). addKey ( text , Mapping . TEXT . asParameter (), Parameter . of ( ParameterType . TEXT_ANALYZER . getName (), 'english' )). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( 'textString' , Vertex . class ). addKey ( text , Mapping . TEXTSTRING . asParameter (), Parameter . of ( ParameterType . STRING_ANALYZER . getName (), 'standard' ), Parameter . of ( ParameterType . TEXT_ANALYZER . getName (), 'english' )). buildMixedIndex ( \"search\" ) mgmt . commit () With these settings, JanusGraph will use the standard analyzer for property key string and the english analyzer for property key text .","title":"For Elasticsearch"},{"location":"index-backend/field-mapping/#for-solr","text":"The class of the tokenizer must be set as parameter value. mgmt = graph . openManagement () string = mgmt . makePropertyKey ( ' string ' ). dataType ( String . class ). make () text = mgmt . makePropertyKey ( ' text ' ). dataType ( String . class ). make () mgmt . buildIndex ( ' string ' , Vertex . class ). addKey ( string , Mapping . STRING . asParameter (), Parameter . of ( ParameterType . STRING_ANALYZER . getName (), ' org . apache . lucene . analysis . standard . StandardTokenizer ' )). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( ' text ' , Vertex . class ). addKey ( text , Mapping . TEXT . asParameter (), Parameter . of ( ParameterType . TEXT_ANALYZER . getName (), ' org . apache . lucene . analysis . core . WhitespaceTokenizer ' )). buildMixedIndex ( \"search\" ) mgmt . commit () With these settings, JanusGraph will use the standard tokenizer for property key string and the whitespace tokenizer for property key text .","title":"For Solr"},{"location":"index-backend/field-mapping/#for-lucene","text":"The name of the analyzer must be set as parameter value or it defaults to KeywordAnalyzer for Mapping.STRING and to StandardAnalyzer for Mapping.TEXT . mgmt = graph . openManagement () string = mgmt . makePropertyKey ( ' string ' ). dataType ( String . class ). make () text = mgmt . makePropertyKey ( ' text ' ). dataType ( String . class ). make () name = mgmt . makePropertyKey ( ' name ' ). dataType ( String . class ). make () document = mgmt . makePropertyKey ( ' document ' ). dataType ( String . class ). make () mgmt . buildIndex ( ' string ' , Vertex . class ). addKey ( string , Mapping . STRING . asParameter (), Parameter . of ( ParameterType . STRING_ANALYZER . getName (), org . apache . lucene . analysis . core . SimpleAnalyzer . class . getName ())). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( ' text ' , Vertex . class ). addKey ( text , Mapping . TEXT . asParameter (), Parameter . of ( ParameterType . TEXT_ANALYZER . getName (), org . apache . lucene . analysis . en . EnglishAnalyzer . class . getName ())). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( ' name ' , Vertex . class ). addKey ( string , Mapping . STRING . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . buildIndex ( ' document ' , Vertex . class ). addKey ( text , Mapping . TEXT . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () With these settings, JanusGraph will use a SimpleAnalyzer analyzer for property key string , an EnglishAnalyzer analyzer for property key text , a KeywordAnalyzer analyzer for property name and a StandardAnalyzer analyzer for property 'document'.","title":"For Lucene"},{"location":"index-backend/field-mapping/#custom-parameters","text":"Sometimes it is required to set additional parameters on mappings (other than mapping type, mapping name and analyzer). For example, when we would like to use a different similarity algorithm (to modify the scoring algorithm of full text search) or if we want to use a custom boosting on some fields in Elasticsearch we can set custom parameters (right now only Elasticsearch supports custom parameters). The name of the custom parameter must be set through ParameterType.customParameterName(\"yourProperty\") .","title":"Custom parameters"},{"location":"index-backend/field-mapping/#for-elasticsearch_1","text":"mgmt = graph . openManagement () myProperty = mgmt . makePropertyKey ( ' my_property ' ). dataType ( String . class ). make () mgmt . buildIndex ( ' custom_property_test ' , Vertex . class ). addKey ( myProperty , Mapping . TEXT . asParameter (), Parameter . of ( ParameterType . customParameterName ( \"boost\" ), 5 ), Parameter . of ( ParameterType . customParameterName ( \"similarity\" ), \"boolean\" )). buildMixedIndex ( \"search\" ) mgmt . commit () With these settings, JanusGraph will use the boost 5 and boolean similarity algorithm for property key my_property . Possible mapping parameters depend on Elasticsearch version. See mapping parameters for current Elasticsearch version.","title":"For Elasticsearch"},{"location":"index-backend/lucene/","text":"Apache Lucene Apache Lucene is a high-performance, full-featured text search engine library written entirely in Java. It is a technology suitable for nearly any application that requires full-text search, especially cross-platform. Apache Lucene is an open source project available for free download. \u2014 Apache Lucene Homepage JanusGraph supports Apache Lucene as a single-machine, embedded index backend. Lucene has a slightly extended feature set and performs better in small-scale applications compared to Elasticsearch , but is limited to single-machine deployments. Lucene Embedded Configuration For single machine deployments, Lucene runs embedded with JanusGraph. JanusGraph starts and interfaces with Lucene internally. To run Lucene embedded, add the following configuration options to the graph configuration file where /data/searchindex specifies the directory where Lucene should store the index data: index.search.backend = lucene index.search.directory = /data/searchindex In the above configuration, the index backend is named search . Replace search by a different name to change the name of the index. Feature Support Full-Text : Supports all Text predicates to search for text properties that matches a given word, prefix or regular expression. Geo : Supports Geo predicates to search for geo properties that are intersecting, within, or contained in a given query geometry. Supports points, lines and polygons for indexing. Supports circles and boxes for querying point properties and all shapes for querying non-point properties. Numeric Range : Supports all numeric comparisons in Compare . Temporal : Nanosecond granularity temporal indexing. Custom Analyzer : Choose to use a custom analyzer Not Query-normal-form : Supports queries other than Query-normal-form (QNF). QNF for JanusGraph is a variant of CNF (conjunctive normal form) with negation inlined where possible. Configuration Options Refer to Configuration Reference for a complete listing of all Lucene specific configuration options in addition to the general JanusGraph configuration options. Note, that each of the index backend options needs to be prefixed with index.[INDEX-NAME]. where [INDEX-NAME] stands for the name of the index backend. For instance, if the index backend is named search then these configuration options need to be prefixed with index.search. . To configure an index backend named search to use Lucene as the index system, set the following configuration option: index.search.backend = lucene Further Reading Please refer to the Apache Lucene homepage and available documentation for more information on Lucene.","title":"Apache Lucene"},{"location":"index-backend/lucene/#apache-lucene","text":"Apache Lucene is a high-performance, full-featured text search engine library written entirely in Java. It is a technology suitable for nearly any application that requires full-text search, especially cross-platform. Apache Lucene is an open source project available for free download. \u2014 Apache Lucene Homepage JanusGraph supports Apache Lucene as a single-machine, embedded index backend. Lucene has a slightly extended feature set and performs better in small-scale applications compared to Elasticsearch , but is limited to single-machine deployments.","title":"Apache Lucene"},{"location":"index-backend/lucene/#lucene-embedded-configuration","text":"For single machine deployments, Lucene runs embedded with JanusGraph. JanusGraph starts and interfaces with Lucene internally. To run Lucene embedded, add the following configuration options to the graph configuration file where /data/searchindex specifies the directory where Lucene should store the index data: index.search.backend = lucene index.search.directory = /data/searchindex In the above configuration, the index backend is named search . Replace search by a different name to change the name of the index.","title":"Lucene Embedded Configuration"},{"location":"index-backend/lucene/#feature-support","text":"Full-Text : Supports all Text predicates to search for text properties that matches a given word, prefix or regular expression. Geo : Supports Geo predicates to search for geo properties that are intersecting, within, or contained in a given query geometry. Supports points, lines and polygons for indexing. Supports circles and boxes for querying point properties and all shapes for querying non-point properties. Numeric Range : Supports all numeric comparisons in Compare . Temporal : Nanosecond granularity temporal indexing. Custom Analyzer : Choose to use a custom analyzer Not Query-normal-form : Supports queries other than Query-normal-form (QNF). QNF for JanusGraph is a variant of CNF (conjunctive normal form) with negation inlined where possible.","title":"Feature Support"},{"location":"index-backend/lucene/#configuration-options","text":"Refer to Configuration Reference for a complete listing of all Lucene specific configuration options in addition to the general JanusGraph configuration options. Note, that each of the index backend options needs to be prefixed with index.[INDEX-NAME]. where [INDEX-NAME] stands for the name of the index backend. For instance, if the index backend is named search then these configuration options need to be prefixed with index.search. . To configure an index backend named search to use Lucene as the index system, set the following configuration option: index.search.backend = lucene","title":"Configuration Options"},{"location":"index-backend/lucene/#further-reading","text":"Please refer to the Apache Lucene homepage and available documentation for more information on Lucene.","title":"Further Reading"},{"location":"index-backend/search-predicates/","text":"Search Predicates and Data Types This page lists all of the comparison predicates that JanusGraph supports in global graph search and local traversals. Compare Predicate The Compare enum specifies the following comparison predicates used for index query construction and used in the examples above: eq (equal) neq (not equal) gt (greater than) gte (greater than or equal) lt (less than) lte (less than or equal) All comparison predicates are supported by String, numeric, Date and Instant data types. Boolean and UUID data types support the eq and neq comparison predicates. eq and neq can be used on Boolean and UUID. Text Predicate The Text enum specifies the Text Search used to query for matching text or string values. We differentiate between two types of predicates: Text search predicates which match against the individual words inside a text string after it has been tokenized. These predicates are not case sensitive. textContains : is true if (at least) one word inside the text string matches the query string textContainsPrefix : is true if (at least) one word inside the text string begins with the query string textContainsRegex : is true if (at least) one word inside the text string matches the given regular expression textContainsFuzzy : is true if (at least) one word inside the text string is similar to the query String (based on Levenshtein edit distance) String search predicates which match against the entire string value textPrefix : if the string value starts with the given query string textRegex : if the string value matches the given regular expression in its entirety textFuzzy : if the string value is similar to the given query string (based on Levenshtein edit distance) See Text Search for more information about full-text and string search. Geo Predicate The Geo enum specifies geo-location predicates. geoIntersect which holds true if the two geometric objects have at least one point in common (opposite of geoDisjoint ). geoWithin which holds true if one geometric object contains the other. geoDisjoint which holds true if the two geometric objects have no points in common (opposite of geoIntersect ). geoContains which holds true if one geometric object is contained by the other. See Geo Mapping for more information about geo search. Query Examples The following query examples demonstrate some of the predicates on the tutorial graph. // 1) Find vertices with the name \"hercules\" g . V (). has ( \"name\" , \"hercules\" ) // 2) Find all vertices with an age greater than 50 g . V (). has ( \"age\" , gt ( 50 )) // or find all vertices between 1000 (inclusive) and 5000 (exclusive) years of age and order by ascending age g . V (). has ( \"age\" , inside ( 1000 , 5000 )). order (). by ( \"age\" , asc ) // which returns the same result set as the following query but in reverse order g . V (). has ( \"age\" , inside ( 1000 , 5000 )). order (). by ( \"age\" , desc ) // 3) Find all edges where the place is at most 50 kilometers from the given latitude-longitude pair g . E (). has ( \"place\" , geoWithin ( Geoshape . circle ( 37.97 , 23.72 , 50 ))) // 4) Find all edges where reason contains the word \"loves\" g . E (). has ( \"reason\" , textContains ( \"loves\" )) // or all edges which contain two words (need to chunk into individual words) g . E (). has ( \"reason\" , textContains ( \"loves\" )). has ( \"reason\" , textContains ( \"breezes\" )) // or all edges which contain words that start with \"lov\" g . E (). has ( \"reason\" , textContainsPrefix ( \"lov\" )) // or all edges which contain words that match the regular expression \"br[ez]*s\" in their entirety g . E (). has ( \"reason\" , textContainsRegex ( \"br[ez]*s\" )) // or all edges which contain words similar to \"love\" g . E (). has ( \"reason\" , textContainsFuzzy ( \"love\" )) // 5) Find all vertices older than a thousand years and named \"saturn\" g . V (). has ( \"age\" , gt ( 1000 )). has ( \"name\" , \"saturn\" ) Data Type Support While JanusGraph's composite indexes support any data type that can be stored in JanusGraph, the mixed indexes are limited to the following data types. Byte Short Integer Long Float Double String Geoshape Date Instant UUID Additional data types will be supported in the future. Geoshape Data Type The Geoshape data type supports representing a point, circle, box, line, polygon, multi-point, multi-line and multi-polygon. Index backends currently support indexing points, circles, boxes, lines, polygons, multi-point, multi-line, multi-polygon and geometry collection. Geospatial index lookups are only supported via mixed indexes. To construct a Geoshape use the following methods: //lat, lng Geoshape . point ( 37.97 , 23.72 ) //lat, lng, radius in km Geoshape . circle ( 37.97 , 23.72 , 50 ) //SW lat, SW lng, NE lat, NE lng Geoshape . box ( 37.97 , 23.72 , 38.97 , 24.72 ) //WKT Geoshape . fromWkt ( \"POLYGON ((35.4 48.9, 35.6 48.9, 35.6 49.1, 35.4 49.1, 35.4 48.9))\" ) //MultiPoint Geoshape . geoshape ( Geoshape . getShapeFactory (). multiPoint (). pointXY ( 60.0 , 60.0 ). pointXY ( 120.0 , 60.0 ) . build ()) //MultiLine Geoshape . geoshape ( Geoshape . getShapeFactory (). multiLineString () . add ( Geoshape . getShapeFactory (). lineString (). pointXY ( 59.0 , 60.0 ). pointXY ( 61.0 , 60.0 )) . add ( Geoshape . getShapeFactory (). lineString (). pointXY ( 119.0 , 60.0 ). pointXY ( 121.0 , 60.0 )). build ()) //MultiPolygon Geoshape . geoshape ( Geoshape . getShapeFactory (). multiPolygon () . add ( Geoshape . getShapeFactory (). polygon (). pointXY ( 59.0 , 59.0 ). pointXY ( 61.0 , 59.0 ) . pointXY ( 61.0 , 61.0 ). pointXY ( 59.0 , 61.0 ). pointXY ( 59.0 , 59.0 )) . add ( Geoshape . getShapeFactory (). polygon (). pointXY ( 119.0 , 59.0 ). pointXY ( 121.0 , 59.0 ) . pointXY ( 121.0 , 61.0 ). pointXY ( 119.0 , 61.0 ). pointXY ( 119.0 , 59.0 )). build ()) //GeometryCollection Geoshape . geoshape ( Geoshape . getGeometryCollectionBuilder () . add ( Geoshape . getShapeFactory (). pointXY ( 60.0 , 60.0 )) . add ( Geoshape . getShapeFactory (). lineString (). pointXY ( 119.0 , 60.0 ). pointXY ( 121.0 , 60.0 ). build ()) . add ( Geoshape . getShapeFactory (). polygon (). pointXY ( 119.0 , 59.0 ). pointXY ( 121.0 , 59.0 ) . pointXY ( 121.0 , 61.0 ). pointXY ( 119.0 , 61.0 ). pointXY ( 119.0 , 59.0 )). build ()) In addition, when importing a graph via GraphSON the geometry may be represented by GeoJSON: string \"37.97, 23.72\" list [ 37.97 , 23.72 ] GeoJSON feature { \"type\" : \"Feature\" , \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 125.6 , 10.1 ] }, \"properties\" : { \"name\" : \"Dinagat Islands\" } } GeoJSON geometry { \"type\" : \"Point\" , \"coordinates\" : [ 125.6 , 10.1 ] } GeoJSON may be specified as Point, Circle, LineString or Polygon. Polygons must be closed. Note that unlike the JanusGraph API GeoJSON specifies coordinates as lng lat. Collections If you are using Elasticsearch then you can index properties with SET and LIST cardinality. For instance: mgmt = graph . openManagement () nameProperty = mgmt . makePropertyKey ( \"names\" ). dataType ( String . class ). cardinality ( Cardinality . SET ). make () mgmt . buildIndex ( \"search\" , Vertex . class ). addKey ( nameProperty , Mapping . STRING . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () //Insert a vertex person = graph . addVertex () person . property ( \"names\" , \"Robert\" ) person . property ( \"names\" , \"Bob\" ) graph . tx (). commit () //Now query it g . V (). has ( \"names\" , \"Bob\" ). count (). next () //1 g . V (). has ( \"names\" , \"Robert\" ). count (). next () //1","title":"Search Predicates and Data Types"},{"location":"index-backend/search-predicates/#search-predicates-and-data-types","text":"This page lists all of the comparison predicates that JanusGraph supports in global graph search and local traversals.","title":"Search Predicates and Data Types"},{"location":"index-backend/search-predicates/#compare-predicate","text":"The Compare enum specifies the following comparison predicates used for index query construction and used in the examples above: eq (equal) neq (not equal) gt (greater than) gte (greater than or equal) lt (less than) lte (less than or equal) All comparison predicates are supported by String, numeric, Date and Instant data types. Boolean and UUID data types support the eq and neq comparison predicates. eq and neq can be used on Boolean and UUID.","title":"Compare Predicate"},{"location":"index-backend/search-predicates/#text-predicate","text":"The Text enum specifies the Text Search used to query for matching text or string values. We differentiate between two types of predicates: Text search predicates which match against the individual words inside a text string after it has been tokenized. These predicates are not case sensitive. textContains : is true if (at least) one word inside the text string matches the query string textContainsPrefix : is true if (at least) one word inside the text string begins with the query string textContainsRegex : is true if (at least) one word inside the text string matches the given regular expression textContainsFuzzy : is true if (at least) one word inside the text string is similar to the query String (based on Levenshtein edit distance) String search predicates which match against the entire string value textPrefix : if the string value starts with the given query string textRegex : if the string value matches the given regular expression in its entirety textFuzzy : if the string value is similar to the given query string (based on Levenshtein edit distance) See Text Search for more information about full-text and string search.","title":"Text Predicate"},{"location":"index-backend/search-predicates/#geo-predicate","text":"The Geo enum specifies geo-location predicates. geoIntersect which holds true if the two geometric objects have at least one point in common (opposite of geoDisjoint ). geoWithin which holds true if one geometric object contains the other. geoDisjoint which holds true if the two geometric objects have no points in common (opposite of geoIntersect ). geoContains which holds true if one geometric object is contained by the other. See Geo Mapping for more information about geo search.","title":"Geo Predicate"},{"location":"index-backend/search-predicates/#query-examples","text":"The following query examples demonstrate some of the predicates on the tutorial graph. // 1) Find vertices with the name \"hercules\" g . V (). has ( \"name\" , \"hercules\" ) // 2) Find all vertices with an age greater than 50 g . V (). has ( \"age\" , gt ( 50 )) // or find all vertices between 1000 (inclusive) and 5000 (exclusive) years of age and order by ascending age g . V (). has ( \"age\" , inside ( 1000 , 5000 )). order (). by ( \"age\" , asc ) // which returns the same result set as the following query but in reverse order g . V (). has ( \"age\" , inside ( 1000 , 5000 )). order (). by ( \"age\" , desc ) // 3) Find all edges where the place is at most 50 kilometers from the given latitude-longitude pair g . E (). has ( \"place\" , geoWithin ( Geoshape . circle ( 37.97 , 23.72 , 50 ))) // 4) Find all edges where reason contains the word \"loves\" g . E (). has ( \"reason\" , textContains ( \"loves\" )) // or all edges which contain two words (need to chunk into individual words) g . E (). has ( \"reason\" , textContains ( \"loves\" )). has ( \"reason\" , textContains ( \"breezes\" )) // or all edges which contain words that start with \"lov\" g . E (). has ( \"reason\" , textContainsPrefix ( \"lov\" )) // or all edges which contain words that match the regular expression \"br[ez]*s\" in their entirety g . E (). has ( \"reason\" , textContainsRegex ( \"br[ez]*s\" )) // or all edges which contain words similar to \"love\" g . E (). has ( \"reason\" , textContainsFuzzy ( \"love\" )) // 5) Find all vertices older than a thousand years and named \"saturn\" g . V (). has ( \"age\" , gt ( 1000 )). has ( \"name\" , \"saturn\" )","title":"Query Examples"},{"location":"index-backend/search-predicates/#data-type-support","text":"While JanusGraph's composite indexes support any data type that can be stored in JanusGraph, the mixed indexes are limited to the following data types. Byte Short Integer Long Float Double String Geoshape Date Instant UUID Additional data types will be supported in the future.","title":"Data Type Support"},{"location":"index-backend/search-predicates/#geoshape-data-type","text":"The Geoshape data type supports representing a point, circle, box, line, polygon, multi-point, multi-line and multi-polygon. Index backends currently support indexing points, circles, boxes, lines, polygons, multi-point, multi-line, multi-polygon and geometry collection. Geospatial index lookups are only supported via mixed indexes. To construct a Geoshape use the following methods: //lat, lng Geoshape . point ( 37.97 , 23.72 ) //lat, lng, radius in km Geoshape . circle ( 37.97 , 23.72 , 50 ) //SW lat, SW lng, NE lat, NE lng Geoshape . box ( 37.97 , 23.72 , 38.97 , 24.72 ) //WKT Geoshape . fromWkt ( \"POLYGON ((35.4 48.9, 35.6 48.9, 35.6 49.1, 35.4 49.1, 35.4 48.9))\" ) //MultiPoint Geoshape . geoshape ( Geoshape . getShapeFactory (). multiPoint (). pointXY ( 60.0 , 60.0 ). pointXY ( 120.0 , 60.0 ) . build ()) //MultiLine Geoshape . geoshape ( Geoshape . getShapeFactory (). multiLineString () . add ( Geoshape . getShapeFactory (). lineString (). pointXY ( 59.0 , 60.0 ). pointXY ( 61.0 , 60.0 )) . add ( Geoshape . getShapeFactory (). lineString (). pointXY ( 119.0 , 60.0 ). pointXY ( 121.0 , 60.0 )). build ()) //MultiPolygon Geoshape . geoshape ( Geoshape . getShapeFactory (). multiPolygon () . add ( Geoshape . getShapeFactory (). polygon (). pointXY ( 59.0 , 59.0 ). pointXY ( 61.0 , 59.0 ) . pointXY ( 61.0 , 61.0 ). pointXY ( 59.0 , 61.0 ). pointXY ( 59.0 , 59.0 )) . add ( Geoshape . getShapeFactory (). polygon (). pointXY ( 119.0 , 59.0 ). pointXY ( 121.0 , 59.0 ) . pointXY ( 121.0 , 61.0 ). pointXY ( 119.0 , 61.0 ). pointXY ( 119.0 , 59.0 )). build ()) //GeometryCollection Geoshape . geoshape ( Geoshape . getGeometryCollectionBuilder () . add ( Geoshape . getShapeFactory (). pointXY ( 60.0 , 60.0 )) . add ( Geoshape . getShapeFactory (). lineString (). pointXY ( 119.0 , 60.0 ). pointXY ( 121.0 , 60.0 ). build ()) . add ( Geoshape . getShapeFactory (). polygon (). pointXY ( 119.0 , 59.0 ). pointXY ( 121.0 , 59.0 ) . pointXY ( 121.0 , 61.0 ). pointXY ( 119.0 , 61.0 ). pointXY ( 119.0 , 59.0 )). build ()) In addition, when importing a graph via GraphSON the geometry may be represented by GeoJSON: string \"37.97, 23.72\" list [ 37.97 , 23.72 ] GeoJSON feature { \"type\" : \"Feature\" , \"geometry\" : { \"type\" : \"Point\" , \"coordinates\" : [ 125.6 , 10.1 ] }, \"properties\" : { \"name\" : \"Dinagat Islands\" } } GeoJSON geometry { \"type\" : \"Point\" , \"coordinates\" : [ 125.6 , 10.1 ] } GeoJSON may be specified as Point, Circle, LineString or Polygon. Polygons must be closed. Note that unlike the JanusGraph API GeoJSON specifies coordinates as lng lat.","title":"Geoshape Data Type"},{"location":"index-backend/search-predicates/#collections","text":"If you are using Elasticsearch then you can index properties with SET and LIST cardinality. For instance: mgmt = graph . openManagement () nameProperty = mgmt . makePropertyKey ( \"names\" ). dataType ( String . class ). cardinality ( Cardinality . SET ). make () mgmt . buildIndex ( \"search\" , Vertex . class ). addKey ( nameProperty , Mapping . STRING . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () //Insert a vertex person = graph . addVertex () person . property ( \"names\" , \"Robert\" ) person . property ( \"names\" , \"Bob\" ) graph . tx (). commit () //Now query it g . V (). has ( \"names\" , \"Bob\" ). count (). next () //1 g . V (). has ( \"names\" , \"Robert\" ). count (). next () //1","title":"Collections"},{"location":"index-backend/solr/","text":"Apache Solr Solr is the popular, blazing fast open source enterprise search platform from the Apache Lucene project. Solr is a standalone enterprise search server with a REST-like API. Solr is highly reliable, scalable and fault tolerant, providing distributed indexing, replication and load-balanced querying, automated failover and recovery, centralized configuration and more. \u2014 Apache Solr Homepage JanusGraph supports Apache Solr as an index backend. Here are some of the Solr features supported by JanusGraph: Full-Text : Supports all Text predicates to search for text properties that matches a given word, prefix or regular expression. Geo : Supports all Geo predicates to search for geo properties that are intersecting, within, disjoint to or contained in a given query geometry. Supports points, lines and polygons for indexing. Supports circles, boxes and polygons for querying point properties and all shapes for querying non-point properties. Numeric Range : Supports all numeric comparisons in Compare . TTL : Supports automatically expiring indexed elements. Temporal : Millisecond granularity temporal indexing. Custom Analyzer : Choose to use a custom analyzer Please see Version Compatibility for details on what versions of Solr will work with JanusGraph. Solr Configuration Overview JanusGraph supports Solr running in either a SolrCloud or Solr Standalone (HTTP) configuration for use with a mixed index (see Mixed Index ). The desired connection mode is configured via the parameter mode which must be set to either cloud or http , the former being the default value. For example, to explicitly specify that Solr is running in a SolrCloud configuration the following property is specified as a JanusGraph configuration property: index.search.solr.mode = cloud These are some key Solr terms: Core : A single index on a single machine Configuration : solrconfig.xml , schema.xml , and other files required to define a core. Collection : A single logical index that can span multiple cores on different machines. Configset : A shared configuration that can be reused by multiple cores. Connecting to SolrCloud When connecting to a SolrCloud cluster by setting the mode equal to cloud , the Zookeeper URL (and optionally port) must be specified so that JanusGraph can discover and interact with the Solr cluster. index.search.backend = solr index.search.solr.mode = cloud index.search.solr.zookeeper-url = localhost:2181 A number of additional configuration options pertaining to the creation of new collections (which is only supported in SolrCloud operation mode) can be configured to control sharding behavior among other things. Refer to the Configuration Reference for a complete listing of those options. SolrCloud leverages Zookeeper to coordinate collection and configset information between the Solr servers. The use of Zookeeper with SolrCloud provides the opportunity to significantly reduce the amount of manual configuration required to use Solr as a back end index for JanusGraph. Configset Configuration A configset is required to create a collection. The configset is stored in Zookeeper to enable access to it across the Solr servers. Each collection can provide its own configset when it is created, so that each collection may have a different configuration. With this approach, each collection must be created manually. A shared configset can be uploaded separately to Zookeeper if it will be reused by multiple collections. With this approach, JanusGraph can create collections automatically by using the shared configset. Another benefit is that reusing a configset significantly reduces the amount of data stored in Zookeeper. Using an Individual Configset In this example, a collection named verticesByAge is created manually using the default JanusGraph configuration for Solr that is found in the distribution. When the collection is created, the configuration is uploaded into Zookeeper, using the same collection name verticesByAge for the configset name. Refer to the Solr Reference Guide for available parameters. # create the collection $SOLR_HOME /bin/solr create -c verticesByAge -d $JANUSGRAPH_HOME /conf/solr Define a mixed index using JanusGraphManagement and the same collection name. mgmt = graph . openManagement () age = mgmt . makePropertyKey ( \"age\" ). dataType ( Integer . class ). make () mgmt . buildIndex ( \"verticesByAge\" , Vertex . class ). addKey ( age ). buildMixedIndex ( \"search\" ) mgmt . commit () Using a Shared Configset When using a shared configset, it is most convenient to upload the configuration first as a one time operation. In this example, a configset named janusgraph-configset is uploaded in to Zookeeper using the default JanusGraph configuration for Solr that is found in the distribution. Refer to the Solr Reference Guide for available parameters. # upload the shared configset into Zookeeper # Solr 5 $SOLR_HOME /server/scripts/cloud-scripts/zkcli.sh -cmd upconfig -z localhost:2181 \\ -d $JANUSGRAPH_HOME /conf/solr -n janusgraph-configset # Solr 6 and higher $SOLR_HOME /bin/solr zk upconfig -d $JANUSGRAPH_HOME /conf/solr -n janusgraph-configset \\ -z localhost:2181 When configuring the SolrCloud indexing backend for JanusGraph, make sure to provide the name of the shared configset using the index.search.solr.configset property. index.search.backend = solr index.search.solr.mode = cloud index.search.solr.zookeeper-url = localhost:2181 index.search.solr.configset = janusgraph-configset Define a mixed index using JanusGraphManagement and the collection name. mgmt = graph . openManagement () age = mgmt . makePropertyKey ( \"age\" ). dataType ( Integer . class ). make () mgmt . buildIndex ( \"verticesByAge\" , Vertex . class ). addKey ( age ). buildMixedIndex ( \"search\" ) mgmt . commit () Connecting to Solr Standalone (HTTP) When connecting to Solr Standalone via HTTP by setting the mode equal to http , a single or list of URLs for the Solr instances must be provided. index.search.backend = solr index.search.solr.mode = http index.search.solr.http-urls = http://localhost:8983/solr Additional configuration options for controlling the maximum number of connections, connection timeout and transmission compression are available for the HTTP mode. Refer to the Configuration Reference for a complete listing of those options. Core Configuration Solr Standalone is used for a single instance, and it keeps configuration information on the file system. A core must be created manually for each mixed index. To create a core, a core_name and a configuration directory is required. Refer to the Solr Reference Guide for available parameters. In this example, a core named verticesByAge is created using the default JanusGraph configuration for Solr that is found in the distribution. $SOLR_HOME /bin/solr create -c verticesByAge -d $JANUSGRAPH_HOME /conf/solr Define a mixed index using JanusGraphManagement and the same core name. mgmt = graph . openManagement () age = mgmt . makePropertyKey ( \"age\" ). dataType ( Integer . class ). make () mgmt . buildIndex ( \"verticesByAge\" , Vertex . class ). addKey ( age ). buildMixedIndex ( \"search\" ) mgmt . commit () Kerberos Configuration When connecting to a Solr environment that is protected by Kerberos we must specify that Kerberos is being used and reference a JAAS configuration file to properly configure the Solr Clients. This configuration is required when Kerberos is in use regardless of the mode in which Solr is operating (SolrCloud or Solr Standalone). index.search.solr.kerberos-enabled = true The JAAS configuration file is supplied by ensuring that you set the java system property java.security.auth.login.config with the absolute path to the file. This property should be set using JVM options. For example to run gremlin.sh you would need to set the JAVA_OPTIONS environment variable prior to running the script: export JAVA_OPTIONS = \"-Djava.security.auth.login.config=/absolute/path/jaas.conf\" $JANUSGRAPH_HOME /bin/gremlin.sh For details on the content required in the JAAS configuration file refer to the https://lucene.apache.org/solr/guide/7_0/kerberos-authentication-plugin.html#define-a-jaas-configuration-file[Solr Reference Guide]. Solr Schema Design Dynamic Field Definition By default, JanusGraph uses Solr\u2019s Dynamic Fields feature to define the field types for all indexed keys. This requires no extra configuration when adding property keys to a mixed index backed by Solr and provides better performance than schemaless mode. JanusGraph assumes the following dynamic field tags are defined in the backing Solr collection\u2019s schema.xml file. Please note that there is additional xml definition of the following fields required in a solr schema.xml file in order to use them. Reference the example schema.xml file provided in the ./conf/solr/schema.xml directory in a JanusGraph installation for more information. <dynamicField name= \"*_i\" type= \"int\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_s\" type= \"string\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_l\" type= \"long\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_t\" type= \"text_general\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_b\" type= \"boolean\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_f\" type= \"float\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_d\" type= \"double\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_g\" type= \"geo\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_dt\" type= \"date\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_uuid\" type= \"uuid\" indexed= \"true\" stored= \"true\" /> In JanusGraph\u2019s default configuration, property key names do not have to end with the type-appropriate suffix to take advantage of Solr\u2019s dynamic field feature. JanusGraph generates the Solr field name from the property key name by encoding the property key definition\u2019s numeric identifier and the type-appropriate suffix. This means that JanusGraph uses synthetic field names with type-appropriate suffixes behind the scenes, regardless of the property key names defined and used by application code using JanusGraph. This field name mapping can be overridden through non-default configuration. That\u2019s described in the next section. Manual Field Definition If the user would rather manually define the field types for each of the indexed fields in a collection, the configuration option dyn-fields needs to be disabled. It is important that the field for each indexed property key is defined in the backing Solr schema before the property key is added to the index. In this scenario, it is advisable to enable explicit property key name to field mapping in order to fix the field names for their explicit definition. This can be achieved in one of two ways: Configuring the name of the field by providing a mapped-name parameter when adding the property key to the index. See Individual Field Mapping for more information. By enabling the map-name configuration option for the Solr index which will use the property key name as the field name in Solr. See Global Field Mapping for more information. Schemaless Mode JanusGraph can also interact with a SolrCloud cluster that is configured for schemaless mode . In this scenario, the configuration option dyn-fields should be disabled since Solr will infer the field type from the values and not the field name. Note, however, that schemaless mode is recommended only for prototyping and initial application development and NOT recommended for production use. Troubleshooting Collection Does Not Exist The collection (and all of the required configuration files) must be initialized before a defined index can use the collection. See Connecting to SolrCloud for more information. When using SolrCloud, the Zookeeper zkCli.sh command line tool can be used to inspect the configurations loaded into Zookeeper. Also verify that the default JanusGraph configuration files are copied to the correct location under solr and that the directory where the files are copied is correct. Cannot Find the Specified Configset When using SolrCloud, a configset is required to create a mixed index for JanusGraph. See Configset Configuration for more information. If using an individual configset, the collection must be created manually first. If using a shared configset, the configset must be uploaded into Zookeeper first. You can verify that the configset and its configuration files are in Zookeeper under /configs . Refer to the Solr Reference Guide for other Zookeeper operations. # verify the configset in Zookeeper # Solr 5 $SOLR_HOME /server/scripts/cloud-scripts/zkcli.sh -cmd list -z localhost:2181 # Solr 6 and higher $SOLR_HOME /bin/solr zk ls -r /configs/configset-name -z localhost:2181 HTTP Error 404 This error may be encountered when using Solr Standalone (HTTP) mode. An example of the error: 20:01:22 ERROR org.janusgraph.diskstorage.solr.SolrIndex - Unable to save documents to Solr as one of the shape objects stored were not compatible with Solr. org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8983/solr: Expected mime type application/octet-stream but got text/html. <html> <head> <meta http-equiv= \"Content-Type\" content= \"text/html;charset=utf-8\" /> <title> Error 404 Not Found </title> </head> <body><h2> HTTP ERROR 404 </h2> <p> Problem accessing /solr/verticesByAge/update. Reason: <pre> Not Found </pre></p> </body> </html> Make sure to create the core manually before attempting to store data into the index. See Core Configuration for more information. Invalid core or collection name The core or collection name is an identifier. It must consist entirely of periods, underscores, hyphens, and/or alphanumerics, and also it may not start with a hyphen. Connection Problems Irrespective of the operation mode, a Solr instance or a cluster of Solr instances must be running and accessible from the JanusGraph instance(s) in order for JanusGraph to use Solr as an indexing backend. Check that the Solr cluster is running correctly and that it is visible and accessible over the network (or locally) from the JanusGraph instances. JTS ClassNotFoundException with Geo Data Solr relies on Spatial4j for geo processing. Spatial4j declares an optional dependency on JTS (\"JTS Topology Suite\"). JTS is required for some geo field definition and query functionality. If the JTS jar is not on the Solr daemon\u2019s classpath and a field in schema.xml uses a geo type, then Solr may throw a ClassNotFoundException on one of the missing JTS classes. The exception can appear when starting Solr using a schema.xml file designed to work with JanusGraph, but can also appear when invoking CREATE in the Solr CoreAdmin API . The exception appears in slightly different formats on the client and server sides, although the root cause is identical. Here\u2019s a representative example from a Solr server log: ERROR [ http - 8983 - exec - 5 ] 2014 - 10 - 07 02 : 54 : 06 , 665 SolrCoreResourceManager . java ( line 344 ) com / vividsolutions / jts / geom / Geometry java . lang . NoClassDefFoundError : com / vividsolutions / jts / geom / Geometry at com . spatial4j . core . context . jts . JtsSpatialContextFactory . newSpatialContext ( JtsSpatialContextFactory . java : 30 ) at com . spatial4j . core . context . SpatialContextFactory . makeSpatialContext ( SpatialContextFactory . java : 83 ) at org . apache . solr . schema . AbstractSpatialFieldType . init ( AbstractSpatialFieldType . java : 95 ) at org . apache . solr . schema . AbstractSpatialPrefixTreeFieldType . init ( AbstractSpatialPrefixTreeFieldType . java : 43 ) at org . apache . solr . schema . SpatialRecursivePrefixTreeFieldType . init ( SpatialRecursivePrefixTreeFieldType . java : 37 ) at org . apache . solr . schema . FieldType . setArgs ( FieldType . java : 164 ) at org . apache . solr . schema . FieldTypePluginLoader . init ( FieldTypePluginLoader . java : 141 ) at org . apache . solr . schema . FieldTypePluginLoader . init ( FieldTypePluginLoader . java : 43 ) at org . apache . solr . util . plugin . AbstractPluginLoader . load ( AbstractPluginLoader . java : 190 ) at org . apache . solr . schema . IndexSchema . readSchema ( IndexSchema . java : 470 ) at com . datastax . bdp . search . solr . CassandraIndexSchema . readSchema ( CassandraIndexSchema . java : 72 ) at org . apache . solr . schema . IndexSchema . < init > ( IndexSchema . java : 168 ) at com . datastax . bdp . search . solr . CassandraIndexSchema . < init > ( CassandraIndexSchema . java : 54 ) at com . datastax . bdp . search . solr . core . CassandraCoreContainer . create ( CassandraCoreContainer . java : 210 ) at com . datastax . bdp . search . solr . core . SolrCoreResourceManager . createCore ( SolrCoreResourceManager . java : 256 ) at com . datastax . bdp . search . solr . handler . admin . CassandraCoreAdminHandler . handleCreateAction ( CassandraCoreAdminHandler . java : 117 ) ... Here\u2019s what normally appears in the output of the client that issued the associated CREATE command to the CoreAdmin API: org . apache . solr . common . SolrException : com / vividsolutions / jts / geom / Geometry at com . datastax . bdp . search . solr . core . SolrCoreResourceManager . createCore ( SolrCoreResourceManager . java : 345 ) at com . datastax . bdp . search . solr . handler . admin . CassandraCoreAdminHandler . handleCreateAction ( CassandraCoreAdminHandler . java : 117 ) at org . apache . solr . handler . admin . CoreAdminHandler . handleRequestBody ( CoreAdminHandler . java : 152 ) ... This is resolved by adding the JTS jar to the classpath of JanusGraph and/or the Solr server. JTS is not included in JanusGraph distributions by default due to its LGPL license. Users must download the JTS jar file separately and copy it into the JanusGraph and/or Solr server lib directory. If using Solr\u2019s built in web server, the JTS jar may be copied to the example/solr-webapp/webapp/WEB-INF/lib directory to include it in the classpath. Solr can be restarted, and the exception should be gone. Solr must be started once with the correct schema.xml file in place first, for the example/solr-webapp/webapp/WEB-INF/lib directory to exist. To determine the ideal JTS version for Solr server, first check the version of Spatial4j in use by the Solr cluster, then determine the version of JTS against which that Spatial4j version was compiled. Spatial4j declares its target JTS version in the pom for the com.spatial4j:spatial4j artifact . Copy the JTS jar to the server/solr-webapp/webapp/WEB-INF/lib directory in your solr installation. Advanced Solr Configuration DSE Search This section covers installation and configuration of JanusGraph with DataStax Enterprise (DSE) Search. There are multiple ways to install DSE, but this section focuses on DSE\u2019s binary tarball install option on Linux. Most of the steps in this section can be generalized to the other install options for DSE. Install DataStax Enterprise as directed by the page Installing DataStax Enterprise using the binary tarball . Export DSE_HOME and append to PATH in your shell environment. Here\u2019s an example using Bash syntax: export DSE_HOME = /path/to/dse-version.number export PATH = \" $DSE_HOME \" /bin: \" $PATH \" Install JTS for Solr. The appropriate version varies with the Spatial4j version. As of DSE 4.5.2, the appropriate version is 1.13. cd $DSE_HOME /resources/solr/lib curl -O 'http://central.maven.org/maven2/com/vividsolutions/jts/1.13/jts-1.13.jar' Start DSE Cassandra and Solr in a single background daemon: # The \"dse-data\" path below was chosen to match the # \"Installing DataStax Enterprise using the binary tarball\" # documentation page from DataStax. The exact path is not # significant. dse cassandra -s -Ddse.solr.data.dir = \" $DSE_HOME \" /dse-data/solr The previous command will write some startup information to the console and to the logfile path log4j.appender.R.File configured in $DSE_HOME/resources/cassandra/conf/log4j-server.properties . Once DSE with Cassandra and Solr has started normally, check the cluster health with nodetool status . A single-instance ring should show one node with flags *U*p and *N*ormal: nodetool status Note: Ownership information does not include topology ; for complete information, specify a keyspace = Datacenter: Solr Status = Up/Down | / State = Normal/Leaving/Joining/Moving -- Address Load Owns Host ID Token Rack UN 127 .0.0.1 99 .89 KB 100 .0% 5484ef7b-ebce-4560-80f0-cbdcd9e9f496 -7317038863489909889 rack1 Next, switch to Gremlin Console and open a JanusGraph database against the DSE instance. This will create JanusGraph\u2019s keyspace and column families. cd $JANUSGRAPH_HOME bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- gremlin> graph = JanusGraphFactory.open ( 'conf/janusgraph-cql-solr.properties' ) == >janusgraph [ cql: [ 127 .0.0.1 ]] gremlin> g = graph.traversal () == >graphtraversalsource [ janusgraph [ cql: [ 127 .0.0.1 ]] , standard ] gremlin> Keep this Gremlin Console open. We\u2019ll take a break now to install a Solr core. Then we\u2019ll come back to this console to load some sample data. Next, upload configuration files for JanusGraph\u2019s Solr collection, then create the core in DSE: # Change to the directory where JanusGraph was extracted. Later commands # use relative paths to the Solr config files shipped with the JanusGraph # distribution. cd $JANUSGRAPH_HOME # The name must be URL safe and should contain one dot/full-stop # character. The part of the name after the dot must not conflict with # any of JanusGraph's internal CF names. Starting the part after the dot # \"solr\" will avoid a conflict with JanusGraph's internal CF names. CORE_NAME = janusgraph.solr1 # Where to upload collection configuration and send CoreAdmin requests. SOLR_HOST = localhost:8983 # The value of index.[X].solr.http-urls in JanusGraph's config file # should match $SOLR_HOST and $CORE_NAME. For example, given the # $CORE_NAME and $SOLR_HOST values above, JanusGraph's config file would # contain (assuming \"search\" is the desired index alias): # # index.search.solr.http-urls=http://localhost:8983/solr/janusgraph.solr1 # # The stock JanusGraph config file conf/janusgraph-cql-solr.properties # ships with this http-urls value. # Upload Solr config files to DSE Search daemon for xml in conf/solr/ { solrconfig, schema, elevate } .xml ; do curl -v http:// \" $SOLR_HOST \" /solr/resource/ \" $CORE_NAME / $xml \" \\ --data-binary @ \" $xml \" -H 'Content-type:text/xml; charset=utf-8' done for txt in conf/solr/ { protwords, stopwords, synonyms } .txt ; do curl -v http:// \" $SOLR_HOST \" /solr/resource/ \" $CORE_NAME / $txt \" \\ --data-binary @ \" $txt \" -H 'Content-type:text/plain; charset=utf-8' done sleep 5 # Create core using the Solr config files just uploaded above curl \"http://\" $SOLR_HOST \"/solr/admin/cores?action=CREATE&name= $CORE_NAME \" sleep 5 # Retrieve and print the status of the core we just created curl \"http://localhost:8983/solr/admin/cores?action=STATUS&core= $CORE_NAME \" Now the JanusGraph database and backing Solr core are ready for use. We can test it out with the Graph of the Gods dataset. Picking up the Gremlin Console session started above: // Assuming graph = JanusGraphFactory.open('conf/janusgraph-cql-solr.properties')... gremlin > GraphOfTheGodsFactory . load ( graph ) ==> null Now we can run any of the queries described in Getting started . Queries involving text and geo predicates will be served by Solr. For more verbose reporting from JanusGraph and the Solr client, run gremlin.sh -l DEBUG and issue some index-backed queries.","title":"Apache Solr"},{"location":"index-backend/solr/#apache-solr","text":"Solr is the popular, blazing fast open source enterprise search platform from the Apache Lucene project. Solr is a standalone enterprise search server with a REST-like API. Solr is highly reliable, scalable and fault tolerant, providing distributed indexing, replication and load-balanced querying, automated failover and recovery, centralized configuration and more. \u2014 Apache Solr Homepage JanusGraph supports Apache Solr as an index backend. Here are some of the Solr features supported by JanusGraph: Full-Text : Supports all Text predicates to search for text properties that matches a given word, prefix or regular expression. Geo : Supports all Geo predicates to search for geo properties that are intersecting, within, disjoint to or contained in a given query geometry. Supports points, lines and polygons for indexing. Supports circles, boxes and polygons for querying point properties and all shapes for querying non-point properties. Numeric Range : Supports all numeric comparisons in Compare . TTL : Supports automatically expiring indexed elements. Temporal : Millisecond granularity temporal indexing. Custom Analyzer : Choose to use a custom analyzer Please see Version Compatibility for details on what versions of Solr will work with JanusGraph.","title":"Apache Solr"},{"location":"index-backend/solr/#solr-configuration-overview","text":"JanusGraph supports Solr running in either a SolrCloud or Solr Standalone (HTTP) configuration for use with a mixed index (see Mixed Index ). The desired connection mode is configured via the parameter mode which must be set to either cloud or http , the former being the default value. For example, to explicitly specify that Solr is running in a SolrCloud configuration the following property is specified as a JanusGraph configuration property: index.search.solr.mode = cloud These are some key Solr terms: Core : A single index on a single machine Configuration : solrconfig.xml , schema.xml , and other files required to define a core. Collection : A single logical index that can span multiple cores on different machines. Configset : A shared configuration that can be reused by multiple cores.","title":"Solr Configuration Overview"},{"location":"index-backend/solr/#connecting-to-solrcloud","text":"When connecting to a SolrCloud cluster by setting the mode equal to cloud , the Zookeeper URL (and optionally port) must be specified so that JanusGraph can discover and interact with the Solr cluster. index.search.backend = solr index.search.solr.mode = cloud index.search.solr.zookeeper-url = localhost:2181 A number of additional configuration options pertaining to the creation of new collections (which is only supported in SolrCloud operation mode) can be configured to control sharding behavior among other things. Refer to the Configuration Reference for a complete listing of those options. SolrCloud leverages Zookeeper to coordinate collection and configset information between the Solr servers. The use of Zookeeper with SolrCloud provides the opportunity to significantly reduce the amount of manual configuration required to use Solr as a back end index for JanusGraph.","title":"Connecting to SolrCloud"},{"location":"index-backend/solr/#configset-configuration","text":"A configset is required to create a collection. The configset is stored in Zookeeper to enable access to it across the Solr servers. Each collection can provide its own configset when it is created, so that each collection may have a different configuration. With this approach, each collection must be created manually. A shared configset can be uploaded separately to Zookeeper if it will be reused by multiple collections. With this approach, JanusGraph can create collections automatically by using the shared configset. Another benefit is that reusing a configset significantly reduces the amount of data stored in Zookeeper.","title":"Configset Configuration"},{"location":"index-backend/solr/#using-an-individual-configset","text":"In this example, a collection named verticesByAge is created manually using the default JanusGraph configuration for Solr that is found in the distribution. When the collection is created, the configuration is uploaded into Zookeeper, using the same collection name verticesByAge for the configset name. Refer to the Solr Reference Guide for available parameters. # create the collection $SOLR_HOME /bin/solr create -c verticesByAge -d $JANUSGRAPH_HOME /conf/solr Define a mixed index using JanusGraphManagement and the same collection name. mgmt = graph . openManagement () age = mgmt . makePropertyKey ( \"age\" ). dataType ( Integer . class ). make () mgmt . buildIndex ( \"verticesByAge\" , Vertex . class ). addKey ( age ). buildMixedIndex ( \"search\" ) mgmt . commit ()","title":"Using an Individual Configset"},{"location":"index-backend/solr/#using-a-shared-configset","text":"When using a shared configset, it is most convenient to upload the configuration first as a one time operation. In this example, a configset named janusgraph-configset is uploaded in to Zookeeper using the default JanusGraph configuration for Solr that is found in the distribution. Refer to the Solr Reference Guide for available parameters. # upload the shared configset into Zookeeper # Solr 5 $SOLR_HOME /server/scripts/cloud-scripts/zkcli.sh -cmd upconfig -z localhost:2181 \\ -d $JANUSGRAPH_HOME /conf/solr -n janusgraph-configset # Solr 6 and higher $SOLR_HOME /bin/solr zk upconfig -d $JANUSGRAPH_HOME /conf/solr -n janusgraph-configset \\ -z localhost:2181 When configuring the SolrCloud indexing backend for JanusGraph, make sure to provide the name of the shared configset using the index.search.solr.configset property. index.search.backend = solr index.search.solr.mode = cloud index.search.solr.zookeeper-url = localhost:2181 index.search.solr.configset = janusgraph-configset Define a mixed index using JanusGraphManagement and the collection name. mgmt = graph . openManagement () age = mgmt . makePropertyKey ( \"age\" ). dataType ( Integer . class ). make () mgmt . buildIndex ( \"verticesByAge\" , Vertex . class ). addKey ( age ). buildMixedIndex ( \"search\" ) mgmt . commit ()","title":"Using a Shared Configset"},{"location":"index-backend/solr/#connecting-to-solr-standalone-http","text":"When connecting to Solr Standalone via HTTP by setting the mode equal to http , a single or list of URLs for the Solr instances must be provided. index.search.backend = solr index.search.solr.mode = http index.search.solr.http-urls = http://localhost:8983/solr Additional configuration options for controlling the maximum number of connections, connection timeout and transmission compression are available for the HTTP mode. Refer to the Configuration Reference for a complete listing of those options.","title":"Connecting to Solr Standalone (HTTP)"},{"location":"index-backend/solr/#core-configuration","text":"Solr Standalone is used for a single instance, and it keeps configuration information on the file system. A core must be created manually for each mixed index. To create a core, a core_name and a configuration directory is required. Refer to the Solr Reference Guide for available parameters. In this example, a core named verticesByAge is created using the default JanusGraph configuration for Solr that is found in the distribution. $SOLR_HOME /bin/solr create -c verticesByAge -d $JANUSGRAPH_HOME /conf/solr Define a mixed index using JanusGraphManagement and the same core name. mgmt = graph . openManagement () age = mgmt . makePropertyKey ( \"age\" ). dataType ( Integer . class ). make () mgmt . buildIndex ( \"verticesByAge\" , Vertex . class ). addKey ( age ). buildMixedIndex ( \"search\" ) mgmt . commit ()","title":"Core Configuration"},{"location":"index-backend/solr/#kerberos-configuration","text":"When connecting to a Solr environment that is protected by Kerberos we must specify that Kerberos is being used and reference a JAAS configuration file to properly configure the Solr Clients. This configuration is required when Kerberos is in use regardless of the mode in which Solr is operating (SolrCloud or Solr Standalone). index.search.solr.kerberos-enabled = true The JAAS configuration file is supplied by ensuring that you set the java system property java.security.auth.login.config with the absolute path to the file. This property should be set using JVM options. For example to run gremlin.sh you would need to set the JAVA_OPTIONS environment variable prior to running the script: export JAVA_OPTIONS = \"-Djava.security.auth.login.config=/absolute/path/jaas.conf\" $JANUSGRAPH_HOME /bin/gremlin.sh For details on the content required in the JAAS configuration file refer to the https://lucene.apache.org/solr/guide/7_0/kerberos-authentication-plugin.html#define-a-jaas-configuration-file[Solr Reference Guide].","title":"Kerberos Configuration"},{"location":"index-backend/solr/#solr-schema-design","text":"","title":"Solr Schema Design"},{"location":"index-backend/solr/#dynamic-field-definition","text":"By default, JanusGraph uses Solr\u2019s Dynamic Fields feature to define the field types for all indexed keys. This requires no extra configuration when adding property keys to a mixed index backed by Solr and provides better performance than schemaless mode. JanusGraph assumes the following dynamic field tags are defined in the backing Solr collection\u2019s schema.xml file. Please note that there is additional xml definition of the following fields required in a solr schema.xml file in order to use them. Reference the example schema.xml file provided in the ./conf/solr/schema.xml directory in a JanusGraph installation for more information. <dynamicField name= \"*_i\" type= \"int\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_s\" type= \"string\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_l\" type= \"long\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_t\" type= \"text_general\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_b\" type= \"boolean\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_f\" type= \"float\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_d\" type= \"double\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_g\" type= \"geo\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_dt\" type= \"date\" indexed= \"true\" stored= \"true\" /> <dynamicField name= \"*_uuid\" type= \"uuid\" indexed= \"true\" stored= \"true\" /> In JanusGraph\u2019s default configuration, property key names do not have to end with the type-appropriate suffix to take advantage of Solr\u2019s dynamic field feature. JanusGraph generates the Solr field name from the property key name by encoding the property key definition\u2019s numeric identifier and the type-appropriate suffix. This means that JanusGraph uses synthetic field names with type-appropriate suffixes behind the scenes, regardless of the property key names defined and used by application code using JanusGraph. This field name mapping can be overridden through non-default configuration. That\u2019s described in the next section.","title":"Dynamic Field Definition"},{"location":"index-backend/solr/#manual-field-definition","text":"If the user would rather manually define the field types for each of the indexed fields in a collection, the configuration option dyn-fields needs to be disabled. It is important that the field for each indexed property key is defined in the backing Solr schema before the property key is added to the index. In this scenario, it is advisable to enable explicit property key name to field mapping in order to fix the field names for their explicit definition. This can be achieved in one of two ways: Configuring the name of the field by providing a mapped-name parameter when adding the property key to the index. See Individual Field Mapping for more information. By enabling the map-name configuration option for the Solr index which will use the property key name as the field name in Solr. See Global Field Mapping for more information.","title":"Manual Field Definition"},{"location":"index-backend/solr/#schemaless-mode","text":"JanusGraph can also interact with a SolrCloud cluster that is configured for schemaless mode . In this scenario, the configuration option dyn-fields should be disabled since Solr will infer the field type from the values and not the field name. Note, however, that schemaless mode is recommended only for prototyping and initial application development and NOT recommended for production use.","title":"Schemaless Mode"},{"location":"index-backend/solr/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"index-backend/solr/#collection-does-not-exist","text":"The collection (and all of the required configuration files) must be initialized before a defined index can use the collection. See Connecting to SolrCloud for more information. When using SolrCloud, the Zookeeper zkCli.sh command line tool can be used to inspect the configurations loaded into Zookeeper. Also verify that the default JanusGraph configuration files are copied to the correct location under solr and that the directory where the files are copied is correct.","title":"Collection Does Not Exist"},{"location":"index-backend/solr/#cannot-find-the-specified-configset","text":"When using SolrCloud, a configset is required to create a mixed index for JanusGraph. See Configset Configuration for more information. If using an individual configset, the collection must be created manually first. If using a shared configset, the configset must be uploaded into Zookeeper first. You can verify that the configset and its configuration files are in Zookeeper under /configs . Refer to the Solr Reference Guide for other Zookeeper operations. # verify the configset in Zookeeper # Solr 5 $SOLR_HOME /server/scripts/cloud-scripts/zkcli.sh -cmd list -z localhost:2181 # Solr 6 and higher $SOLR_HOME /bin/solr zk ls -r /configs/configset-name -z localhost:2181","title":"Cannot Find the Specified Configset"},{"location":"index-backend/solr/#http-error-404","text":"This error may be encountered when using Solr Standalone (HTTP) mode. An example of the error: 20:01:22 ERROR org.janusgraph.diskstorage.solr.SolrIndex - Unable to save documents to Solr as one of the shape objects stored were not compatible with Solr. org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8983/solr: Expected mime type application/octet-stream but got text/html. <html> <head> <meta http-equiv= \"Content-Type\" content= \"text/html;charset=utf-8\" /> <title> Error 404 Not Found </title> </head> <body><h2> HTTP ERROR 404 </h2> <p> Problem accessing /solr/verticesByAge/update. Reason: <pre> Not Found </pre></p> </body> </html> Make sure to create the core manually before attempting to store data into the index. See Core Configuration for more information.","title":"HTTP Error 404"},{"location":"index-backend/solr/#invalid-core-or-collection-name","text":"The core or collection name is an identifier. It must consist entirely of periods, underscores, hyphens, and/or alphanumerics, and also it may not start with a hyphen.","title":"Invalid core or collection name"},{"location":"index-backend/solr/#connection-problems","text":"Irrespective of the operation mode, a Solr instance or a cluster of Solr instances must be running and accessible from the JanusGraph instance(s) in order for JanusGraph to use Solr as an indexing backend. Check that the Solr cluster is running correctly and that it is visible and accessible over the network (or locally) from the JanusGraph instances.","title":"Connection Problems"},{"location":"index-backend/solr/#jts-classnotfoundexception-with-geo-data","text":"Solr relies on Spatial4j for geo processing. Spatial4j declares an optional dependency on JTS (\"JTS Topology Suite\"). JTS is required for some geo field definition and query functionality. If the JTS jar is not on the Solr daemon\u2019s classpath and a field in schema.xml uses a geo type, then Solr may throw a ClassNotFoundException on one of the missing JTS classes. The exception can appear when starting Solr using a schema.xml file designed to work with JanusGraph, but can also appear when invoking CREATE in the Solr CoreAdmin API . The exception appears in slightly different formats on the client and server sides, although the root cause is identical. Here\u2019s a representative example from a Solr server log: ERROR [ http - 8983 - exec - 5 ] 2014 - 10 - 07 02 : 54 : 06 , 665 SolrCoreResourceManager . java ( line 344 ) com / vividsolutions / jts / geom / Geometry java . lang . NoClassDefFoundError : com / vividsolutions / jts / geom / Geometry at com . spatial4j . core . context . jts . JtsSpatialContextFactory . newSpatialContext ( JtsSpatialContextFactory . java : 30 ) at com . spatial4j . core . context . SpatialContextFactory . makeSpatialContext ( SpatialContextFactory . java : 83 ) at org . apache . solr . schema . AbstractSpatialFieldType . init ( AbstractSpatialFieldType . java : 95 ) at org . apache . solr . schema . AbstractSpatialPrefixTreeFieldType . init ( AbstractSpatialPrefixTreeFieldType . java : 43 ) at org . apache . solr . schema . SpatialRecursivePrefixTreeFieldType . init ( SpatialRecursivePrefixTreeFieldType . java : 37 ) at org . apache . solr . schema . FieldType . setArgs ( FieldType . java : 164 ) at org . apache . solr . schema . FieldTypePluginLoader . init ( FieldTypePluginLoader . java : 141 ) at org . apache . solr . schema . FieldTypePluginLoader . init ( FieldTypePluginLoader . java : 43 ) at org . apache . solr . util . plugin . AbstractPluginLoader . load ( AbstractPluginLoader . java : 190 ) at org . apache . solr . schema . IndexSchema . readSchema ( IndexSchema . java : 470 ) at com . datastax . bdp . search . solr . CassandraIndexSchema . readSchema ( CassandraIndexSchema . java : 72 ) at org . apache . solr . schema . IndexSchema . < init > ( IndexSchema . java : 168 ) at com . datastax . bdp . search . solr . CassandraIndexSchema . < init > ( CassandraIndexSchema . java : 54 ) at com . datastax . bdp . search . solr . core . CassandraCoreContainer . create ( CassandraCoreContainer . java : 210 ) at com . datastax . bdp . search . solr . core . SolrCoreResourceManager . createCore ( SolrCoreResourceManager . java : 256 ) at com . datastax . bdp . search . solr . handler . admin . CassandraCoreAdminHandler . handleCreateAction ( CassandraCoreAdminHandler . java : 117 ) ... Here\u2019s what normally appears in the output of the client that issued the associated CREATE command to the CoreAdmin API: org . apache . solr . common . SolrException : com / vividsolutions / jts / geom / Geometry at com . datastax . bdp . search . solr . core . SolrCoreResourceManager . createCore ( SolrCoreResourceManager . java : 345 ) at com . datastax . bdp . search . solr . handler . admin . CassandraCoreAdminHandler . handleCreateAction ( CassandraCoreAdminHandler . java : 117 ) at org . apache . solr . handler . admin . CoreAdminHandler . handleRequestBody ( CoreAdminHandler . java : 152 ) ... This is resolved by adding the JTS jar to the classpath of JanusGraph and/or the Solr server. JTS is not included in JanusGraph distributions by default due to its LGPL license. Users must download the JTS jar file separately and copy it into the JanusGraph and/or Solr server lib directory. If using Solr\u2019s built in web server, the JTS jar may be copied to the example/solr-webapp/webapp/WEB-INF/lib directory to include it in the classpath. Solr can be restarted, and the exception should be gone. Solr must be started once with the correct schema.xml file in place first, for the example/solr-webapp/webapp/WEB-INF/lib directory to exist. To determine the ideal JTS version for Solr server, first check the version of Spatial4j in use by the Solr cluster, then determine the version of JTS against which that Spatial4j version was compiled. Spatial4j declares its target JTS version in the pom for the com.spatial4j:spatial4j artifact . Copy the JTS jar to the server/solr-webapp/webapp/WEB-INF/lib directory in your solr installation.","title":"JTS ClassNotFoundException with Geo Data"},{"location":"index-backend/solr/#advanced-solr-configuration","text":"","title":"Advanced Solr Configuration"},{"location":"index-backend/solr/#dse-search","text":"This section covers installation and configuration of JanusGraph with DataStax Enterprise (DSE) Search. There are multiple ways to install DSE, but this section focuses on DSE\u2019s binary tarball install option on Linux. Most of the steps in this section can be generalized to the other install options for DSE. Install DataStax Enterprise as directed by the page Installing DataStax Enterprise using the binary tarball . Export DSE_HOME and append to PATH in your shell environment. Here\u2019s an example using Bash syntax: export DSE_HOME = /path/to/dse-version.number export PATH = \" $DSE_HOME \" /bin: \" $PATH \" Install JTS for Solr. The appropriate version varies with the Spatial4j version. As of DSE 4.5.2, the appropriate version is 1.13. cd $DSE_HOME /resources/solr/lib curl -O 'http://central.maven.org/maven2/com/vividsolutions/jts/1.13/jts-1.13.jar' Start DSE Cassandra and Solr in a single background daemon: # The \"dse-data\" path below was chosen to match the # \"Installing DataStax Enterprise using the binary tarball\" # documentation page from DataStax. The exact path is not # significant. dse cassandra -s -Ddse.solr.data.dir = \" $DSE_HOME \" /dse-data/solr The previous command will write some startup information to the console and to the logfile path log4j.appender.R.File configured in $DSE_HOME/resources/cassandra/conf/log4j-server.properties . Once DSE with Cassandra and Solr has started normally, check the cluster health with nodetool status . A single-instance ring should show one node with flags *U*p and *N*ormal: nodetool status Note: Ownership information does not include topology ; for complete information, specify a keyspace = Datacenter: Solr Status = Up/Down | / State = Normal/Leaving/Joining/Moving -- Address Load Owns Host ID Token Rack UN 127 .0.0.1 99 .89 KB 100 .0% 5484ef7b-ebce-4560-80f0-cbdcd9e9f496 -7317038863489909889 rack1 Next, switch to Gremlin Console and open a JanusGraph database against the DSE instance. This will create JanusGraph\u2019s keyspace and column families. cd $JANUSGRAPH_HOME bin/gremlin.sh \\, ,,/ ( o o ) -----oOOo- ( 3 ) -oOOo----- gremlin> graph = JanusGraphFactory.open ( 'conf/janusgraph-cql-solr.properties' ) == >janusgraph [ cql: [ 127 .0.0.1 ]] gremlin> g = graph.traversal () == >graphtraversalsource [ janusgraph [ cql: [ 127 .0.0.1 ]] , standard ] gremlin> Keep this Gremlin Console open. We\u2019ll take a break now to install a Solr core. Then we\u2019ll come back to this console to load some sample data. Next, upload configuration files for JanusGraph\u2019s Solr collection, then create the core in DSE: # Change to the directory where JanusGraph was extracted. Later commands # use relative paths to the Solr config files shipped with the JanusGraph # distribution. cd $JANUSGRAPH_HOME # The name must be URL safe and should contain one dot/full-stop # character. The part of the name after the dot must not conflict with # any of JanusGraph's internal CF names. Starting the part after the dot # \"solr\" will avoid a conflict with JanusGraph's internal CF names. CORE_NAME = janusgraph.solr1 # Where to upload collection configuration and send CoreAdmin requests. SOLR_HOST = localhost:8983 # The value of index.[X].solr.http-urls in JanusGraph's config file # should match $SOLR_HOST and $CORE_NAME. For example, given the # $CORE_NAME and $SOLR_HOST values above, JanusGraph's config file would # contain (assuming \"search\" is the desired index alias): # # index.search.solr.http-urls=http://localhost:8983/solr/janusgraph.solr1 # # The stock JanusGraph config file conf/janusgraph-cql-solr.properties # ships with this http-urls value. # Upload Solr config files to DSE Search daemon for xml in conf/solr/ { solrconfig, schema, elevate } .xml ; do curl -v http:// \" $SOLR_HOST \" /solr/resource/ \" $CORE_NAME / $xml \" \\ --data-binary @ \" $xml \" -H 'Content-type:text/xml; charset=utf-8' done for txt in conf/solr/ { protwords, stopwords, synonyms } .txt ; do curl -v http:// \" $SOLR_HOST \" /solr/resource/ \" $CORE_NAME / $txt \" \\ --data-binary @ \" $txt \" -H 'Content-type:text/plain; charset=utf-8' done sleep 5 # Create core using the Solr config files just uploaded above curl \"http://\" $SOLR_HOST \"/solr/admin/cores?action=CREATE&name= $CORE_NAME \" sleep 5 # Retrieve and print the status of the core we just created curl \"http://localhost:8983/solr/admin/cores?action=STATUS&core= $CORE_NAME \" Now the JanusGraph database and backing Solr core are ready for use. We can test it out with the Graph of the Gods dataset. Picking up the Gremlin Console session started above: // Assuming graph = JanusGraphFactory.open('conf/janusgraph-cql-solr.properties')... gremlin > GraphOfTheGodsFactory . load ( graph ) ==> null Now we can run any of the queries described in Getting started . Queries involving text and geo predicates will be served by Solr. For more verbose reporting from JanusGraph and the Solr client, run gremlin.sh -l DEBUG and issue some index-backed queries.","title":"DSE Search"},{"location":"index-backend/text-search/","text":"Index Parameters and Full-Text Search When defining a mixed index, a list of parameters can be optionally specified for each property key added to the index. These parameters control how the particular key is to be indexed. JanusGraph recognizes the following index parameters. Whether these are supported depends on the configured index backend. A particular index backend might also support custom parameters in addition to the ones listed here. Full-Text Search When indexing string values, that is property keys with String.class data type, one has the choice to either index those as text or character strings which is controlled by the mapping parameter type. When the value is indexed as text, the string is tokenized into a bag of words which allows the user to efficiently query for all matches that contain one or multiple words. This is commonly referred to as full-text search . When the value is indexed as a character string, the string is index \"as-is\" without any further analysis or tokenization. This facilitates queries looking for an exact character sequence match. This is commonly referred to as string search . Full-Text Search By default, strings are indexed as text. To make this indexing option explicit, one can define a mapping when indexing a property key as text. mgmt = graph . openManagement () summary = mgmt . makePropertyKey ( 'booksummary' ). dataType ( String . class ). make () mgmt . buildIndex ( 'booksBySummary' , Vertex . class ). addKey ( summary , Mapping . TEXT . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () This is identical to a standard mixed index definition with the only addition of an extra parameter that specifies the mapping in the index - in this case Mapping.TEXT . When a string property is indexed as text, the string value is tokenized into a bag of tokens. The exact tokenization depends on the indexing backend and its configuration. JanusGraph\u2019s default tokenization splits the string on non-alphanumeric characters and removes any tokens with less than 2 characters. The tokenization used by an indexing backend may differ (e.g. stop words are removed) which can lead to minor differences in how full-text search queries are handled for modifications inside a transaction and committed data in the indexing backend. When a string property is indexed as text, only full-text search predicates are supported in graph queries by the indexing backend. Full-text search is case-insensitive. textContains : is true if (at least) one word inside the text string matches the query string textContainsPrefix : is true if (at least) one word inside the text string begins with the query string textContainsRegex : is true if (at least) one word inside the text string matches the given regular expression textContainsFuzzy : is true if (at least) one word inside the text string is similar to the query String (based on Levenshtein edit distance) import static org . janusgraph . core . attribute . Text .* g . V (). has ( 'booksummary' , textContains ( 'unicorns' )) g . V (). has ( 'booksummary' , textContainsPrefix ( 'uni' )) g . V (). has ( 'booksummary' , textContainsRegex ( '.*corn.*' )) g . V (). has ( 'booksummary' , textContainsFuzzy ( 'unicorn' )) String search predicates (see below) may be used in queries, but those require filtering in memory which can be very costly. String Search To index string properties as character sequences without any analysis or tokenization, specify the mapping as Mapping.STRING : mgmt = graph . openManagement () name = mgmt . makePropertyKey ( 'bookname' ). dataType ( String . class ). make () mgmt . buildIndex ( 'booksBySummary' , Vertex . class ). addKey ( name , Mapping . STRING . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () When a string mapping is configured, the string value is indexed and can be queried \"as-is\" - including stop words and non-letter characters. However, in this case the query must match the entire string value. Hence, the string mapping is useful when indexing short character sequences that are considered to be one token. When a string property is indexed as string, only the following predicates are supported in graph queries by the indexing backend. String search is case-sensitive. eq : if the string is identical to the query string neq : if the string is different than the query string textPrefix : if the string value starts with the given query string textRegex : if the string value matches the given regular expression in its entirety textFuzzy : if the string value is similar to the given query string (based on Levenshtein edit distance) import static org . apache . tinkerpop . gremlin . process . traversal . P .* import static org . janusgraph . core . attribute . Text .* g . V (). has ( 'bookname' , eq ( 'unicorns' )) g . V (). has ( 'bookname' , neq ( 'unicorns' )) g . V (). has ( 'bookname' , textPrefix ( 'uni' )) g . V (). has ( 'bookname' , textRegex ( '.*corn.*' )) g . V (). has ( 'bookname' , textFuzzy ( 'unicorn' )) Full-text search predicates may be used in queries, but those require filtering in memory which can be very costly. Full text and string search If you are using Elasticsearch it is possible to index properties as both text and string allowing you to use all of the predicates for exact and fuzzy matching. mgmt = graph . openManagement () summary = mgmt . makePropertyKey ( 'booksummary' ). dataType ( String . class ). make () mgmt . buildIndex ( 'booksBySummary' , Vertex . class ). addKey ( summary , Mapping . TEXTSTRING . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () Note that the data will be stored in the index twice, once for exact matching and once for fuzzy matching. TinkerPop Text Predicates It is also possible to use the TinkerPop text predicates with JanusGraph, but these predicates do not make use of indices which means that they require filtering in memory which can be very costly. import static org . apache . tinkerpop . gremlin . process . traversal . TextP .*; g . V (). has ( 'bookname' , startingWith ( 'uni' )) g . V (). has ( 'bookname' , endingWith ( 'corn' )) g . V (). has ( 'bookname' , containing ( 'nico' )) Geo Mapping By default, JanusGraph supports indexing geo properties with point type and querying geo properties by circle or box. To index a non-point geo property with support for querying by any geoshape type, specify the mapping as Mapping.PREFIX_TREE : mgmt = graph . openManagement () name = mgmt . makePropertyKey ( 'border' ). dataType ( Geoshape . class ). make () mgmt . buildIndex ( 'borderIndex' , Vertex . class ). addKey ( name , Mapping . PREFIX_TREE . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () Additional parameters can be specified to tune the configuration of the underlying prefix tree mapping. These optional parameters include the number of levels used in the prefix tree as well as the associated precision. mgmt = graph . openManagement () name = mgmt . makePropertyKey ( 'border' ). dataType ( Geoshape . class ). make () mgmt . buildIndex ( 'borderIndex' , Vertex . class ). addKey ( name , Mapping . PREFIX_TREE . asParameter (), Parameter . of ( \"index-geo-max-levels\" , 18 ), Parameter . of ( \"index-geo-dist-error-pct\" , 0.0125 )). buildMixedIndex ( \"search\" ) mgmt . commit () Note that some indexing backends (e.g. Solr) may require additional external schema configuration to support and tune indexing non-point properties.","title":"Index Parameters and Full-Text Search"},{"location":"index-backend/text-search/#index-parameters-and-full-text-search","text":"When defining a mixed index, a list of parameters can be optionally specified for each property key added to the index. These parameters control how the particular key is to be indexed. JanusGraph recognizes the following index parameters. Whether these are supported depends on the configured index backend. A particular index backend might also support custom parameters in addition to the ones listed here.","title":"Index Parameters and Full-Text Search"},{"location":"index-backend/text-search/#full-text-search","text":"When indexing string values, that is property keys with String.class data type, one has the choice to either index those as text or character strings which is controlled by the mapping parameter type. When the value is indexed as text, the string is tokenized into a bag of words which allows the user to efficiently query for all matches that contain one or multiple words. This is commonly referred to as full-text search . When the value is indexed as a character string, the string is index \"as-is\" without any further analysis or tokenization. This facilitates queries looking for an exact character sequence match. This is commonly referred to as string search .","title":"Full-Text Search"},{"location":"index-backend/text-search/#full-text-search_1","text":"By default, strings are indexed as text. To make this indexing option explicit, one can define a mapping when indexing a property key as text. mgmt = graph . openManagement () summary = mgmt . makePropertyKey ( 'booksummary' ). dataType ( String . class ). make () mgmt . buildIndex ( 'booksBySummary' , Vertex . class ). addKey ( summary , Mapping . TEXT . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () This is identical to a standard mixed index definition with the only addition of an extra parameter that specifies the mapping in the index - in this case Mapping.TEXT . When a string property is indexed as text, the string value is tokenized into a bag of tokens. The exact tokenization depends on the indexing backend and its configuration. JanusGraph\u2019s default tokenization splits the string on non-alphanumeric characters and removes any tokens with less than 2 characters. The tokenization used by an indexing backend may differ (e.g. stop words are removed) which can lead to minor differences in how full-text search queries are handled for modifications inside a transaction and committed data in the indexing backend. When a string property is indexed as text, only full-text search predicates are supported in graph queries by the indexing backend. Full-text search is case-insensitive. textContains : is true if (at least) one word inside the text string matches the query string textContainsPrefix : is true if (at least) one word inside the text string begins with the query string textContainsRegex : is true if (at least) one word inside the text string matches the given regular expression textContainsFuzzy : is true if (at least) one word inside the text string is similar to the query String (based on Levenshtein edit distance) import static org . janusgraph . core . attribute . Text .* g . V (). has ( 'booksummary' , textContains ( 'unicorns' )) g . V (). has ( 'booksummary' , textContainsPrefix ( 'uni' )) g . V (). has ( 'booksummary' , textContainsRegex ( '.*corn.*' )) g . V (). has ( 'booksummary' , textContainsFuzzy ( 'unicorn' )) String search predicates (see below) may be used in queries, but those require filtering in memory which can be very costly.","title":"Full-Text Search"},{"location":"index-backend/text-search/#string-search","text":"To index string properties as character sequences without any analysis or tokenization, specify the mapping as Mapping.STRING : mgmt = graph . openManagement () name = mgmt . makePropertyKey ( 'bookname' ). dataType ( String . class ). make () mgmt . buildIndex ( 'booksBySummary' , Vertex . class ). addKey ( name , Mapping . STRING . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () When a string mapping is configured, the string value is indexed and can be queried \"as-is\" - including stop words and non-letter characters. However, in this case the query must match the entire string value. Hence, the string mapping is useful when indexing short character sequences that are considered to be one token. When a string property is indexed as string, only the following predicates are supported in graph queries by the indexing backend. String search is case-sensitive. eq : if the string is identical to the query string neq : if the string is different than the query string textPrefix : if the string value starts with the given query string textRegex : if the string value matches the given regular expression in its entirety textFuzzy : if the string value is similar to the given query string (based on Levenshtein edit distance) import static org . apache . tinkerpop . gremlin . process . traversal . P .* import static org . janusgraph . core . attribute . Text .* g . V (). has ( 'bookname' , eq ( 'unicorns' )) g . V (). has ( 'bookname' , neq ( 'unicorns' )) g . V (). has ( 'bookname' , textPrefix ( 'uni' )) g . V (). has ( 'bookname' , textRegex ( '.*corn.*' )) g . V (). has ( 'bookname' , textFuzzy ( 'unicorn' )) Full-text search predicates may be used in queries, but those require filtering in memory which can be very costly.","title":"String Search"},{"location":"index-backend/text-search/#full-text-and-string-search","text":"If you are using Elasticsearch it is possible to index properties as both text and string allowing you to use all of the predicates for exact and fuzzy matching. mgmt = graph . openManagement () summary = mgmt . makePropertyKey ( 'booksummary' ). dataType ( String . class ). make () mgmt . buildIndex ( 'booksBySummary' , Vertex . class ). addKey ( summary , Mapping . TEXTSTRING . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () Note that the data will be stored in the index twice, once for exact matching and once for fuzzy matching.","title":"Full text and string search"},{"location":"index-backend/text-search/#tinkerpop-text-predicates","text":"It is also possible to use the TinkerPop text predicates with JanusGraph, but these predicates do not make use of indices which means that they require filtering in memory which can be very costly. import static org . apache . tinkerpop . gremlin . process . traversal . TextP .*; g . V (). has ( 'bookname' , startingWith ( 'uni' )) g . V (). has ( 'bookname' , endingWith ( 'corn' )) g . V (). has ( 'bookname' , containing ( 'nico' ))","title":"TinkerPop Text Predicates"},{"location":"index-backend/text-search/#geo-mapping","text":"By default, JanusGraph supports indexing geo properties with point type and querying geo properties by circle or box. To index a non-point geo property with support for querying by any geoshape type, specify the mapping as Mapping.PREFIX_TREE : mgmt = graph . openManagement () name = mgmt . makePropertyKey ( 'border' ). dataType ( Geoshape . class ). make () mgmt . buildIndex ( 'borderIndex' , Vertex . class ). addKey ( name , Mapping . PREFIX_TREE . asParameter ()). buildMixedIndex ( \"search\" ) mgmt . commit () Additional parameters can be specified to tune the configuration of the underlying prefix tree mapping. These optional parameters include the number of levels used in the prefix tree as well as the associated precision. mgmt = graph . openManagement () name = mgmt . makePropertyKey ( 'border' ). dataType ( Geoshape . class ). make () mgmt . buildIndex ( 'borderIndex' , Vertex . class ). addKey ( name , Mapping . PREFIX_TREE . asParameter (), Parameter . of ( \"index-geo-max-levels\" , 18 ), Parameter . of ( \"index-geo-dist-error-pct\" , 0.0125 )). buildMixedIndex ( \"search\" ) mgmt . commit () Note that some indexing backends (e.g. Solr) may require additional external schema configuration to support and tune indexing non-point properties.","title":"Geo Mapping"},{"location":"index-management/index-lifecycle/","text":"Index Lifecycle JanusGraph uses only indexes which have status ENABLED . When the index is created it will not be used by JanusGraph until it is enabled. After the index is build you should wait until it is registered (i.e. available) by JanusGraph: //Wait for the index to become available (i.e. wait for status REGISTERED) ManagementSystem . awaitGraphIndexStatus ( graph , \"myIndex\" ). call (); After the index is registered we should either enable the index (if we are sure that the current data should not be indexed by the newly created index) or we should reindex current data so that it would be available in the newly created index. Reindex the existing data and automatically enable the index example: mgmt = graph . openManagement (); mgmt . updateIndex ( mgmt . getGraphIndex ( \"myIndex\" ), SchemaAction . REINDEX ). get (); mgmt . commit (); Enable the index without reindexing existing data example: mgmt = graph . openManagement (); mgmt . updateIndex ( mgmt . getGraphIndex ( \"myAnotherIndex\" ), SchemaAction . ENABLE_INDEX ). get (); mgmt . commit (); Index states and transitions States (SchemaStatus) An index can be in one of the following states: INSTALLED The index is installed in the system but not yet registered with all instances in the cluster REGISTERED The index is registered with all instances in the cluster but not (yet) enabled ENABLED The index is enabled and in use DISABLED The index is disabled and no longer in use Actions (SchemaAction) The following actions can be performed on an index to change its state via mgmt.updateIndex() : REGISTER_INDEX Registers the index with all instances in the graph cluster. After an index is installed, it must be registered with all graph instances REINDEX Re-builds the index from the graph ENABLE_INDEX Enables the index so that it can be used by the query processing engine. An index must be registered before it can be enabled. DISABLE_INDEX Disables the index in the graph so that it is no longer used. REMOVE_INDEX Removes the index from the graph (optional operation). Only on composite index.","title":"Index Lifecycle"},{"location":"index-management/index-lifecycle/#index-lifecycle","text":"JanusGraph uses only indexes which have status ENABLED . When the index is created it will not be used by JanusGraph until it is enabled. After the index is build you should wait until it is registered (i.e. available) by JanusGraph: //Wait for the index to become available (i.e. wait for status REGISTERED) ManagementSystem . awaitGraphIndexStatus ( graph , \"myIndex\" ). call (); After the index is registered we should either enable the index (if we are sure that the current data should not be indexed by the newly created index) or we should reindex current data so that it would be available in the newly created index. Reindex the existing data and automatically enable the index example: mgmt = graph . openManagement (); mgmt . updateIndex ( mgmt . getGraphIndex ( \"myIndex\" ), SchemaAction . REINDEX ). get (); mgmt . commit (); Enable the index without reindexing existing data example: mgmt = graph . openManagement (); mgmt . updateIndex ( mgmt . getGraphIndex ( \"myAnotherIndex\" ), SchemaAction . ENABLE_INDEX ). get (); mgmt . commit ();","title":"Index Lifecycle"},{"location":"index-management/index-lifecycle/#index-states-and-transitions","text":"","title":"Index states and transitions"},{"location":"index-management/index-lifecycle/#states-schemastatus","text":"An index can be in one of the following states: INSTALLED The index is installed in the system but not yet registered with all instances in the cluster REGISTERED The index is registered with all instances in the cluster but not (yet) enabled ENABLED The index is enabled and in use DISABLED The index is disabled and no longer in use","title":"States (SchemaStatus)"},{"location":"index-management/index-lifecycle/#actions-schemaaction","text":"The following actions can be performed on an index to change its state via mgmt.updateIndex() : REGISTER_INDEX Registers the index with all instances in the graph cluster. After an index is installed, it must be registered with all graph instances REINDEX Re-builds the index from the graph ENABLE_INDEX Enables the index so that it can be used by the query processing engine. An index must be registered before it can be enabled. DISABLE_INDEX Disables the index in the graph so that it is no longer used. REMOVE_INDEX Removes the index from the graph (optional operation). Only on composite index.","title":"Actions (SchemaAction)"},{"location":"index-management/index-performance/","text":"Indexing for Better Performance JanusGraph supports two different kinds of indexing to speed up query processing: graph indexes and vertex-centric indexes . Most graph queries start the traversal from a list of vertices or edges that are identified by their properties. Graph indexes make these global retrieval operations efficient on large graphs. Vertex-centric indexes speed up the actual traversal through the graph, in particular when traversing through vertices with many incident edges. Graph Index Graph indexes are global index structures over the entire graph which allow efficient retrieval of vertices or edges by their properties for sufficiently selective conditions. For instance, consider the following queries g . V (). has ( ' name ' , ' hercules ' ) g . E (). has ( ' reason ' , textContains ( ' loves ' )) The first query asks for all vertices with the name hercules . The second asks for all edges where the property reason contains the word loves . Without a graph index answering those queries would require a full scan over all vertices or edges in the graph to find those that match the given condition which is very inefficient and infeasible for huge graphs. JanusGraph distinguishes between two types of graph indexes: composite and mixed indexes. Composite indexes are very fast and efficient but limited to equality lookups for a particular, previously-defined combination of property keys. Mixed indexes can be used for lookups on any combination of indexed keys and support multiple condition predicates in addition to equality depending on the backing index store. Both types of indexes are created through the JanusGraph management system and the index builder returned by JanusGraphManagement.buildIndex(String, Class) where the first argument defines the name of the index and the second argument specifies the type of element to be indexed (e.g. Vertex.class ). The name of a graph index must be unique. Graph indexes built against newly defined property keys, i.e. property keys that are defined in the same management transaction as the index, are immediately available. The same applies to graph indexes that are constrained to a label that is created in the same management transaction as the index. Graph indexes built against property keys that are already in use without being constrained to a newly created label require the execution of a reindex procedure to ensure that the index contains all previously added elements. Until the reindex procedure has completed, the index will not be available. It is encouraged to define graph indexes in the same transaction as the initial schema. Note In the absence of an index, JanusGraph will default to a full graph scan in order to retrieve the desired list of vertices. While this produces the correct result set, the graph scan can be very inefficient and lead to poor overall system performance in a production environment. Enable the force-index configuration option in production deployments of JanusGraph to prohibit graph scans. Info See index lifecycle documentation for more information about index states. Composite Index Composite indexes retrieve vertices or edges by one or a (fixed) composition of multiple keys. Consider the following composite index definitions. graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () name = mgmt . getPropertyKey ( ' name ' ) age = mgmt . getPropertyKey ( ' age ' ) mgmt . buildIndex ( ' byNameComposite ' , Vertex . class ). addKey ( name ). buildCompositeIndex () mgmt . buildIndex ( ' byNameAndAgeComposite ' , Vertex . class ). addKey ( name ). addKey ( age ). buildCompositeIndex () mgmt . commit () //Wait for the index to become available ManagementSystem . awaitGraphIndexStatus ( graph , ' byNameComposite ' ). call () ManagementSystem . awaitGraphIndexStatus ( graph , ' byNameAndAgeComposite ' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"byNameComposite\" ), SchemaAction . REINDEX ). get () mgmt . updateIndex ( mgmt . getGraphIndex ( \"byNameAndAgeComposite\" ), SchemaAction . REINDEX ). get () mgmt . commit () First, two property keys name and age are already defined. Next, a simple composite index on just the name property key is built. JanusGraph will use this index to answer the following query. g . V (). has ( 'name' , 'hercules' ) The second composite graph index includes both keys. JanusGraph will use this index to answer the following query. g . V (). has ( 'age' , 30 ). has ( 'name' , 'hercules' ) Note, that all keys of a composite graph index must be found in the query\u2019s equality conditions for this index to be used. For example, the following query cannot be answered with either of the indexes because it only contains a constraint on age but not name . g . V (). has ( 'age' , 30 ) Also note, that composite graph indexes can only be used for equality constraints like those in the queries above. The following query would be answered with just the simple composite index defined on the name key because the age constraint is not an equality constraint. g . V (). has ( ' name ' , ' hercules ' ). has ( ' age ' , inside ( 20 , 50 )) Composite indexes do not require configuration of an external indexing backend and are supported through the primary storage backend. Hence, composite index modifications are persisted through the same transaction as graph modifications which means that those changes are atomic and/or consistent if the underlying storage backend supports atomicity and/or consistency. Note A composite index may comprise just one or multiple keys. A composite index with just one key is sometimes referred to as a key-index. Index Uniqueness Composite indexes can also be used to enforce property uniqueness in the graph. If a composite graph index is defined as unique() there can be at most one vertex or edge for any given concatenation of property values associated with the keys of that index. For instance, to enforce that names are unique across the entire graph the following composite graph index would be defined. graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () name = mgmt . getPropertyKey ( 'name' ) mgmt . buildIndex ( 'byNameUnique' , Vertex . class ). addKey ( name ). unique (). buildCompositeIndex () mgmt . commit () //Wait for the index to become available ManagementSystem . awaitGraphIndexStatus ( graph , 'byNameUnique' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"byNameUnique\" ), SchemaAction . REINDEX ). get () mgmt . commit () Note To enforce uniqueness against an eventually consistent storage backend, the consistency of the index must be explicitly set to enabling locking. Mixed Index Mixed indexes retrieve vertices or edges by any combination of previously added property keys. Mixed indexes provide more flexibility than composite indexes and support additional condition predicates beyond equality. On the other hand, mixed indexes are slower for most equality queries than composite indexes. Unlike composite indexes, mixed indexes require the configuration of an indexing backend and use that indexing backend to execute lookup operations. JanusGraph can support multiple indexing backends in a single installation. Each indexing backend must be uniquely identified by name in the JanusGraph configuration which is called the indexing backend name . graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () name = mgmt . getPropertyKey ( 'name' ) age = mgmt . getPropertyKey ( 'age' ) mgmt . buildIndex ( 'nameAndAge' , Vertex . class ). addKey ( name ). addKey ( age ). buildMixedIndex ( \"search\" ) mgmt . commit () //Wait for the index to become available ManagementSystem . awaitGraphIndexStatus ( graph , 'nameAndAge' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"nameAndAge\" ), SchemaAction . REINDEX ). get () mgmt . commit () The example above defines a mixed index containing the property keys name and age . The definition refers to the indexing backend name search so that JanusGraph knows which configured indexing backend it should use for this particular index. The search parameter specified in the buildMixedIndex call must match the second clause in the JanusGraph configuration definition like this: index. search .backend If the index was named solrsearch then the configuration definition would appear like this: index. solrsearch .backend. The mgmt.buildIndex example specified above uses text search as its default behavior. An index statement that explicitly defines the index as a text index can be written as follows: mgmt . buildIndex ( 'nameAndAge' , Vertex . class ). addKey ( name , Mapping . TEXT . getParameter ()). addKey ( age , Mapping . TEXT . getParameter ()). buildMixedIndex ( \"search\" ) See Index Parameters and Full-Text Search for more information on text and string search options, and see the documentation section specific to the indexing backend in use for more details on how each backend handles text versus string searches. While the index definition example looks similar to the composite index above, it provides greater query support and can answer any of the following queries. g . V (). has ( 'name' , textContains ( 'hercules' )). has ( 'age' , inside ( 20 , 50 )) g . V (). has ( 'name' , textContains ( 'hercules' )) g . V (). has ( 'age' , lt ( 50 )) g . V (). has ( 'age' , outside ( 20 , 50 )) g . V (). has ( 'age' , lt ( 50 ). or ( gte ( 60 ))) g . V (). or ( __ . has ( 'name' , textContains ( 'hercules' )), __ . has ( 'age' , inside ( 20 , 50 ))) Mixed indexes support full-text search, range search, geo search and others. Refer to Search Predicates and Data Types for a list of predicates supported by a particular indexing backend. Note Unlike composite indexes, mixed indexes do not support uniqueness. Adding Property Keys Property keys can be added to an existing mixed index which allows subsequent queries to include this key in the query condition. graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () location = mgmt . makePropertyKey ( 'location' ). dataType ( Geoshape . class ). make () nameAndAge = mgmt . getGraphIndex ( 'nameAndAge' ) mgmt . addIndexKey ( nameAndAge , location ) mgmt . commit () //Previously created property keys already have the status ENABLED, but //our newly created property key \"location\" needs to REGISTER so we wait for both statuses ManagementSystem . awaitGraphIndexStatus ( graph , 'nameAndAge' ). status ( SchemaStatus . REGISTERED , SchemaStatus . ENABLED ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"nameAndAge\" ), SchemaAction . REINDEX ). get () mgmt . commit () To add a newly defined key, we first retrieve the existing index from the management transaction by its name and then invoke the addIndexKey method to add the key to this index. If the added key is defined in the same management transaction, it will be immediately available for querying. If the property key has already been in use, adding the key requires the execution of a reindex procedure to ensure that the index contains all previously added elements. Until the reindex procedure has completed, the key will not be available in the mixed index. Mapping Parameters When adding a property key to a mixed index - either through the index builder or the addIndexKey method - a list of parameters can be optionally specified to adjust how the property value is mapped into the indexing backend. Refer to the mapping parameters overview for a complete list of parameter types supported by each indexing backend. Ordering The order in which the results of a graph query are returned can be defined using the order().by() directive. The order().by() method expects two parameters: The name of the property key by which to order the results. The results will be ordered by the value of the vertices or edges for this property key. The sort order: either ascending asc or descending desc For example, the query g.V().has('name', textContains('hercules')).order().by('age', desc).limit(10) retrieves the ten oldest individuals with hercules in their name. When using order().by() it is important to note that: Composite graph indexes do not natively support ordering search results. All results will be retrieved and then sorted in-memory. For large result sets, this can be very expensive. Mixed indexes support ordering natively and efficiently. However, the property key used in the order().by() method must have been previously added to the mixed indexed for native result ordering support. This is important in cases where the the order().by() key is different from the query keys. If the property key is not part of the index, then sorting requires loading all results into memory. Label Constraint In many cases it is desirable to only index vertices or edges with a particular label. For instance, one may want to index only gods by their name and not every single vertex that has a name property. When defining an index it is possible to restrict the index to a particular vertex or edge label using the indexOnly method of the index builder. The following creates a composite index for the property key name that indexes only vertices labeled god . graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () name = mgmt . getPropertyKey ( 'name' ) god = mgmt . getVertexLabel ( 'god' ) mgmt . buildIndex ( 'byNameAndLabel' , Vertex . class ). addKey ( name ). indexOnly ( god ). buildCompositeIndex () mgmt . commit () //Wait for the index to become available ManagementSystem . awaitGraphIndexStatus ( graph , 'byNameAndLabel' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"byNameAndLabel\" ), SchemaAction . REINDEX ). get () mgmt . commit () Label restrictions similarly apply to mixed indexes. When a composite index with label restriction is defined as unique, the uniqueness constraint only applies to properties on vertices or edges for the specified label. Composite versus Mixed Indexes Use a composite index for exact match index retrievals. Composite indexes do not require configuring or operating an external index system and are often significantly faster than mixed indexes. As an exception, use a mixed index for exact matches when the number of distinct values for query constraint is relatively small or if one value is expected to be associated with many elements in the graph (i.e. in case of low selectivity). Use a mixed indexes for numeric range, full-text or geo-spatial indexing. Also, using a mixed index can speed up the order().by() queries. Vertex-centric Indexes Vertex-centric indexes are local index structures built individually per vertex. In large graphs vertices can have thousands of incident edges. Traversing through those vertices can be very slow because a large subset of the incident edges has to be retrieved and then filtered in memory to match the conditions of the traversal. Vertex-centric indexes can speed up such traversals by using localized index structures to retrieve only those edges that need to be traversed. Suppose that Hercules battled hundreds of monsters in addition to the three captured in the introductory Graph of the Gods . Without a vertex-centric index, a query asking for those monsters battled between time point 10 and 20 would require retrieving all battled edges even though there are only a handful of matching edges. h = g . V (). has ( 'name' , 'hercules' ). next () g . V ( h ). outE ( 'battled' ). has ( 'time' , inside ( 10 , 20 )). inV () Building a vertex-centric index by time speeds up such traversal queries. Note, this initial index example already exists in the Graph of the Gods as an index named edges . As a result, running the steps below will result in a uniqueness constraint error. graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () time = mgmt . getPropertyKey ( 'time' ) battled = mgmt . getEdgeLabel ( 'battled' ) mgmt . buildEdgeIndex ( battled , 'battlesByTime' , Direction . BOTH , Order . desc , time ) mgmt . commit () //Wait for the index to become available ManagementSystem . awaitRelationIndexStatus ( graph , 'battlesByTime' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getRelationIndex ( battled , \"battlesByTime\" ), SchemaAction . REINDEX ). get () mgmt . commit () This example builds a vertex-centric index which indexes battled edges in both direction by time in descending order. A vertex-centric index is built against a particular edge label which is the first argument to the index construction method JanusGraphManagement.buildEdgeIndex() . The index only applies to edges of this label - battled in the example above. The second argument is a unique name for the index. The third argument is the edge direction in which the index is built. The index will only apply to traversals along edges in this direction. In this example, the vertex-centric index is built in both direction which means that time restricted traversals along battled edges can be served by this index in both the IN and OUT direction. JanusGraph will maintain a vertex-centric index on both the in- and out-vertex of battled edges. Alternatively, one could define the index to apply to the OUT direction only which would speed up traversals from Hercules to the monsters but not in the reverse direction. This would only require maintaining one index and hence half the index maintenance and storage cost. The last two arguments are the sort order of the index and a list of property keys to index by. The sort order is optional and defaults to ascending order (i.e. Order.ASC ). The list of property keys must be non-empty and defines the keys by which to index the edges of the given label. A vertex-centric index can be defined with multiple keys. graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () time = mgmt . getPropertyKey ( 'time' ) rating = mgmt . makePropertyKey ( 'rating' ). dataType ( Double . class ). make () battled = mgmt . getEdgeLabel ( 'battled' ) mgmt . buildEdgeIndex ( battled , 'battlesByRatingAndTime' , Direction . OUT , Order . desc , rating , time ) mgmt . commit () //Wait for the index to become available ManagementSystem . awaitRelationIndexStatus ( graph , 'battlesByRatingAndTime' , 'battled' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getRelationIndex ( battled , 'battlesByRatingAndTime' ), SchemaAction . REINDEX ). get () mgmt . commit () This example extends the schema by a rating property on battled edges and builds a vertex-centric index which indexes battled edges in the out-going direction by rating and time in descending order. Note, that the order in which the property keys are specified is important because vertex-centric indexes are prefix indexes. This means, that battled edges are indexed by rating first and time second . h = g . V (). has ( 'name' , 'hercules' ). next () g . V ( h ). outE ( 'battled' ). property ( 'rating' , 5.0 ) //Add some rating properties g . V ( h ). outE ( 'battled' ). has ( 'rating' , gt ( 3.0 )). inV () g . V ( h ). outE ( 'battled' ). has ( 'rating' , 5.0 ). has ( 'time' , inside ( 10 , 50 )). inV () g . V ( h ). outE ( 'battled' ). has ( 'time' , inside ( 10 , 50 )). inV () Hence, the battlesByRatingAndTime index can speed up the first two but not the third query. Multiple vertex-centric indexes can be built for the same edge label in order to support different constraint traversals. JanusGraph\u2019s query optimizer attempts to pick the most efficient index for any given traversal. Vertex-centric indexes only support equality and range/interval constraints. Note The property keys used in a vertex-centric index must have an explicitly defined data type (i.e. not Object.class ) which supports a native sort order. This means not only that they must implement Comparable but that their serializer must impement OrderPreservingSerializer . The types that are currently supported are Boolean , UUID , Byte , Float , Long , String , Integer , Date , Double , Character , and Short If the vertex-centric index is built against an edge label that is defined in the same management transaction, the index will be immediately available for querying. If the edge label has already been in use, building a vertex-centric index against it requires the execution of a reindex procedure to ensure that the index contains all previously added edges. Until the reindex procedure has completed, the index will not be available. Note JanusGraph automatically builds vertex-centric indexes per edge label and property key. That means, even with thousands of incident battled edges, queries like g.V(h).out('mother') or g.V(h).values('age') are efficiently answered by the local index. Vertex-centric indexes cannot speed up unconstrained traversals which require traversing through all incident edges of a particular label. Those traversals will become slower as the number of incident edges increases. Often, such traversals can be rewritten as constrained traversals that can utilize a vertex-centric index to ensure acceptable performance at scale. Ordered Traversals The following queries specify an order in which the incident edges are to be traversed. Use the localLimit command to retrieve a subset of the edges (in a given order) for EACH vertex that is traversed. h = g .. V (). has ( 'name' , 'hercules' ). next () g . V ( h ). local ( outE ( 'battled' ). order (). by ( 'time' , desc ). limit ( 10 )). inV (). values ( 'name' ) g . V ( h ). local ( outE ( 'battled' ). has ( 'rating' , 5.0 ). order (). by ( 'time' , desc ). limit ( 10 )). values ( 'place' ) The first query asks for the names of the 10 most recently battled monsters by Hercules. The second query asks for the places of the 10 most recent battles of Hercules that are rated 5 stars. In both cases, the query is constrained by an order on a property key with a limit on the number of elements to be returned. Such queries can also be efficiently answered by vertex-centric indexes if the order key matches the key of the index and the requested order (i.e. ascending or descending) is the same as the one defined for the index. The battlesByTime index would be used to answer the first query and battlesByRatingAndTime applies to the second. Note, that the battlesByRatingAndTime index cannot be used to answer the first query because an equality constraint on rating must be present for the second key in the index to be effective. Note Ordered vertex queries are a JanusGraph extension to Gremlin which causes the verbose syntax and requires the _() step to convert the JanusGraph result back into a Gremlin pipeline.","title":"Indexing for Better Performance"},{"location":"index-management/index-performance/#indexing-for-better-performance","text":"JanusGraph supports two different kinds of indexing to speed up query processing: graph indexes and vertex-centric indexes . Most graph queries start the traversal from a list of vertices or edges that are identified by their properties. Graph indexes make these global retrieval operations efficient on large graphs. Vertex-centric indexes speed up the actual traversal through the graph, in particular when traversing through vertices with many incident edges.","title":"Indexing for Better Performance"},{"location":"index-management/index-performance/#graph-index","text":"Graph indexes are global index structures over the entire graph which allow efficient retrieval of vertices or edges by their properties for sufficiently selective conditions. For instance, consider the following queries g . V (). has ( ' name ' , ' hercules ' ) g . E (). has ( ' reason ' , textContains ( ' loves ' )) The first query asks for all vertices with the name hercules . The second asks for all edges where the property reason contains the word loves . Without a graph index answering those queries would require a full scan over all vertices or edges in the graph to find those that match the given condition which is very inefficient and infeasible for huge graphs. JanusGraph distinguishes between two types of graph indexes: composite and mixed indexes. Composite indexes are very fast and efficient but limited to equality lookups for a particular, previously-defined combination of property keys. Mixed indexes can be used for lookups on any combination of indexed keys and support multiple condition predicates in addition to equality depending on the backing index store. Both types of indexes are created through the JanusGraph management system and the index builder returned by JanusGraphManagement.buildIndex(String, Class) where the first argument defines the name of the index and the second argument specifies the type of element to be indexed (e.g. Vertex.class ). The name of a graph index must be unique. Graph indexes built against newly defined property keys, i.e. property keys that are defined in the same management transaction as the index, are immediately available. The same applies to graph indexes that are constrained to a label that is created in the same management transaction as the index. Graph indexes built against property keys that are already in use without being constrained to a newly created label require the execution of a reindex procedure to ensure that the index contains all previously added elements. Until the reindex procedure has completed, the index will not be available. It is encouraged to define graph indexes in the same transaction as the initial schema. Note In the absence of an index, JanusGraph will default to a full graph scan in order to retrieve the desired list of vertices. While this produces the correct result set, the graph scan can be very inefficient and lead to poor overall system performance in a production environment. Enable the force-index configuration option in production deployments of JanusGraph to prohibit graph scans. Info See index lifecycle documentation for more information about index states.","title":"Graph Index"},{"location":"index-management/index-performance/#composite-index","text":"Composite indexes retrieve vertices or edges by one or a (fixed) composition of multiple keys. Consider the following composite index definitions. graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () name = mgmt . getPropertyKey ( ' name ' ) age = mgmt . getPropertyKey ( ' age ' ) mgmt . buildIndex ( ' byNameComposite ' , Vertex . class ). addKey ( name ). buildCompositeIndex () mgmt . buildIndex ( ' byNameAndAgeComposite ' , Vertex . class ). addKey ( name ). addKey ( age ). buildCompositeIndex () mgmt . commit () //Wait for the index to become available ManagementSystem . awaitGraphIndexStatus ( graph , ' byNameComposite ' ). call () ManagementSystem . awaitGraphIndexStatus ( graph , ' byNameAndAgeComposite ' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"byNameComposite\" ), SchemaAction . REINDEX ). get () mgmt . updateIndex ( mgmt . getGraphIndex ( \"byNameAndAgeComposite\" ), SchemaAction . REINDEX ). get () mgmt . commit () First, two property keys name and age are already defined. Next, a simple composite index on just the name property key is built. JanusGraph will use this index to answer the following query. g . V (). has ( 'name' , 'hercules' ) The second composite graph index includes both keys. JanusGraph will use this index to answer the following query. g . V (). has ( 'age' , 30 ). has ( 'name' , 'hercules' ) Note, that all keys of a composite graph index must be found in the query\u2019s equality conditions for this index to be used. For example, the following query cannot be answered with either of the indexes because it only contains a constraint on age but not name . g . V (). has ( 'age' , 30 ) Also note, that composite graph indexes can only be used for equality constraints like those in the queries above. The following query would be answered with just the simple composite index defined on the name key because the age constraint is not an equality constraint. g . V (). has ( ' name ' , ' hercules ' ). has ( ' age ' , inside ( 20 , 50 )) Composite indexes do not require configuration of an external indexing backend and are supported through the primary storage backend. Hence, composite index modifications are persisted through the same transaction as graph modifications which means that those changes are atomic and/or consistent if the underlying storage backend supports atomicity and/or consistency. Note A composite index may comprise just one or multiple keys. A composite index with just one key is sometimes referred to as a key-index.","title":"Composite Index"},{"location":"index-management/index-performance/#index-uniqueness","text":"Composite indexes can also be used to enforce property uniqueness in the graph. If a composite graph index is defined as unique() there can be at most one vertex or edge for any given concatenation of property values associated with the keys of that index. For instance, to enforce that names are unique across the entire graph the following composite graph index would be defined. graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () name = mgmt . getPropertyKey ( 'name' ) mgmt . buildIndex ( 'byNameUnique' , Vertex . class ). addKey ( name ). unique (). buildCompositeIndex () mgmt . commit () //Wait for the index to become available ManagementSystem . awaitGraphIndexStatus ( graph , 'byNameUnique' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"byNameUnique\" ), SchemaAction . REINDEX ). get () mgmt . commit () Note To enforce uniqueness against an eventually consistent storage backend, the consistency of the index must be explicitly set to enabling locking.","title":"Index Uniqueness"},{"location":"index-management/index-performance/#mixed-index","text":"Mixed indexes retrieve vertices or edges by any combination of previously added property keys. Mixed indexes provide more flexibility than composite indexes and support additional condition predicates beyond equality. On the other hand, mixed indexes are slower for most equality queries than composite indexes. Unlike composite indexes, mixed indexes require the configuration of an indexing backend and use that indexing backend to execute lookup operations. JanusGraph can support multiple indexing backends in a single installation. Each indexing backend must be uniquely identified by name in the JanusGraph configuration which is called the indexing backend name . graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () name = mgmt . getPropertyKey ( 'name' ) age = mgmt . getPropertyKey ( 'age' ) mgmt . buildIndex ( 'nameAndAge' , Vertex . class ). addKey ( name ). addKey ( age ). buildMixedIndex ( \"search\" ) mgmt . commit () //Wait for the index to become available ManagementSystem . awaitGraphIndexStatus ( graph , 'nameAndAge' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"nameAndAge\" ), SchemaAction . REINDEX ). get () mgmt . commit () The example above defines a mixed index containing the property keys name and age . The definition refers to the indexing backend name search so that JanusGraph knows which configured indexing backend it should use for this particular index. The search parameter specified in the buildMixedIndex call must match the second clause in the JanusGraph configuration definition like this: index. search .backend If the index was named solrsearch then the configuration definition would appear like this: index. solrsearch .backend. The mgmt.buildIndex example specified above uses text search as its default behavior. An index statement that explicitly defines the index as a text index can be written as follows: mgmt . buildIndex ( 'nameAndAge' , Vertex . class ). addKey ( name , Mapping . TEXT . getParameter ()). addKey ( age , Mapping . TEXT . getParameter ()). buildMixedIndex ( \"search\" ) See Index Parameters and Full-Text Search for more information on text and string search options, and see the documentation section specific to the indexing backend in use for more details on how each backend handles text versus string searches. While the index definition example looks similar to the composite index above, it provides greater query support and can answer any of the following queries. g . V (). has ( 'name' , textContains ( 'hercules' )). has ( 'age' , inside ( 20 , 50 )) g . V (). has ( 'name' , textContains ( 'hercules' )) g . V (). has ( 'age' , lt ( 50 )) g . V (). has ( 'age' , outside ( 20 , 50 )) g . V (). has ( 'age' , lt ( 50 ). or ( gte ( 60 ))) g . V (). or ( __ . has ( 'name' , textContains ( 'hercules' )), __ . has ( 'age' , inside ( 20 , 50 ))) Mixed indexes support full-text search, range search, geo search and others. Refer to Search Predicates and Data Types for a list of predicates supported by a particular indexing backend. Note Unlike composite indexes, mixed indexes do not support uniqueness.","title":"Mixed Index"},{"location":"index-management/index-performance/#adding-property-keys","text":"Property keys can be added to an existing mixed index which allows subsequent queries to include this key in the query condition. graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () location = mgmt . makePropertyKey ( 'location' ). dataType ( Geoshape . class ). make () nameAndAge = mgmt . getGraphIndex ( 'nameAndAge' ) mgmt . addIndexKey ( nameAndAge , location ) mgmt . commit () //Previously created property keys already have the status ENABLED, but //our newly created property key \"location\" needs to REGISTER so we wait for both statuses ManagementSystem . awaitGraphIndexStatus ( graph , 'nameAndAge' ). status ( SchemaStatus . REGISTERED , SchemaStatus . ENABLED ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"nameAndAge\" ), SchemaAction . REINDEX ). get () mgmt . commit () To add a newly defined key, we first retrieve the existing index from the management transaction by its name and then invoke the addIndexKey method to add the key to this index. If the added key is defined in the same management transaction, it will be immediately available for querying. If the property key has already been in use, adding the key requires the execution of a reindex procedure to ensure that the index contains all previously added elements. Until the reindex procedure has completed, the key will not be available in the mixed index.","title":"Adding Property Keys"},{"location":"index-management/index-performance/#mapping-parameters","text":"When adding a property key to a mixed index - either through the index builder or the addIndexKey method - a list of parameters can be optionally specified to adjust how the property value is mapped into the indexing backend. Refer to the mapping parameters overview for a complete list of parameter types supported by each indexing backend.","title":"Mapping Parameters"},{"location":"index-management/index-performance/#ordering","text":"The order in which the results of a graph query are returned can be defined using the order().by() directive. The order().by() method expects two parameters: The name of the property key by which to order the results. The results will be ordered by the value of the vertices or edges for this property key. The sort order: either ascending asc or descending desc For example, the query g.V().has('name', textContains('hercules')).order().by('age', desc).limit(10) retrieves the ten oldest individuals with hercules in their name. When using order().by() it is important to note that: Composite graph indexes do not natively support ordering search results. All results will be retrieved and then sorted in-memory. For large result sets, this can be very expensive. Mixed indexes support ordering natively and efficiently. However, the property key used in the order().by() method must have been previously added to the mixed indexed for native result ordering support. This is important in cases where the the order().by() key is different from the query keys. If the property key is not part of the index, then sorting requires loading all results into memory.","title":"Ordering"},{"location":"index-management/index-performance/#label-constraint","text":"In many cases it is desirable to only index vertices or edges with a particular label. For instance, one may want to index only gods by their name and not every single vertex that has a name property. When defining an index it is possible to restrict the index to a particular vertex or edge label using the indexOnly method of the index builder. The following creates a composite index for the property key name that indexes only vertices labeled god . graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () name = mgmt . getPropertyKey ( 'name' ) god = mgmt . getVertexLabel ( 'god' ) mgmt . buildIndex ( 'byNameAndLabel' , Vertex . class ). addKey ( name ). indexOnly ( god ). buildCompositeIndex () mgmt . commit () //Wait for the index to become available ManagementSystem . awaitGraphIndexStatus ( graph , 'byNameAndLabel' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"byNameAndLabel\" ), SchemaAction . REINDEX ). get () mgmt . commit () Label restrictions similarly apply to mixed indexes. When a composite index with label restriction is defined as unique, the uniqueness constraint only applies to properties on vertices or edges for the specified label.","title":"Label Constraint"},{"location":"index-management/index-performance/#composite-versus-mixed-indexes","text":"Use a composite index for exact match index retrievals. Composite indexes do not require configuring or operating an external index system and are often significantly faster than mixed indexes. As an exception, use a mixed index for exact matches when the number of distinct values for query constraint is relatively small or if one value is expected to be associated with many elements in the graph (i.e. in case of low selectivity). Use a mixed indexes for numeric range, full-text or geo-spatial indexing. Also, using a mixed index can speed up the order().by() queries.","title":"Composite versus Mixed Indexes"},{"location":"index-management/index-performance/#vertex-centric-indexes","text":"Vertex-centric indexes are local index structures built individually per vertex. In large graphs vertices can have thousands of incident edges. Traversing through those vertices can be very slow because a large subset of the incident edges has to be retrieved and then filtered in memory to match the conditions of the traversal. Vertex-centric indexes can speed up such traversals by using localized index structures to retrieve only those edges that need to be traversed. Suppose that Hercules battled hundreds of monsters in addition to the three captured in the introductory Graph of the Gods . Without a vertex-centric index, a query asking for those monsters battled between time point 10 and 20 would require retrieving all battled edges even though there are only a handful of matching edges. h = g . V (). has ( 'name' , 'hercules' ). next () g . V ( h ). outE ( 'battled' ). has ( 'time' , inside ( 10 , 20 )). inV () Building a vertex-centric index by time speeds up such traversal queries. Note, this initial index example already exists in the Graph of the Gods as an index named edges . As a result, running the steps below will result in a uniqueness constraint error. graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () time = mgmt . getPropertyKey ( 'time' ) battled = mgmt . getEdgeLabel ( 'battled' ) mgmt . buildEdgeIndex ( battled , 'battlesByTime' , Direction . BOTH , Order . desc , time ) mgmt . commit () //Wait for the index to become available ManagementSystem . awaitRelationIndexStatus ( graph , 'battlesByTime' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getRelationIndex ( battled , \"battlesByTime\" ), SchemaAction . REINDEX ). get () mgmt . commit () This example builds a vertex-centric index which indexes battled edges in both direction by time in descending order. A vertex-centric index is built against a particular edge label which is the first argument to the index construction method JanusGraphManagement.buildEdgeIndex() . The index only applies to edges of this label - battled in the example above. The second argument is a unique name for the index. The third argument is the edge direction in which the index is built. The index will only apply to traversals along edges in this direction. In this example, the vertex-centric index is built in both direction which means that time restricted traversals along battled edges can be served by this index in both the IN and OUT direction. JanusGraph will maintain a vertex-centric index on both the in- and out-vertex of battled edges. Alternatively, one could define the index to apply to the OUT direction only which would speed up traversals from Hercules to the monsters but not in the reverse direction. This would only require maintaining one index and hence half the index maintenance and storage cost. The last two arguments are the sort order of the index and a list of property keys to index by. The sort order is optional and defaults to ascending order (i.e. Order.ASC ). The list of property keys must be non-empty and defines the keys by which to index the edges of the given label. A vertex-centric index can be defined with multiple keys. graph . tx (). rollback () //Never create new indexes while a transaction is active mgmt = graph . openManagement () time = mgmt . getPropertyKey ( 'time' ) rating = mgmt . makePropertyKey ( 'rating' ). dataType ( Double . class ). make () battled = mgmt . getEdgeLabel ( 'battled' ) mgmt . buildEdgeIndex ( battled , 'battlesByRatingAndTime' , Direction . OUT , Order . desc , rating , time ) mgmt . commit () //Wait for the index to become available ManagementSystem . awaitRelationIndexStatus ( graph , 'battlesByRatingAndTime' , 'battled' ). call () //Reindex the existing data mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getRelationIndex ( battled , 'battlesByRatingAndTime' ), SchemaAction . REINDEX ). get () mgmt . commit () This example extends the schema by a rating property on battled edges and builds a vertex-centric index which indexes battled edges in the out-going direction by rating and time in descending order. Note, that the order in which the property keys are specified is important because vertex-centric indexes are prefix indexes. This means, that battled edges are indexed by rating first and time second . h = g . V (). has ( 'name' , 'hercules' ). next () g . V ( h ). outE ( 'battled' ). property ( 'rating' , 5.0 ) //Add some rating properties g . V ( h ). outE ( 'battled' ). has ( 'rating' , gt ( 3.0 )). inV () g . V ( h ). outE ( 'battled' ). has ( 'rating' , 5.0 ). has ( 'time' , inside ( 10 , 50 )). inV () g . V ( h ). outE ( 'battled' ). has ( 'time' , inside ( 10 , 50 )). inV () Hence, the battlesByRatingAndTime index can speed up the first two but not the third query. Multiple vertex-centric indexes can be built for the same edge label in order to support different constraint traversals. JanusGraph\u2019s query optimizer attempts to pick the most efficient index for any given traversal. Vertex-centric indexes only support equality and range/interval constraints. Note The property keys used in a vertex-centric index must have an explicitly defined data type (i.e. not Object.class ) which supports a native sort order. This means not only that they must implement Comparable but that their serializer must impement OrderPreservingSerializer . The types that are currently supported are Boolean , UUID , Byte , Float , Long , String , Integer , Date , Double , Character , and Short If the vertex-centric index is built against an edge label that is defined in the same management transaction, the index will be immediately available for querying. If the edge label has already been in use, building a vertex-centric index against it requires the execution of a reindex procedure to ensure that the index contains all previously added edges. Until the reindex procedure has completed, the index will not be available. Note JanusGraph automatically builds vertex-centric indexes per edge label and property key. That means, even with thousands of incident battled edges, queries like g.V(h).out('mother') or g.V(h).values('age') are efficiently answered by the local index. Vertex-centric indexes cannot speed up unconstrained traversals which require traversing through all incident edges of a particular label. Those traversals will become slower as the number of incident edges increases. Often, such traversals can be rewritten as constrained traversals that can utilize a vertex-centric index to ensure acceptable performance at scale.","title":"Vertex-centric Indexes"},{"location":"index-management/index-performance/#ordered-traversals","text":"The following queries specify an order in which the incident edges are to be traversed. Use the localLimit command to retrieve a subset of the edges (in a given order) for EACH vertex that is traversed. h = g .. V (). has ( 'name' , 'hercules' ). next () g . V ( h ). local ( outE ( 'battled' ). order (). by ( 'time' , desc ). limit ( 10 )). inV (). values ( 'name' ) g . V ( h ). local ( outE ( 'battled' ). has ( 'rating' , 5.0 ). order (). by ( 'time' , desc ). limit ( 10 )). values ( 'place' ) The first query asks for the names of the 10 most recently battled monsters by Hercules. The second query asks for the places of the 10 most recent battles of Hercules that are rated 5 stars. In both cases, the query is constrained by an order on a property key with a limit on the number of elements to be returned. Such queries can also be efficiently answered by vertex-centric indexes if the order key matches the key of the index and the requested order (i.e. ascending or descending) is the same as the one defined for the index. The battlesByTime index would be used to answer the first query and battlesByRatingAndTime applies to the second. Note, that the battlesByRatingAndTime index cannot be used to answer the first query because an equality constraint on rating must be present for the second key in the index to be effective. Note Ordered vertex queries are a JanusGraph extension to Gremlin which causes the verbose syntax and requires the _() step to convert the JanusGraph result back into a Gremlin pipeline.","title":"Ordered Traversals"},{"location":"index-management/index-reindexing/","text":"Reindexing Graph Index and Vertex-centric Indexes describe how to build graph-global and vertex-centric indexes to improve query performance. These indexes are immediately available if the indexed keys or labels have been newly defined in the same management transaction. In this case, there is no need to reindex the graph and this section can be skipped. If the indexed keys and labels already existed prior to index construction it is necessary to reindex the entire graph in order to ensure that the index contains previously added elements. This section describes the reindexing process. Warning Reindexing is a manual process comprised of multiple steps. These steps must be carefully followed in the right order to avoid index inconsistencies. Overview JanusGraph can begin writing incremental index updates right after an index is defined. However, before the index is complete and usable, JanusGraph must also take a one-time read pass over all existing graph elements associated with the newly indexed schema type(s). Once this reindexing job has completed, the index is fully populated and ready to be used. The index must then be enabled to be used during query processing. Prior to Reindex The starting point of the reindexing process is the construction of an index. Refer to Indexing for Better Performance for a complete discussion of global graph and vertex-centric indexes. Note, that a global graph index is uniquely identified by its name. A vertex-centric index is uniquely identified by the combination of its name and the edge label or property key on which the index is defined - the name of the latter is referred to as the index type in this section and only applies to vertex-centric indexes. After building a new index against existing schema elements it is recommended to wait a few minutes for the index to be announced to the cluster. Note the index name (and the index type in case of a vertex-centric index) since this information is needed when reindexing. Preparing to Reindex There is a choice between two execution frameworks for reindex jobs: MapReduce JanusGraphManagement Reindex on MapReduce supports large, horizontally-distributed databases. Reindex on JanusGraphManagement spawns a single-machine OLAP job. This is intended for convenience and speed on those databases small enough to be handled by one machine. Reindexing requires: The index name (a string\u2009\u2014\u2009the user provides this to JanusGraph when building a new index) The index type (a string\u2009\u2014\u2009the name of the edge label or property key on which the vertex-centric index is built). This applies only to vertex-centric indexes - leave blank for global graph indexes. Executing a Reindex Job on MapReduce The recommended way to generate and run a reindex job on MapReduce is through the MapReduceIndexManagement class. Here is a rough outline of the steps to run a reindex job using this class: Open a JanusGraph instance Pass the graph instance into MapReduceIndexManagement 's constructor Call updateIndex(<index>, SchemaAction.REINDEX) on the MapReduceIndexManagement instance If the index has not yet been enabled, enable it through JanusGraphManagement This class implements an updateIndex method that supports only the REINDEX and REMOVE_INDEX actions for its SchemaAction parameter. The class starts a Hadoop MapReduce job using the Hadoop configuration and jars on the classpath. Both Hadoop 1 and 2 are supported. This class gets metadata about the index and storage backend (e.g. the Cassandra partitioner) from the JanusGraph instance given to its constructor. graph = JanusGraphFactory . open (...) mgmt = graph . openManagement () mr = new MapReduceIndexManagement ( graph ) mr . updateIndex ( mgmt . getRelationIndex ( mgmt . getRelationType ( \"battled\" ), \"battlesByTime\" ), SchemaAction . REINDEX ). get () mgmt . commit () Reindex Example on MapReduce The following Gremlin snippet outlines all steps of the MapReduce reindex process in one self-contained example using minimal dummy data against the Cassandra storage backend. // Open a graph graph = JanusGraphFactory . open ( \"conf/janusgraph-cql-es.properties\" ) g = graph . traversal () // Define a property mgmt = graph . openManagement () desc = mgmt . makePropertyKey ( \"desc\" ). dataType ( String . class ). make () mgmt . commit () // Insert some data graph . addVertex ( \"desc\" , \"foo bar\" ) graph . addVertex ( \"desc\" , \"foo baz\" ) graph . tx (). commit () // Run a query -- note the planner warning recommending the use of an index g . V (). has ( \"desc\" , containsText ( \"baz\" )) // Create an index mgmt = graph . openManagement () desc = mgmt . getPropertyKey ( \"desc\" ) mixedIndex = mgmt . buildIndex ( \"mixedExample\" , Vertex . class ). addKey ( desc ). buildMixedIndex ( \"search\" ) mgmt . commit () // Rollback or commit transactions on the graph which predate the index definition graph . tx (). rollback () // Block until the SchemaStatus transitions from INSTALLED to REGISTERED report = ManagementSystem . awaitGraphIndexStatus ( graph , \"mixedExample\" ). call () // Run a JanusGraph-Hadoop job to reindex mgmt = graph . openManagement () mr = new MapReduceIndexManagement ( graph ) mr . updateIndex ( mgmt . getGraphIndex ( \"mixedExample\" ), SchemaAction . REINDEX ). get () // Enable the index mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"mixedExample\" ), SchemaAction . ENABLE_INDEX ). get () mgmt . commit () // Block until the SchemaStatus is ENABLED mgmt = graph . openManagement () report = ManagementSystem . awaitGraphIndexStatus ( graph , \"mixedExample\" ). status ( SchemaStatus . ENABLED ). call () mgmt . rollback () // Run a query -- JanusGraph will use the new index, no planner warning g . V (). has ( \"desc\" , containsText ( \"baz\" )) // Concerned that JanusGraph could have read cache in that last query, instead of relying on the index? // Start a new instance to rule out cache hits. Now we're definitely using the index. graph . close () graph = JanusGraphFactory . open ( \"conf/janusgraph-cql-es.properties\" ) g . V (). has ( \"desc\" , containsText ( \"baz\" )) Executing a Reindex job on JanusGraphManagement To run a reindex job on JanusGraphManagement, invoke JanusGraphManagement.updateIndex with the SchemaAction.REINDEX argument. For example: m = graph . openManagement () i = m . getGraphIndex ( 'indexName' ) m . updateIndex ( i , SchemaAction . REINDEX ). get () m . commit () Example for JanusGraphManagement The following loads some sample data into a BerkeleyDB-backed JanusGraph database, defines an index after the fact, reindexes using JanusGraphManagement, and finally enables and uses the index: import org.janusgraph.graphdb.database.management.ManagementSystem // Load some data from a file without any predefined schema graph = JanusGraphFactory . open ( 'conf/janusgraph-berkeleyje.properties' ) g = graph . traversal () m = graph . openManagement () m . makePropertyKey ( 'name' ). dataType ( String . class ). cardinality ( Cardinality . LIST ). make () m . makePropertyKey ( 'lang' ). dataType ( String . class ). cardinality ( Cardinality . LIST ). make () m . makePropertyKey ( 'age' ). dataType ( Integer . class ). cardinality ( Cardinality . LIST ). make () m . commit () graph . io ( IoCore . gryo ()). readGraph ( 'data/tinkerpop-modern.gio' ) graph . tx (). commit () // Run a query -- note the planner warning recommending the use of an index g . V (). has ( 'name' , 'lop' ) graph . tx (). rollback () // Create an index m = graph . openManagement () m . buildIndex ( 'names' , Vertex . class ). addKey ( m . getPropertyKey ( 'name' )). buildCompositeIndex () m . commit () graph . tx (). commit () // Block until the SchemaStatus transitions from INSTALLED to REGISTERED ManagementSystem . awaitGraphIndexStatus ( graph , 'names' ). status ( SchemaStatus . REGISTERED ). call () // Reindex using JanusGraphManagement m = graph . openManagement () i = m . getGraphIndex ( 'names' ) m . updateIndex ( i , SchemaAction . REINDEX ) m . commit () // Enable the index ManagementSystem . awaitGraphIndexStatus ( graph , 'names' ). status ( SchemaStatus . ENABLED ). call () // Run a query -- JanusGraph will use the new index, no planner warning g . V (). has ( 'name' , 'lop' ) graph . tx (). rollback () // Concerned that JanusGraph could have read cache in that last query, instead of relying on the index? // Start a new instance to rule out cache hits. Now we're definitely using the index. graph . close () graph = JanusGraphFactory . open ( \"conf/janusgraph-berkeleyje.properties\" ) g = graph . traversal () g . V (). has ( 'name' , 'lop' ) Common problems IllegalArgumentException when starting job When a reindexing job is started shortly after a the index has been built, the job might fail with an exception like one of the following: 1 2 3 4 5 6 The index mixedExample is in an invalid state and cannot be indexed . The following index keys have invalid status : desc has status INSTALLED ( status must be one of [ REGISTERED , ENABLED ]) The index mixedExample is in an invalid state and cannot be indexed . The index has status INSTALLED , but one of [ REGISTERED , ENABLED ] is required When an index is built, its existence is broadcast to all other JanusGraph instances in the cluster. Those must acknowledge the existence of the index before the reindexing process can be started. The acknowledgments can take a while to come in depending on the size of the cluster and the connection speed. Hence, one should wait a few minutes after building the index and before starting the reindex process. Note, that the acknowledgment might fail due to JanusGraph instance failure. In other words, the cluster might wait indefinitely on the acknowledgment of a failed instance. In this case, the user must manually remove the failed instance from the cluster registry as described in Failure & Recovery . After the cluster state has been restored, the acknowledgment process must be reinitiated by manually registering the index again in the management system. mgmt = graph . openManagement () rindex = mgmt . getRelationIndex ( mgmt . getRelationType ( \"battled\" ), \"battlesByTime\" ) mgmt . updateIndex ( rindex , SchemaAction . REGISTER_INDEX ). get () gindex = mgmt . getGraphIndex ( \"byName\" ) mgmt . updateIndex ( gindex , SchemaAction . REGISTER_INDEX ). get () mgmt . commit () After waiting a few minutes for the acknowledgment to arrive the reindex job should start successfully. Could not find index This exception in the reindexing job indicates that an index with the given name does not exist or that the name has not been specified correctly. When reindexing a global graph index, only the name of the index as defined when building the index should be specified. When reindexing a global graph index, the name of the index must be given in addition to the name of the edge label or property key on which the vertex-centric index is defined. Cassandra Mappers Fail with \"Too many open files\" The end of the exception stacktrace may look like this: java . net . SocketException : Too many open files at java . net . Socket . createImpl ( Socket . java : 447 ) at java . net . Socket . getImpl ( Socket . java : 510 ) at java . net . Socket . setSoLinger ( Socket . java : 988 ) at org . apache . thrift . transport . TSocket . initSocket ( TSocket . java : 118 ) at org . apache . thrift . transport . TSocket . < init > ( TSocket . java : 109 ) When running Cassandra with virtual nodes enabled, the number of virtual nodes seems to set a floor under the number of mappers. Cassandra may generate more mappers than virtual nodes for clusters with lots of data, but it seems to generate at least as many mappers as there are virtual nodes even though the cluster might be empty or close to empty. The default is 256 as of this writing. Each mapper opens and quickly closes several sockets to Cassandra. The kernel on the client side of those closed sockets goes into asynchronous TIME_WAIT, since Thrift uses SO_LINGER. Only a small number of sockets are open at any one time\u2009\u2014\u2009usually low single digits\u2009\u2014\u2009but potentially many lingering sockets can accumulate in TIME_WAIT. This accumulation is most pronounced when running a reindex job locally (not on a distributed MapReduce cluster), since all of those client-side TIME_WAIT sockets are lingering on a single client machine instead of being spread out across many machines in a cluster. Combined with the floor of 256 mappers, a reindex job can open thousands of sockets of the course of its execution. When these sockets all linger in TIME_WAIT on the same client, they have the potential to reach the open-files ulimit, which also controls the number of open sockets. The open-files ulimit is often set to 1024. Here are a few suggestions for dealing with the \"Too many open files\" problem during reindexing on a single machine: Reduce the maximum size of the Cassandra connection pool. For example, consider setting the cassandrathrift storage backend\u2019s max-active and max-idle options to 1 each, and setting max-total to -1. See Configuration Reference for full listings of connection pool settings on the Cassandra storage backends. Increase the nofile ulimit. The ideal value depends on the size of the Cassandra dataset and the throughput of the reindex mappers; if starting at 1024, try an order of magnitude larger: 10000. This is just necessary to sustain lingering TIME_WAIT sockets. The reindex job won\u2019t try to open nearly that many sockets at once. Run the reindex task on a multi-node MapReduce cluster to spread out the socket load.","title":"Reindexing"},{"location":"index-management/index-reindexing/#reindexing","text":"Graph Index and Vertex-centric Indexes describe how to build graph-global and vertex-centric indexes to improve query performance. These indexes are immediately available if the indexed keys or labels have been newly defined in the same management transaction. In this case, there is no need to reindex the graph and this section can be skipped. If the indexed keys and labels already existed prior to index construction it is necessary to reindex the entire graph in order to ensure that the index contains previously added elements. This section describes the reindexing process. Warning Reindexing is a manual process comprised of multiple steps. These steps must be carefully followed in the right order to avoid index inconsistencies.","title":"Reindexing"},{"location":"index-management/index-reindexing/#overview","text":"JanusGraph can begin writing incremental index updates right after an index is defined. However, before the index is complete and usable, JanusGraph must also take a one-time read pass over all existing graph elements associated with the newly indexed schema type(s). Once this reindexing job has completed, the index is fully populated and ready to be used. The index must then be enabled to be used during query processing.","title":"Overview"},{"location":"index-management/index-reindexing/#prior-to-reindex","text":"The starting point of the reindexing process is the construction of an index. Refer to Indexing for Better Performance for a complete discussion of global graph and vertex-centric indexes. Note, that a global graph index is uniquely identified by its name. A vertex-centric index is uniquely identified by the combination of its name and the edge label or property key on which the index is defined - the name of the latter is referred to as the index type in this section and only applies to vertex-centric indexes. After building a new index against existing schema elements it is recommended to wait a few minutes for the index to be announced to the cluster. Note the index name (and the index type in case of a vertex-centric index) since this information is needed when reindexing.","title":"Prior to Reindex"},{"location":"index-management/index-reindexing/#preparing-to-reindex","text":"There is a choice between two execution frameworks for reindex jobs: MapReduce JanusGraphManagement Reindex on MapReduce supports large, horizontally-distributed databases. Reindex on JanusGraphManagement spawns a single-machine OLAP job. This is intended for convenience and speed on those databases small enough to be handled by one machine. Reindexing requires: The index name (a string\u2009\u2014\u2009the user provides this to JanusGraph when building a new index) The index type (a string\u2009\u2014\u2009the name of the edge label or property key on which the vertex-centric index is built). This applies only to vertex-centric indexes - leave blank for global graph indexes.","title":"Preparing to Reindex"},{"location":"index-management/index-reindexing/#executing-a-reindex-job-on-mapreduce","text":"The recommended way to generate and run a reindex job on MapReduce is through the MapReduceIndexManagement class. Here is a rough outline of the steps to run a reindex job using this class: Open a JanusGraph instance Pass the graph instance into MapReduceIndexManagement 's constructor Call updateIndex(<index>, SchemaAction.REINDEX) on the MapReduceIndexManagement instance If the index has not yet been enabled, enable it through JanusGraphManagement This class implements an updateIndex method that supports only the REINDEX and REMOVE_INDEX actions for its SchemaAction parameter. The class starts a Hadoop MapReduce job using the Hadoop configuration and jars on the classpath. Both Hadoop 1 and 2 are supported. This class gets metadata about the index and storage backend (e.g. the Cassandra partitioner) from the JanusGraph instance given to its constructor. graph = JanusGraphFactory . open (...) mgmt = graph . openManagement () mr = new MapReduceIndexManagement ( graph ) mr . updateIndex ( mgmt . getRelationIndex ( mgmt . getRelationType ( \"battled\" ), \"battlesByTime\" ), SchemaAction . REINDEX ). get () mgmt . commit ()","title":"Executing a Reindex Job on MapReduce"},{"location":"index-management/index-reindexing/#reindex-example-on-mapreduce","text":"The following Gremlin snippet outlines all steps of the MapReduce reindex process in one self-contained example using minimal dummy data against the Cassandra storage backend. // Open a graph graph = JanusGraphFactory . open ( \"conf/janusgraph-cql-es.properties\" ) g = graph . traversal () // Define a property mgmt = graph . openManagement () desc = mgmt . makePropertyKey ( \"desc\" ). dataType ( String . class ). make () mgmt . commit () // Insert some data graph . addVertex ( \"desc\" , \"foo bar\" ) graph . addVertex ( \"desc\" , \"foo baz\" ) graph . tx (). commit () // Run a query -- note the planner warning recommending the use of an index g . V (). has ( \"desc\" , containsText ( \"baz\" )) // Create an index mgmt = graph . openManagement () desc = mgmt . getPropertyKey ( \"desc\" ) mixedIndex = mgmt . buildIndex ( \"mixedExample\" , Vertex . class ). addKey ( desc ). buildMixedIndex ( \"search\" ) mgmt . commit () // Rollback or commit transactions on the graph which predate the index definition graph . tx (). rollback () // Block until the SchemaStatus transitions from INSTALLED to REGISTERED report = ManagementSystem . awaitGraphIndexStatus ( graph , \"mixedExample\" ). call () // Run a JanusGraph-Hadoop job to reindex mgmt = graph . openManagement () mr = new MapReduceIndexManagement ( graph ) mr . updateIndex ( mgmt . getGraphIndex ( \"mixedExample\" ), SchemaAction . REINDEX ). get () // Enable the index mgmt = graph . openManagement () mgmt . updateIndex ( mgmt . getGraphIndex ( \"mixedExample\" ), SchemaAction . ENABLE_INDEX ). get () mgmt . commit () // Block until the SchemaStatus is ENABLED mgmt = graph . openManagement () report = ManagementSystem . awaitGraphIndexStatus ( graph , \"mixedExample\" ). status ( SchemaStatus . ENABLED ). call () mgmt . rollback () // Run a query -- JanusGraph will use the new index, no planner warning g . V (). has ( \"desc\" , containsText ( \"baz\" )) // Concerned that JanusGraph could have read cache in that last query, instead of relying on the index? // Start a new instance to rule out cache hits. Now we're definitely using the index. graph . close () graph = JanusGraphFactory . open ( \"conf/janusgraph-cql-es.properties\" ) g . V (). has ( \"desc\" , containsText ( \"baz\" ))","title":"Reindex Example on MapReduce"},{"location":"index-management/index-reindexing/#executing-a-reindex-job-on-janusgraphmanagement","text":"To run a reindex job on JanusGraphManagement, invoke JanusGraphManagement.updateIndex with the SchemaAction.REINDEX argument. For example: m = graph . openManagement () i = m . getGraphIndex ( 'indexName' ) m . updateIndex ( i , SchemaAction . REINDEX ). get () m . commit ()","title":"Executing a Reindex job on JanusGraphManagement"},{"location":"index-management/index-reindexing/#example-for-janusgraphmanagement","text":"The following loads some sample data into a BerkeleyDB-backed JanusGraph database, defines an index after the fact, reindexes using JanusGraphManagement, and finally enables and uses the index: import org.janusgraph.graphdb.database.management.ManagementSystem // Load some data from a file without any predefined schema graph = JanusGraphFactory . open ( 'conf/janusgraph-berkeleyje.properties' ) g = graph . traversal () m = graph . openManagement () m . makePropertyKey ( 'name' ). dataType ( String . class ). cardinality ( Cardinality . LIST ). make () m . makePropertyKey ( 'lang' ). dataType ( String . class ). cardinality ( Cardinality . LIST ). make () m . makePropertyKey ( 'age' ). dataType ( Integer . class ). cardinality ( Cardinality . LIST ). make () m . commit () graph . io ( IoCore . gryo ()). readGraph ( 'data/tinkerpop-modern.gio' ) graph . tx (). commit () // Run a query -- note the planner warning recommending the use of an index g . V (). has ( 'name' , 'lop' ) graph . tx (). rollback () // Create an index m = graph . openManagement () m . buildIndex ( 'names' , Vertex . class ). addKey ( m . getPropertyKey ( 'name' )). buildCompositeIndex () m . commit () graph . tx (). commit () // Block until the SchemaStatus transitions from INSTALLED to REGISTERED ManagementSystem . awaitGraphIndexStatus ( graph , 'names' ). status ( SchemaStatus . REGISTERED ). call () // Reindex using JanusGraphManagement m = graph . openManagement () i = m . getGraphIndex ( 'names' ) m . updateIndex ( i , SchemaAction . REINDEX ) m . commit () // Enable the index ManagementSystem . awaitGraphIndexStatus ( graph , 'names' ). status ( SchemaStatus . ENABLED ). call () // Run a query -- JanusGraph will use the new index, no planner warning g . V (). has ( 'name' , 'lop' ) graph . tx (). rollback () // Concerned that JanusGraph could have read cache in that last query, instead of relying on the index? // Start a new instance to rule out cache hits. Now we're definitely using the index. graph . close () graph = JanusGraphFactory . open ( \"conf/janusgraph-berkeleyje.properties\" ) g = graph . traversal () g . V (). has ( 'name' , 'lop' )","title":"Example for JanusGraphManagement"},{"location":"index-management/index-reindexing/#common-problems","text":"","title":"Common problems"},{"location":"index-management/index-reindexing/#illegalargumentexception-when-starting-job","text":"When a reindexing job is started shortly after a the index has been built, the job might fail with an exception like one of the following: 1 2 3 4 5 6 The index mixedExample is in an invalid state and cannot be indexed . The following index keys have invalid status : desc has status INSTALLED ( status must be one of [ REGISTERED , ENABLED ]) The index mixedExample is in an invalid state and cannot be indexed . The index has status INSTALLED , but one of [ REGISTERED , ENABLED ] is required When an index is built, its existence is broadcast to all other JanusGraph instances in the cluster. Those must acknowledge the existence of the index before the reindexing process can be started. The acknowledgments can take a while to come in depending on the size of the cluster and the connection speed. Hence, one should wait a few minutes after building the index and before starting the reindex process. Note, that the acknowledgment might fail due to JanusGraph instance failure. In other words, the cluster might wait indefinitely on the acknowledgment of a failed instance. In this case, the user must manually remove the failed instance from the cluster registry as described in Failure & Recovery . After the cluster state has been restored, the acknowledgment process must be reinitiated by manually registering the index again in the management system. mgmt = graph . openManagement () rindex = mgmt . getRelationIndex ( mgmt . getRelationType ( \"battled\" ), \"battlesByTime\" ) mgmt . updateIndex ( rindex , SchemaAction . REGISTER_INDEX ). get () gindex = mgmt . getGraphIndex ( \"byName\" ) mgmt . updateIndex ( gindex , SchemaAction . REGISTER_INDEX ). get () mgmt . commit () After waiting a few minutes for the acknowledgment to arrive the reindex job should start successfully.","title":"IllegalArgumentException when starting job"},{"location":"index-management/index-reindexing/#could-not-find-index","text":"This exception in the reindexing job indicates that an index with the given name does not exist or that the name has not been specified correctly. When reindexing a global graph index, only the name of the index as defined when building the index should be specified. When reindexing a global graph index, the name of the index must be given in addition to the name of the edge label or property key on which the vertex-centric index is defined.","title":"Could not find index"},{"location":"index-management/index-reindexing/#cassandra-mappers-fail-with-too-many-open-files","text":"The end of the exception stacktrace may look like this: java . net . SocketException : Too many open files at java . net . Socket . createImpl ( Socket . java : 447 ) at java . net . Socket . getImpl ( Socket . java : 510 ) at java . net . Socket . setSoLinger ( Socket . java : 988 ) at org . apache . thrift . transport . TSocket . initSocket ( TSocket . java : 118 ) at org . apache . thrift . transport . TSocket . < init > ( TSocket . java : 109 ) When running Cassandra with virtual nodes enabled, the number of virtual nodes seems to set a floor under the number of mappers. Cassandra may generate more mappers than virtual nodes for clusters with lots of data, but it seems to generate at least as many mappers as there are virtual nodes even though the cluster might be empty or close to empty. The default is 256 as of this writing. Each mapper opens and quickly closes several sockets to Cassandra. The kernel on the client side of those closed sockets goes into asynchronous TIME_WAIT, since Thrift uses SO_LINGER. Only a small number of sockets are open at any one time\u2009\u2014\u2009usually low single digits\u2009\u2014\u2009but potentially many lingering sockets can accumulate in TIME_WAIT. This accumulation is most pronounced when running a reindex job locally (not on a distributed MapReduce cluster), since all of those client-side TIME_WAIT sockets are lingering on a single client machine instead of being spread out across many machines in a cluster. Combined with the floor of 256 mappers, a reindex job can open thousands of sockets of the course of its execution. When these sockets all linger in TIME_WAIT on the same client, they have the potential to reach the open-files ulimit, which also controls the number of open sockets. The open-files ulimit is often set to 1024. Here are a few suggestions for dealing with the \"Too many open files\" problem during reindexing on a single machine: Reduce the maximum size of the Cassandra connection pool. For example, consider setting the cassandrathrift storage backend\u2019s max-active and max-idle options to 1 each, and setting max-total to -1. See Configuration Reference for full listings of connection pool settings on the Cassandra storage backends. Increase the nofile ulimit. The ideal value depends on the size of the Cassandra dataset and the throughput of the reindex mappers; if starting at 1024, try an order of magnitude larger: 10000. This is just necessary to sustain lingering TIME_WAIT sockets. The reindex job won\u2019t try to open nearly that many sockets at once. Run the reindex task on a multi-node MapReduce cluster to spread out the socket load.","title":"Cassandra Mappers Fail with \"Too many open files\""},{"location":"index-management/index-removal/","text":"Removal Warning Index removal is a manual process comprised of multiple steps. These steps must be carefully followed in the right order to avoid index inconsistencies. Overview Index removal is a two-stage process. In the first stage, one JanusGraph signals to all others via the storage backend that the index is slated for deletion. This changes the index\u2019s state to DISABLED . At that point, JanusGraph stops using the index to answer queries and stops incrementally updating the index. Index-related data in the storage backend remains present but ignored. The second stage depends on whether the index is mixed or composite. A composite index can be deleted via JanusGraph. As with reindexing, removal can be done through either MapReduce or JanusGraphManagement. However, a mixed index must be manually dropped in the index backend; JanusGraph does not provide an automated mechanism to delete an index from its index backend. Index removal deletes everything associated with the index except its schema definition and its DISABLED state. This schema stub for the index remains even after deletion, though its storage footprint is negligible and fixed. Preparing for Index Removal If the index is currently enabled, it should first be disabled. This is done through the ManagementSystem . mgmt = graph . openManagement () rindex = mgmt . getRelationIndex ( mgmt . getRelationType ( \"battled\" ), \"battlesByTime\" ) mgmt . updateIndex ( rindex , SchemaAction . DISABLE_INDEX ). get () gindex = mgmt . getGraphIndex ( \"byName\" ) mgmt . updateIndex ( gindex , SchemaAction . DISABLE_INDEX ). get () mgmt . commit () Once the status of all keys on the index changes to DISABLED , the index is ready to be removed. A utility in ManagementSystem can automate the wait-for- DISABLED step: ManagementSystem . awaitGraphIndexStatus ( graph , 'byName' ). status ( SchemaStatus . DISABLED ). call () After a composite index is DISABLED , there is a choice between two execution frameworks for its removal: MapReduce JanusGraphManagement Index removal on MapReduce supports large, horizontally-distributed databases. Index removal on JanusGraphManagement spawns a single-machine OLAP job. This is intended for convenience and speed on those databases small enough to be handled by one machine. Index removal requires: The index name (a string\u2009\u2014\u2009the user provides this to JanusGraph when building a new index) The index type (a string\u2009\u2014\u2009the name of the edge label or property key on which the vertex-centric index is built). This applies only to vertex-centric indexes - leave blank for global graph indexes. As noted in the overview, a mixed index must be manually dropped from the indexing backend. Neither the MapReduce framework nor the JanusGraphManagement framework will delete a mixed backend from the indexing backend. Executing an Index Removal Job on MapReduce As with reindexing, the recommended way to generate and run an index removal job on MapReduce is through the MapReduceIndexManagement class. Here is a rough outline of the steps to run an index removal job using this class: Open a JanusGraph instance If the index has not yet been disabled, disable it through JanusGraphManagement Pass the graph instance into MapReduceIndexManagement 's constructor Call updateIndex(<index>, SchemaAction.REMOVE_INDEX) A commented code example follows in the next subsection. Example for MapReduce import org.janusgraph.graphdb.database.management.ManagementSystem // Load the \"Graph of the Gods\" sample data graph = JanusGraphFactory . open ( 'conf/janusgraph-cql-es.properties' ) g = graph . traversal () GraphOfTheGodsFactory . load ( graph ) g . V (). has ( 'name' , 'jupiter' ) // Disable the \"name\" composite index m = graph . openManagement () nameIndex = m . getGraphIndex ( 'name' ) m . updateIndex ( nameIndex , SchemaAction . DISABLE_INDEX ). get () m . commit () graph . tx (). commit () // Block until the SchemaStatus transitions from INSTALLED to REGISTERED ManagementSystem . awaitGraphIndexStatus ( graph , 'name' ). status ( SchemaStatus . DISABLED ). call () // Delete the index using MapReduceIndexJobs m = graph . openManagement () mr = new MapReduceIndexManagement ( graph ) future = mr . updateIndex ( m . getGraphIndex ( 'name' ), SchemaAction . REMOVE_INDEX ) m . commit () graph . tx (). commit () future . get () // Index still shows up in management interface as DISABLED -- this is normal m = graph . openManagement () idx = m . getGraphIndex ( 'name' ) idx . getIndexStatus ( m . getPropertyKey ( 'name' )) m . rollback () // JanusGraph should issue a warning about this query requiring a full scan g . V (). has ( 'name' , 'jupiter' ) Executing an Index Removal job on JanusGraphManagement To run an index removal job on JanusGraphManagement, invoke JanusGraphManagement.updateIndex with the SchemaAction.REMOVE_INDEX argument. For example: m = graph . openManagement () i = m . getGraphIndex ( 'indexName' ) m . updateIndex ( i , SchemaAction . REMOVE_INDEX ). get () m . commit () Example for JanusGraphManagement The following loads some indexed sample data into a BerkeleyDB-backed JanusGraph database, then disables and removes the index through JanusGraphManagement: import org.janusgraph.graphdb.database.management.ManagementSystem // Load the \"Graph of the Gods\" sample data graph = JanusGraphFactory . open ( 'conf/janusgraph-cql-es.properties' ) g = graph . traversal () GraphOfTheGodsFactory . load ( graph ) g . V (). has ( 'name' , 'jupiter' ) // Disable the \"name\" composite index m = graph . openManagement () nameIndex = m . getGraphIndex ( 'name' ) m . updateIndex ( nameIndex , SchemaAction . DISABLE_INDEX ). get () m . commit () graph . tx (). commit () // Block until the SchemaStatus transitions from INSTALLED to REGISTERED ManagementSystem . awaitGraphIndexStatus ( graph , 'name' ). status ( SchemaStatus . DISABLED ). call () // Delete the index using JanusGraphManagement m = graph . openManagement () nameIndex = m . getGraphIndex ( 'name' ) future = m . updateIndex ( nameIndex , SchemaAction . REMOVE_INDEX ) m . commit () graph . tx (). commit () future . get () m = graph . openManagement () nameIndex = m . getGraphIndex ( 'name' ) g . V (). has ( 'name' , 'jupiter' )","title":"Removal"},{"location":"index-management/index-removal/#removal","text":"Warning Index removal is a manual process comprised of multiple steps. These steps must be carefully followed in the right order to avoid index inconsistencies.","title":"Removal"},{"location":"index-management/index-removal/#overview","text":"Index removal is a two-stage process. In the first stage, one JanusGraph signals to all others via the storage backend that the index is slated for deletion. This changes the index\u2019s state to DISABLED . At that point, JanusGraph stops using the index to answer queries and stops incrementally updating the index. Index-related data in the storage backend remains present but ignored. The second stage depends on whether the index is mixed or composite. A composite index can be deleted via JanusGraph. As with reindexing, removal can be done through either MapReduce or JanusGraphManagement. However, a mixed index must be manually dropped in the index backend; JanusGraph does not provide an automated mechanism to delete an index from its index backend. Index removal deletes everything associated with the index except its schema definition and its DISABLED state. This schema stub for the index remains even after deletion, though its storage footprint is negligible and fixed.","title":"Overview"},{"location":"index-management/index-removal/#preparing-for-index-removal","text":"If the index is currently enabled, it should first be disabled. This is done through the ManagementSystem . mgmt = graph . openManagement () rindex = mgmt . getRelationIndex ( mgmt . getRelationType ( \"battled\" ), \"battlesByTime\" ) mgmt . updateIndex ( rindex , SchemaAction . DISABLE_INDEX ). get () gindex = mgmt . getGraphIndex ( \"byName\" ) mgmt . updateIndex ( gindex , SchemaAction . DISABLE_INDEX ). get () mgmt . commit () Once the status of all keys on the index changes to DISABLED , the index is ready to be removed. A utility in ManagementSystem can automate the wait-for- DISABLED step: ManagementSystem . awaitGraphIndexStatus ( graph , 'byName' ). status ( SchemaStatus . DISABLED ). call () After a composite index is DISABLED , there is a choice between two execution frameworks for its removal: MapReduce JanusGraphManagement Index removal on MapReduce supports large, horizontally-distributed databases. Index removal on JanusGraphManagement spawns a single-machine OLAP job. This is intended for convenience and speed on those databases small enough to be handled by one machine. Index removal requires: The index name (a string\u2009\u2014\u2009the user provides this to JanusGraph when building a new index) The index type (a string\u2009\u2014\u2009the name of the edge label or property key on which the vertex-centric index is built). This applies only to vertex-centric indexes - leave blank for global graph indexes. As noted in the overview, a mixed index must be manually dropped from the indexing backend. Neither the MapReduce framework nor the JanusGraphManagement framework will delete a mixed backend from the indexing backend.","title":"Preparing for Index Removal"},{"location":"index-management/index-removal/#executing-an-index-removal-job-on-mapreduce","text":"As with reindexing, the recommended way to generate and run an index removal job on MapReduce is through the MapReduceIndexManagement class. Here is a rough outline of the steps to run an index removal job using this class: Open a JanusGraph instance If the index has not yet been disabled, disable it through JanusGraphManagement Pass the graph instance into MapReduceIndexManagement 's constructor Call updateIndex(<index>, SchemaAction.REMOVE_INDEX) A commented code example follows in the next subsection.","title":"Executing an Index Removal Job on MapReduce"},{"location":"index-management/index-removal/#example-for-mapreduce","text":"import org.janusgraph.graphdb.database.management.ManagementSystem // Load the \"Graph of the Gods\" sample data graph = JanusGraphFactory . open ( 'conf/janusgraph-cql-es.properties' ) g = graph . traversal () GraphOfTheGodsFactory . load ( graph ) g . V (). has ( 'name' , 'jupiter' ) // Disable the \"name\" composite index m = graph . openManagement () nameIndex = m . getGraphIndex ( 'name' ) m . updateIndex ( nameIndex , SchemaAction . DISABLE_INDEX ). get () m . commit () graph . tx (). commit () // Block until the SchemaStatus transitions from INSTALLED to REGISTERED ManagementSystem . awaitGraphIndexStatus ( graph , 'name' ). status ( SchemaStatus . DISABLED ). call () // Delete the index using MapReduceIndexJobs m = graph . openManagement () mr = new MapReduceIndexManagement ( graph ) future = mr . updateIndex ( m . getGraphIndex ( 'name' ), SchemaAction . REMOVE_INDEX ) m . commit () graph . tx (). commit () future . get () // Index still shows up in management interface as DISABLED -- this is normal m = graph . openManagement () idx = m . getGraphIndex ( 'name' ) idx . getIndexStatus ( m . getPropertyKey ( 'name' )) m . rollback () // JanusGraph should issue a warning about this query requiring a full scan g . V (). has ( 'name' , 'jupiter' )","title":"Example for MapReduce"},{"location":"index-management/index-removal/#executing-an-index-removal-job-on-janusgraphmanagement","text":"To run an index removal job on JanusGraphManagement, invoke JanusGraphManagement.updateIndex with the SchemaAction.REMOVE_INDEX argument. For example: m = graph . openManagement () i = m . getGraphIndex ( 'indexName' ) m . updateIndex ( i , SchemaAction . REMOVE_INDEX ). get () m . commit ()","title":"Executing an Index Removal job on JanusGraphManagement"},{"location":"index-management/index-removal/#example-for-janusgraphmanagement","text":"The following loads some indexed sample data into a BerkeleyDB-backed JanusGraph database, then disables and removes the index through JanusGraphManagement: import org.janusgraph.graphdb.database.management.ManagementSystem // Load the \"Graph of the Gods\" sample data graph = JanusGraphFactory . open ( 'conf/janusgraph-cql-es.properties' ) g = graph . traversal () GraphOfTheGodsFactory . load ( graph ) g . V (). has ( 'name' , 'jupiter' ) // Disable the \"name\" composite index m = graph . openManagement () nameIndex = m . getGraphIndex ( 'name' ) m . updateIndex ( nameIndex , SchemaAction . DISABLE_INDEX ). get () m . commit () graph . tx (). commit () // Block until the SchemaStatus transitions from INSTALLED to REGISTERED ManagementSystem . awaitGraphIndexStatus ( graph , 'name' ). status ( SchemaStatus . DISABLED ). call () // Delete the index using JanusGraphManagement m = graph . openManagement () nameIndex = m . getGraphIndex ( 'name' ) future = m . updateIndex ( nameIndex , SchemaAction . REMOVE_INDEX ) m . commit () graph . tx (). commit () future . get () m = graph . openManagement () nameIndex = m . getGraphIndex ( 'name' ) g . V (). has ( 'name' , 'jupiter' )","title":"Example for JanusGraphManagement"},{"location":"storage-backend/","text":"JanusGraph\u2019s data storage layer is pluggable. Implementations of the pluggable storage layer\u2009\u2014\u2009that is, the software component tells JanusGraph how to talk to its data store\u2009\u2014\u2009are called storage backends. This section describes configuration and administration of JanusGraph\u2019s standard storage backends. This section only addresses configuration of the stock storage backends that come with JanusGraph.","title":"Introduction"},{"location":"storage-backend/bdb/","text":"Oracle Berkeley DB Java Edition Oracle Berkeley DB Java Edition is an open source, embeddable, transactional storage engine written entirely in Java. It takes full advantage of the Java environment to simplify development and deployment. The architecture of Oracle Berkeley DB Java Edition supports very high performance and concurrency for both read-intensive and write-intensive workloads. \u2014 Oracle Berkeley DB Java Edition Homepage The Oracle Berkeley DB Java Edition storage backend runs in the same JVM as JanusGraph and provides local persistence on a single machine. Hence, the BerkeleyDB storage backend requires that all of the graph data fits on the local disk and all of the frequently accessed graph elements fit into main memory. This imposes a practical limitation of graphs with 10-100s million vertices on commodity hardware. However, for graphs of that size the BerkeleyDB storage backend exhibits high performance because all data can be accessed locally within the same JVM. BerkeleyDB JE Setup Since BerkeleyDB runs in the same JVM as JanusGraph, connecting the two only requires a simple configuration and no additional setup: JanusGraph g = JanusGraphFactory . build (). set ( \"storage.backend\" , \"berkeleyje\" ). set ( \"storage.directory\" , \"/data/graph\" ). open (); In the Gremlin Console, you can not define the type of the variables conf and g . Therefore, simply leave off the type declaration. BerkeleyDB Specific Configuration Refer to Configuration Reference for a complete listing of all BerkeleyDB specific configuration options in addition to the general JanusGraph configuration options. When configuring BerkeleyDB it is recommended to consider the following BerkeleyDB specific configuration options: transactions : Enables transactions and detects conflicting database operations. CAUTION: While disabling transactions can lead to better performance it can cause to inconsistencies and even corrupt the database if multiple JanusGraph instances interact with the same instance of BerkeleyDB. cache-percentage : The percentage of JVM heap space (configured via -Xmx) to be allocated to BerkeleyDB for its cache. Try to give BerkeleyDB as much space as possible without causing memory problems for JanusGraph. For instance, if JanusGraph only runs short transactions, use a value of 80 or higher. Ideal Use Case The BerkeleyDB storage backend is best suited for small to medium size graphs with up to 100 million vertices on commodity hardware. For graphs of that size, it will likely deliver higher performance than the distributed storage backends. Note, that BerkeleyDB is also limited in the number of concurrent requests it can handle efficiently because it runs on a single machine. Hence, it is not well suited for applications with many concurrent users mutating the graph, even if that graph is small to medium size. Since BerkeleyDB runs in the same JVM as JanusGraph, this storage backend is ideally suited for unit testing of application code using JanusGraph. Global Graph Operations JanusGraph backed by BerkeleyDB supports global graph operations such as iterating over all vertices or edges. However, note that such operations need to scan the entire database which can require a significant amount of time for larger graphs. In order to not run out of memory, it is advised to disable transactions ( storage.transactions=false ) when iterating over large graphs. Having transactions enabled requires BerkeleyDB to acquire read locks on the data it is reading. When iterating over the entire graph, these read locks can easily require more memory than is available.","title":"Oracle Berkeley DB Java Edition"},{"location":"storage-backend/bdb/#oracle-berkeley-db-java-edition","text":"Oracle Berkeley DB Java Edition is an open source, embeddable, transactional storage engine written entirely in Java. It takes full advantage of the Java environment to simplify development and deployment. The architecture of Oracle Berkeley DB Java Edition supports very high performance and concurrency for both read-intensive and write-intensive workloads. \u2014 Oracle Berkeley DB Java Edition Homepage The Oracle Berkeley DB Java Edition storage backend runs in the same JVM as JanusGraph and provides local persistence on a single machine. Hence, the BerkeleyDB storage backend requires that all of the graph data fits on the local disk and all of the frequently accessed graph elements fit into main memory. This imposes a practical limitation of graphs with 10-100s million vertices on commodity hardware. However, for graphs of that size the BerkeleyDB storage backend exhibits high performance because all data can be accessed locally within the same JVM.","title":"Oracle Berkeley DB Java Edition"},{"location":"storage-backend/bdb/#berkeleydb-je-setup","text":"Since BerkeleyDB runs in the same JVM as JanusGraph, connecting the two only requires a simple configuration and no additional setup: JanusGraph g = JanusGraphFactory . build (). set ( \"storage.backend\" , \"berkeleyje\" ). set ( \"storage.directory\" , \"/data/graph\" ). open (); In the Gremlin Console, you can not define the type of the variables conf and g . Therefore, simply leave off the type declaration.","title":"BerkeleyDB JE Setup"},{"location":"storage-backend/bdb/#berkeleydb-specific-configuration","text":"Refer to Configuration Reference for a complete listing of all BerkeleyDB specific configuration options in addition to the general JanusGraph configuration options. When configuring BerkeleyDB it is recommended to consider the following BerkeleyDB specific configuration options: transactions : Enables transactions and detects conflicting database operations. CAUTION: While disabling transactions can lead to better performance it can cause to inconsistencies and even corrupt the database if multiple JanusGraph instances interact with the same instance of BerkeleyDB. cache-percentage : The percentage of JVM heap space (configured via -Xmx) to be allocated to BerkeleyDB for its cache. Try to give BerkeleyDB as much space as possible without causing memory problems for JanusGraph. For instance, if JanusGraph only runs short transactions, use a value of 80 or higher.","title":"BerkeleyDB Specific Configuration"},{"location":"storage-backend/bdb/#ideal-use-case","text":"The BerkeleyDB storage backend is best suited for small to medium size graphs with up to 100 million vertices on commodity hardware. For graphs of that size, it will likely deliver higher performance than the distributed storage backends. Note, that BerkeleyDB is also limited in the number of concurrent requests it can handle efficiently because it runs on a single machine. Hence, it is not well suited for applications with many concurrent users mutating the graph, even if that graph is small to medium size. Since BerkeleyDB runs in the same JVM as JanusGraph, this storage backend is ideally suited for unit testing of application code using JanusGraph.","title":"Ideal Use Case"},{"location":"storage-backend/bdb/#global-graph-operations","text":"JanusGraph backed by BerkeleyDB supports global graph operations such as iterating over all vertices or edges. However, note that such operations need to scan the entire database which can require a significant amount of time for larger graphs. In order to not run out of memory, it is advised to disable transactions ( storage.transactions=false ) when iterating over large graphs. Having transactions enabled requires BerkeleyDB to acquire read locks on the data it is reading. When iterating over the entire graph, these read locks can easily require more memory than is available.","title":"Global Graph Operations"},{"location":"storage-backend/bigtable/","text":"Google Cloud Bigtable Cloud Bigtable is Google\u2019s NoSQL Big Data database service. It\u2019s the same database that powers many core Google services, including Search, Analytics, Maps, and Gmail. Bigtable is designed to handle massive workloads at consistent low latency and high throughput, so it\u2019s a great choice for both operational and analytical applications, including IoT, user analytics, and financial data analysis. \u2014 Google Cloud Bigtable Homepage Bigtable Setup Bigtable implements the HBase interface for all data access operations, and requires a few configuration options to connect. Connecting to Bigtable Configuring JanusGraph to connect to Bigtable is achieved by using the hbase backend, along with a custom connection implementation, the project id of the Google Cloud Platform project containing the Bigtable instance, and the Cloud Bigtable instance id you are connecting to. Example: storage.backend=hbase storage.hbase.ext.hbase.client.connection.impl=com.google.cloud.bigtable.hbase1_x.BigtableConnection storage.hbase.ext.google.bigtable.project.id=<Google Cloud Platform project id> storage.hbase.ext.google.bigtable.instance.id=<Bigtable instance id>","title":"Google Cloud Bigtable"},{"location":"storage-backend/bigtable/#google-cloud-bigtable","text":"Cloud Bigtable is Google\u2019s NoSQL Big Data database service. It\u2019s the same database that powers many core Google services, including Search, Analytics, Maps, and Gmail. Bigtable is designed to handle massive workloads at consistent low latency and high throughput, so it\u2019s a great choice for both operational and analytical applications, including IoT, user analytics, and financial data analysis. \u2014 Google Cloud Bigtable Homepage","title":"Google Cloud Bigtable"},{"location":"storage-backend/bigtable/#bigtable-setup","text":"Bigtable implements the HBase interface for all data access operations, and requires a few configuration options to connect.","title":"Bigtable Setup"},{"location":"storage-backend/bigtable/#connecting-to-bigtable","text":"Configuring JanusGraph to connect to Bigtable is achieved by using the hbase backend, along with a custom connection implementation, the project id of the Google Cloud Platform project containing the Bigtable instance, and the Cloud Bigtable instance id you are connecting to. Example: storage.backend=hbase storage.hbase.ext.hbase.client.connection.impl=com.google.cloud.bigtable.hbase1_x.BigtableConnection storage.hbase.ext.google.bigtable.project.id=<Google Cloud Platform project id> storage.hbase.ext.google.bigtable.instance.id=<Bigtable instance id>","title":"Connecting to Bigtable"},{"location":"storage-backend/cassandra/","text":"Apache Cassandra The Apache Cassandra database is the right choice when you need scalability and high availability without compromising performance. Linear scalability and proven fault-tolerance on commodity hardware or cloud infrastructure make it the perfect platform for mission-critical data. Cassandra\u2019s support for replicating across multiple datacenters is best-in-class, providing lower latency for your users and the peace of mind of knowing that you can survive regional outages. The largest known Cassandra cluster has over 300 TB of data in over 400 machines. \u2014 Apache Cassandra Homepage The following sections outline the various ways in which JanusGraph can be used in concert with Apache Cassandra. Cassandra Storage Backend JanusGraph provides the following backends for use with Cassandra: cql - CQL based driver. This is the recommended driver. cassandrathrift - JanusGraph\u2019s Thrift connection pool driver cassandra - Astyanax driver. The Astyanax project is retired . embeddedcassandra - Embedded driver for running Cassandra and JanusGraph within the same JVM Cassandra has two protocols for clients to use: CQL and Thrift. Thrift was the original interface, however it was deprecated starting with Cassandra 2.1. The core of JanusGraph was originally written before the deprecation of Thrift, and it has several classes that support Thrift. With Cassandra 4.0, Thrift support will be removed in Cassandra. JanusGraph users are recommended to use the cql storage backend. Warning Starting with JanusGraph 0.4.1, all non CQL-backends are deprecated, including cassandrathrift , cassandra and embeddedcassandra . Note If you plan to use a Thrift-based driver and you are using Cassandra 2.2 or higher, you need to explicitly enable Thrift so that JanusGraph can connect to the cluster. Do so by running ./bin/nodetool enablethrift on every Cassandra node. Note If security is enabled on Cassandra, the user must have CREATE permission on <all keyspaces> , otherwise the keyspace must be created ahead of time by an administrator including the required tables or the user must have CREATE permission on <the configured keyspace> . The create table file containing the required tables is located in conf/cassandra/cassandraTables.cql . Please define your keyspace before executing it. Local Server Mode Cassandra can be run as a standalone database on the same local host as JanusGraph and the end-user application. In this model, JanusGraph and Cassandra communicate with one another via a localhost socket. Running JanusGraph over Cassandra requires the following setup steps: Download Cassandra , unpack it, and set filesystem paths in conf/cassandra.yaml and conf/log4j-server.properties Connecting Gremlin Server to Cassandra using the default configuration files provided in the pre-packaged distribution requires that Cassandra Thrift is enabled. To enable Cassandra Thrift open conf/cassandra.yaml and update start_rpc: false to start_rpc: true . If Cassandra is already running Thrift can be started manually with bin/nodetool enablethrift . the Thrift status can be verified with bin/nodetool statusthrift. Start Cassandra by invoking bin/cassandra -f on the command line in the directory where Cassandra was unpacked. Read output to check that Cassandra started successfully. Now, you can create a Cassandra JanusGraph as follows JanusGraph g = JanusGraphFactory . build (). set ( \"storage.backend\" , \"cql\" ). set ( \"storage.hostname\" , \"127.0.0.1\" ). open (); In the Gremlin Console, you can not define the type of the variables conf and g . Therefore, simply leave off the type declaration. Local Container Mode Cassandra does not have a native install for Windows or OSX. One of the easiest ways to run Cassandra on OSX, Windows, or Linux is to use a Docker Container. You can download and run Cassandra with a single Docker command. It is important to install a version that is supported by the version of JanusGraph you intend to use. The compatible versions can be found under the Tested Compatibility section of the specific release on the Releases page . The Cassandra Docker Hub page can be referenced for the available versions and useful commands. In the command below an environment variable is being set to enable Cassandra Thrift with -e CASSANDRA_START_RPC=true . A description of the ports can be found here . Port 9160 is used for the Thrift client API. Port 9042 is for CQL native clients. Ports 7000, 7001 and 7099 are for inter-node communication. Version 3.11 of Cassandra was the latest compatible version for JanusGraph 0.2.0 and is specified in the reference command below. docker run --name jg-cassandra -d -e CASSANDRA_START_RPC = true -p 9160 :9160 \\ -p 9042 :9042 -p 7199 :7199 -p 7001 :7001 -p 7000 :7000 cassandra:3.11 Remote Server Mode When the graph needs to scale beyond the confines of a single machine, then Cassandra and JanusGraph are logically separated into different machines. In this model, the Cassandra cluster maintains the graph representation and any number of JanusGraph instances maintain socket-based read/write access to the Cassandra cluster. The end-user application can directly interact with JanusGraph within the same JVM as JanusGraph. For example, suppose we have a running Cassandra cluster where one of the machines has the IP address 77.77.77.77, then connecting JanusGraph with the cluster is accomplished as follows (comma separate IP addresses to reference more than one machine): JanusGraph graph = JanusGraphFactory . build (). set ( \"storage.backend\" , \"cql\" ). set ( \"storage.hostname\" , \"77.77.77.77\" ). open (); In the Gremlin Console, you can not define the type of the variables conf and g . Therefore, simply leave off the type declaration. Remote Server Mode with Gremlin Server Gremlin Server can be wrapped around each JanusGraph instance defined in the previous subsection. In this way, the end-user application need not be a Java-based application as it can communicate with Gremlin Server as a client. This type of deployment is great for polyglot architectures where various components written in different languages need to reference and compute on the graph. Start Gremlin Server using bin/gremlin-server.sh and then in an external Gremlin Console session using bin/gremlin.sh you can send Gremlin commands over the wire: : plugin use tinkerpop . server : remote connect tinkerpop . server conf / remote . yaml :> g . addV () In this case, each Gremlin Server would be configured to connect to the Cassandra cluster. The following shows the graph specific fragment of the Gremlin Server configuration. Refer to JanusGraph Server for a complete example and more information on how to configure the server. ... graphs : { g : conf/janusgraph-cql.properties } scriptEngines : { gremlin-groovy : { plugins : { org.janusgraph.graphdb.tinkerpop.plugin.JanusGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.server.jsr223.GremlinServerGremlinPlugin : {}, org.apache.tinkerpop.gremlin.tinkergraph.jsr223.TinkerGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.jsr223.ImportGremlinPlugin : { classImports : [ java.lang.Math ], methodImports : [ java.lang.Math#* ]}, org.apache.tinkerpop.gremlin.jsr223.ScriptFileGremlinPlugin : { files : [ scripts/empty-sample.groovy ]}}}} ... For more information about Gremlin Server see the Apache TinkerPop documentation JanusGraph Embedded Mode Finally, Cassandra can be embedded in JanusGraph, which means, that JanusGraph and Cassandra run in the same JVM and communicate via in process calls rather than over the network. This removes the (de)serialization and network protocol overhead and can therefore lead to considerable performance improvements. In this deployment mode, JanusGraph internally starts a cassandra daemon and JanusGraph no longer connects to an existing cluster but is its own cluster. To use JanusGraph in embedded mode, simply configure embeddedcassandra as the storage backend. The configuration options listed below also apply to embedded Cassandra. In creating a JanusGraph cluster, ensure that the individual nodes can discover each other via the Gossip protocol, so setup a JanusGraph-with-Cassandra-embedded cluster much like you would a stand alone Cassandra cluster. When running JanusGraph in embedded mode, the Cassandra yaml file is configured using the additional configuration option storage.conf-file , which specifies the yaml file as a full url, e.g. storage.conf-file = file:///home/cassandra.yaml . When running a cluster with JanusGraph and Cassandra embedded, it is advisable to expose JanusGraph through the Gremlin Server so that applications can remotely connect to the JanusGraph graph database and execute queries. Note, that running JanusGraph with Cassandra embedded requires GC tuning. While embedded Cassandra can provide lower latency query answering, its GC behavior under load is less predictable. Cassandra Specific Configuration Refer to Configuration Reference for a complete listing of all Cassandra specific configuration options in addition to the general JanusGraph configuration options. When configuring Cassandra it is recommended to consider the following Cassandra specific configuration options: read-consistency-level : Cassandra consistency level for read operations write-consistency-level : Cassandra consistency level for write operations replication-factor : The replication factor to use. The higher the replication factor, the more robust the graph database is to machine failure at the expense of data duplication. The default value should be overwritten for production system to ensure robustness. A value of 3 is recommended. This replication factor can only be set when the keyspace is initially created. On an existing keyspace, this value is ignored. thrift.frame_size_mb : The maximum frame size to be used by thrift for transport. Increase this value when retrieving very large result sets. Only applicable when storage.backend=cassandrathrift keyspace : The name of the keyspace to store the JanusGraph graph in. Allows multiple JanusGraph graphs to co-exist in the same Cassandra cluster. For more information on Cassandra consistency levels and acceptable values, please refer to the Cassandra Thrift API . In general, higher levels are more consistent and robust but have higher latency. Global Graph Operations JanusGraph over Cassandra supports global vertex and edge iteration. However, note that all these vertices and/or edges will be loaded into memory which can cause OutOfMemoryException . Use JanusGraph with TinkerPop\u2019s Hadoop-Gremlin to iterate over all vertices or edges in large graphs effectively. Deploying on Amazon EC2 Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides resizable compute capacity in the cloud. It is designed to make web-scale computing easier for developers. \u2014 Amazon EC2 Follow these steps to setup a Cassandra cluster on EC2 and deploy JanusGraph over Cassandra. To follow these instructions, you need an Amazon AWS account with established authentication credentials and some basic knowledge of AWS and EC2. Setup Cassandra Cluster These instructions for configuring and launching the DataStax Cassandra Community Edition AMI are based on the DataStax AMI Docs and focus on aspects relevant for a JanusGraph deployment. Setting up Security Group Navigate to the EC2 Console Dashboard, then click on \"Security Groups\" under \"Network & Security\". Create a new security group. Click Inbound. Set the \"Create a new rule\" dropdown menu to \"Custom TCP rule\". Add a rule for port 22 from source 0.0.0.0/0. Add a rule for ports 1024-65535 from the security group members. If you don\u2019t want to open all unprivileged ports among security group members, then at least open 7000, 7199, and 9160 among security group members. Tip: the \"Source\" dropdown will autocomplete security group identifiers once \"sg\" is typed in the box, so you needn\u2019t have the exact value ready beforehand. Launch DataStax Cassandra AMI \"Launch the DataStax AMI in your desired zone On the Instance Details page of the Request Instances Wizard, set \"Number of Instances\" to your desired number of Cassandra nodes. Set \"Instance Type\" to at least m1.large. We recommend m1.large. On the Advanced Instance Options page of the Request Instances Wizard, set the \"as text\" radio button under \"User Data\", then fill this into the text box: --clustername [cassandra-cluster-name] --totalnodes [number-of-instances] --version community --opscenter no [number-of-instances] in this configuration must match the number of EC2 instances configured on the previous wizard page. [cassandra-cluster-name] can be any string used for identification. For example: --clustername janusgraph --totalnodes 4 --version community --opscenter no On the Tags page of the Request Instances Wizard you can apply any desired configurations. These tags exist only at the EC2 administrative level and have no effect on the Cassandra daemons' configuration or operation. On the Create Key Pair page of the Request Instances Wizard, either select an existing key pair or create a new one. The PEM file containing the private half of the selected key pair will be required to connect to these instances. On the Configure Firewall page of the Request Instances Wizard, select the security group created earlier. Review and launch instances on the final wizard page. Verify Successful Instance Launch SSH into any Cassandra instance node: ssh -i [your-private-key].pem ubuntu@[public-dns-name-of-any-cassandra-instance] Run the Cassandra nodetool nodetool -h 127.0.0.1 ring to inspect the state of the Cassandra token ring. You should see as many nodes in this command\u2019s output as instances launched in the previous steps. Note, that the AMI takes a few minutes to configure each instance. A shell prompt will appear upon successful configuration when you SSH into the instance. Launch JanusGraph Instances Launch additional EC2 instances to run JanusGraph which are either configured in Remote Server Mode or Remote Server Mode with Gremlin-Server as described above. You only need to note the IP address of one of the Cassandra cluster instances and configure it as the host name. The particular EC2 instance to run and the particular configuration depends on your use case. Example JanusGraph Instance on Amazon Linux AMI Launch the Amazon Linux AMI in the same zone of the Cassandra cluster. Choose your desired EC2 instance type depending on the amount of resources you need. Use the default configuration options and select the same Key Pair and Security Group as for the Cassandra cluster configured in the previous step. SSH into the newly created instance via ssh -i [your-private-key].pem ec2-user@[public-dns-name-of-the-instance] . You may have to wait a little for the instance to launch. Download the current JanusGraph distribution with wget and unpack the archive locally to the home directory. Start the Gremlin Console to verify that JanusGraph runs successfully. For more information on how to unpack JanusGraph and start the Gremlin Console, please refer to the Getting Started guide Create a configuration file with vi janusgraph.properties and add the following lines:: storage.backend = cql storage.hostname = [IP-address-of-one-Cassandra-EC2-instance] You may add additional configuration options found on this page or in Configuration Reference . Start the Gremlin Console again and type the following:: gremlin > graph = JanusGraphFactory . open ( 'janusgraph.properties' ) ==> janusgraph [ cql: [ IP - address - of - one - Cassandra - EC2 - instance ]] Note You have successfully connected this JanusGraph instance to the Cassandra cluster and can start to operate on the graph. Connect to Cassandra cluster in EC2 from outside EC2 Opening the usual Cassandra ports (9160, 7000, 7199) in the security group is not enough, because the Cassandra nodes by default broadcast their ec2-internal IPs, and not their public-facing IPs. The resulting behavior is that you can open a JanusGraph graph on the cluster by connecting to port 9160 on any Cassandra node, but all requests to that graph time out. This is because Cassandra is telling the client to connect to an unreachable IP. To fix this, set the \"broadcast-address\" property for each instance in /etc/cassandra/cassandra.yaml to its public-facing IP, and restart the instance. Do this for all nodes in the cluster. Once the cluster comes back, nodetool reports the correct public-facing IPs to which connections from the local machine are allowed. Changing the \"broadcast-address\" property allows you to connect to the cluster from outside ec2, but it might also mean that traffic originating within ec2 will have to round-trip to the internet and back before it gets to the cluster. So, this approach is only useful for development and testing.","title":"Apache Cassandra"},{"location":"storage-backend/cassandra/#apache-cassandra","text":"The Apache Cassandra database is the right choice when you need scalability and high availability without compromising performance. Linear scalability and proven fault-tolerance on commodity hardware or cloud infrastructure make it the perfect platform for mission-critical data. Cassandra\u2019s support for replicating across multiple datacenters is best-in-class, providing lower latency for your users and the peace of mind of knowing that you can survive regional outages. The largest known Cassandra cluster has over 300 TB of data in over 400 machines. \u2014 Apache Cassandra Homepage The following sections outline the various ways in which JanusGraph can be used in concert with Apache Cassandra.","title":"Apache Cassandra"},{"location":"storage-backend/cassandra/#cassandra-storage-backend","text":"JanusGraph provides the following backends for use with Cassandra: cql - CQL based driver. This is the recommended driver. cassandrathrift - JanusGraph\u2019s Thrift connection pool driver cassandra - Astyanax driver. The Astyanax project is retired . embeddedcassandra - Embedded driver for running Cassandra and JanusGraph within the same JVM Cassandra has two protocols for clients to use: CQL and Thrift. Thrift was the original interface, however it was deprecated starting with Cassandra 2.1. The core of JanusGraph was originally written before the deprecation of Thrift, and it has several classes that support Thrift. With Cassandra 4.0, Thrift support will be removed in Cassandra. JanusGraph users are recommended to use the cql storage backend. Warning Starting with JanusGraph 0.4.1, all non CQL-backends are deprecated, including cassandrathrift , cassandra and embeddedcassandra . Note If you plan to use a Thrift-based driver and you are using Cassandra 2.2 or higher, you need to explicitly enable Thrift so that JanusGraph can connect to the cluster. Do so by running ./bin/nodetool enablethrift on every Cassandra node. Note If security is enabled on Cassandra, the user must have CREATE permission on <all keyspaces> , otherwise the keyspace must be created ahead of time by an administrator including the required tables or the user must have CREATE permission on <the configured keyspace> . The create table file containing the required tables is located in conf/cassandra/cassandraTables.cql . Please define your keyspace before executing it.","title":"Cassandra Storage Backend"},{"location":"storage-backend/cassandra/#local-server-mode","text":"Cassandra can be run as a standalone database on the same local host as JanusGraph and the end-user application. In this model, JanusGraph and Cassandra communicate with one another via a localhost socket. Running JanusGraph over Cassandra requires the following setup steps: Download Cassandra , unpack it, and set filesystem paths in conf/cassandra.yaml and conf/log4j-server.properties Connecting Gremlin Server to Cassandra using the default configuration files provided in the pre-packaged distribution requires that Cassandra Thrift is enabled. To enable Cassandra Thrift open conf/cassandra.yaml and update start_rpc: false to start_rpc: true . If Cassandra is already running Thrift can be started manually with bin/nodetool enablethrift . the Thrift status can be verified with bin/nodetool statusthrift. Start Cassandra by invoking bin/cassandra -f on the command line in the directory where Cassandra was unpacked. Read output to check that Cassandra started successfully. Now, you can create a Cassandra JanusGraph as follows JanusGraph g = JanusGraphFactory . build (). set ( \"storage.backend\" , \"cql\" ). set ( \"storage.hostname\" , \"127.0.0.1\" ). open (); In the Gremlin Console, you can not define the type of the variables conf and g . Therefore, simply leave off the type declaration.","title":"Local Server Mode"},{"location":"storage-backend/cassandra/#local-container-mode","text":"Cassandra does not have a native install for Windows or OSX. One of the easiest ways to run Cassandra on OSX, Windows, or Linux is to use a Docker Container. You can download and run Cassandra with a single Docker command. It is important to install a version that is supported by the version of JanusGraph you intend to use. The compatible versions can be found under the Tested Compatibility section of the specific release on the Releases page . The Cassandra Docker Hub page can be referenced for the available versions and useful commands. In the command below an environment variable is being set to enable Cassandra Thrift with -e CASSANDRA_START_RPC=true . A description of the ports can be found here . Port 9160 is used for the Thrift client API. Port 9042 is for CQL native clients. Ports 7000, 7001 and 7099 are for inter-node communication. Version 3.11 of Cassandra was the latest compatible version for JanusGraph 0.2.0 and is specified in the reference command below. docker run --name jg-cassandra -d -e CASSANDRA_START_RPC = true -p 9160 :9160 \\ -p 9042 :9042 -p 7199 :7199 -p 7001 :7001 -p 7000 :7000 cassandra:3.11","title":"Local Container Mode"},{"location":"storage-backend/cassandra/#remote-server-mode","text":"When the graph needs to scale beyond the confines of a single machine, then Cassandra and JanusGraph are logically separated into different machines. In this model, the Cassandra cluster maintains the graph representation and any number of JanusGraph instances maintain socket-based read/write access to the Cassandra cluster. The end-user application can directly interact with JanusGraph within the same JVM as JanusGraph. For example, suppose we have a running Cassandra cluster where one of the machines has the IP address 77.77.77.77, then connecting JanusGraph with the cluster is accomplished as follows (comma separate IP addresses to reference more than one machine): JanusGraph graph = JanusGraphFactory . build (). set ( \"storage.backend\" , \"cql\" ). set ( \"storage.hostname\" , \"77.77.77.77\" ). open (); In the Gremlin Console, you can not define the type of the variables conf and g . Therefore, simply leave off the type declaration.","title":"Remote Server Mode"},{"location":"storage-backend/cassandra/#remote-server-mode-with-gremlin-server","text":"Gremlin Server can be wrapped around each JanusGraph instance defined in the previous subsection. In this way, the end-user application need not be a Java-based application as it can communicate with Gremlin Server as a client. This type of deployment is great for polyglot architectures where various components written in different languages need to reference and compute on the graph. Start Gremlin Server using bin/gremlin-server.sh and then in an external Gremlin Console session using bin/gremlin.sh you can send Gremlin commands over the wire: : plugin use tinkerpop . server : remote connect tinkerpop . server conf / remote . yaml :> g . addV () In this case, each Gremlin Server would be configured to connect to the Cassandra cluster. The following shows the graph specific fragment of the Gremlin Server configuration. Refer to JanusGraph Server for a complete example and more information on how to configure the server. ... graphs : { g : conf/janusgraph-cql.properties } scriptEngines : { gremlin-groovy : { plugins : { org.janusgraph.graphdb.tinkerpop.plugin.JanusGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.server.jsr223.GremlinServerGremlinPlugin : {}, org.apache.tinkerpop.gremlin.tinkergraph.jsr223.TinkerGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.jsr223.ImportGremlinPlugin : { classImports : [ java.lang.Math ], methodImports : [ java.lang.Math#* ]}, org.apache.tinkerpop.gremlin.jsr223.ScriptFileGremlinPlugin : { files : [ scripts/empty-sample.groovy ]}}}} ... For more information about Gremlin Server see the Apache TinkerPop documentation","title":"Remote Server Mode with Gremlin Server"},{"location":"storage-backend/cassandra/#janusgraph-embedded-mode","text":"Finally, Cassandra can be embedded in JanusGraph, which means, that JanusGraph and Cassandra run in the same JVM and communicate via in process calls rather than over the network. This removes the (de)serialization and network protocol overhead and can therefore lead to considerable performance improvements. In this deployment mode, JanusGraph internally starts a cassandra daemon and JanusGraph no longer connects to an existing cluster but is its own cluster. To use JanusGraph in embedded mode, simply configure embeddedcassandra as the storage backend. The configuration options listed below also apply to embedded Cassandra. In creating a JanusGraph cluster, ensure that the individual nodes can discover each other via the Gossip protocol, so setup a JanusGraph-with-Cassandra-embedded cluster much like you would a stand alone Cassandra cluster. When running JanusGraph in embedded mode, the Cassandra yaml file is configured using the additional configuration option storage.conf-file , which specifies the yaml file as a full url, e.g. storage.conf-file = file:///home/cassandra.yaml . When running a cluster with JanusGraph and Cassandra embedded, it is advisable to expose JanusGraph through the Gremlin Server so that applications can remotely connect to the JanusGraph graph database and execute queries. Note, that running JanusGraph with Cassandra embedded requires GC tuning. While embedded Cassandra can provide lower latency query answering, its GC behavior under load is less predictable.","title":"JanusGraph Embedded Mode"},{"location":"storage-backend/cassandra/#cassandra-specific-configuration","text":"Refer to Configuration Reference for a complete listing of all Cassandra specific configuration options in addition to the general JanusGraph configuration options. When configuring Cassandra it is recommended to consider the following Cassandra specific configuration options: read-consistency-level : Cassandra consistency level for read operations write-consistency-level : Cassandra consistency level for write operations replication-factor : The replication factor to use. The higher the replication factor, the more robust the graph database is to machine failure at the expense of data duplication. The default value should be overwritten for production system to ensure robustness. A value of 3 is recommended. This replication factor can only be set when the keyspace is initially created. On an existing keyspace, this value is ignored. thrift.frame_size_mb : The maximum frame size to be used by thrift for transport. Increase this value when retrieving very large result sets. Only applicable when storage.backend=cassandrathrift keyspace : The name of the keyspace to store the JanusGraph graph in. Allows multiple JanusGraph graphs to co-exist in the same Cassandra cluster. For more information on Cassandra consistency levels and acceptable values, please refer to the Cassandra Thrift API . In general, higher levels are more consistent and robust but have higher latency.","title":"Cassandra Specific Configuration"},{"location":"storage-backend/cassandra/#global-graph-operations","text":"JanusGraph over Cassandra supports global vertex and edge iteration. However, note that all these vertices and/or edges will be loaded into memory which can cause OutOfMemoryException . Use JanusGraph with TinkerPop\u2019s Hadoop-Gremlin to iterate over all vertices or edges in large graphs effectively.","title":"Global Graph Operations"},{"location":"storage-backend/cassandra/#deploying-on-amazon-ec2","text":"Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides resizable compute capacity in the cloud. It is designed to make web-scale computing easier for developers. \u2014 Amazon EC2 Follow these steps to setup a Cassandra cluster on EC2 and deploy JanusGraph over Cassandra. To follow these instructions, you need an Amazon AWS account with established authentication credentials and some basic knowledge of AWS and EC2.","title":"Deploying on Amazon EC2"},{"location":"storage-backend/cassandra/#setup-cassandra-cluster","text":"These instructions for configuring and launching the DataStax Cassandra Community Edition AMI are based on the DataStax AMI Docs and focus on aspects relevant for a JanusGraph deployment.","title":"Setup Cassandra Cluster"},{"location":"storage-backend/cassandra/#setting-up-security-group","text":"Navigate to the EC2 Console Dashboard, then click on \"Security Groups\" under \"Network & Security\". Create a new security group. Click Inbound. Set the \"Create a new rule\" dropdown menu to \"Custom TCP rule\". Add a rule for port 22 from source 0.0.0.0/0. Add a rule for ports 1024-65535 from the security group members. If you don\u2019t want to open all unprivileged ports among security group members, then at least open 7000, 7199, and 9160 among security group members. Tip: the \"Source\" dropdown will autocomplete security group identifiers once \"sg\" is typed in the box, so you needn\u2019t have the exact value ready beforehand.","title":"Setting up Security Group"},{"location":"storage-backend/cassandra/#launch-datastax-cassandra-ami","text":"\"Launch the DataStax AMI in your desired zone On the Instance Details page of the Request Instances Wizard, set \"Number of Instances\" to your desired number of Cassandra nodes. Set \"Instance Type\" to at least m1.large. We recommend m1.large. On the Advanced Instance Options page of the Request Instances Wizard, set the \"as text\" radio button under \"User Data\", then fill this into the text box: --clustername [cassandra-cluster-name] --totalnodes [number-of-instances] --version community --opscenter no [number-of-instances] in this configuration must match the number of EC2 instances configured on the previous wizard page. [cassandra-cluster-name] can be any string used for identification. For example: --clustername janusgraph --totalnodes 4 --version community --opscenter no On the Tags page of the Request Instances Wizard you can apply any desired configurations. These tags exist only at the EC2 administrative level and have no effect on the Cassandra daemons' configuration or operation. On the Create Key Pair page of the Request Instances Wizard, either select an existing key pair or create a new one. The PEM file containing the private half of the selected key pair will be required to connect to these instances. On the Configure Firewall page of the Request Instances Wizard, select the security group created earlier. Review and launch instances on the final wizard page.","title":"Launch DataStax Cassandra AMI"},{"location":"storage-backend/cassandra/#verify-successful-instance-launch","text":"SSH into any Cassandra instance node: ssh -i [your-private-key].pem ubuntu@[public-dns-name-of-any-cassandra-instance] Run the Cassandra nodetool nodetool -h 127.0.0.1 ring to inspect the state of the Cassandra token ring. You should see as many nodes in this command\u2019s output as instances launched in the previous steps. Note, that the AMI takes a few minutes to configure each instance. A shell prompt will appear upon successful configuration when you SSH into the instance.","title":"Verify Successful Instance Launch"},{"location":"storage-backend/cassandra/#launch-janusgraph-instances","text":"Launch additional EC2 instances to run JanusGraph which are either configured in Remote Server Mode or Remote Server Mode with Gremlin-Server as described above. You only need to note the IP address of one of the Cassandra cluster instances and configure it as the host name. The particular EC2 instance to run and the particular configuration depends on your use case.","title":"Launch JanusGraph Instances"},{"location":"storage-backend/cassandra/#example-janusgraph-instance-on-amazon-linux-ami","text":"Launch the Amazon Linux AMI in the same zone of the Cassandra cluster. Choose your desired EC2 instance type depending on the amount of resources you need. Use the default configuration options and select the same Key Pair and Security Group as for the Cassandra cluster configured in the previous step. SSH into the newly created instance via ssh -i [your-private-key].pem ec2-user@[public-dns-name-of-the-instance] . You may have to wait a little for the instance to launch. Download the current JanusGraph distribution with wget and unpack the archive locally to the home directory. Start the Gremlin Console to verify that JanusGraph runs successfully. For more information on how to unpack JanusGraph and start the Gremlin Console, please refer to the Getting Started guide Create a configuration file with vi janusgraph.properties and add the following lines:: storage.backend = cql storage.hostname = [IP-address-of-one-Cassandra-EC2-instance] You may add additional configuration options found on this page or in Configuration Reference . Start the Gremlin Console again and type the following:: gremlin > graph = JanusGraphFactory . open ( 'janusgraph.properties' ) ==> janusgraph [ cql: [ IP - address - of - one - Cassandra - EC2 - instance ]] Note You have successfully connected this JanusGraph instance to the Cassandra cluster and can start to operate on the graph.","title":"Example JanusGraph Instance on Amazon Linux AMI"},{"location":"storage-backend/cassandra/#connect-to-cassandra-cluster-in-ec2-from-outside-ec2","text":"Opening the usual Cassandra ports (9160, 7000, 7199) in the security group is not enough, because the Cassandra nodes by default broadcast their ec2-internal IPs, and not their public-facing IPs. The resulting behavior is that you can open a JanusGraph graph on the cluster by connecting to port 9160 on any Cassandra node, but all requests to that graph time out. This is because Cassandra is telling the client to connect to an unreachable IP. To fix this, set the \"broadcast-address\" property for each instance in /etc/cassandra/cassandra.yaml to its public-facing IP, and restart the instance. Do this for all nodes in the cluster. Once the cluster comes back, nodetool reports the correct public-facing IPs to which connections from the local machine are allowed. Changing the \"broadcast-address\" property allows you to connect to the cluster from outside ec2, but it might also mean that traffic originating within ec2 will have to round-trip to the internet and back before it gets to the cluster. So, this approach is only useful for development and testing.","title":"Connect to Cassandra cluster in EC2 from outside EC2"},{"location":"storage-backend/hbase/","text":"Apache HBase Apache HBase is an open-source, distributed, versioned, non-relational database modeled after Google\u2019s Bigtable: A Distributed Storage System for Structured Data by Chang et al. Just as Bigtable leverages the distributed data storage provided by the Google File System, Apache HBase provides Bigtable-like capabilities on top of Hadoop and HDFS. \u2014 Apache HBase Homepage HBase Setup The following sections outline the various ways in which JanusGraph can be used in concert with Apache HBase. Local Server Mode HBase can be run as a standalone database on the same local host as JanusGraph and the end-user application. In this model, JanusGraph and HBase communicate with one another via a localhost socket. Running JanusGraph over HBase requires the following setup steps: Download and extract a stable HBase from https://www.apache.org/dyn/closer.cgi/hbase/stable/ . Start HBase by invoking the start-hbase.sh script in the bin directory inside the extracted HBase directory. To stop HBase, use stop-hbase.sh . $ ./bin/start-hbase.sh starting master, logging to ../logs/hbase-master-machine-name.local.out Now, you can create an HBase JanusGraph as follows: JanusGraph graph = JanusGraphFactory . build () . set ( \"storage.backend\" , \"hbase\" ) . open (); Note, that you do not need to specify a hostname since a localhost connection is attempted by default. Also, in the Gremlin Console, you can not define the type of the variables conf and g . Therefore, simply leave off the type declaration. Remote Server Mode When the graph needs to scale beyond the confines of a single machine, then HBase and JanusGraph are logically separated into different machines. In this model, the HBase cluster maintains the graph representation and any number of JanusGraph instances maintain socket-based read/write access to the HBase cluster. The end-user application can directly interact with JanusGraph within the same JVM as JanusGraph. For example, suppose we have a running HBase cluster with a ZooKeeper quorum composed of three machines at IP address 77.77.77.77, 77.77.77.78, and 77.77.77.79, then connecting JanusGraph with the cluster is accomplished as follows: JanusGraph g = JanusGraphFactory . build () . set ( \"storage.backend\" , \"hbase\" ) . set ( \"storage.hostname\" , \"77.77.77.77, 77.77.77.78, 77.77.77.79\" ) . open (); storage.hostname accepts a comma separated list of IP addresses and hostname for any subset of machines in the HBase cluster JanusGraph should connect to. Also, in the Gremlin Console, you can not define the type of the variables conf and g . Therefore, simply leave off the type declaration. Remote Server Mode with Gremlin Server Finally, Gremlin Server can be wrapped around each JanusGraph instance defined in the previous subsection. In this way, the end-user application need not be a Java-based application as it can communicate with Gremlin Server as a client. This type of deployment is great for polyglot architectures where various components written in different languages need to reference and compute on the graph. 1 2 http://gremlin-server.janusgraph.machine1/mygraph/vertices/1 http://gremlin-server.janusgraph.machine2/mygraph/tp/gremlin?script=g.v(1).out('follows').out('created') In this case, each Gremlin Server would be configured to connect to the HBase cluster. The following shows the graph specific fragment of the Gremlin Server configuration. Refer to JanusGraph Server for a complete example and more information on how to configure the server. ... graphs : { g : conf/janusgraph-hbase.properties } scriptEngines : { gremlin-groovy : { plugins : { org.janusgraph.graphdb.tinkerpop.plugin.JanusGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.server.jsr223.GremlinServerGremlinPlugin : {}, org.apache.tinkerpop.gremlin.tinkergraph.jsr223.TinkerGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.jsr223.ImportGremlinPlugin : { classImports : [ java.lang.Math ], methodImports : [ java.lang.Math#* ]}, org.apache.tinkerpop.gremlin.jsr223.ScriptFileGremlinPlugin : { files : [ scripts/empty-sample.groovy ]}}}} ... HBase Specific Configuration Refer to Configuration Reference for a complete listing of all HBase specific configuration options in addition to the general JanusGraph configuration options. When configuring HBase it is recommended to consider the following HBase specific configuration options: storage.hbase.table : Name of the HBase table in which to store the JanusGraph graph. Allows multiple JanusGraph graphs to co-exist in the same HBase cluster. Please refer to the HBase configuration documentation for more HBase configuration options and their description. By prefixing the respective HBase configuration option with storage.hbase.ext in the JanusGraph configuration it will be passed on to HBase at initialization time. For example, to use the znode /hbase-secure for HBase, set the property: storage.hbase.ext.zookeeper.znode.parent=/hbase-secure . The prefix allows arbitrary HBase configuration options to be configured through JanusGraph. Important HBase backend uses millisecond for timestamps. In JanusGraph 0.2.0 and earlier, if the graph.timestamps property is not explicitly set, the default is MICRO . In this case, the graph.timestamps property must be explicitly set to MILLI . Do not set the graph.timestamps property to another value in any cases. Global Graph Operations JanusGraph over HBase supports global vertex and edge iteration. However, note that all these vertices and/or edges will be loaded into memory which can cause OutOfMemoryException . Use JanusGraph with TinkerPop\u2019s Hadoop-Gremlin to iterate over all vertices or edges in large graphs effectively. Tips and Tricks for Managing an HBase Cluster The HBase shell on the master server can be used to get an overall status check of the cluster. $HBASE_HOME /bin/hbase shell From the shell, the following commands are generally useful for understanding the status of the cluster. status 'janusgraph' status 'simple' status 'detailed' The above commands can identify if a region server has gone down. If so, it is possible to ssh into the failed region server machines and do the following: sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh stop regionserver sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh start regionserver The use of pssh can make this process easy as there is no need to log into each machine individually to run the commands. Put the IP addresses of the regionservers into a hosts.txt file and then execute the following. pssh -h host.txt sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh stop regionserver pssh -h host.txt sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh start regionserver Next, sometimes you need to restart the master server (e.g. connection refused exceptions). To do so, on the master execute the following: sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh stop master sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh start master Finally, if an HBase cluster has already been deployed and more memory is required of the master or region servers, simply edit the $HBASE_HOME/conf/hbase-env.sh files on the respective machines with requisite -Xmx -Xms parameters. Once edited, stop/start the master and/or region servers as described previous.","title":"Apache HBase"},{"location":"storage-backend/hbase/#apache-hbase","text":"Apache HBase is an open-source, distributed, versioned, non-relational database modeled after Google\u2019s Bigtable: A Distributed Storage System for Structured Data by Chang et al. Just as Bigtable leverages the distributed data storage provided by the Google File System, Apache HBase provides Bigtable-like capabilities on top of Hadoop and HDFS. \u2014 Apache HBase Homepage","title":"Apache HBase"},{"location":"storage-backend/hbase/#hbase-setup","text":"The following sections outline the various ways in which JanusGraph can be used in concert with Apache HBase.","title":"HBase Setup"},{"location":"storage-backend/hbase/#local-server-mode","text":"HBase can be run as a standalone database on the same local host as JanusGraph and the end-user application. In this model, JanusGraph and HBase communicate with one another via a localhost socket. Running JanusGraph over HBase requires the following setup steps: Download and extract a stable HBase from https://www.apache.org/dyn/closer.cgi/hbase/stable/ . Start HBase by invoking the start-hbase.sh script in the bin directory inside the extracted HBase directory. To stop HBase, use stop-hbase.sh . $ ./bin/start-hbase.sh starting master, logging to ../logs/hbase-master-machine-name.local.out Now, you can create an HBase JanusGraph as follows: JanusGraph graph = JanusGraphFactory . build () . set ( \"storage.backend\" , \"hbase\" ) . open (); Note, that you do not need to specify a hostname since a localhost connection is attempted by default. Also, in the Gremlin Console, you can not define the type of the variables conf and g . Therefore, simply leave off the type declaration.","title":"Local Server Mode"},{"location":"storage-backend/hbase/#remote-server-mode","text":"When the graph needs to scale beyond the confines of a single machine, then HBase and JanusGraph are logically separated into different machines. In this model, the HBase cluster maintains the graph representation and any number of JanusGraph instances maintain socket-based read/write access to the HBase cluster. The end-user application can directly interact with JanusGraph within the same JVM as JanusGraph. For example, suppose we have a running HBase cluster with a ZooKeeper quorum composed of three machines at IP address 77.77.77.77, 77.77.77.78, and 77.77.77.79, then connecting JanusGraph with the cluster is accomplished as follows: JanusGraph g = JanusGraphFactory . build () . set ( \"storage.backend\" , \"hbase\" ) . set ( \"storage.hostname\" , \"77.77.77.77, 77.77.77.78, 77.77.77.79\" ) . open (); storage.hostname accepts a comma separated list of IP addresses and hostname for any subset of machines in the HBase cluster JanusGraph should connect to. Also, in the Gremlin Console, you can not define the type of the variables conf and g . Therefore, simply leave off the type declaration.","title":"Remote Server Mode"},{"location":"storage-backend/hbase/#remote-server-mode-with-gremlin-server","text":"Finally, Gremlin Server can be wrapped around each JanusGraph instance defined in the previous subsection. In this way, the end-user application need not be a Java-based application as it can communicate with Gremlin Server as a client. This type of deployment is great for polyglot architectures where various components written in different languages need to reference and compute on the graph. 1 2 http://gremlin-server.janusgraph.machine1/mygraph/vertices/1 http://gremlin-server.janusgraph.machine2/mygraph/tp/gremlin?script=g.v(1).out('follows').out('created') In this case, each Gremlin Server would be configured to connect to the HBase cluster. The following shows the graph specific fragment of the Gremlin Server configuration. Refer to JanusGraph Server for a complete example and more information on how to configure the server. ... graphs : { g : conf/janusgraph-hbase.properties } scriptEngines : { gremlin-groovy : { plugins : { org.janusgraph.graphdb.tinkerpop.plugin.JanusGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.server.jsr223.GremlinServerGremlinPlugin : {}, org.apache.tinkerpop.gremlin.tinkergraph.jsr223.TinkerGraphGremlinPlugin : {}, org.apache.tinkerpop.gremlin.jsr223.ImportGremlinPlugin : { classImports : [ java.lang.Math ], methodImports : [ java.lang.Math#* ]}, org.apache.tinkerpop.gremlin.jsr223.ScriptFileGremlinPlugin : { files : [ scripts/empty-sample.groovy ]}}}} ...","title":"Remote Server Mode with Gremlin Server"},{"location":"storage-backend/hbase/#hbase-specific-configuration","text":"Refer to Configuration Reference for a complete listing of all HBase specific configuration options in addition to the general JanusGraph configuration options. When configuring HBase it is recommended to consider the following HBase specific configuration options: storage.hbase.table : Name of the HBase table in which to store the JanusGraph graph. Allows multiple JanusGraph graphs to co-exist in the same HBase cluster. Please refer to the HBase configuration documentation for more HBase configuration options and their description. By prefixing the respective HBase configuration option with storage.hbase.ext in the JanusGraph configuration it will be passed on to HBase at initialization time. For example, to use the znode /hbase-secure for HBase, set the property: storage.hbase.ext.zookeeper.znode.parent=/hbase-secure . The prefix allows arbitrary HBase configuration options to be configured through JanusGraph. Important HBase backend uses millisecond for timestamps. In JanusGraph 0.2.0 and earlier, if the graph.timestamps property is not explicitly set, the default is MICRO . In this case, the graph.timestamps property must be explicitly set to MILLI . Do not set the graph.timestamps property to another value in any cases.","title":"HBase Specific Configuration"},{"location":"storage-backend/hbase/#global-graph-operations","text":"JanusGraph over HBase supports global vertex and edge iteration. However, note that all these vertices and/or edges will be loaded into memory which can cause OutOfMemoryException . Use JanusGraph with TinkerPop\u2019s Hadoop-Gremlin to iterate over all vertices or edges in large graphs effectively.","title":"Global Graph Operations"},{"location":"storage-backend/hbase/#tips-and-tricks-for-managing-an-hbase-cluster","text":"The HBase shell on the master server can be used to get an overall status check of the cluster. $HBASE_HOME /bin/hbase shell From the shell, the following commands are generally useful for understanding the status of the cluster. status 'janusgraph' status 'simple' status 'detailed' The above commands can identify if a region server has gone down. If so, it is possible to ssh into the failed region server machines and do the following: sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh stop regionserver sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh start regionserver The use of pssh can make this process easy as there is no need to log into each machine individually to run the commands. Put the IP addresses of the regionservers into a hosts.txt file and then execute the following. pssh -h host.txt sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh stop regionserver pssh -h host.txt sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh start regionserver Next, sometimes you need to restart the master server (e.g. connection refused exceptions). To do so, on the master execute the following: sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh stop master sudo -u hadoop $HBASE_HOME /bin/hbase-daemon.sh start master Finally, if an HBase cluster has already been deployed and more memory is required of the master or region servers, simply edit the $HBASE_HOME/conf/hbase-env.sh files on the respective machines with requisite -Xmx -Xms parameters. Once edited, stop/start the master and/or region servers as described previous.","title":"Tips and Tricks for Managing an HBase Cluster"},{"location":"storage-backend/inmemorybackend/","text":"InMemory Storage Backend JanusGraph ships with an in-memory storage backend which can be used through the following configuration: storage.backend=inmemory Alternatively, an in-memory JanusGraph graph can be opened directly in the Gremlin Console: graph = JanusGraphFactory . build (). set ( ' storage . backend ' , ' inmemory ' ). open () There are no additional configuration options for the in-memory storage backend. As the name suggests, this backend holds all data in memory. Shutting down the graph or terminating the process that hosts the JanusGraph graph will irrevocably delete all data from the graph. This backend is local to a particular JanusGraph graph instance and cannot be shared across multiple JanusGraph graphs. Ideal Use Case The in-memory storage backend was primarily developed to simplify testing (for those tests that do not require persistence) and graph exploration. The in-memory storage backend is NOT meant for production use, large graphs, or high performance use cases. The in-memory storage backend is not performance or memory optimized. All data is stored in the heap space allocated to the Java virtual machine.","title":"InMemory Storage Backend"},{"location":"storage-backend/inmemorybackend/#inmemory-storage-backend","text":"JanusGraph ships with an in-memory storage backend which can be used through the following configuration: storage.backend=inmemory Alternatively, an in-memory JanusGraph graph can be opened directly in the Gremlin Console: graph = JanusGraphFactory . build (). set ( ' storage . backend ' , ' inmemory ' ). open () There are no additional configuration options for the in-memory storage backend. As the name suggests, this backend holds all data in memory. Shutting down the graph or terminating the process that hosts the JanusGraph graph will irrevocably delete all data from the graph. This backend is local to a particular JanusGraph graph instance and cannot be shared across multiple JanusGraph graphs.","title":"InMemory Storage Backend"},{"location":"storage-backend/inmemorybackend/#ideal-use-case","text":"The in-memory storage backend was primarily developed to simplify testing (for those tests that do not require persistence) and graph exploration. The in-memory storage backend is NOT meant for production use, large graphs, or high performance use cases. The in-memory storage backend is not performance or memory optimized. All data is stored in the heap space allocated to the Java virtual machine.","title":"Ideal Use Case"}]}